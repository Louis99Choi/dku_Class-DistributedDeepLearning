digraph {
	graph [size="904.8,904.8"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140360636698128 [label="
 (1, 9, 64, 64)" fillcolor=darkolivegreen1]
	140360637349792 [label=ConvolutionBackward0]
	140360637339904 -> 140360637349792
	140360637339904 [label=ReluBackward0]
	140360637348880 -> 140360637339904
	140360637348880 [label=NativeBatchNormBackward0]
	140360637345712 -> 140360637348880
	140360637345712 [label=ConvolutionBackward0]
	140360637347824 -> 140360637345712
	140360637347824 [label=CatBackward0]
	140360637348208 -> 140360637347824
	140360637348208 [label=ReluBackward0]
	140360637348256 -> 140360637348208
	140360637348256 [label=AddBackward0]
	140360637349456 -> 140360637348256
	140360637349456 [label=AddBackward0]
	140360637346720 -> 140360637349456
	140360637346720 [label=AddBackward0]
	140360637347200 -> 140360637346720
	140360637347200 [label=ReluBackward0]
	140360637346912 -> 140360637347200
	140360637346912 [label=AddBackward0]
	140360637346864 -> 140360637346912
	140360637346864 [label=NativeBatchNormBackward0]
	140360637345760 -> 140360637346864
	140360637345760 [label=ConvolutionBackward0]
	140360637346096 -> 140360637345760
	140360637346096 [label=ReluBackward0]
	140360637345856 -> 140360637346096
	140360637345856 [label=NativeBatchNormBackward0]
	140360637345280 -> 140360637345856
	140360637345280 [label=ConvolutionBackward0]
	140360637346768 -> 140360637345280
	140360637346768 [label=ReluBackward0]
	140360637345136 -> 140360637346768
	140360637345136 [label=AddBackward0]
	140360637345040 -> 140360637345136
	140360637345040 [label=NativeBatchNormBackward0]
	140360637344896 -> 140360637345040
	140360637344896 [label=ConvolutionBackward0]
	140360637344368 -> 140360637344896
	140360637344368 [label=ReluBackward0]
	140360637344560 -> 140360637344368
	140360637344560 [label=NativeBatchNormBackward0]
	140360637344464 -> 140360637344560
	140360637344464 [label=ConvolutionBackward0]
	140360637345088 -> 140360637344464
	140360637345088 [label=ReluBackward0]
	140360637344128 -> 140360637345088
	140360637344128 [label=AddBackward0]
	140360637343600 -> 140360637344128
	140360637343600 [label=NativeBatchNormBackward0]
	140360637343744 -> 140360637343600
	140360637343744 [label=ConvolutionBackward0]
	140360637343552 -> 140360637343744
	140360637343552 [label=ReluBackward0]
	140360637343408 -> 140360637343552
	140360637343408 [label=NativeBatchNormBackward0]
	140360637342976 -> 140360637343408
	140360637342976 [label=ConvolutionBackward0]
	140360637343024 -> 140360637342976
	140360637343024 [label=ReluBackward0]
	140360637342496 -> 140360637343024
	140360637342496 [label=AddBackward0]
	140360637342880 -> 140360637342496
	140360637342880 [label=NativeBatchNormBackward0]
	140360637342736 -> 140360637342880
	140360637342736 [label=ConvolutionBackward0]
	140360637342400 -> 140360637342736
	140360637342400 [label=ReluBackward0]
	140360637342256 -> 140360637342400
	140360637342256 [label=NativeBatchNormBackward0]
	140360637342160 -> 140360637342256
	140360637342160 [label=ConvolutionBackward0]
	140360637342928 -> 140360637342160
	140360637342928 [label=ReluBackward0]
	140360637341872 -> 140360637342928
	140360637341872 [label=AddBackward0]
	140360637341776 -> 140360637341872
	140360637341776 [label=AddBackward0]
	140360637341584 -> 140360637341776
	140360637341584 [label=AddBackward0]
	140360637341440 -> 140360637341584
	140360637341440 [label=ReluBackward0]
	140360637340912 -> 140360637341440
	140360637340912 [label=AddBackward0]
	140360637341104 -> 140360637340912
	140360637341104 [label=NativeBatchNormBackward0]
	140360637340960 -> 140360637341104
	140360637340960 [label=ConvolutionBackward0]
	140360637340768 -> 140360637340960
	140360637340768 [label=ReluBackward0]
	140360637340288 -> 140360637340768
	140360637340288 [label=NativeBatchNormBackward0]
	140360637340528 -> 140360637340288
	140360637340528 [label=ConvolutionBackward0]
	140360637341152 -> 140360637340528
	140360637341152 [label=ReluBackward0]
	140360637340192 -> 140360637341152
	140360637340192 [label=AddBackward0]
	140360637340096 -> 140360637340192
	140360637340096 [label=NativeBatchNormBackward0]
	140360637333808 -> 140360637340096
	140360637333808 [label=ConvolutionBackward0]
	140360637339232 -> 140360637333808
	140360637339232 [label=ReluBackward0]
	140360637338896 -> 140360637339232
	140360637338896 [label=NativeBatchNormBackward0]
	140360637338656 -> 140360637338896
	140360637338656 [label=ConvolutionBackward0]
	140360637340144 -> 140360637338656
	140360637340144 [label=ReluBackward0]
	140360637338128 -> 140360637340144
	140360637338128 [label=AddBackward0]
	140360637337888 -> 140360637338128
	140360637337888 [label=NativeBatchNormBackward0]
	140360637337744 -> 140360637337888
	140360637337744 [label=ConvolutionBackward0]
	140360637337408 -> 140360637337744
	140360637337408 [label=ReluBackward0]
	140360637336976 -> 140360637337408
	140360637336976 [label=NativeBatchNormBackward0]
	140360637336736 -> 140360637336976
	140360637336736 [label=ConvolutionBackward0]
	140360637338080 -> 140360637336736
	140360637338080 [label=ReluBackward0]
	140360637336304 -> 140360637338080
	140360637336304 [label=AddBackward0]
	140360637336064 -> 140360637336304
	140360637336064 [label=NativeBatchNormBackward0]
	140360637335920 -> 140360637336064
	140360637335920 [label=ConvolutionBackward0]
	140360637335392 -> 140360637335920
	140360637335392 [label=ReluBackward0]
	140360637335152 -> 140360637335392
	140360637335152 [label=NativeBatchNormBackward0]
	140360637334816 -> 140360637335152
	140360637334816 [label=ConvolutionBackward0]
	140360637336256 -> 140360637334816
	140360637336256 [label=ReluBackward0]
	140360637334384 -> 140360637336256
	140360637334384 [label=AddBackward0]
	140360637334192 -> 140360637334384
	140360637334192 [label=AddBackward0]
	140360637333952 -> 140360637334192
	140360637333952 [label=AddBackward0]
	140360637333904 -> 140360637333952
	140360637333904 [label=ReluBackward0]
	140360636677664 -> 140360637333904
	140360636677664 [label=AddBackward0]
	140360636677856 -> 140360636677664
	140360636677856 [label=NativeBatchNormBackward0]
	140360636677712 -> 140360636677856
	140360636677712 [label=ConvolutionBackward0]
	140360636677520 -> 140360636677712
	140360636677520 [label=ReluBackward0]
	140360636677040 -> 140360636677520
	140360636677040 [label=NativeBatchNormBackward0]
	140360636677280 -> 140360636677040
	140360636677280 [label=ConvolutionBackward0]
	140360636677904 -> 140360636677280
	140360636677904 [label=ReluBackward0]
	140360636676944 -> 140360636677904
	140360636676944 [label=AddBackward0]
	140360636676848 -> 140360636676944
	140360636676848 [label=NativeBatchNormBackward0]
	140360636676560 -> 140360636676848
	140360636676560 [label=ConvolutionBackward0]
	140360636676368 -> 140360636676560
	140360636676368 [label=ReluBackward0]
	140360636676224 -> 140360636676368
	140360636676224 [label=NativeBatchNormBackward0]
	140360636676128 -> 140360636676224
	140360636676128 [label=ConvolutionBackward0]
	140360636676896 -> 140360636676128
	140360636676896 [label=ReluBackward0]
	140360636675840 -> 140360636676896
	140360636675840 [label=AddBackward0]
	140360636675264 -> 140360636675840
	140360636675264 [label=NativeBatchNormBackward0]
	140360636675552 -> 140360636675264
	140360636675552 [label=ConvolutionBackward0]
	140360636674976 -> 140360636675552
	140360636674976 [label=ReluBackward0]
	140360636675120 -> 140360636674976
	140360636675120 [label=NativeBatchNormBackward0]
	140360636675024 -> 140360636675120
	140360636675024 [label=ConvolutionBackward0]
	140360636675792 -> 140360636675024
	140360636675792 [label=ReluBackward0]
	140360636674736 -> 140360636675792
	140360636674736 [label=AddBackward0]
	140360636674640 -> 140360636674736
	140360636674640 [label=NativeBatchNormBackward0]
	140360636674496 -> 140360636674640
	140360636674496 [label=ConvolutionBackward0]
	140360636674256 -> 140360636674496
	140360636674256 [label=ReluBackward0]
	140360636674112 -> 140360636674256
	140360636674112 [label=NativeBatchNormBackward0]
	140360636673584 -> 140360636674112
	140360636673584 [label=ConvolutionBackward0]
	140360636674352 -> 140360636673584
	140360636674352 [label=ReluBackward0]
	140360636673296 -> 140360636674352
	140360636673296 [label=AddBackward0]
	140360636673488 -> 140360636673296
	140360636673488 [label=AddBackward0]
	140360636673344 -> 140360636673488
	140360636673344 [label=ReluBackward0]
	140360636673200 -> 140360636673344
	140360636673200 [label=AddBackward0]
	140360636673104 -> 140360636673200
	140360636673104 [label=NativeBatchNormBackward0]
	140360636672912 -> 140360636673104
	140360636672912 [label=ConvolutionBackward0]
	140360636672720 -> 140360636672912
	140360636672720 [label=ReluBackward0]
	140360636670080 -> 140360636672720
	140360636670080 [label=NativeBatchNormBackward0]
	140360636671952 -> 140360636670080
	140360636671952 [label=ConvolutionBackward0]
	140360636673152 -> 140360636671952
	140360636673152 [label=ReluBackward0]
	140360636671424 -> 140360636673152
	140360636671424 [label=AddBackward0]
	140360636671328 -> 140360636671424
	140360636671328 [label=NativeBatchNormBackward0]
	140360636670128 -> 140360636671328
	140360636670128 [label=ConvolutionBackward0]
	140360636670608 -> 140360636670128
	140360636670608 [label=ReluBackward0]
	140360636670320 -> 140360636670608
	140360636670320 [label=NativeBatchNormBackward0]
	140360636670224 -> 140360636670320
	140360636670224 [label=ConvolutionBackward0]
	140360636671376 -> 140360636670224
	140360636671376 [label=ReluBackward0]
	140360636669552 -> 140360636671376
	140360636669552 [label=AddBackward0]
	140360636669504 -> 140360636669552
	140360636669504 [label=NativeBatchNormBackward0]
	140360636668832 -> 140360636669504
	140360636668832 [label=ConvolutionBackward0]
	140360636668928 -> 140360636668832
	140360636668928 [label=ReluBackward0]
	140360636667536 -> 140360636668928
	140360636667536 [label=NativeBatchNormBackward0]
	140360636668352 -> 140360636667536
	140360636668352 [label=ConvolutionBackward0]
	140360636669408 -> 140360636668352
	140360636669408 [label=ReluBackward0]
	140360636667920 -> 140360636669408
	140360636667920 [label=AddBackward0]
	140360636667488 -> 140360636667920
	140360636667488 [label=NativeBatchNormBackward0]
	140360636667248 -> 140360636667488
	140360636667248 [label=ConvolutionBackward0]
	140360636667008 -> 140360636667248
	140360636667008 [label=ReluBackward0]
	140360636666192 -> 140360636667008
	140360636666192 [label=NativeBatchNormBackward0]
	140360636666384 -> 140360636666192
	140360636666384 [label=ConvolutionBackward0]
	140360636666960 -> 140360636666384
	140360636666960 [label=ReluBackward0]
	140360636666096 -> 140360636666960
	140360636666096 [label=AddBackward0]
	140360636666000 -> 140360636666096
	140360636666000 [label=AddBackward0]
	140360636665856 -> 140360636666000
	140360636665856 [label=ReluBackward0]
	140360636665712 -> 140360636665856
	140360636665712 [label=AddBackward0]
	140360636665136 -> 140360636665712
	140360636665136 [label=NativeBatchNormBackward0]
	140360636665424 -> 140360636665136
	140360636665424 [label=ConvolutionBackward0]
	140360636665088 -> 140360636665424
	140360636665088 [label=ReluBackward0]
	140360636664944 -> 140360636665088
	140360636664944 [label=NativeBatchNormBackward0]
	140360636664560 -> 140360636664944
	140360636664560 [label=ConvolutionBackward0]
	140360636665664 -> 140360636664560
	140360636665664 [label=ReluBackward0]
	140360636664224 -> 140360636665664
	140360636664224 [label=AddBackward0]
	140360636664464 -> 140360636664224
	140360636664464 [label=NativeBatchNormBackward0]
	140360636664320 -> 140360636664464
	140360636664320 [label=ConvolutionBackward0]
	140360636664080 -> 140360636664320
	140360636664080 [label=ReluBackward0]
	140360636662880 -> 140360636664080
	140360636662880 [label=NativeBatchNormBackward0]
	140360636663696 -> 140360636662880
	140360636663696 [label=ConvolutionBackward0]
	140360636664512 -> 140360636663696
	140360636664512 [label=ReluBackward0]
	140360636663408 -> 140360636664512
	140360636663408 [label=AddBackward0]
	140360636663312 -> 140360636663408
	140360636663312 [label=NativeBatchNormBackward0]
	140360636662832 -> 140360636663312
	140360636662832 [label=ConvolutionBackward0]
	140360636662976 -> 140360636662832
	140360636662976 [label=ReluBackward0]
	140360636662784 -> 140360636662976
	140360636662784 [label=NativeBatchNormBackward0]
	140360636662688 -> 140360636662784
	140360636662688 [label=ConvolutionBackward0]
	140360636663360 -> 140360636662688
	140360636663360 [label=ReluBackward0]
	140360636662208 -> 140360636663360
	140360636662208 [label=AddBackward0]
	140360636662112 -> 140360636662208
	140360636662112 [label=NativeBatchNormBackward0]
	140360636661920 -> 140360636662112
	140360636661920 [label=ConvolutionBackward0]
	140360651468624 -> 140360636661920
	140360651468624 [label=ReluBackward0]
	140360859460336 -> 140360651468624
	140360859460336 [label=NativeBatchNormBackward0]
	140360638168416 -> 140360859460336
	140360638168416 [label=ConvolutionBackward0]
	140360636662160 -> 140360638168416
	140360636662160 [label=ReluBackward0]
	140360638168896 -> 140360636662160
	140360638168896 [label=AddBackward0]
	140360638168800 -> 140360638168896
	140360638168800 [label=AddBackward0]
	140360638168608 -> 140360638168800
	140360638168608 [label=ReluBackward0]
	140360638168464 -> 140360638168608
	140360638168464 [label=AddBackward0]
	140360638167744 -> 140360638168464
	140360638167744 [label=NativeBatchNormBackward0]
	140360638167792 -> 140360638167744
	140360638167792 [label=ConvolutionBackward0]
	140360638164768 -> 140360638167792
	140360638164768 [label=ReluBackward0]
	140360638166928 -> 140360638164768
	140360638166928 [label=NativeBatchNormBackward0]
	140360638166256 -> 140360638166928
	140360638166256 [label=ConvolutionBackward0]
	140360638167456 -> 140360638166256
	140360638167456 [label=ReluBackward0]
	140360638166304 -> 140360638167456
	140360638166304 [label=AddBackward0]
	140360638165440 -> 140360638166304
	140360638165440 [label=NativeBatchNormBackward0]
	140360638165632 -> 140360638165440
	140360638165632 [label=ConvolutionBackward0]
	140360638165200 -> 140360638165632
	140360638165200 [label=ReluBackward0]
	140360638165104 -> 140360638165200
	140360638165104 [label=NativeBatchNormBackward0]
	140360638164912 -> 140360638165104
	140360638164912 [label=ConvolutionBackward0]
	140360638165920 -> 140360638164912
	140360638165920 [label=ReluBackward0]
	140360638164336 -> 140360638165920
	140360638164336 [label=AddBackward0]
	140360638164240 -> 140360638164336
	140360638164240 [label=NativeBatchNormBackward0]
	140360638163808 -> 140360638164240
	140360638163808 [label=ConvolutionBackward0]
	140360638163904 -> 140360638163808
	140360638163904 [label=ReluBackward0]
	140360638163760 -> 140360638163904
	140360638163760 [label=NativeBatchNormBackward0]
	140360638163664 -> 140360638163760
	140360638163664 [label=ConvolutionBackward0]
	140360638164288 -> 140360638163664
	140360638164288 [label=ReluBackward0]
	140360638163328 -> 140360638164288
	140360638163328 [label=AddBackward0]
	140360638163232 -> 140360638163328
	140360638163232 [label=NativeBatchNormBackward0]
	140360638162944 -> 140360638163232
	140360638162944 [label=ConvolutionBackward0]
	140360638162512 -> 140360638162944
	140360638162512 [label=ReluBackward0]
	140360638162656 -> 140360638162512
	140360638162656 [label=NativeBatchNormBackward0]
	140360638162560 -> 140360638162656
	140360638162560 [label=ConvolutionBackward0]
	140360638163280 -> 140360638162560
	140360638163280 [label=ReluBackward0]
	140360638162272 -> 140360638163280
	140360638162272 [label=AddBackward0]
	140360638162128 -> 140360638162272
	140360638162128 [label=AddBackward0]
	140360638161984 -> 140360638162128
	140360638161984 [label=ReluBackward0]
	140360638161408 -> 140360638161984
	140360638161408 [label=AddBackward0]
	140360638161600 -> 140360638161408
	140360638161600 [label=NativeBatchNormBackward0]
	140360638161456 -> 140360638161600
	140360638161456 [label=ConvolutionBackward0]
	140360638161264 -> 140360638161456
	140360638161264 [label=ReluBackward0]
	140360638160784 -> 140360638161264
	140360638160784 [label=NativeBatchNormBackward0]
	140360638161024 -> 140360638160784
	140360638161024 [label=ConvolutionBackward0]
	140360638161648 -> 140360638161024
	140360638161648 [label=ReluBackward0]
	140360638160688 -> 140360638161648
	140360638160688 [label=AddBackward0]
	140360638160592 -> 140360638160688
	140360638160592 [label=NativeBatchNormBackward0]
	140360638159920 -> 140360638160592
	140360638159920 [label=ConvolutionBackward0]
	140360638159872 -> 140360638159920
	140360638159872 [label=ReluBackward0]
	140360638159056 -> 140360638159872
	140360638159056 [label=NativeBatchNormBackward0]
	140360638159440 -> 140360638159056
	140360638159440 [label=ConvolutionBackward0]
	140360638160640 -> 140360638159440
	140360638160640 [label=ReluBackward0]
	140360638158288 -> 140360638160640
	140360638158288 [label=AddBackward0]
	140360638158672 -> 140360638158288
	140360638158672 [label=NativeBatchNormBackward0]
	140360638158432 -> 140360638158672
	140360638158432 [label=ConvolutionBackward0]
	140360638157952 -> 140360638158432
	140360638157952 [label=ReluBackward0]
	140360638157712 -> 140360638157952
	140360638157712 [label=NativeBatchNormBackward0]
	140360638153392 -> 140360638157712
	140360638153392 [label=ConvolutionBackward0]
	140360638158720 -> 140360638153392
	140360638158720 [label=ReluBackward0]
	140360638157040 -> 140360638158720
	140360638157040 [label=AddBackward0]
	140360638156896 -> 140360638157040
	140360638156896 [label=NativeBatchNormBackward0]
	140360638156752 -> 140360638156896
	140360638156752 [label=ConvolutionBackward0]
	140360638156608 -> 140360638156752
	140360638156608 [label=ReluBackward0]
	140360638156464 -> 140360638156608
	140360638156464 [label=NativeBatchNormBackward0]
	140360638156320 -> 140360638156464
	140360638156320 [label=ConvolutionBackward0]
	140360638156992 -> 140360638156320
	140360638156992 [label=ReluBackward0]
	140360638155600 -> 140360638156992
	140360638155600 [label=AddBackward0]
	140360638155792 -> 140360638155600
	140360638155792 [label=ReluBackward0]
	140360638155648 -> 140360638155792
	140360638155648 [label=AddBackward0]
	140360638155552 -> 140360638155648
	140360638155552 [label=NativeBatchNormBackward0]
	140360638155408 -> 140360638155552
	140360638155408 [label=ConvolutionBackward0]
	140360638155216 -> 140360638155408
	140360638155216 [label=ReluBackward0]
	140360638155072 -> 140360638155216
	140360638155072 [label=NativeBatchNormBackward0]
	140360638154928 -> 140360638155072
	140360638154928 [label=ConvolutionBackward0]
	140360638155312 -> 140360638154928
	140360638155312 [label=ReluBackward0]
	140360638154496 -> 140360638155312
	140360638154496 [label=AddBackward0]
	140360638154400 -> 140360638154496
	140360638154400 [label=NativeBatchNormBackward0]
	140360638154016 -> 140360638154400
	140360638154016 [label=ConvolutionBackward0]
	140360638154064 -> 140360638154016
	140360638154064 [label=ReluBackward0]
	140360638153920 -> 140360638154064
	140360638153920 [label=NativeBatchNormBackward0]
	140360638153824 -> 140360638153920
	140360638153824 [label=ConvolutionBackward0]
	140360638154448 -> 140360638153824
	140360638154448 [label=ReluBackward0]
	140360638153488 -> 140360638154448
	140360638153488 [label=AddBackward0]
	140360638152816 -> 140360638153488
	140360638152816 [label=NativeBatchNormBackward0]
	140360638152768 -> 140360638152816
	140360638152768 [label=ConvolutionBackward0]
	140360895704048 -> 140360638152768
	140360895704048 [label=ReluBackward0]
	140360642719616 -> 140360895704048
	140360642719616 [label=NativeBatchNormBackward0]
	140360638891776 -> 140360642719616
	140360638891776 [label=ConvolutionBackward0]
	140360638153440 -> 140360638891776
	140360638153440 [label=ReluBackward0]
	140360872109264 -> 140360638153440
	140360872109264 [label=AddBackward0]
	140360887245632 -> 140360872109264
	140360887245632 [label=NativeBatchNormBackward0]
	140360887356480 -> 140360887245632
	140360887356480 [label=ConvolutionBackward0]
	140360894203024 -> 140360887356480
	140360894203024 [label=ReluBackward0]
	140360675489968 -> 140360894203024
	140360675489968 [label=NativeBatchNormBackward0]
	140360680209904 -> 140360675489968
	140360680209904 [label=ConvolutionBackward0]
	140360675941520 -> 140360680209904
	140360675941520 [label=ReluBackward0]
	140360680245328 -> 140360675941520
	140360680245328 [label=NativeBatchNormBackward0]
	140360887472608 -> 140360680245328
	140360887472608 [label=ConvolutionBackward0]
	140360662245264 -> 140360887472608
	140360662245264 [label=ReluBackward0]
	140360662462048 -> 140360662245264
	140360662462048 [label=AddBackward0]
	140360662457104 -> 140360662462048
	140360662457104 [label=NativeBatchNormBackward0]
	140360663054128 -> 140360662457104
	140360663054128 [label=ConvolutionBackward0]
	140360663045680 -> 140360663054128
	140360663045680 [label=ReluBackward0]
	140360663040736 -> 140360663045680
	140360663040736 [label=NativeBatchNormBackward0]
	140360643716688 -> 140360663040736
	140360643716688 [label=ConvolutionBackward0]
	140360635180384 -> 140360643716688
	140360635180384 [label=ReluBackward0]
	140360635181872 -> 140360635180384
	140360635181872 [label=NativeBatchNormBackward0]
	140360635181200 -> 140360635181872
	140360635181200 [label=ConvolutionBackward0]
	140360662465504 -> 140360635181200
	140360662465504 [label=ReluBackward0]
	140360635184752 -> 140360662465504
	140360635184752 [label=AddBackward0]
	140360635177360 -> 140360635184752
	140360635177360 [label=NativeBatchNormBackward0]
	140360635173136 -> 140360635177360
	140360635173136 [label=ConvolutionBackward0]
	140360633712352 -> 140360635173136
	140360633712352 [label=ReluBackward0]
	140360633712592 -> 140360633712352
	140360633712592 [label=NativeBatchNormBackward0]
	140360633712400 -> 140360633712592
	140360633712400 [label=ConvolutionBackward0]
	140360633712304 -> 140360633712400
	140360633712304 [label=ReluBackward0]
	140360633712064 -> 140360633712304
	140360633712064 [label=NativeBatchNormBackward0]
	140360633711680 -> 140360633712064
	140360633711680 [label=ConvolutionBackward0]
	140360635182496 -> 140360633711680
	140360635182496 [label=ReluBackward0]
	140360633711392 -> 140360635182496
	140360633711392 [label=AddBackward0]
	140360633711584 -> 140360633711392
	140360633711584 [label=NativeBatchNormBackward0]
	140360633711440 -> 140360633711584
	140360633711440 [label=ConvolutionBackward0]
	140360633711344 -> 140360633711440
	140360633711344 [label=ReluBackward0]
	140360633711200 -> 140360633711344
	140360633711200 [label=NativeBatchNormBackward0]
	140360633711056 -> 140360633711200
	140360633711056 [label=ConvolutionBackward0]
	140360633710816 -> 140360633711056
	140360633710816 [label=ReluBackward0]
	140360633710720 -> 140360633710816
	140360633710720 [label=NativeBatchNormBackward0]
	140360633710576 -> 140360633710720
	140360633710576 [label=ConvolutionBackward0]
	140360633711248 -> 140360633710576
	140360633711248 [label=ReluBackward0]
	140360633710288 -> 140360633711248
	140360633710288 [label=AddBackward0]
	140360633709952 -> 140360633710288
	140360633709952 [label=NativeBatchNormBackward0]
	140360633709808 -> 140360633709952
	140360633709808 [label=ConvolutionBackward0]
	140360633709856 -> 140360633709808
	140360633709856 [label=ReluBackward0]
	140360633709760 -> 140360633709856
	140360633709760 [label=NativeBatchNormBackward0]
	140360633709664 -> 140360633709760
	140360633709664 [label=ConvolutionBackward0]
	140360633708896 -> 140360633709664
	140360633708896 [label=ReluBackward0]
	140360633709136 -> 140360633708896
	140360633709136 [label=NativeBatchNormBackward0]
	140360633709184 -> 140360633709136
	140360633709184 [label=ConvolutionBackward0]
	140360633708608 -> 140360633709184
	140360633708608 [label=ReluBackward0]
	140360633708464 -> 140360633708608
	140360633708464 [label=NativeBatchNormBackward0]
	140360633708848 -> 140360633708464
	140360633708848 [label=ConvolutionBackward0]
	140360633708224 -> 140360633708848
	140360633708224 [label=ReluBackward0]
	140360633708080 -> 140360633708224
	140360633708080 [label=NativeBatchNormBackward0]
	140360633708416 -> 140360633708080
	140360633708416 [label=ConvolutionBackward0]
	140360633708128 -> 140360633708416
	140360633531712 [label="conv1.weight
 (64, 3, 3, 3)" fillcolor=lightblue]
	140360633531712 -> 140360633708128
	140360633708128 [label=AccumulateGrad]
	140360633708368 -> 140360633708080
	140360633531472 [label="bn1.weight
 (64)" fillcolor=lightblue]
	140360633531472 -> 140360633708368
	140360633708368 [label=AccumulateGrad]
	140360633708512 -> 140360633708080
	140360633531792 [label="bn1.bias
 (64)" fillcolor=lightblue]
	140360633531792 -> 140360633708512
	140360633708512 [label=AccumulateGrad]
	140360633708704 -> 140360633708848
	140360633530352 [label="conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140360633530352 -> 140360633708704
	140360633708704 [label=AccumulateGrad]
	140360633708800 -> 140360633708464
	140360633530272 [label="bn2.weight
 (64)" fillcolor=lightblue]
	140360633530272 -> 140360633708800
	140360633708800 [label=AccumulateGrad]
	140360633708944 -> 140360633708464
	140360633530432 [label="bn2.bias
 (64)" fillcolor=lightblue]
	140360633530432 -> 140360633708944
	140360633708944 [label=AccumulateGrad]
	140360633709088 -> 140360633709184
	140360633528352 [label="layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	140360633528352 -> 140360633709088
	140360633709088 [label=AccumulateGrad]
	140360633709040 -> 140360633709136
	140360633527792 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	140360633527792 -> 140360633709040
	140360633709040 [label=AccumulateGrad]
	140360633709376 -> 140360633709136
	140360633528432 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	140360633528432 -> 140360633709376
	140360633709376 [label=AccumulateGrad]
	140360633709568 -> 140360633709664
	140360633526592 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140360633526592 -> 140360633709568
	140360633709568 [label=AccumulateGrad]
	140360633709472 -> 140360633709760
	140360633526432 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	140360633526432 -> 140360633709472
	140360633709472 [label=AccumulateGrad]
	140360633709904 -> 140360633709760
	140360633526752 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	140360633526752 -> 140360633709904
	140360633709904 [label=AccumulateGrad]
	140360633709712 -> 140360633709808
	140360633525232 [label="layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140360633525232 -> 140360633709712
	140360633709712 [label=AccumulateGrad]
	140360633710192 -> 140360633709952
	140360633525072 [label="layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	140360633525072 -> 140360633710192
	140360633710192 [label=AccumulateGrad]
	140360633710144 -> 140360633709952
	140360633525392 [label="layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	140360633525392 -> 140360633710144
	140360633710144 [label=AccumulateGrad]
	140360633710336 -> 140360633710288
	140360633710336 [label=NativeBatchNormBackward0]
	140360633709424 -> 140360633710336
	140360633709424 [label=ConvolutionBackward0]
	140360633708608 -> 140360633709424
	140360633709520 -> 140360633709424
	140360633523632 [label="layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140360633523632 -> 140360633709520
	140360633709520 [label=AccumulateGrad]
	140360633709616 -> 140360633710336
	140360633523312 [label="layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	140360633523312 -> 140360633709616
	140360633709616 [label=AccumulateGrad]
	140360633710000 -> 140360633710336
	140360633523712 [label="layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	140360633523712 -> 140360633710000
	140360633710000 [label=AccumulateGrad]
	140360633710480 -> 140360633710576
	140360633524032 [label="layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	140360633524032 -> 140360633710480
	140360633710480 [label=AccumulateGrad]
	140360633710240 -> 140360633710720
	140360633522032 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	140360633522032 -> 140360633710240
	140360633710240 [label=AccumulateGrad]
	140360633710864 -> 140360633710720
	140360633527952 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	140360633527952 -> 140360633710864
	140360633710864 [label=AccumulateGrad]
	140360633710528 -> 140360633711056
	140360633520672 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140360633520672 -> 140360633710528
	140360633710528 [label=AccumulateGrad]
	140360633710768 -> 140360633711200
	140360633520592 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	140360633520592 -> 140360633710768
	140360633710768 [label=AccumulateGrad]
	140360633710912 -> 140360633711200
	140360633520832 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	140360633520832 -> 140360633710912
	140360633710912 [label=AccumulateGrad]
	140360633711296 -> 140360633711440
	140360633519312 [label="layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140360633519312 -> 140360633711296
	140360633711296 [label=AccumulateGrad]
	140360633711008 -> 140360633711584
	140360633519232 [label="layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	140360633519232 -> 140360633711008
	140360633711008 [label=AccumulateGrad]
	140360633711632 -> 140360633711584
	140360633519472 [label="layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	140360633519472 -> 140360633711632
	140360633711632 [label=AccumulateGrad]
	140360633711248 -> 140360633711392
	140360633711776 -> 140360633711680
	140360633523872 [label="layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	140360633523872 -> 140360633711776
	140360633711776 [label=AccumulateGrad]
	140360633712112 -> 140360633712064
	140360633517712 [label="layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	140360633517712 -> 140360633712112
	140360633712112 [label=AccumulateGrad]
	140360633711872 -> 140360633712064
	140360633517792 [label="layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	140360633517792 -> 140360633711872
	140360633711872 [label=AccumulateGrad]
	140360633712256 -> 140360633712400
	140360633516272 [label="layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140360633516272 -> 140360633712256
	140360633712256 [label=AccumulateGrad]
	140360633712016 -> 140360633712592
	140360633516192 [label="layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	140360633516192 -> 140360633712016
	140360633712016 [label=AccumulateGrad]
	140360633712208 -> 140360633712592
	140360633516432 [label="layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	140360633516432 -> 140360633712208
	140360633712208 [label=AccumulateGrad]
	140360633712496 -> 140360635173136
	140360633528512 [label="layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140360633528512 -> 140360633712496
	140360633712496 [label=AccumulateGrad]
	140360635174000 -> 140360635177360
	140360633528272 [label="layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	140360633528272 -> 140360635174000
	140360635174000 [label=AccumulateGrad]
	140360635185040 -> 140360635177360
	140360633528752 [label="layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	140360633528752 -> 140360635185040
	140360635185040 [label=AccumulateGrad]
	140360635182496 -> 140360635184752
	140360635183024 -> 140360635181200
	140360633517952 [label="layer1.3.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	140360633517952 -> 140360635183024
	140360635183024 [label=AccumulateGrad]
	140360635183696 -> 140360635181872
	140360633523152 [label="layer1.3.bn1.weight
 (64)" fillcolor=lightblue]
	140360633523152 -> 140360635183696
	140360635183696 [label=AccumulateGrad]
	140360635180336 -> 140360635181872
	140360633523392 [label="layer1.3.bn1.bias
 (64)" fillcolor=lightblue]
	140360633523392 -> 140360635180336
	140360635180336 [label=AccumulateGrad]
	140360635180528 -> 140360643716688
	140360633519392 [label="layer1.3.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140360633519392 -> 140360635180528
	140360635180528 [label=AccumulateGrad]
	140360643710544 -> 140360663040736
	140360633518992 [label="layer1.3.bn2.weight
 (64)" fillcolor=lightblue]
	140360633518992 -> 140360643710544
	140360643710544 [label=AccumulateGrad]
	140360635185760 -> 140360663040736
	140360633519792 [label="layer1.3.bn2.bias
 (64)" fillcolor=lightblue]
	140360633519792 -> 140360635185760
	140360635185760 [label=AccumulateGrad]
	140360663041024 -> 140360663054128
	140360633466656 [label="layer1.3.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140360633466656 -> 140360663041024
	140360663041024 [label=AccumulateGrad]
	140360663042080 -> 140360662457104
	140360633466576 [label="layer1.3.bn3.weight
 (256)" fillcolor=lightblue]
	140360633466576 -> 140360663042080
	140360663042080 [label=AccumulateGrad]
	140360663044816 -> 140360662457104
	140360633466816 [label="layer1.3.bn3.bias
 (256)" fillcolor=lightblue]
	140360633466816 -> 140360663044816
	140360663044816 [label=AccumulateGrad]
	140360662465504 -> 140360662462048
	140360662239408 -> 140360887472608
	140360633465296 [label="transition1.0.0.weight
 (18, 256, 3, 3)" fillcolor=lightblue]
	140360633465296 -> 140360662239408
	140360662239408 [label=AccumulateGrad]
	140360887472512 -> 140360680245328
	140360633465056 [label="transition1.0.1.weight
 (18)" fillcolor=lightblue]
	140360633465056 -> 140360887472512
	140360887472512 [label=AccumulateGrad]
	140360887468912 -> 140360680245328
	140360633465136 [label="transition1.0.1.bias
 (18)" fillcolor=lightblue]
	140360633465136 -> 140360887468912
	140360887468912 [label=AccumulateGrad]
	140360651831040 -> 140360680209904
	140360633460896 [label="stage2.0.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360633460896 -> 140360651831040
	140360651831040 [label=AccumulateGrad]
	140360680209328 -> 140360675489968
	140360633460576 [label="stage2.0.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140360633460576 -> 140360680209328
	140360680209328 [label=AccumulateGrad]
	140360680245232 -> 140360675489968
	140360633460976 [label="stage2.0.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140360633460976 -> 140360680245232
	140360680245232 [label=AccumulateGrad]
	140360894549872 -> 140360887356480
	140360633460736 [label="stage2.0.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360633460736 -> 140360894549872
	140360894549872 [label=AccumulateGrad]
	140360887359072 -> 140360887245632
	140360633459056 [label="stage2.0.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140360633459056 -> 140360887359072
	140360887359072 [label=AccumulateGrad]
	140360675941616 -> 140360887245632
	140360633459216 [label="stage2.0.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140360633459216 -> 140360675941616
	140360675941616 [label=AccumulateGrad]
	140360675941520 -> 140360872109264
	140360887241888 -> 140360638891776
	140360633457696 [label="stage2.0.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360633457696 -> 140360887241888
	140360887241888 [label=AccumulateGrad]
	140360643584752 -> 140360642719616
	140360633457536 [label="stage2.0.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140360633457536 -> 140360643584752
	140360643584752 [label=AccumulateGrad]
	140360643590368 -> 140360642719616
	140360633457776 [label="stage2.0.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140360633457776 -> 140360643590368
	140360643590368 [label=AccumulateGrad]
	140360894301232 -> 140360638152768
	140360633459296 [label="stage2.0.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360633459296 -> 140360894301232
	140360894301232 [label=AccumulateGrad]
	140360894302288 -> 140360638152816
	140360633456016 [label="stage2.0.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140360633456016 -> 140360894302288
	140360894302288 [label=AccumulateGrad]
	140360894302720 -> 140360638152816
	140360633456176 [label="stage2.0.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140360633456176 -> 140360894302720
	140360894302720 [label=AccumulateGrad]
	140360638153440 -> 140360638153488
	140360638153584 -> 140360638153824
	140360633454736 [label="stage2.0.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360633454736 -> 140360638153584
	140360638153584 [label=AccumulateGrad]
	140360638153872 -> 140360638153920
	140360633454656 [label="stage2.0.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140360633454656 -> 140360638153872
	140360638153872 [label=AccumulateGrad]
	140360638153680 -> 140360638153920
	140360633454816 [label="stage2.0.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140360633454816 -> 140360638153680
	140360638153680 [label=AccumulateGrad]
	140360638154112 -> 140360638154016
	140360633456256 [label="stage2.0.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360633456256 -> 140360638154112
	140360638154112 [label=AccumulateGrad]
	140360638154304 -> 140360638154400
	140360633453136 [label="stage2.0.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140360633453136 -> 140360638154304
	140360638154304 [label=AccumulateGrad]
	140360638154352 -> 140360638154400
	140360633453216 [label="stage2.0.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140360633453216 -> 140360638154352
	140360638154352 [label=AccumulateGrad]
	140360638154448 -> 140360638154496
	140360638154736 -> 140360638154928
	140360633451696 [label="stage2.0.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360633451696 -> 140360638154736
	140360638154736 [label=AccumulateGrad]
	140360638153728 -> 140360638155072
	140360633451616 [label="stage2.0.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140360633451616 -> 140360638153728
	140360638153728 [label=AccumulateGrad]
	140360638155168 -> 140360638155072
	140360633451776 [label="stage2.0.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140360633451776 -> 140360638155168
	140360638155168 [label=AccumulateGrad]
	140360638155264 -> 140360638155408
	140360633453296 [label="stage2.0.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360633453296 -> 140360638155264
	140360638155264 [label=AccumulateGrad]
	140360638155456 -> 140360638155552
	140360633465616 [label="stage2.0.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140360633465616 -> 140360638155456
	140360638155456 [label=AccumulateGrad]
	140360638155504 -> 140360638155552
	140360633466016 [label="stage2.0.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140360633466016 -> 140360638155504
	140360638155504 [label=AccumulateGrad]
	140360638155312 -> 140360638155648
	140360638155840 -> 140360638155600
	140360638155840 [label=UpsampleBilinear2DBackward0]
	140360638155360 -> 140360638155840
	140360638155360 [label=NativeBatchNormBackward0]
	140360638154256 -> 140360638155360
	140360638154256 [label=ConvolutionBackward0]
	140360638154784 -> 140360638154256
	140360638154784 [label=ReluBackward0]
	140360638153536 -> 140360638154784
	140360638153536 [label=AddBackward0]
	140360638153776 -> 140360638153536
	140360638153776 [label=NativeBatchNormBackward0]
	140360894302624 -> 140360638153776
	140360894302624 [label=ConvolutionBackward0]
	140360643589792 -> 140360894302624
	140360643589792 [label=ReluBackward0]
	140360675941472 -> 140360643589792
	140360675941472 [label=NativeBatchNormBackward0]
	140360894549776 -> 140360675941472
	140360894549776 [label=ConvolutionBackward0]
	140360638154160 -> 140360894549776
	140360638154160 [label=ReluBackward0]
	140360662461952 -> 140360638154160
	140360662461952 [label=AddBackward0]
	140360680245136 -> 140360662461952
	140360680245136 [label=NativeBatchNormBackward0]
	140360663044624 -> 140360680245136
	140360663044624 [label=ConvolutionBackward0]
	140360635178320 -> 140360663044624
	140360635178320 [label=ReluBackward0]
	140360865135776 -> 140360635178320
	140360865135776 [label=NativeBatchNormBackward0]
	140360635184080 -> 140360865135776
	140360635184080 [label=ConvolutionBackward0]
	140360663043280 -> 140360635184080
	140360663043280 [label=ReluBackward0]
	140360633711488 -> 140360663043280
	140360633711488 [label=AddBackward0]
	140360633711968 -> 140360633711488
	140360633711968 [label=NativeBatchNormBackward0]
	140360633711104 -> 140360633711968
	140360633711104 [label=ConvolutionBackward0]
	140360633710624 -> 140360633711104
	140360633710624 [label=ReluBackward0]
	140360633710096 -> 140360633710624
	140360633710096 [label=NativeBatchNormBackward0]
	140360633708560 -> 140360633710096
	140360633708560 [label=ConvolutionBackward0]
	140360633711536 -> 140360633708560
	140360633711536 [label=ReluBackward0]
	140360633708656 -> 140360633711536
	140360633708656 [label=AddBackward0]
	140360633708272 -> 140360633708656
	140360633708272 [label=NativeBatchNormBackward0]
	140360633708032 -> 140360633708272
	140360633708032 [label=ConvolutionBackward0]
	140360633707504 -> 140360633708032
	140360633707504 [label=ReluBackward0]
	140360633707360 -> 140360633707504
	140360633707360 [label=NativeBatchNormBackward0]
	140360633707552 -> 140360633707360
	140360633707552 [label=ConvolutionBackward0]
	140360633707984 -> 140360633707552
	140360633707984 [label=ReluBackward0]
	140360633707264 -> 140360633707984
	140360633707264 [label=NativeBatchNormBackward0]
	140360633706832 -> 140360633707264
	140360633706832 [label=ConvolutionBackward0]
	140360662245264 -> 140360633706832
	140360633707072 -> 140360633706832
	140360633463376 [label="transition1.1.0.0.weight
 (36, 256, 3, 3)" fillcolor=lightblue]
	140360633463376 -> 140360633707072
	140360633707072 [label=AccumulateGrad]
	140360633707312 -> 140360633707264
	140360633463136 [label="transition1.1.0.1.weight
 (36)" fillcolor=lightblue]
	140360633463136 -> 140360633707312
	140360633707312 [label=AccumulateGrad]
	140360633706976 -> 140360633707264
	140360633463536 [label="transition1.1.0.1.bias
 (36)" fillcolor=lightblue]
	140360633463536 -> 140360633706976
	140360633706976 [label=AccumulateGrad]
	140360633707456 -> 140360633707552
	140360633462176 [label="stage2.0.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360633462176 -> 140360633707456
	140360633707456 [label=AccumulateGrad]
	140360633707216 -> 140360633707360
	140360633461936 [label="stage2.0.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140360633461936 -> 140360633707216
	140360633707216 [label=AccumulateGrad]
	140360633707744 -> 140360633707360
	140360633462576 [label="stage2.0.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140360633462576 -> 140360633707744
	140360633707744 [label=AccumulateGrad]
	140360633707936 -> 140360633708032
	140360633466256 [label="stage2.0.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360633466256 -> 140360633707936
	140360633707936 [label=AccumulateGrad]
	140360633708176 -> 140360633708272
	140360633458416 [label="stage2.0.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140360633458416 -> 140360633708176
	140360633708176 [label=AccumulateGrad]
	140360633707840 -> 140360633708272
	140360633458656 [label="stage2.0.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140360633458656 -> 140360633707840
	140360633707840 [label=AccumulateGrad]
	140360633707984 -> 140360633708656
	140360633708320 -> 140360633708560
	140360633454976 [label="stage2.0.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360633454976 -> 140360633708320
	140360633708320 [label=AccumulateGrad]
	140360633709280 -> 140360633710096
	140360633454576 [label="stage2.0.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140360633454576 -> 140360633709280
	140360633709280 [label=AccumulateGrad]
	140360633710048 -> 140360633710096
	140360633455376 [label="stage2.0.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140360633455376 -> 140360633710048
	140360633710048 [label=AccumulateGrad]
	140360633710960 -> 140360633711104
	140360633458896 [label="stage2.0.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360633458896 -> 140360633710960
	140360633710960 [label=AccumulateGrad]
	140360633710384 -> 140360633711968
	140360633451056 [label="stage2.0.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140360633451056 -> 140360633710384
	140360633710384 [label=AccumulateGrad]
	140360633711152 -> 140360633711968
	140360633451296 [label="stage2.0.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140360633451296 -> 140360633711152
	140360633711152 [label=AccumulateGrad]
	140360633711536 -> 140360633711488
	140360633712160 -> 140360635184080
	140360633400240 [label="stage2.0.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360633400240 -> 140360633712160
	140360633712160 [label=AccumulateGrad]
	140360633711728 -> 140360865135776
	140360633400160 [label="stage2.0.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140360633400160 -> 140360633711728
	140360633711728 [label=AccumulateGrad]
	140360633712544 -> 140360865135776
	140360633400400 [label="stage2.0.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140360633400400 -> 140360633712544
	140360633712544 [label=AccumulateGrad]
	140360635174960 -> 140360663044624
	140360633398880 [label="stage2.0.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360633398880 -> 140360635174960
	140360635174960 [label=AccumulateGrad]
	140360663040880 -> 140360680245136
	140360633398640 [label="stage2.0.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140360633398640 -> 140360663040880
	140360663040880 [label=AccumulateGrad]
	140360635178512 -> 140360680245136
	140360633398720 [label="stage2.0.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140360633398720 -> 140360635178512
	140360635178512 [label=AccumulateGrad]
	140360663043280 -> 140360662461952
	140360887472320 -> 140360894549776
	140360633397200 [label="stage2.0.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360633397200 -> 140360887472320
	140360887472320 [label=AccumulateGrad]
	140360894550160 -> 140360675941472
	140360633397120 [label="stage2.0.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140360633397120 -> 140360894550160
	140360894550160 [label=AccumulateGrad]
	140360887241792 -> 140360675941472
	140360633397360 [label="stage2.0.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140360633397360 -> 140360887241792
	140360887241792 [label=AccumulateGrad]
	140360887241984 -> 140360894302624
	140360633395840 [label="stage2.0.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360633395840 -> 140360887241984
	140360887241984 [label=AccumulateGrad]
	140360638153632 -> 140360638153776
	140360633395600 [label="stage2.0.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140360633395600 -> 140360638153632
	140360638153632 [label=AccumulateGrad]
	140360638153344 -> 140360638153776
	140360633395680 [label="stage2.0.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140360633395680 -> 140360638153344
	140360638153344 [label=AccumulateGrad]
	140360638154160 -> 140360638153536
	140360638154208 -> 140360638154256
	140360633394160 [label="stage2.0.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140360633394160 -> 140360638154208
	140360638154208 [label=AccumulateGrad]
	140360638155120 -> 140360638155360
	140360633394080 [label="stage2.0.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140360633394080 -> 140360638155120
	140360638155120 [label=AccumulateGrad]
	140360638155696 -> 140360638155360
	140360633394320 [label="stage2.0.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140360633394320 -> 140360638155696
	140360638155696 [label=AccumulateGrad]
	140360638156128 -> 140360638156320
	140360633389600 [label="stage3.0.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360633389600 -> 140360638156128
	140360638156128 [label=AccumulateGrad]
	140360638155888 -> 140360638156464
	140360633389280 [label="stage3.0.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140360633389280 -> 140360638155888
	140360638155888 [label=AccumulateGrad]
	140360638156560 -> 140360638156464
	140360633389760 [label="stage3.0.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140360633389760 -> 140360638156560
	140360638156560 [label=AccumulateGrad]
	140360638156656 -> 140360638156752
	140360633389520 [label="stage3.0.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360633389520 -> 140360638156656
	140360638156656 [label=AccumulateGrad]
	140360638156800 -> 140360638156896
	140360633387760 [label="stage3.0.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140360633387760 -> 140360638156800
	140360638156800 [label=AccumulateGrad]
	140360638156848 -> 140360638156896
	140360633388000 [label="stage3.0.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140360633388000 -> 140360638156848
	140360638156848 [label=AccumulateGrad]
	140360638156992 -> 140360638157040
	140360638157136 -> 140360638153392
	140360633386480 [label="stage3.0.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360633386480 -> 140360638157136
	140360638157136 [label=AccumulateGrad]
	140360638157232 -> 140360638157712
	140360633386240 [label="stage3.0.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140360633386240 -> 140360638157232
	140360638157232 [label=AccumulateGrad]
	140360638157904 -> 140360638157712
	140360633386560 [label="stage3.0.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140360633386560 -> 140360638157904
	140360638157904 [label=AccumulateGrad]
	140360638157664 -> 140360638158432
	140360633388080 [label="stage3.0.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360633388080 -> 140360638157664
	140360638157664 [label=AccumulateGrad]
	140360638158336 -> 140360638158672
	140360633400800 [label="stage3.0.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140360633400800 -> 140360638158336
	140360638158336 [label=AccumulateGrad]
	140360638158480 -> 140360638158672
	140360633401200 [label="stage3.0.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140360633401200 -> 140360638158480
	140360638158480 [label=AccumulateGrad]
	140360638158720 -> 140360638158288
	140360638159104 -> 140360638159440
	140360633397520 [label="stage3.0.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360633397520 -> 140360638159104
	140360638159104 [label=AccumulateGrad]
	140360638159488 -> 140360638159056
	140360633397280 [label="stage3.0.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140360633397280 -> 140360638159488
	140360638159488 [label=AccumulateGrad]
	140360638159824 -> 140360638159056
	140360633397760 [label="stage3.0.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140360633397760 -> 140360638159824
	140360638159824 [label=AccumulateGrad]
	140360638159776 -> 140360638159920
	140360633385040 [label="stage3.0.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360633385040 -> 140360638159776
	140360638159776 [label=AccumulateGrad]
	140360638153296 -> 140360638160592
	140360633393600 [label="stage3.0.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140360633393600 -> 140360638153296
	140360638153296 [label=AccumulateGrad]
	140360638160544 -> 140360638160592
	140360633394000 [label="stage3.0.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140360633394000 -> 140360638160544
	140360638160544 [label=AccumulateGrad]
	140360638160640 -> 140360638160688
	140360638160448 -> 140360638161024
	140360633390160 [label="stage3.0.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360633390160 -> 140360638160448
	140360638160448 [label=AccumulateGrad]
	140360638161072 -> 140360638160784
	140360633389920 [label="stage3.0.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140360633389920 -> 140360638161072
	140360638161072 [label=AccumulateGrad]
	140360638161216 -> 140360638160784
	140360633390560 [label="stage3.0.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140360633390560 -> 140360638161216
	140360638161216 [label=AccumulateGrad]
	140360638161312 -> 140360638161456
	140360633394240 [label="stage3.0.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360633394240 -> 140360638161312
	140360638161312 [label=AccumulateGrad]
	140360638161504 -> 140360638161600
	140360633386400 [label="stage3.0.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140360633386400 -> 140360638161504
	140360638161504 [label=AccumulateGrad]
	140360638161552 -> 140360638161600
	140360633386640 [label="stage3.0.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140360633386640 -> 140360638161552
	140360638161552 [label=AccumulateGrad]
	140360638161648 -> 140360638161408
	140360638162032 -> 140360638162128
	140360638162032 [label=UpsampleBilinear2DBackward0]
	140360638161120 -> 140360638162032
	140360638161120 [label=NativeBatchNormBackward0]
	140360638160736 -> 140360638161120
	140360638160736 [label=ConvolutionBackward0]
	140360638160880 -> 140360638160736
	140360638160880 [label=ReluBackward0]
	140360638158768 -> 140360638160880
	140360638158768 [label=AddBackward0]
	140360638159248 -> 140360638158768
	140360638159248 [label=NativeBatchNormBackward0]
	140360638159200 -> 140360638159248
	140360638159200 [label=ConvolutionBackward0]
	140360638156416 -> 140360638159200
	140360638156416 [label=ReluBackward0]
	140360638156944 -> 140360638156416
	140360638156944 [label=NativeBatchNormBackward0]
	140360638155024 -> 140360638156944
	140360638155024 [label=ConvolutionBackward0]
	140360638159008 -> 140360638155024
	140360638159008 [label=ReluBackward0]
	140360638154976 -> 140360638159008
	140360638154976 [label=AddBackward0]
	140360638154832 -> 140360638154976
	140360638154832 [label=NativeBatchNormBackward0]
	140360894203264 -> 140360638154832
	140360894203264 [label=ConvolutionBackward0]
	140360663053936 -> 140360894203264
	140360663053936 [label=ReluBackward0]
	140360887472704 -> 140360663053936
	140360887472704 [label=NativeBatchNormBackward0]
	140360635184416 -> 140360887472704
	140360635184416 [label=ConvolutionBackward0]
	140360638153968 -> 140360635184416
	140360638153968 [label=ReluBackward0]
	140360633707696 -> 140360638153968
	140360633707696 [label=AddBackward0]
	140360633708992 -> 140360633707696
	140360633708992 [label=NativeBatchNormBackward0]
	140360633709232 -> 140360633708992
	140360633709232 [label=ConvolutionBackward0]
	140360633707600 -> 140360633709232
	140360633707600 [label=ReluBackward0]
	140360633707168 -> 140360633707600
	140360633707168 [label=NativeBatchNormBackward0]
	140360633707024 -> 140360633707168
	140360633707024 [label=ConvolutionBackward0]
	140360633709328 -> 140360633707024
	140360633709328 [label=ReluBackward0]
	140360633706304 -> 140360633709328
	140360633706304 [label=AddBackward0]
	140360633706208 -> 140360633706304
	140360633706208 [label=NativeBatchNormBackward0]
	140360633705968 -> 140360633706208
	140360633705968 [label=ConvolutionBackward0]
	140360633706256 -> 140360633705968
	140360633706256 [label=ReluBackward0]
	140360633705728 -> 140360633706256
	140360633705728 [label=NativeBatchNormBackward0]
	140360633706064 -> 140360633705728
	140360633706064 [label=ConvolutionBackward0]
	140360633706640 -> 140360633706064
	140360633706640 [label=ReluBackward0]
	140360633705296 -> 140360633706640
	140360633705296 [label=AddBackward0]
	140360633705680 -> 140360633705296
	140360633705680 [label=NativeBatchNormBackward0]
	140360633705488 -> 140360633705680
	140360633705488 [label=ConvolutionBackward0]
	140360638155792 -> 140360633705488
	140360633705392 -> 140360633705488
	140360633392320 [label="stage2.0.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140360633392320 -> 140360633705392
	140360633705392 [label=AccumulateGrad]
	140360633705152 -> 140360633705680
	140360633391920 [label="stage2.0.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140360633391920 -> 140360633705152
	140360633705152 [label=AccumulateGrad]
	140360633705920 -> 140360633705680
	140360633392560 [label="stage2.0.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140360633392560 -> 140360633705920
	140360633705920 [label=AccumulateGrad]
	140360638154784 -> 140360633705296
	140360633705776 -> 140360633706064
	140360633318560 [label="stage3.0.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360633318560 -> 140360633705776
	140360633705776 [label=AccumulateGrad]
	140360633706016 -> 140360633705728
	140360633318400 [label="stage3.0.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140360633318400 -> 140360633706016
	140360633706016 [label=AccumulateGrad]
	140360633705872 -> 140360633705728
	140360633318640 [label="stage3.0.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140360633318640 -> 140360633705872
	140360633705872 [label=AccumulateGrad]
	140360633706112 -> 140360633705968
	140360633317120 [label="stage3.0.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360633317120 -> 140360633706112
	140360633706112 [label=AccumulateGrad]
	140360633706544 -> 140360633706208
	140360633316880 [label="stage3.0.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140360633316880 -> 140360633706544
	140360633706544 [label=AccumulateGrad]
	140360633706496 -> 140360633706208
	140360633317040 [label="stage3.0.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140360633317040 -> 140360633706496
	140360633706496 [label=AccumulateGrad]
	140360633706640 -> 140360633706304
	140360633706736 -> 140360633707024
	140360633315520 [label="stage3.0.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360633315520 -> 140360633706736
	140360633706736 [label=AccumulateGrad]
	140360633706880 -> 140360633707168
	140360633315360 [label="stage3.0.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140360633315360 -> 140360633706880
	140360633706880 [label=AccumulateGrad]
	140360633706688 -> 140360633707168
	140360633315600 [label="stage3.0.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140360633315600 -> 140360633706688
	140360633706688 [label=AccumulateGrad]
	140360633707888 -> 140360633709232
	140360633314080 [label="stage3.0.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360633314080 -> 140360633707888
	140360633707888 [label=AccumulateGrad]
	140360633708752 -> 140360633708992
	140360633313840 [label="stage3.0.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140360633313840 -> 140360633708752
	140360633708752 [label=AccumulateGrad]
	140360633707648 -> 140360633708992
	140360633314000 [label="stage3.0.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140360633314000 -> 140360633707648
	140360633707648 [label=AccumulateGrad]
	140360633709328 -> 140360633707696
	140360633712448 -> 140360635184416
	140360633312480 [label="stage3.0.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360633312480 -> 140360633712448
	140360633712448 [label=AccumulateGrad]
	140360635175104 -> 140360887472704
	140360633312320 [label="stage3.0.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140360633312320 -> 140360635175104
	140360635175104 [label=AccumulateGrad]
	140360633711920 -> 140360887472704
	140360633312560 [label="stage3.0.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140360633312560 -> 140360633711920
	140360633711920 [label=AccumulateGrad]
	140360675787536 -> 140360894203264
	140360633311040 [label="stage3.0.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360633311040 -> 140360675787536
	140360675787536 [label=AccumulateGrad]
	140360642709248 -> 140360638154832
	140360633310800 [label="stage3.0.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140360633310800 -> 140360642709248
	140360642709248 [label=AccumulateGrad]
	140360638154880 -> 140360638154832
	140360633310960 [label="stage3.0.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140360633310960 -> 140360638154880
	140360638154880 [label=AccumulateGrad]
	140360638153968 -> 140360638154976
	140360638156176 -> 140360638155024
	140360633309440 [label="stage3.0.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360633309440 -> 140360638156176
	140360638156176 [label=AccumulateGrad]
	140360638156512 -> 140360638156944
	140360633309280 [label="stage3.0.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140360633309280 -> 140360638156512
	140360638156512 [label=AccumulateGrad]
	140360638156704 -> 140360638156944
	140360633309520 [label="stage3.0.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140360633309520 -> 140360638156704
	140360638156704 [label=AccumulateGrad]
	140360638158000 -> 140360638159200
	140360633308000 [label="stage3.0.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360633308000 -> 140360638158000
	140360638158000 [label=AccumulateGrad]
	140360638159152 -> 140360638159248
	140360633307760 [label="stage3.0.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140360633307760 -> 140360638159152
	140360638159152 [label=AccumulateGrad]
	140360638158384 -> 140360638159248
	140360633307920 [label="stage3.0.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140360633307920 -> 140360638158384
	140360638158384 [label=AccumulateGrad]
	140360638159008 -> 140360638158768
	140360638157616 -> 140360638160736
	140360635349216 [label="stage3.0.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140360635349216 -> 140360638157616
	140360638157616 [label=AccumulateGrad]
	140360638161168 -> 140360638161120
	140360635348976 [label="stage3.0.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140360635348976 -> 140360638161168
	140360638161168 [label=AccumulateGrad]
	140360638160832 -> 140360638161120
	140360635349296 [label="stage3.0.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140360635349296 -> 140360638160832
	140360638160832 [label=AccumulateGrad]
	140360638161696 -> 140360638162272
	140360638161696 [label=UpsampleBilinear2DBackward0]
	140360638161360 -> 140360638161696
	140360638161360 [label=NativeBatchNormBackward0]
	140360638157760 -> 140360638161360
	140360638157760 [label=ConvolutionBackward0]
	140360638156224 -> 140360638157760
	140360638156224 [label=ReluBackward0]
	140360638156272 -> 140360638156224
	140360638156272 [label=AddBackward0]
	140360662245312 -> 140360638156272
	140360662245312 [label=NativeBatchNormBackward0]
	140360635177840 -> 140360662245312
	140360635177840 [label=ConvolutionBackward0]
	140360633710672 -> 140360635177840
	140360633710672 [label=ReluBackward0]
	140360633707120 -> 140360633710672
	140360633707120 [label=NativeBatchNormBackward0]
	140360633706352 -> 140360633707120
	140360633706352 [label=ConvolutionBackward0]
	140360638155744 -> 140360633706352
	140360638155744 [label=ReluBackward0]
	140360633705584 -> 140360638155744
	140360633705584 [label=AddBackward0]
	140360633705440 -> 140360633705584
	140360633705440 [label=NativeBatchNormBackward0]
	140360633705200 -> 140360633705440
	140360633705200 [label=ConvolutionBackward0]
	140360633704720 -> 140360633705200
	140360633704720 [label=ReluBackward0]
	140360633704576 -> 140360633704720
	140360633704576 [label=NativeBatchNormBackward0]
	140360633704960 -> 140360633704576
	140360633704960 [label=ConvolutionBackward0]
	140360633705536 -> 140360633704960
	140360633705536 [label=ReluBackward0]
	140360633704672 -> 140360633705536
	140360633704672 [label=AddBackward0]
	140360633704480 -> 140360633704672
	140360633704480 [label=NativeBatchNormBackward0]
	140360633704336 -> 140360633704480
	140360633704336 [label=ConvolutionBackward0]
	140360633704240 -> 140360633704336
	140360633704240 [label=ReluBackward0]
	140360633704096 -> 140360633704240
	140360633704096 [label=NativeBatchNormBackward0]
	140360633703904 -> 140360633704096
	140360633703904 [label=ConvolutionBackward0]
	140360633704144 -> 140360633703904
	140360633704144 [label=ReluBackward0]
	140360633703616 -> 140360633704144
	140360633703616 [label=AddBackward0]
	140360633703280 -> 140360633703616
	140360633703280 [label=NativeBatchNormBackward0]
	140360633703136 -> 140360633703280
	140360633703136 [label=ConvolutionBackward0]
	140360633703184 -> 140360633703136
	140360633703184 [label=ReluBackward0]
	140360633703040 -> 140360633703184
	140360633703040 [label=NativeBatchNormBackward0]
	140360633702752 -> 140360633703040
	140360633702752 [label=ConvolutionBackward0]
	140360633703664 -> 140360633702752
	140360633703664 [label=ReluBackward0]
	140360633702656 -> 140360633703664
	140360633702656 [label=NativeBatchNormBackward0]
	140360633696800 -> 140360633702656
	140360633696800 [label=ConvolutionBackward0]
	140360633706640 -> 140360633696800
	140360633696416 -> 140360633696800
	140360633461856 [label="transition2.2.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140360633461856 -> 140360633696416
	140360633696416 [label=AccumulateGrad]
	140360633702704 -> 140360633702656
	140360633461296 [label="transition2.2.0.1.weight
 (72)" fillcolor=lightblue]
	140360633461296 -> 140360633702704
	140360633702704 [label=AccumulateGrad]
	140360633702608 -> 140360633702656
	140360633463296 [label="transition2.2.0.1.bias
 (72)" fillcolor=lightblue]
	140360633463296 -> 140360633702608
	140360633702608 [label=AccumulateGrad]
	140360633702848 -> 140360633702752
	140360633306400 [label="stage3.0.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360633306400 -> 140360633702848
	140360633702848 [label=AccumulateGrad]
	140360633703088 -> 140360633703040
	140360633306240 [label="stage3.0.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140360633306240 -> 140360633703088
	140360633703088 [label=AccumulateGrad]
	140360633703232 -> 140360633703040
	140360633306480 [label="stage3.0.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140360633306480 -> 140360633703232
	140360633703232 [label=AccumulateGrad]
	140360633702896 -> 140360633703136
	140360633304960 [label="stage3.0.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360633304960 -> 140360633702896
	140360633702896 [label=AccumulateGrad]
	140360633703520 -> 140360633703280
	140360633304720 [label="stage3.0.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140360633304720 -> 140360633703520
	140360633703520 [label=AccumulateGrad]
	140360633703472 -> 140360633703280
	140360633304880 [label="stage3.0.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140360633304880 -> 140360633703472
	140360633703472 [label=AccumulateGrad]
	140360633703664 -> 140360633703616
	140360633703808 -> 140360633703904
	140360633303440 [label="stage3.0.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360633303440 -> 140360633703808
	140360633703808 [label=AccumulateGrad]
	140360633703712 -> 140360633704096
	140360633303360 [label="stage3.0.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140360633303360 -> 140360633703712
	140360633703712 [label=AccumulateGrad]
	140360633702992 -> 140360633704096
	140360633303520 [label="stage3.0.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140360633303520 -> 140360633702992
	140360633702992 [label=AccumulateGrad]
	140360633704192 -> 140360633704336
	140360633316960 [label="stage3.0.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360633316960 -> 140360633704192
	140360633704192 [label=AccumulateGrad]
	140360633704000 -> 140360633704480
	140360633316480 [label="stage3.0.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140360633316480 -> 140360633704000
	140360633704000 [label=AccumulateGrad]
	140360633704528 -> 140360633704480
	140360633316720 [label="stage3.0.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140360633316720 -> 140360633704528
	140360633704528 [label=AccumulateGrad]
	140360633704144 -> 140360633704672
	140360633704288 -> 140360633704960
	140360633313200 [label="stage3.0.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360633313200 -> 140360633704288
	140360633704288 [label=AccumulateGrad]
	140360633704912 -> 140360633704576
	140360633312800 [label="stage3.0.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140360633312800 -> 140360633704912
	140360633704912 [label=AccumulateGrad]
	140360633705056 -> 140360633704576
	140360633313440 [label="stage3.0.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140360633313440 -> 140360633705056
	140360633705056 [label=AccumulateGrad]
	140360633705248 -> 140360633705200
	140360633309760 [label="stage3.0.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360633309760 -> 140360633705248
	140360633705248 [label=AccumulateGrad]
	140360633704864 -> 140360633705440
	140360633309120 [label="stage3.0.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140360633309120 -> 140360633704864
	140360633704864 [label=AccumulateGrad]
	140360633705632 -> 140360633705440
	140360633309360 [label="stage3.0.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140360633309360 -> 140360633705632
	140360633705632 [label=AccumulateGrad]
	140360633705536 -> 140360633705584
	140360633705824 -> 140360633706352
	140360633305840 [label="stage3.0.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360633305840 -> 140360633705824
	140360633705824 [label=AccumulateGrad]
	140360633706592 -> 140360633707120
	140360633305600 [label="stage3.0.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140360633305600 -> 140360633706592
	140360633706592 [label=AccumulateGrad]
	140360633707408 -> 140360633707120
	140360633306080 [label="stage3.0.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140360633306080 -> 140360633707408
	140360633707408 [label=AccumulateGrad]
	140360633711824 -> 140360635177840
	140360635350656 [label="stage3.0.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635350656 -> 140360633711824
	140360633711824 [label=AccumulateGrad]
	140360887245248 -> 140360662245312
	140360635350336 [label="stage3.0.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140360635350336 -> 140360887245248
	140360887245248 [label=AccumulateGrad]
	140360633710432 -> 140360662245312
	140360635350576 [label="stage3.0.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140360635350576 -> 140360633710432
	140360633710432 [label=AccumulateGrad]
	140360638155744 -> 140360638156272
	140360638157184 -> 140360638157760
	140360635347856 [label="stage3.0.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140360635347856 -> 140360638157184
	140360638157184 [label=AccumulateGrad]
	140360638159536 -> 140360638161360
	140360635347616 [label="stage3.0.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140360635347616 -> 140360638159536
	140360638159536 [label=AccumulateGrad]
	140360638162080 -> 140360638161360
	140360635347936 [label="stage3.0.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140360635347936 -> 140360638162080
	140360638162080 [label=AccumulateGrad]
	140360638162368 -> 140360638162560
	140360635343856 [label="stage3.1.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635343856 -> 140360638162368
	140360638162368 [label=AccumulateGrad]
	140360638162608 -> 140360638162656
	140360635339136 [label="stage3.1.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140360635339136 -> 140360638162608
	140360638162608 [label=AccumulateGrad]
	140360638162752 -> 140360638162656
	140360635343776 [label="stage3.1.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140360635343776 -> 140360638162752
	140360638162752 [label=AccumulateGrad]
	140360638162800 -> 140360638162944
	140360635338256 [label="stage3.1.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635338256 -> 140360638162800
	140360638162800 [label=AccumulateGrad]
	140360638162992 -> 140360638163232
	140360635337936 [label="stage3.1.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140360635337936 -> 140360638162992
	140360638162992 [label=AccumulateGrad]
	140360638162224 -> 140360638163232
	140360635338176 [label="stage3.1.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140360635338176 -> 140360638162224
	140360638162224 [label=AccumulateGrad]
	140360638163280 -> 140360638163328
	140360638163424 -> 140360638163664
	140360635336816 [label="stage3.1.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635336816 -> 140360638163424
	140360638163424 [label=AccumulateGrad]
	140360638163712 -> 140360638163760
	140360635336576 [label="stage3.1.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140360635336576 -> 140360638163712
	140360638163712 [label=AccumulateGrad]
	140360638163856 -> 140360638163760
	140360635336896 [label="stage3.1.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140360635336896 -> 140360638163856
	140360638163856 [label=AccumulateGrad]
	140360638163952 -> 140360638163808
	140360635335376 [label="stage3.1.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635335376 -> 140360638163952
	140360638163952 [label=AccumulateGrad]
	140360638164144 -> 140360638164240
	140360635335056 [label="stage3.1.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140360635335056 -> 140360638164144
	140360638164144 [label=AccumulateGrad]
	140360638164192 -> 140360638164240
	140360635335296 [label="stage3.1.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140360635335296 -> 140360638164192
	140360638164192 [label=AccumulateGrad]
	140360638164288 -> 140360638164336
	140360638163520 -> 140360638164912
	140360635347776 [label="stage3.1.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635347776 -> 140360638163520
	140360638163520 [label=AccumulateGrad]
	140360638164960 -> 140360638165104
	140360635347376 [label="stage3.1.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140360635347376 -> 140360638164960
	140360638164960 [label=AccumulateGrad]
	140360638164816 -> 140360638165104
	140360635348016 [label="stage3.1.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140360635348016 -> 140360638164816
	140360638164816 [label=AccumulateGrad]
	140360638165536 -> 140360638165632
	140360635342576 [label="stage3.1.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635342576 -> 140360638165536
	140360638165536 [label=AccumulateGrad]
	140360638165824 -> 140360638165440
	140360635341936 [label="stage3.1.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140360635341936 -> 140360638165824
	140360638165824 [label=AccumulateGrad]
	140360638165872 -> 140360638165440
	140360635342336 [label="stage3.1.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140360635342336 -> 140360638165872
	140360638165872 [label=AccumulateGrad]
	140360638165920 -> 140360638166304
	140360638166400 -> 140360638166256
	140360635337696 [label="stage3.1.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635337696 -> 140360638166400
	140360638166400 [label=AccumulateGrad]
	140360638166640 -> 140360638166928
	140360635336976 [label="stage3.1.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140360635336976 -> 140360638166640
	140360638166640 [label=AccumulateGrad]
	140360638166208 -> 140360638166928
	140360635338096 [label="stage3.1.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140360635338096 -> 140360638166208
	140360638166208 [label=AccumulateGrad]
	140360638166976 -> 140360638167792
	140360635268896 [label="stage3.1.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635268896 -> 140360638166976
	140360638166976 [label=AccumulateGrad]
	140360638167840 -> 140360638167744
	140360635268656 [label="stage3.1.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140360635268656 -> 140360638167840
	140360638167840 [label=AccumulateGrad]
	140360638167888 -> 140360638167744
	140360635268736 [label="stage3.1.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140360635268736 -> 140360638167888
	140360638167888 [label=AccumulateGrad]
	140360638167456 -> 140360638168464
	140360638168656 -> 140360638168800
	140360638168656 [label=UpsampleBilinear2DBackward0]
	140360638167696 -> 140360638168656
	140360638167696 [label=NativeBatchNormBackward0]
	140360638166352 -> 140360638167696
	140360638166352 [label=ConvolutionBackward0]
	140360638166448 -> 140360638166352
	140360638166448 [label=ReluBackward0]
	140360638164096 -> 140360638166448
	140360638164096 [label=AddBackward0]
	140360638164864 -> 140360638164096
	140360638164864 [label=NativeBatchNormBackward0]
	140360638164384 -> 140360638164864
	140360638164384 [label=ConvolutionBackward0]
	140360638163616 -> 140360638164384
	140360638163616 [label=ReluBackward0]
	140360638163568 -> 140360638163616
	140360638163568 [label=NativeBatchNormBackward0]
	140360638162320 -> 140360638163568
	140360638162320 [label=ConvolutionBackward0]
	140360638165584 -> 140360638162320
	140360638165584 [label=ReluBackward0]
	140360638160976 -> 140360638165584
	140360638160976 [label=AddBackward0]
	140360638157088 -> 140360638160976
	140360638157088 [label=NativeBatchNormBackward0]
	140360638160928 -> 140360638157088
	140360638160928 [label=ConvolutionBackward0]
	140360633705344 -> 140360638160928
	140360633705344 [label=ReluBackward0]
	140360633705104 -> 140360633705344
	140360633705104 [label=NativeBatchNormBackward0]
	140360633705008 -> 140360633705104
	140360633705008 [label=ConvolutionBackward0]
	140360638156368 -> 140360633705008
	140360638156368 [label=ReluBackward0]
	140360633703424 -> 140360638156368
	140360633703424 [label=AddBackward0]
	140360633703952 -> 140360633703424
	140360633703952 [label=NativeBatchNormBackward0]
	140360633703568 -> 140360633703952
	140360633703568 [label=ConvolutionBackward0]
	140360633702944 -> 140360633703568
	140360633702944 [label=ReluBackward0]
	140360633702512 -> 140360633702944
	140360633702512 [label=NativeBatchNormBackward0]
	140360633696992 -> 140360633702512
	140360633696992 [label=ConvolutionBackward0]
	140360633703856 -> 140360633696992
	140360633703856 [label=ReluBackward0]
	140360633696944 -> 140360633703856
	140360633696944 [label=AddBackward0]
	140360633697328 -> 140360633696944
	140360633697328 [label=NativeBatchNormBackward0]
	140360633697760 -> 140360633697328
	140360633697760 [label=ConvolutionBackward0]
	140360633698960 -> 140360633697760
	140360633698960 [label=ReluBackward0]
	140360633699392 -> 140360633698960
	140360633699392 [label=NativeBatchNormBackward0]
	140360633699632 -> 140360633699392
	140360633699632 [label=ConvolutionBackward0]
	140360633698000 -> 140360633699632
	140360633698000 [label=ReluBackward0]
	140360633700112 -> 140360633698000
	140360633700112 [label=AddBackward0]
	140360633699296 -> 140360633700112
	140360633699296 [label=AddBackward0]
	140360633699776 -> 140360633699296
	140360633699776 [label=NativeBatchNormBackward0]
	140360633700208 -> 140360633699776
	140360633700208 [label=ConvolutionBackward0]
	140360638161984 -> 140360633700208
	140360633701312 -> 140360633700208
	140360635346096 [label="stage3.0.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140360635346096 -> 140360633701312
	140360633701312 [label=AccumulateGrad]
	140360633700592 -> 140360633699776
	140360635345856 [label="stage3.0.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140360635345856 -> 140360633700592
	140360633700592 [label=AccumulateGrad]
	140360633701024 -> 140360633699776
	140360635346256 [label="stage3.0.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140360635346256 -> 140360633701024
	140360633701024 [label=AccumulateGrad]
	140360638160880 -> 140360633699296
	140360633699440 -> 140360633700112
	140360633699440 [label=UpsampleBilinear2DBackward0]
	140360633700448 -> 140360633699440
	140360633700448 [label=NativeBatchNormBackward0]
	140360633700256 -> 140360633700448
	140360633700256 [label=ConvolutionBackward0]
	140360638156224 -> 140360633700256
	140360633700928 -> 140360633700256
	140360635346576 [label="stage3.0.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140360635346576 -> 140360633700928
	140360633700928 [label=AccumulateGrad]
	140360633700736 -> 140360633700448
	140360635344736 [label="stage3.0.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140360635344736 -> 140360633700736
	140360633700736 [label=AccumulateGrad]
	140360633699920 -> 140360633700448
	140360635346496 [label="stage3.0.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140360635346496 -> 140360633699920
	140360633699920 [label=AccumulateGrad]
	140360633699248 -> 140360633699632
	140360635267296 [label="stage3.1.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635267296 -> 140360633699248
	140360633699248 [label=AccumulateGrad]
	140360633698576 -> 140360633699392
	140360635267216 [label="stage3.1.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140360635267216 -> 140360633698576
	140360633698576 [label=AccumulateGrad]
	140360633698288 -> 140360633699392
	140360635267376 [label="stage3.1.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140360635267376 -> 140360633698288
	140360633698288 [label=AccumulateGrad]
	140360633697808 -> 140360633697760
	140360635266016 [label="stage3.1.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635266016 -> 140360633697808
	140360633697808 [label=AccumulateGrad]
	140360633698432 -> 140360633697328
	140360635265776 [label="stage3.1.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140360635265776 -> 140360633698432
	140360633698432 [label=AccumulateGrad]
	140360633697136 -> 140360633697328
	140360635265856 [label="stage3.1.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140360635265856 -> 140360633697136
	140360633697136 [label=AccumulateGrad]
	140360633698000 -> 140360633696944
	140360633697664 -> 140360633696992
	140360635264336 [label="stage3.1.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635264336 -> 140360633697664
	140360633697664 [label=AccumulateGrad]
	140360633697472 -> 140360633702512
	140360635264256 [label="stage3.1.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140360635264256 -> 140360633697472
	140360633697472 [label=AccumulateGrad]
	140360633702560 -> 140360633702512
	140360635264496 [label="stage3.1.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140360635264496 -> 140360633702560
	140360633702560 [label=AccumulateGrad]
	140360633703376 -> 140360633703568
	140360635262976 [label="stage3.1.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635262976 -> 140360633703376
	140360633703376 [label=AccumulateGrad]
	140360633703760 -> 140360633703952
	140360635262736 [label="stage3.1.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140360635262736 -> 140360633703760
	140360633703760 [label=AccumulateGrad]
	140360633703328 -> 140360633703952
	140360635262816 [label="stage3.1.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140360635262816 -> 140360633703328
	140360633703328 [label=AccumulateGrad]
	140360633703856 -> 140360633703424
	140360633704768 -> 140360633705008
	140360635261296 [label="stage3.1.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635261296 -> 140360633704768
	140360633704768 [label=AccumulateGrad]
	140360633704624 -> 140360633705104
	140360635261216 [label="stage3.1.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140360635261216 -> 140360633704624
	140360633704624 [label=AccumulateGrad]
	140360633706160 -> 140360633705104
	140360635261456 [label="stage3.1.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140360635261456 -> 140360633706160
	140360633706160 [label=AccumulateGrad]
	140360633706448 -> 140360638160928
	140360635259936 [label="stage3.1.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635259936 -> 140360633706448
	140360633706448 [label=AccumulateGrad]
	140360633706784 -> 140360638157088
	140360635259696 [label="stage3.1.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140360635259696 -> 140360633706784
	140360633706784 [label=AccumulateGrad]
	140360633702080 -> 140360638157088
	140360635259776 [label="stage3.1.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140360635259776 -> 140360633702080
	140360633702080 [label=AccumulateGrad]
	140360638156368 -> 140360638160976
	140360638162416 -> 140360638162320
	140360635258256 [label="stage3.1.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635258256 -> 140360638162416
	140360638162416 [label=AccumulateGrad]
	140360638162704 -> 140360638163568
	140360635258176 [label="stage3.1.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140360635258176 -> 140360638162704
	140360638162704 [label=AccumulateGrad]
	140360638162896 -> 140360638163568
	140360635258416 [label="stage3.1.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140360635258416 -> 140360638162896
	140360638162896 [label=AccumulateGrad]
	140360638164000 -> 140360638164384
	140360635256896 [label="stage3.1.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635256896 -> 140360638164000
	140360638164000 [label=AccumulateGrad]
	140360638160496 -> 140360638164864
	140360635256656 [label="stage3.1.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140360635256656 -> 140360638160496
	140360638160496 [label=AccumulateGrad]
	140360638164048 -> 140360638164864
	140360635256736 [label="stage3.1.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140360635256736 -> 140360638164048
	140360638164048 [label=AccumulateGrad]
	140360638165584 -> 140360638164096
	140360638165488 -> 140360638166352
	140360635216704 [label="stage3.1.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140360635216704 -> 140360638165488
	140360638165488 [label=AccumulateGrad]
	140360638166880 -> 140360638167696
	140360635216624 [label="stage3.1.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140360635216624 -> 140360638166880
	140360638166880 [label=AccumulateGrad]
	140360638168512 -> 140360638167696
	140360635216864 [label="stage3.1.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140360635216864 -> 140360638168512
	140360638168512 [label=AccumulateGrad]
	140360638168848 -> 140360638168896
	140360638168848 [label=UpsampleBilinear2DBackward0]
	140360638160400 -> 140360638168848
	140360638160400 [label=NativeBatchNormBackward0]
	140360638163472 -> 140360638160400
	140360638163472 [label=ConvolutionBackward0]
	140360638162464 -> 140360638163472
	140360638162464 [label=ReluBackward0]
	140360638162176 -> 140360638162464
	140360638162176 [label=AddBackward0]
	140360638161936 -> 140360638162176
	140360638161936 [label=NativeBatchNormBackward0]
	140360633707792 -> 140360638161936
	140360633707792 [label=ConvolutionBackward0]
	140360633704384 -> 140360633707792
	140360633704384 [label=ReluBackward0]
	140360633696320 -> 140360633704384
	140360633696320 [label=NativeBatchNormBackward0]
	140360633697616 -> 140360633696320
	140360633697616 [label=ConvolutionBackward0]
	140360638163376 -> 140360633697616
	140360638163376 [label=ReluBackward0]
	140360633698816 -> 140360638163376
	140360633698816 [label=AddBackward0]
	140360633700064 -> 140360633698816
	140360633700064 [label=NativeBatchNormBackward0]
	140360633701456 -> 140360633700064
	140360633701456 [label=ConvolutionBackward0]
	140360633701216 -> 140360633701456
	140360633701216 [label=ReluBackward0]
	140360633701552 -> 140360633701216
	140360633701552 [label=NativeBatchNormBackward0]
	140360633702272 -> 140360633701552
	140360633702272 [label=ConvolutionBackward0]
	140360633701840 -> 140360633702272
	140360633701840 [label=ReluBackward0]
	140360642877456 -> 140360633701840
	140360642877456 [label=AddBackward0]
	140360642875824 -> 140360642877456
	140360642875824 [label=NativeBatchNormBackward0]
	140360642875536 -> 140360642875824
	140360642875536 [label=ConvolutionBackward0]
	140360642877504 -> 140360642875536
	140360642877504 [label=ReluBackward0]
	140360662729440 -> 140360642877504
	140360662729440 [label=NativeBatchNormBackward0]
	140360662732272 -> 140360662729440
	140360662732272 [label=ConvolutionBackward0]
	140360642883264 -> 140360662732272
	140360642883264 [label=ReluBackward0]
	140360886911040 -> 140360642883264
	140360886911040 [label=AddBackward0]
	140360886911136 -> 140360886911040
	140360886911136 [label=NativeBatchNormBackward0]
	140364033595024 -> 140360886911136
	140364033595024 [label=ConvolutionBackward0]
	140360652017376 -> 140364033595024
	140360652017376 [label=ReluBackward0]
	140360652014592 -> 140360652017376
	140360652014592 [label=NativeBatchNormBackward0]
	140360652016656 -> 140360652014592
	140360652016656 [label=ConvolutionBackward0]
	140360886911328 -> 140360652016656
	140360886911328 [label=ReluBackward0]
	140360636351104 -> 140360886911328
	140360636351104 [label=AddBackward0]
	140360636350624 -> 140360636351104
	140360636350624 [label=AddBackward0]
	140360636351200 -> 140360636350624
	140360636351200 [label=NativeBatchNormBackward0]
	140360636351440 -> 140360636351200
	140360636351440 [label=ConvolutionBackward0]
	140360636351728 -> 140360636351440
	140360636351728 [label=ReluBackward0]
	140360636351920 -> 140360636351728
	140360636351920 [label=NativeBatchNormBackward0]
	140360636352544 -> 140360636351920
	140360636352544 [label=ConvolutionBackward0]
	140360638161984 -> 140360636352544
	140360636352592 -> 140360636352544
	140360635343376 [label="stage3.0.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635343376 -> 140360636352592
	140360636352592 [label=AccumulateGrad]
	140360636353120 -> 140360636351920
	140360635343136 [label="stage3.0.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140360635343136 -> 140360636353120
	140360636353120 [label=AccumulateGrad]
	140360636352928 -> 140360636351920
	140360635343536 [label="stage3.0.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140360635343536 -> 140360636352928
	140360636352928 [label=AccumulateGrad]
	140360636351872 -> 140360636351440
	140360635343216 [label="stage3.0.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140360635343216 -> 140360636351872
	140360636351872 [label=AccumulateGrad]
	140360636352256 -> 140360636351200
	140360635341776 [label="stage3.0.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140360635341776 -> 140360636352256
	140360636352256 [label=AccumulateGrad]
	140360636351056 -> 140360636351200
	140360635341856 [label="stage3.0.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140360635341856 -> 140360636351056
	140360636351056 [label=AccumulateGrad]
	140360636351776 -> 140360636350624
	140360636351776 [label=NativeBatchNormBackward0]
	140360636353600 -> 140360636351776
	140360636353600 [label=ConvolutionBackward0]
	140360638160880 -> 140360636353600
	140360636352784 -> 140360636353600
	140360635340336 [label="stage3.0.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140360635340336 -> 140360636352784
	140360636352784 [label=AccumulateGrad]
	140360636352112 -> 140360636351776
	140360635340256 [label="stage3.0.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140360635340256 -> 140360636352112
	140360636352112 [label=AccumulateGrad]
	140360636351248 -> 140360636351776
	140360635340496 [label="stage3.0.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140360635340496 -> 140360636351248
	140360636351248 [label=AccumulateGrad]
	140360638156224 -> 140360636351104
	140360636350528 -> 140360652016656
	140360635255216 [label="stage3.1.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635255216 -> 140360636350528
	140360636350528 [label=AccumulateGrad]
	140360652026832 -> 140360652014592
	140360635255136 [label="stage3.1.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140360635255136 -> 140360652026832
	140360652026832 [label=AccumulateGrad]
	140360652027888 -> 140360652014592
	140360635255376 [label="stage3.1.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140360635255376 -> 140360652027888
	140360652027888 [label=AccumulateGrad]
	140360652024384 -> 140364033595024
	140360635253856 [label="stage3.1.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635253856 -> 140360652024384
	140360652024384 [label=AccumulateGrad]
	140360652027168 -> 140360886911136
	140360635253616 [label="stage3.1.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140360635253616 -> 140360652027168
	140360652027168 [label=AccumulateGrad]
	140360652016608 -> 140360886911136
	140360635253696 [label="stage3.1.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140360635253696 -> 140360652016608
	140360652016608 [label=AccumulateGrad]
	140360886911328 -> 140360886911040
	140360886912384 -> 140360662732272
	140360635266976 [label="stage3.1.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635266976 -> 140360886912384
	140360886912384 [label=AccumulateGrad]
	140360662729728 -> 140360662729440
	140360635266736 [label="stage3.1.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140360635266736 -> 140360662729728
	140360662729728 [label=AccumulateGrad]
	140360662737552 -> 140360662729440
	140360635267696 [label="stage3.1.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140360635267696 -> 140360662737552
	140360662737552 [label=AccumulateGrad]
	140360642877744 -> 140360642875536
	140360635263696 [label="stage3.1.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635263696 -> 140360642877744
	140360642877744 [label=AccumulateGrad]
	140360642875440 -> 140360642875824
	140360635262896 [label="stage3.1.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140360635262896 -> 140360642875440
	140360642875440 [label=AccumulateGrad]
	140360642875776 -> 140360642875824
	140360635263296 [label="stage3.1.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140360635263296 -> 140360642875776
	140360642875776 [label=AccumulateGrad]
	140360642883264 -> 140360642877456
	140360642884800 -> 140360633702272
	140360635259616 [label="stage3.1.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635259616 -> 140360642884800
	140360642884800 [label=AccumulateGrad]
	140360633701504 -> 140360633701552
	140360635259376 [label="stage3.1.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140360635259376 -> 140360633701504
	140360633701504 [label=AccumulateGrad]
	140360633701408 -> 140360633701552
	140360635259856 [label="stage3.1.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140360635259856 -> 140360633701408
	140360633701408 [label=AccumulateGrad]
	140360633701600 -> 140360633701456
	140360635256336 [label="stage3.1.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635256336 -> 140360633701600
	140360633701600 [label=AccumulateGrad]
	140360633700880 -> 140360633700064
	140360635255696 [label="stage3.1.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140360635255696 -> 140360633700880
	140360633700880 [label=AccumulateGrad]
	140360633698624 -> 140360633700064
	140360635256096 [label="stage3.1.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140360635256096 -> 140360633698624
	140360633698624 [label=AccumulateGrad]
	140360633701840 -> 140360633698816
	140360633699104 -> 140360633697616
	140360635219744 [label="stage3.1.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635219744 -> 140360633699104
	140360633699104 [label=AccumulateGrad]
	140360633701696 -> 140360633696320
	140360635219664 [label="stage3.1.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140360635219664 -> 140360633701696
	140360633701696 [label=AccumulateGrad]
	140360633702800 -> 140360633696320
	140360635219904 [label="stage3.1.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140360635219904 -> 140360633702800
	140360633702800 [label=AccumulateGrad]
	140360633704816 -> 140360633707792
	140360635218384 [label="stage3.1.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635218384 -> 140360633704816
	140360633704816 [label=AccumulateGrad]
	140360633704048 -> 140360638161936
	140360635218144 [label="stage3.1.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140360635218144 -> 140360633704048
	140360633704048 [label=AccumulateGrad]
	140360633706928 -> 140360638161936
	140360635218224 [label="stage3.1.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140360635218224 -> 140360633706928
	140360633706928 [label=AccumulateGrad]
	140360638163376 -> 140360638162176
	140360638163040 -> 140360638163472
	140360635215184 [label="stage3.1.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140360635215184 -> 140360638163040
	140360638163040 [label=AccumulateGrad]
	140360638165152 -> 140360638160400
	140360635215104 [label="stage3.1.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140360635215104 -> 140360638165152
	140360638165152 [label=AccumulateGrad]
	140360638168368 -> 140360638160400
	140360635215344 [label="stage3.1.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140360635215344 -> 140360638168368
	140360638168368 [label=AccumulateGrad]
	140360638168992 -> 140360638168416
	140360635210784 [label="stage3.2.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635210784 -> 140360638168992
	140360638168992 [label=AccumulateGrad]
	140360638167936 -> 140360859460336
	140360635205904 [label="stage3.2.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140360635205904 -> 140360638167936
	140360638167936 [label=AccumulateGrad]
	140360638168320 -> 140360859460336
	140360635210624 [label="stage3.2.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140360635210624 -> 140360638168320
	140360638168320 [label=AccumulateGrad]
	140360651462912 -> 140360636661920
	140360635204704 [label="stage3.2.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635204704 -> 140360651462912
	140360651462912 [label=AccumulateGrad]
	140360636661968 -> 140360636662112
	140360635204464 [label="stage3.2.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140360635204464 -> 140360636661968
	140360636661968 [label=AccumulateGrad]
	140360636662016 -> 140360636662112
	140360635204544 [label="stage3.2.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140360635204544 -> 140360636662016
	140360636662016 [label=AccumulateGrad]
	140360636662160 -> 140360636662208
	140360636662304 -> 140360636662688
	140360635218944 [label="stage3.2.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635218944 -> 140360636662304
	140360636662304 [label=AccumulateGrad]
	140360636662736 -> 140360636662784
	140360635218704 [label="stage3.2.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140360635218704 -> 140360636662736
	140360636662736 [label=AccumulateGrad]
	140360636662928 -> 140360636662784
	140360635219184 [label="stage3.2.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140360635219184 -> 140360636662928
	140360636662928 [label=AccumulateGrad]
	140360636663024 -> 140360636662832
	140360635215664 [label="stage3.2.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635215664 -> 140360636663024
	140360636663024 [label=AccumulateGrad]
	140360636663216 -> 140360636663312
	140360635214864 [label="stage3.2.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140360635214864 -> 140360636663216
	140360636663216 [label=AccumulateGrad]
	140360636663264 -> 140360636663312
	140360635215264 [label="stage3.2.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140360635215264 -> 140360636663264
	140360636663264 [label=AccumulateGrad]
	140360636663360 -> 140360636663408
	140360636663504 -> 140360636663696
	140360635211584 [label="stage3.2.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635211584 -> 140360636663504
	140360636663504 [label=AccumulateGrad]
	140360636663456 -> 140360636662880
	140360635211344 [label="stage3.2.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140360635211344 -> 140360636663456
	140360636663456 [label=AccumulateGrad]
	140360636664032 -> 140360636662880
	140360635211824 [label="stage3.2.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140360635211824 -> 140360636664032
	140360636664032 [label=AccumulateGrad]
	140360636664128 -> 140360636664320
	140360635208304 [label="stage3.2.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635208304 -> 140360636664128
	140360636664128 [label=AccumulateGrad]
	140360636664368 -> 140360636664464
	140360635207664 [label="stage3.2.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140360635207664 -> 140360636664368
	140360636664368 [label=AccumulateGrad]
	140360636664416 -> 140360636664464
	140360635208064 [label="stage3.2.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140360635208064 -> 140360636664416
	140360636664416 [label=AccumulateGrad]
	140360636664512 -> 140360636664224
	140360636664656 -> 140360636664560
	140360635204224 [label="stage3.2.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635204224 -> 140360636664656
	140360636664656 [label=AccumulateGrad]
	140360636664896 -> 140360636664944
	140360635203984 [label="stage3.2.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140360635203984 -> 140360636664896
	140360636664896 [label=AccumulateGrad]
	140360636665040 -> 140360636664944
	140360635204624 [label="stage3.2.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140360635204624 -> 140360636665040
	140360636665040 [label=AccumulateGrad]
	140360636664848 -> 140360636665424
	140360635136944 [label="stage3.2.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635136944 -> 140360636664848
	140360636664848 [label=AccumulateGrad]
	140360636665472 -> 140360636665136
	140360635136704 [label="stage3.2.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140360635136704 -> 140360636665472
	140360636665472 [label=AccumulateGrad]
	140360636665520 -> 140360636665136
	140360635136784 [label="stage3.2.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140360635136784 -> 140360636665520
	140360636665520 [label=AccumulateGrad]
	140360636665664 -> 140360636665712
	140360636665568 -> 140360636666000
	140360636665568 [label=UpsampleBilinear2DBackward0]
	140360636665376 -> 140360636665568
	140360636665376 [label=NativeBatchNormBackward0]
	140360636664608 -> 140360636665376
	140360636664608 [label=ConvolutionBackward0]
	140360636664704 -> 140360636664608
	140360636664704 [label=ReluBackward0]
	140360636663168 -> 140360636664704
	140360636663168 [label=AddBackward0]
	140360636663648 -> 140360636663168
	140360636663648 [label=NativeBatchNormBackward0]
	140360636663600 -> 140360636663648
	140360636663600 [label=ConvolutionBackward0]
	140360636662640 -> 140360636663600
	140360636662640 [label=ReluBackward0]
	140360636662592 -> 140360636662640
	140360636662592 [label=NativeBatchNormBackward0]
	140360859451936 -> 140360636662592
	140360859451936 [label=ConvolutionBackward0]
	140360636664176 -> 140360859451936
	140360636664176 [label=ReluBackward0]
	140360638166592 -> 140360636664176
	140360638166592 [label=AddBackward0]
	140360638162848 -> 140360638166592
	140360638162848 [label=NativeBatchNormBackward0]
	140360633697088 -> 140360638162848
	140360633697088 [label=ConvolutionBackward0]
	140360633701264 -> 140360633697088
	140360633701264 [label=ReluBackward0]
	140360633701360 -> 140360633701264
	140360633701360 [label=NativeBatchNormBackward0]
	140360633701072 -> 140360633701360
	140360633701072 [label=ConvolutionBackward0]
	140360638166544 -> 140360633701072
	140360638166544 [label=ReluBackward0]
	140360642887632 -> 140360638166544
	140360642887632 [label=AddBackward0]
	140360662735584 -> 140360642887632
	140360662735584 [label=NativeBatchNormBackward0]
	140360886912960 -> 140360662735584
	140360886912960 [label=ConvolutionBackward0]
	140360652028176 -> 140360886912960
	140360652028176 [label=ReluBackward0]
	140360636350768 -> 140360652028176
	140360636350768 [label=NativeBatchNormBackward0]
	140360636352400 -> 140360636350768
	140360636352400 [label=ConvolutionBackward0]
	140360662730784 -> 140360636352400
	140360662730784 [label=ReluBackward0]
	140360636353264 -> 140360662730784
	140360636353264 [label=AddBackward0]
	140360636353888 -> 140360636353264
	140360636353888 [label=NativeBatchNormBackward0]
	140360636354128 -> 140360636353888
	140360636354128 [label=ConvolutionBackward0]
	140360636354416 -> 140360636354128
	140360636354416 [label=ReluBackward0]
	140360636354608 -> 140360636354416
	140360636354608 [label=NativeBatchNormBackward0]
	140360636355088 -> 140360636354608
	140360636355088 [label=ConvolutionBackward0]
	140360636354272 -> 140360636355088
	140360636354272 [label=ReluBackward0]
	140360636355616 -> 140360636354272
	140360636355616 [label=AddBackward0]
	140360636355952 -> 140360636355616
	140360636355952 [label=AddBackward0]
	140360636356432 -> 140360636355952
	140360636356432 [label=NativeBatchNormBackward0]
	140360636357296 -> 140360636356432
	140360636357296 [label=ConvolutionBackward0]
	140360638168608 -> 140360636357296
	140360636356816 -> 140360636357296
	140360635213504 [label="stage3.1.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140360635213504 -> 140360636356816
	140360636356816 [label=AccumulateGrad]
	140360636356288 -> 140360636356432
	140360635213264 [label="stage3.1.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140360635213264 -> 140360636356288
	140360636356288 [label=AccumulateGrad]
	140360636355808 -> 140360636356432
	140360635213584 [label="stage3.1.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140360635213584 -> 140360636355808
	140360636355808 [label=AccumulateGrad]
	140360638166448 -> 140360636355952
	140360636356624 -> 140360636355616
	140360636356624 [label=UpsampleBilinear2DBackward0]
	140360636357776 -> 140360636356624
	140360636357776 [label=NativeBatchNormBackward0]
	140360636356960 -> 140360636357776
	140360636356960 [label=ConvolutionBackward0]
	140360638162464 -> 140360636356960
	140360636357632 -> 140360636356960
	140360635213824 [label="stage3.1.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140360635213824 -> 140360636357632
	140360636357632 [label=AccumulateGrad]
	140360636357152 -> 140360636357776
	140360635211984 [label="stage3.1.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140360635211984 -> 140360636357152
	140360636357152 [label=AccumulateGrad]
	140360636357104 -> 140360636357776
	140360635213664 [label="stage3.1.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140360635213664 -> 140360636357104
	140360636357104 [label=AccumulateGrad]
	140360636356576 -> 140360636355088
	140360635135264 [label="stage3.2.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635135264 -> 140360636356576
	140360636356576 [label=AccumulateGrad]
	140360636355904 -> 140360636354608
	140360635135184 [label="stage3.2.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140360635135184 -> 140360636355904
	140360636355904 [label=AccumulateGrad]
	140360636355472 -> 140360636354608
	140360635135424 [label="stage3.2.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140360635135424 -> 140360636355472
	140360636355472 [label=AccumulateGrad]
	140360636354560 -> 140360636354128
	140360635133904 [label="stage3.2.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635133904 -> 140360636354560
	140360636354560 [label=AccumulateGrad]
	140360636354464 -> 140360636353888
	140360635133664 [label="stage3.2.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140360635133664 -> 140360636354464
	140360636354464 [label=AccumulateGrad]
	140360636353744 -> 140360636353888
	140360635133744 [label="stage3.2.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140360635133744 -> 140360636353744
	140360636353744 [label=AccumulateGrad]
	140360636354272 -> 140360636353264
	140360636353792 -> 140360636352400
	140360635132224 [label="stage3.2.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635132224 -> 140360636353792
	140360636353792 [label=AccumulateGrad]
	140360636352448 -> 140360636350768
	140360635132144 [label="stage3.2.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140360635132144 -> 140360636352448
	140360636352448 [label=AccumulateGrad]
	140360636350912 -> 140360636350768
	140360635132384 [label="stage3.2.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140360635132384 -> 140360636350912
	140360636350912 [label=AccumulateGrad]
	140360636350576 -> 140360886912960
	140360635130864 [label="stage3.2.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635130864 -> 140360636350576
	140360636350576 [label=AccumulateGrad]
	140360886913152 -> 140360662735584
	140360635130624 [label="stage3.2.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140360635130624 -> 140360886913152
	140360886913152 [label=AccumulateGrad]
	140360652023856 -> 140360662735584
	140360635130704 [label="stage3.2.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140360635130704 -> 140360652023856
	140360652023856 [label=AccumulateGrad]
	140360662730784 -> 140360642887632
	140360642883312 -> 140360633701072
	140360635129184 [label="stage3.2.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635129184 -> 140360642883312
	140360642883312 [label=AccumulateGrad]
	140360633701168 -> 140360633701360
	140360635129104 [label="stage3.2.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140360635129104 -> 140360633701168
	140360633701168 [label=AccumulateGrad]
	140360633698144 -> 140360633701360
	140360635129344 [label="stage3.2.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140360635129344 -> 140360633698144
	140360633698144 [label=AccumulateGrad]
	140360633696464 -> 140360633697088
	140360635127824 [label="stage3.2.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635127824 -> 140360633696464
	140360633696464 [label=AccumulateGrad]
	140360633706400 -> 140360638162848
	140360635127584 [label="stage3.2.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140360635127584 -> 140360633706400
	140360633706400 [label=AccumulateGrad]
	140360633704432 -> 140360638162848
	140360635127664 [label="stage3.2.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140360635127664 -> 140360633704432
	140360633704432 [label=AccumulateGrad]
	140360638166544 -> 140360638166592
	140360638168704 -> 140360859451936
	140360635126144 [label="stage3.2.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635126144 -> 140360638168704
	140360638168704 [label=AccumulateGrad]
	140360636661824 -> 140360636662592
	140360635126064 [label="stage3.2.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140360635126064 -> 140360636661824
	140360636661824 [label=AccumulateGrad]
	140360636661872 -> 140360636662592
	140360635126304 [label="stage3.2.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140360635126304 -> 140360636661872
	140360636661872 [label=AccumulateGrad]
	140360636663072 -> 140360636663600
	140360635124784 [label="stage3.2.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635124784 -> 140360636663072
	140360636663072 [label=AccumulateGrad]
	140360636663552 -> 140360636663648
	140360635124544 [label="stage3.2.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140360635124544 -> 140360636663552
	140360636663552 [label=AccumulateGrad]
	140360636663120 -> 140360636663648
	140360635124624 [label="stage3.2.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140360635124624 -> 140360636663120
	140360636663120 [label=AccumulateGrad]
	140360636664176 -> 140360636663168
	140360636663744 -> 140360636664608
	140360635084752 [label="stage3.2.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140360635084752 -> 140360636663744
	140360636663744 [label=AccumulateGrad]
	140360636664992 -> 140360636665376
	140360635084672 [label="stage3.2.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140360635084672 -> 140360636664992
	140360636664992 [label=AccumulateGrad]
	140360636665760 -> 140360636665376
	140360635084832 [label="stage3.2.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140360635084832 -> 140360636665760
	140360636665760 [label=AccumulateGrad]
	140360636666048 -> 140360636666096
	140360636666048 [label=UpsampleBilinear2DBackward0]
	140360636664272 -> 140360636666048
	140360636664272 [label=NativeBatchNormBackward0]
	140360636662352 -> 140360636664272
	140360636662352 [label=ConvolutionBackward0]
	140360636662064 -> 140360636662352
	140360636662064 [label=ReluBackward0]
	140360638168752 -> 140360636662064
	140360638168752 [label=AddBackward0]
	140360638168560 -> 140360638168752
	140360638168560 [label=NativeBatchNormBackward0]
	140360652026208 -> 140360638168560
	140360652026208 [label=ConvolutionBackward0]
	140360886912624 -> 140360652026208
	140360886912624 [label=ReluBackward0]
	140360636350720 -> 140360886912624
	140360636350720 [label=NativeBatchNormBackward0]
	140360636353936 -> 140360636350720
	140360636353936 [label=ConvolutionBackward0]
	140360638169040 -> 140360636353936
	140360638169040 [label=ReluBackward0]
	140360636356144 -> 140360638169040
	140360636356144 [label=AddBackward0]
	140360636355136 -> 140360636356144
	140360636355136 [label=NativeBatchNormBackward0]
	140360636357248 -> 140360636355136
	140360636357248 [label=ConvolutionBackward0]
	140360636357824 -> 140360636357248
	140360636357824 [label=ReluBackward0]
	140360636358304 -> 140360636357824
	140360636358304 [label=NativeBatchNormBackward0]
	140360636359120 -> 140360636358304
	140360636359120 [label=ConvolutionBackward0]
	140360636356480 -> 140360636359120
	140360636356480 [label=ReluBackward0]
	140360636359984 -> 140360636356480
	140360636359984 [label=AddBackward0]
	140360636359264 -> 140360636359984
	140360636359264 [label=NativeBatchNormBackward0]
	140360636359504 -> 140360636359264
	140360636359504 [label=ConvolutionBackward0]
	140360636360992 -> 140360636359504
	140360636360992 [label=ReluBackward0]
	140360636360608 -> 140360636360992
	140360636360608 [label=NativeBatchNormBackward0]
	140360636361856 -> 140360636360608
	140360636361856 [label=ConvolutionBackward0]
	140360636359168 -> 140360636361856
	140360636359168 [label=ReluBackward0]
	140360636362336 -> 140360636359168
	140360636362336 [label=AddBackward0]
	140360636361328 -> 140360636362336
	140360636361328 [label=NativeBatchNormBackward0]
	140360636361808 -> 140360636361328
	140360636361808 [label=ConvolutionBackward0]
	140360636363200 -> 140360636361808
	140360636363200 [label=ReluBackward0]
	140360636363680 -> 140360636363200
	140360636363680 [label=NativeBatchNormBackward0]
	140360636362672 -> 140360636363680
	140360636362672 [label=ConvolutionBackward0]
	140360636361520 -> 140360636362672
	140360636361520 [label=ReluBackward0]
	140360636363344 -> 140360636361520
	140360636363344 [label=AddBackward0]
	140360636363968 -> 140360636363344
	140360636363968 [label=AddBackward0]
	140360636364544 -> 140360636363968
	140360636364544 [label=NativeBatchNormBackward0]
	140360636365024 -> 140360636364544
	140360636365024 [label=ConvolutionBackward0]
	140360636364880 -> 140360636365024
	140360636364880 [label=ReluBackward0]
	140360636365312 -> 140360636364880
	140360636365312 [label=NativeBatchNormBackward0]
	140360636366224 -> 140360636365312
	140360636366224 [label=ConvolutionBackward0]
	140360638168608 -> 140360636366224
	140360636365840 -> 140360636366224
	140360635210464 [label="stage3.1.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635210464 -> 140360636365840
	140360636365840 [label=AccumulateGrad]
	140360636365168 -> 140360636365312
	140360635210224 [label="stage3.1.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140360635210224 -> 140360636365168
	140360636365168 [label=AccumulateGrad]
	140360636364688 -> 140360636365312
	140360635210544 [label="stage3.1.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140360635210544 -> 140360636364688
	140360636364688 [label=AccumulateGrad]
	140360636365696 -> 140360636365024
	140360635210384 [label="stage3.1.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140360635210384 -> 140360636365696
	140360636365696 [label=AccumulateGrad]
	140360636364016 -> 140360636364544
	140360635208704 [label="stage3.1.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140360635208704 -> 140360636364016
	140360636364016 [label=AccumulateGrad]
	140360636364208 -> 140360636364544
	140360635208864 [label="stage3.1.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140360635208864 -> 140360636364208
	140360636364208 [label=AccumulateGrad]
	140360636363824 -> 140360636363968
	140360636363824 [label=NativeBatchNormBackward0]
	140360636365360 -> 140360636363824
	140360636365360 [label=ConvolutionBackward0]
	140360638166448 -> 140360636365360
	140360636366656 -> 140360636365360
	140360635207344 [label="stage3.1.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140360635207344 -> 140360636366656
	140360636366656 [label=AccumulateGrad]
	140360636365984 -> 140360636363824
	140360635207184 [label="stage3.1.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140360635207184 -> 140360636365984
	140360636365984 [label=AccumulateGrad]
	140360636364640 -> 140360636363824
	140360635207424 [label="stage3.1.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140360635207424 -> 140360636364640
	140360636364640 [label=AccumulateGrad]
	140360638162464 -> 140360636363344
	140360636364352 -> 140360636362672
	140360635123104 [label="stage3.2.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635123104 -> 140360636364352
	140360636364352 [label=AccumulateGrad]
	140360636362864 -> 140360636363680
	140360635123024 [label="stage3.2.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140360635123024 -> 140360636362864
	140360636362864 [label=AccumulateGrad]
	140360636362624 -> 140360636363680
	140360635123264 [label="stage3.2.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140360635123264 -> 140360636362624
	140360636362624 [label=AccumulateGrad]
	140360636362000 -> 140360636361808
	140360635121744 [label="stage3.2.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635121744 -> 140360636362000
	140360636362000 [label=AccumulateGrad]
	140360636361952 -> 140360636361328
	140360635137504 [label="stage3.2.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140360635137504 -> 140360636361952
	140360636361952 [label=AccumulateGrad]
	140360636362528 -> 140360636361328
	140360635137904 [label="stage3.2.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140360635137904 -> 140360636362528
	140360636362528 [label=AccumulateGrad]
	140360636361520 -> 140360636362336
	140360636361280 -> 140360636361856
	140360635134064 [label="stage3.2.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635134064 -> 140360636361280
	140360636361280 [label=AccumulateGrad]
	140360636360464 -> 140360636360608
	140360635133824 [label="stage3.2.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140360635133824 -> 140360636360464
	140360636360464 [label=AccumulateGrad]
	140360636360176 -> 140360636360608
	140360635134464 [label="stage3.2.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140360635134464 -> 140360636360176
	140360636360176 [label=AccumulateGrad]
	140360636359936 -> 140360636359504
	140360635130784 [label="stage3.2.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635130784 -> 140360636359936
	140360636359936 [label=AccumulateGrad]
	140360636359648 -> 140360636359264
	140360635130304 [label="stage3.2.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140360635130304 -> 140360636359648
	140360636359648 [label=AccumulateGrad]
	140360636360320 -> 140360636359264
	140360635130544 [label="stage3.2.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140360635130544 -> 140360636360320
	140360636360320 [label=AccumulateGrad]
	140360636359168 -> 140360636359984
	140360636358976 -> 140360636359120
	140360635126864 [label="stage3.2.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635126864 -> 140360636358976
	140360636358976 [label=AccumulateGrad]
	140360636358160 -> 140360636358304
	140360635126464 [label="stage3.2.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140360635126464 -> 140360636358160
	140360636358160 [label=AccumulateGrad]
	140360636357920 -> 140360636358304
	140360635127264 [label="stage3.2.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140360635127264 -> 140360636357920
	140360636357920 [label=AccumulateGrad]
	140360636357488 -> 140360636357248
	140360635123424 [label="stage3.2.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635123424 -> 140360636357488
	140360636357488 [label=AccumulateGrad]
	140360636357968 -> 140360636355136
	140360635122944 [label="stage3.2.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140360635122944 -> 140360636357968
	140360636357968 [label=AccumulateGrad]
	140360636355280 -> 140360636355136
	140360635123184 [label="stage3.2.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140360635123184 -> 140360636355280
	140360636355280 [label=AccumulateGrad]
	140360636356480 -> 140360636356144
	140360636355760 -> 140360636353936
	140360635087792 [label="stage3.2.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635087792 -> 140360636355760
	140360636355760 [label=AccumulateGrad]
	140360636353072 -> 140360636350720
	140360635087712 [label="stage3.2.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140360635087712 -> 140360636353072
	140360636353072 [label=AccumulateGrad]
	140360636351584 -> 140360636350720
	140360635087872 [label="stage3.2.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140360635087872 -> 140360636351584
	140360636351584 [label=AccumulateGrad]
	140360642884896 -> 140360652026208
	140360635086352 [label="stage3.2.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635086352 -> 140360642884896
	140360642884896 [label=AccumulateGrad]
	140360633702464 -> 140360638168560
	140360635086192 [label="stage3.2.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140360635086192 -> 140360633702464
	140360633702464 [label=AccumulateGrad]
	140360633696656 -> 140360638168560
	140360635086272 [label="stage3.2.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140360635086272 -> 140360633696656
	140360633696656 [label=AccumulateGrad]
	140360638169040 -> 140360638168752
	140360636662256 -> 140360636662352
	140360635083232 [label="stage3.2.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140360635083232 -> 140360636662256
	140360636662256 [label=AccumulateGrad]
	140360636663984 -> 140360636664272
	140360635083152 [label="stage3.2.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140360635083152 -> 140360636663984
	140360636663984 [label=AccumulateGrad]
	140360636665952 -> 140360636664272
	140360635083312 [label="stage3.2.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140360635083312 -> 140360636665952
	140360636665952 [label=AccumulateGrad]
	140360636665904 -> 140360636666384
	140360635079072 [label="stage3.3.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635079072 -> 140360636665904
	140360636665904 [label=AccumulateGrad]
	140360636666432 -> 140360636666192
	140360635074832 [label="stage3.3.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140360635074832 -> 140360636666432
	140360636666432 [label=AccumulateGrad]
	140360636666480 -> 140360636666192
	140360635078992 [label="stage3.3.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140360635078992 -> 140360636666480
	140360636666480 [label=AccumulateGrad]
	140360636667056 -> 140360636667248
	140360635073792 [label="stage3.3.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635073792 -> 140360636667056
	140360636667056 [label=AccumulateGrad]
	140360636667296 -> 140360636667488
	140360635073552 [label="stage3.3.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140360635073552 -> 140360636667296
	140360636667296 [label=AccumulateGrad]
	140360636667440 -> 140360636667488
	140360635073632 [label="stage3.3.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140360635073632 -> 140360636667440
	140360636667440 [label=AccumulateGrad]
	140360636666960 -> 140360636667920
	140360636667872 -> 140360636668352
	140360635088352 [label="stage3.3.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635088352 -> 140360636667872
	140360636667872 [label=AccumulateGrad]
	140360636668400 -> 140360636667536
	140360635087952 [label="stage3.3.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140360635087952 -> 140360636668400
	140360636668400 [label=AccumulateGrad]
	140360636668880 -> 140360636667536
	140360635088592 [label="stage3.3.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140360635088592 -> 140360636668880
	140360636668880 [label=AccumulateGrad]
	140360636668976 -> 140360636668832
	140360635084912 [label="stage3.3.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635084912 -> 140360636668976
	140360636668976 [label=AccumulateGrad]
	140360636669168 -> 140360636669504
	140360635084272 [label="stage3.3.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140360635084272 -> 140360636669168
	140360636669168 [label=AccumulateGrad]
	140360636669456 -> 140360636669504
	140360635084512 [label="stage3.3.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140360635084512 -> 140360636669456
	140360636669456 [label=AccumulateGrad]
	140360636669408 -> 140360636669552
	140360636669792 -> 140360636670224
	140360635080512 [label="stage3.3.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635080512 -> 140360636669792
	140360636669792 [label=AccumulateGrad]
	140360636670272 -> 140360636670320
	140360635079792 [label="stage3.3.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140360635079792 -> 140360636670272
	140360636670272 [label=AccumulateGrad]
	140360636670560 -> 140360636670320
	140360635080912 [label="stage3.3.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140360635080912 -> 140360636670560
	140360636670560 [label=AccumulateGrad]
	140360636670656 -> 140360636670128
	140360635075472 [label="stage3.3.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635075472 -> 140360636670656
	140360636670656 [label=AccumulateGrad]
	140360636670944 -> 140360636671328
	140360635074352 [label="stage3.3.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140360635074352 -> 140360636670944
	140360636670944 [label=AccumulateGrad]
	140360636671280 -> 140360636671328
	140360635075072 [label="stage3.3.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140360635075072 -> 140360636671280
	140360636671280 [label=AccumulateGrad]
	140360636671376 -> 140360636671424
	140360636671568 -> 140360636671952
	140360635022736 [label="stage3.3.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635022736 -> 140360636671568
	140360636671568 [label=AccumulateGrad]
	140360636671856 -> 140360636670080
	140360635022656 [label="stage3.3.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140360635022656 -> 140360636671856
	140360636671856 [label=AccumulateGrad]
	140360636672000 -> 140360636670080
	140360635022816 [label="stage3.3.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140360635022816 -> 140360636672000
	140360636672000 [label=AccumulateGrad]
	140360636672768 -> 140360636672912
	140360635021456 [label="stage3.3.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635021456 -> 140360636672768
	140360636672768 [label=AccumulateGrad]
	140360636672624 -> 140360636673104
	140360635021296 [label="stage3.3.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140360635021296 -> 140360636672624
	140360636672624 [label=AccumulateGrad]
	140360636673056 -> 140360636673104
	140360635021376 [label="stage3.3.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140360635021376 -> 140360636673056
	140360636673056 [label=AccumulateGrad]
	140360636673152 -> 140360636673200
	140360636673392 -> 140360636673488
	140360636673392 [label=UpsampleBilinear2DBackward0]
	140360662735728 -> 140360636673392
	140360662735728 [label=NativeBatchNormBackward0]
	140360636672864 -> 140360662735728
	140360636672864 [label=ConvolutionBackward0]
	140360636671232 -> 140360636672864
	140360636671232 [label=ReluBackward0]
	140360636670896 -> 140360636671232
	140360636670896 [label=AddBackward0]
	140360636670512 -> 140360636670896
	140360636670512 [label=NativeBatchNormBackward0]
	140360636669744 -> 140360636670512
	140360636669744 [label=ConvolutionBackward0]
	140360636668448 -> 140360636669744
	140360636668448 [label=ReluBackward0]
	140360636667968 -> 140360636668448
	140360636667968 [label=NativeBatchNormBackward0]
	140360636667200 -> 140360636667968
	140360636667200 [label=ConvolutionBackward0]
	140360636670848 -> 140360636667200
	140360636670848 [label=ReluBackward0]
	140360636666288 -> 140360636670848
	140360636666288 [label=AddBackward0]
	140360636664800 -> 140360636666288
	140360636664800 [label=NativeBatchNormBackward0]
	140360642877600 -> 140360636664800
	140360642877600 [label=ConvolutionBackward0]
	140360636358640 -> 140360642877600
	140360636358640 [label=ReluBackward0]
	140360636359312 -> 140360636358640
	140360636359312 [label=NativeBatchNormBackward0]
	140360636358448 -> 140360636359312
	140360636358448 [label=ConvolutionBackward0]
	140360636665808 -> 140360636358448
	140360636665808 [label=ReluBackward0]
	140360636361136 -> 140360636665808
	140360636361136 [label=AddBackward0]
	140360636360848 -> 140360636361136
	140360636360848 [label=NativeBatchNormBackward0]
	140360636360656 -> 140360636360848
	140360636360656 [label=ConvolutionBackward0]
	140360636363872 -> 140360636360656
	140360636363872 [label=ReluBackward0]
	140360636365216 -> 140360636363872
	140360636365216 [label=NativeBatchNormBackward0]
	140360636365552 -> 140360636365216
	140360636365552 [label=ConvolutionBackward0]
	140360636359840 -> 140360636365552
	140360636359840 [label=ReluBackward0]
	140360636366704 -> 140360636359840
	140360636366704 [label=AddBackward0]
	140360668660544 -> 140360636366704
	140360668660544 [label=NativeBatchNormBackward0]
	140360633424176 -> 140360668660544
	140360633424176 [label=ConvolutionBackward0]
	140360633428592 -> 140360633424176
	140360633428592 [label=ReluBackward0]
	140360633430224 -> 140360633428592
	140360633430224 [label=NativeBatchNormBackward0]
	140360668832400 -> 140360633430224
	140360668832400 [label=ConvolutionBackward0]
	140360636366560 -> 140360668832400
	140360636366560 [label=ReluBackward0]
	140360676031792 -> 140360636366560
	140360676031792 [label=AddBackward0]
	140360676024016 -> 140360676031792
	140360676024016 [label=AddBackward0]
	140360662326704 -> 140360676024016
	140360662326704 [label=NativeBatchNormBackward0]
	140360887086832 -> 140360662326704
	140360887086832 [label=ConvolutionBackward0]
	140360636665856 -> 140360887086832
	140360635795584 -> 140360887086832
	140360635081552 [label="stage3.2.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140360635081552 -> 140360635795584
	140360635795584 [label=AccumulateGrad]
	140360903421392 -> 140360662326704
	140360635081392 [label="stage3.2.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140360635081392 -> 140360903421392
	140360903421392 [label=AccumulateGrad]
	140360676022096 -> 140360662326704
	140360635081632 [label="stage3.2.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140360635081632 -> 140360676022096
	140360676022096 [label=AccumulateGrad]
	140360636664704 -> 140360676024016
	140360676018448 -> 140360676031792
	140360676018448 [label=UpsampleBilinear2DBackward0]
	140360679844992 -> 140360676018448
	140360679844992 [label=NativeBatchNormBackward0]
	140360635795632 -> 140360679844992
	140360635795632 [label=ConvolutionBackward0]
	140360636662064 -> 140360635795632
	140360635794768 -> 140360635795632
	140360635081792 [label="stage3.2.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140360635081792 -> 140360635794768
	140360635794768 [label=AccumulateGrad]
	140360635794864 -> 140360679844992
	140360635080192 [label="stage3.2.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140360635080192 -> 140360635794864
	140360635794864 [label=AccumulateGrad]
	140360635795680 -> 140360679844992
	140360635081712 [label="stage3.2.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140360635081712 -> 140360635795680
	140360635795680 [label=AccumulateGrad]
	140360676020176 -> 140360668832400
	140360635020016 [label="stage3.3.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635020016 -> 140360676020176
	140360676020176 [label=AccumulateGrad]
	140360668834080 -> 140360633430224
	140360635019936 [label="stage3.3.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140360635019936 -> 140360668834080
	140360668834080 [label=AccumulateGrad]
	140360668831296 -> 140360633430224
	140360635020096 [label="stage3.3.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140360635020096 -> 140360668831296
	140360668831296 [label=AccumulateGrad]
	140360633425904 -> 140360633424176
	140360635018736 [label="stage3.3.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635018736 -> 140360633425904
	140360633425904 [label=AccumulateGrad]
	140360633422688 -> 140360668660544
	140360635018576 [label="stage3.3.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140360635018576 -> 140360633422688
	140360633422688 [label=AccumulateGrad]
	140360633431712 -> 140360668660544
	140360635018656 [label="stage3.3.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140360635018656 -> 140360633431712
	140360633431712 [label=AccumulateGrad]
	140360636366560 -> 140360636366704
	140360636366512 -> 140360636365552
	140360635017136 [label="stage3.3.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635017136 -> 140360636366512
	140360636366512 [label=AccumulateGrad]
	140360636364496 -> 140360636365216
	140360635017056 [label="stage3.3.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140360635017056 -> 140360636364496
	140360636364496 [label=AccumulateGrad]
	140360636363296 -> 140360636365216
	140360635017216 [label="stage3.3.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140360635017216 -> 140360636363296
	140360636363296 [label=AccumulateGrad]
	140360636362192 -> 140360636360656
	140360635015696 [label="stage3.3.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635015696 -> 140360636362192
	140360636362192 [label=AccumulateGrad]
	140360636361664 -> 140360636360848
	140360635015536 [label="stage3.3.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140360635015536 -> 140360636361664
	140360636361664 [label=AccumulateGrad]
	140360636363008 -> 140360636360848
	140360635015616 [label="stage3.3.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140360635015616 -> 140360636363008
	140360636363008 [label=AccumulateGrad]
	140360636359840 -> 140360636361136
	140360636358592 -> 140360636358448
	140360635014256 [label="stage3.3.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635014256 -> 140360636358592
	140360636358592 [label=AccumulateGrad]
	140360636358832 -> 140360636359312
	140360635014176 [label="stage3.3.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140360635014176 -> 140360636358832
	140360636358832 [label=AccumulateGrad]
	140360636354800 -> 140360636359312
	140360635014336 [label="stage3.3.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140360635014336 -> 140360636354800
	140360636354800 [label=AccumulateGrad]
	140360636355232 -> 140360642877600
	140360635012816 [label="stage3.3.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635012816 -> 140360636355232
	140360636355232 [label=AccumulateGrad]
	140360633698480 -> 140360636664800
	140360635012656 [label="stage3.3.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140360635012656 -> 140360633698480
	140360633698480 [label=AccumulateGrad]
	140360636664752 -> 140360636664800
	140360635012736 [label="stage3.3.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140360635012736 -> 140360636664752
	140360636664752 [label=AccumulateGrad]
	140360636665808 -> 140360636666288
	140360636666240 -> 140360636667200
	140360635011216 [label="stage3.3.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635011216 -> 140360636666240
	140360636666240 [label=AccumulateGrad]
	140360636668160 -> 140360636667968
	140360635011136 [label="stage3.3.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140360635011136 -> 140360636668160
	140360636668160 [label=AccumulateGrad]
	140360636668208 -> 140360636667968
	140360635011296 [label="stage3.3.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140360635011296 -> 140360636668208
	140360636668208 [label=AccumulateGrad]
	140360636669072 -> 140360636669744
	140360635009776 [label="stage3.3.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360635009776 -> 140360636669072
	140360636669072 [label=AccumulateGrad]
	140360636668784 -> 140360636670512
	140360635009616 [label="stage3.3.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140360635009616 -> 140360636668784
	140360636668784 [label=AccumulateGrad]
	140360636670176 -> 140360636670512
	140360635009696 [label="stage3.3.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140360635009696 -> 140360636670176
	140360636670176 [label=AccumulateGrad]
	140360636670848 -> 140360636670896
	140360636671904 -> 140360636672864
	140360634936416 [label="stage3.3.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140360634936416 -> 140360636671904
	140360636671904 [label=AccumulateGrad]
	140360636672960 -> 140360662735728
	140360634936256 [label="stage3.3.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140360634936256 -> 140360636672960
	140360636672960 [label=AccumulateGrad]
	140360636673248 -> 140360662735728
	140360634936496 [label="stage3.3.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140360634936496 -> 140360636673248
	140360636673248 [label=AccumulateGrad]
	140360636673536 -> 140360636673296
	140360636673536 [label=UpsampleBilinear2DBackward0]
	140360638168944 -> 140360636673536
	140360638168944 [label=NativeBatchNormBackward0]
	140360636669840 -> 140360638168944
	140360636669840 [label=ConvolutionBackward0]
	140360636666144 -> 140360636669840
	140360636666144 [label=ReluBackward0]
	140360636665616 -> 140360636666144
	140360636665616 [label=AddBackward0]
	140360636666336 -> 140360636665616
	140360636666336 [label=NativeBatchNormBackward0]
	140360636354944 -> 140360636666336
	140360636354944 [label=ConvolutionBackward0]
	140360636360512 -> 140360636354944
	140360636360512 [label=ReluBackward0]
	140360636363536 -> 140360636360512
	140360636363536 [label=NativeBatchNormBackward0]
	140360636366032 -> 140360636363536
	140360636366032 [label=ConvolutionBackward0]
	140360636669120 -> 140360636366032
	140360636669120 [label=ReluBackward0]
	140360668839264 -> 140360636669120
	140360668839264 [label=AddBackward0]
	140360676021952 -> 140360668839264
	140360676021952 [label=NativeBatchNormBackward0]
	140360662326272 -> 140360676021952
	140360662326272 [label=ConvolutionBackward0]
	140360635794432 -> 140360662326272
	140360635794432 [label=ReluBackward0]
	140360635794144 -> 140360635794432
	140360635794144 [label=NativeBatchNormBackward0]
	140360635794048 -> 140360635794144
	140360635794048 [label=ConvolutionBackward0]
	140360676022288 -> 140360635794048
	140360676022288 [label=ReluBackward0]
	140360635808976 -> 140360676022288
	140360635808976 [label=AddBackward0]
	140360635809648 -> 140360635808976
	140360635809648 [label=NativeBatchNormBackward0]
	140360635809456 -> 140360635809648
	140360635809456 [label=ConvolutionBackward0]
	140360635808352 -> 140360635809456
	140360635808352 [label=ReluBackward0]
	140360635807824 -> 140360635808352
	140360635807824 [label=NativeBatchNormBackward0]
	140360635808592 -> 140360635807824
	140360635808592 [label=ConvolutionBackward0]
	140360635809696 -> 140360635808592
	140360635809696 [label=ReluBackward0]
	140360635808256 -> 140360635809696
	140360635808256 [label=AddBackward0]
	140360635807776 -> 140360635808256
	140360635807776 [label=NativeBatchNormBackward0]
	140360635807632 -> 140360635807776
	140360635807632 [label=ConvolutionBackward0]
	140360635806624 -> 140360635807632
	140360635806624 [label=ReluBackward0]
	140360635806288 -> 140360635806624
	140360635806288 [label=NativeBatchNormBackward0]
	140360635806960 -> 140360635806288
	140360635806960 [label=ConvolutionBackward0]
	140360635807248 -> 140360635806960
	140360635807248 [label=ReluBackward0]
	140360635806432 -> 140360635807248
	140360635806432 [label=AddBackward0]
	140360635806240 -> 140360635806432
	140360635806240 [label=AddBackward0]
	140360635805232 -> 140360635806240
	140360635805232 [label=NativeBatchNormBackward0]
	140360635805136 -> 140360635805232
	140360635805136 [label=ConvolutionBackward0]
	140360635805424 -> 140360635805136
	140360635805424 [label=ReluBackward0]
	140360635805088 -> 140360635805424
	140360635805088 [label=NativeBatchNormBackward0]
	140360635804416 -> 140360635805088
	140360635804416 [label=ConvolutionBackward0]
	140360636665856 -> 140360635804416
	140360635803648 -> 140360635804416
	140360635078832 [label="stage3.2.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360635078832 -> 140360635803648
	140360635803648 [label=AccumulateGrad]
	140360635805280 -> 140360635805088
	140360635078672 [label="stage3.2.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140360635078672 -> 140360635805280
	140360635805280 [label=AccumulateGrad]
	140360635805568 -> 140360635805088
	140360635078912 [label="stage3.2.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140360635078912 -> 140360635805568
	140360635805568 [label=AccumulateGrad]
	140360635804992 -> 140360635805136
	140360635078752 [label="stage3.2.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140360635078752 -> 140360635804992
	140360635804992 [label=AccumulateGrad]
	140360635805904 -> 140360635805232
	140360635077392 [label="stage3.2.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140360635077392 -> 140360635805904
	140360635805904 [label=AccumulateGrad]
	140360635805952 -> 140360635805232
	140360635077472 [label="stage3.2.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140360635077472 -> 140360635805952
	140360635805952 [label=AccumulateGrad]
	140360635806336 -> 140360635806240
	140360635806336 [label=NativeBatchNormBackward0]
	140360635804320 -> 140360635806336
	140360635804320 [label=ConvolutionBackward0]
	140360636664704 -> 140360635804320
	140360635804896 -> 140360635804320
	140360635076112 [label="stage3.2.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140360635076112 -> 140360635804896
	140360635804896 [label=AccumulateGrad]
	140360635804752 -> 140360635806336
	140360635076032 [label="stage3.2.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140360635076032 -> 140360635804752
	140360635804752 [label=AccumulateGrad]
	140360635805616 -> 140360635806336
	140360635076192 [label="stage3.2.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140360635076192 -> 140360635805616
	140360635805616 [label=AccumulateGrad]
	140360636662064 -> 140360635806432
	140360635806096 -> 140360635806960
	140360635008176 [label="stage3.3.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635008176 -> 140360635806096
	140360635806096 [label=AccumulateGrad]
	140360635807008 -> 140360635806288
	140360635008096 [label="stage3.3.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140360635008096 -> 140360635807008
	140360635807008 [label=AccumulateGrad]
	140360635807104 -> 140360635806288
	140360635008256 [label="stage3.3.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140360635008256 -> 140360635807104
	140360635807104 [label=AccumulateGrad]
	140360635807584 -> 140360635807632
	140360635022016 [label="stage3.3.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635022016 -> 140360635807584
	140360635807584 [label=AccumulateGrad]
	140360635807152 -> 140360635807776
	140360635020896 [label="stage3.3.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140360635020896 -> 140360635807152
	140360635807152 [label=AccumulateGrad]
	140360635807920 -> 140360635807776
	140360635021616 [label="stage3.3.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140360635021616 -> 140360635807920
	140360635807920 [label=AccumulateGrad]
	140360635807248 -> 140360635808256
	140360635807680 -> 140360635808592
	140360635016976 [label="stage3.3.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635016976 -> 140360635807680
	140360635807680 [label=AccumulateGrad]
	140360635808640 -> 140360635807824
	140360635016736 [label="stage3.3.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140360635016736 -> 140360635808640
	140360635808640 [label=AccumulateGrad]
	140360635808928 -> 140360635807824
	140360635017376 [label="stage3.3.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140360635017376 -> 140360635808928
	140360635808928 [label=AccumulateGrad]
	140360635809120 -> 140360635809456
	140360635013376 [label="stage3.3.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635013376 -> 140360635809120
	140360635809120 [label=AccumulateGrad]
	140360635809264 -> 140360635809648
	140360635012576 [label="stage3.3.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140360635012576 -> 140360635809264
	140360635809264 [label=AccumulateGrad]
	140360635808784 -> 140360635809648
	140360635012976 [label="stage3.3.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140360635012976 -> 140360635808784
	140360635808784 [label=AccumulateGrad]
	140360635809696 -> 140360635808976
	140360635809600 -> 140360635794048
	140360635009296 [label="stage3.3.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360635009296 -> 140360635809600
	140360635809600 [label=AccumulateGrad]
	140360635794096 -> 140360635794144
	140360635009056 [label="stage3.3.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140360635009056 -> 140360635794096
	140360635794096 [label=AccumulateGrad]
	140360635794384 -> 140360635794144
	140360635009536 [label="stage3.3.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140360635009536 -> 140360635794384
	140360635794384 [label=AccumulateGrad]
	140360635794480 -> 140360662326272
	140360634941056 [label="stage3.3.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634941056 -> 140360635794480
	140360635794480 [label=AccumulateGrad]
	140360635794720 -> 140360676021952
	140360634940816 [label="stage3.3.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140360634940816 -> 140360635794720
	140360635794720 [label=AccumulateGrad]
	140360635795536 -> 140360676021952
	140360634940976 [label="stage3.3.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140360634940976 -> 140360635795536
	140360635795536 [label=AccumulateGrad]
	140360676022288 -> 140360668839264
	140360633424848 -> 140360636366032
	140360634939456 [label="stage3.3.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634939456 -> 140360633424848
	140360633424848 [label=AccumulateGrad]
	140360636365888 -> 140360636363536
	140360634939296 [label="stage3.3.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140360634939296 -> 140360636365888
	140360636365888 [label=AccumulateGrad]
	140360636363152 -> 140360636363536
	140360634939536 [label="stage3.3.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140360634939536 -> 140360636363152
	140360636363152 [label=AccumulateGrad]
	140360636359792 -> 140360636354944
	140360634938016 [label="stage3.3.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634938016 -> 140360636359792
	140360636359792 [label=AccumulateGrad]
	140360636361184 -> 140360636666336
	140360634937776 [label="stage3.3.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140360634937776 -> 140360636361184
	140360636361184 [label=AccumulateGrad]
	140360636353216 -> 140360636666336
	140360634937936 [label="stage3.3.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140360634937936 -> 140360636353216
	140360636353216 [label=AccumulateGrad]
	140360636669120 -> 140360636665616
	140360636668112 -> 140360636669840
	140360634934896 [label="stage3.3.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140360634934896 -> 140360636668112
	140360636668112 [label=AccumulateGrad]
	140360636671616 -> 140360638168944
	140360634934736 [label="stage3.3.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140360634934736 -> 140360636671616
	140360636671616 [label=AccumulateGrad]
	140360636673440 -> 140360638168944
	140360634934976 [label="stage3.3.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140360634934976 -> 140360636673440
	140360636673440 [label=AccumulateGrad]
	140360636673680 -> 140360636673584
	140360634939776 [label="stage4.0.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634939776 -> 140360636673680
	140360636673680 [label=AccumulateGrad]
	140360636673008 -> 140360636674112
	140360634939136 [label="stage4.0.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140360634939136 -> 140360636673008
	140360636673008 [label=AccumulateGrad]
	140360636674208 -> 140360636674112
	140360634940176 [label="stage4.0.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140360634940176 -> 140360636674208
	140360636674208 [label=AccumulateGrad]
	140360636674304 -> 140360636674496
	140360634939376 [label="stage4.0.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634939376 -> 140360636674304
	140360636674304 [label=AccumulateGrad]
	140360636674544 -> 140360636674640
	140360634935616 [label="stage4.0.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140360634935616 -> 140360636674544
	140360636674544 [label=AccumulateGrad]
	140360636674592 -> 140360636674640
	140360634935856 [label="stage4.0.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140360634935856 -> 140360636674592
	140360636674592 [label=AccumulateGrad]
	140360636674352 -> 140360636674736
	140360636674832 -> 140360636675024
	140360634932176 [label="stage4.0.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634932176 -> 140360636674832
	140360636674832 [label=AccumulateGrad]
	140360636675072 -> 140360636675120
	140360634931776 [label="stage4.0.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140360634931776 -> 140360636675072
	140360636675072 [label=AccumulateGrad]
	140360636675216 -> 140360636675120
	140360634932576 [label="stage4.0.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140360634932576 -> 140360636675216
	140360636675216 [label=AccumulateGrad]
	140360636674400 -> 140360636675552
	140360634936096 [label="stage4.0.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634936096 -> 140360636674400
	140360636674400 [label=AccumulateGrad]
	140360636675600 -> 140360636675264
	140360634928256 [label="stage4.0.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140360634928256 -> 140360636675600
	140360636675600 [label=AccumulateGrad]
	140360636675648 -> 140360636675264
	140360634928496 [label="stage4.0.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140360634928496 -> 140360636675648
	140360636675648 [label=AccumulateGrad]
	140360636675792 -> 140360636675840
	140360636675936 -> 140360636676128
	140360634925216 [label="stage4.0.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634925216 -> 140360636675936
	140360636675936 [label=AccumulateGrad]
	140360636676176 -> 140360636676224
	140360634875600 [label="stage4.0.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140360634875600 -> 140360636676176
	140360636676176 [label=AccumulateGrad]
	140360636676032 -> 140360636676224
	140360634875840 [label="stage4.0.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140360634875840 -> 140360636676032
	140360636676032 [label=AccumulateGrad]
	140360636676416 -> 140360636676560
	140360634874400 [label="stage4.0.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634874400 -> 140360636676416
	140360636676416 [label=AccumulateGrad]
	140360636676320 -> 140360636676848
	140360634874080 [label="stage4.0.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140360634874080 -> 140360636676320
	140360636676320 [label=AccumulateGrad]
	140360636676800 -> 140360636676848
	140360634874320 [label="stage4.0.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140360634874320 -> 140360636676800
	140360636676800 [label=AccumulateGrad]
	140360636676896 -> 140360636676944
	140360636675744 -> 140360636677280
	140360634872800 [label="stage4.0.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634872800 -> 140360636675744
	140360636675744 [label=AccumulateGrad]
	140360636677328 -> 140360636677040
	140360634872560 [label="stage4.0.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140360634872560 -> 140360636677328
	140360636677328 [label=AccumulateGrad]
	140360636677472 -> 140360636677040
	140360634872880 [label="stage4.0.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140360634872880 -> 140360636677472
	140360636677472 [label=AccumulateGrad]
	140360636677568 -> 140360636677712
	140360634871360 [label="stage4.0.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634871360 -> 140360636677568
	140360636677568 [label=AccumulateGrad]
	140360636677760 -> 140360636677856
	140360634871040 [label="stage4.0.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140360634871040 -> 140360636677760
	140360636677760 [label=AccumulateGrad]
	140360636677808 -> 140360636677856
	140360634871280 [label="stage4.0.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140360634871280 -> 140360636677808
	140360636677808 [label=AccumulateGrad]
	140360636677904 -> 140360636677664
	140360636677952 -> 140360637333952
	140360636677952 [label=UpsampleBilinear2DBackward0]
	140360636677376 -> 140360636677952
	140360636677376 [label=NativeBatchNormBackward0]
	140360636676992 -> 140360636677376
	140360636676992 [label=ConvolutionBackward0]
	140360636677136 -> 140360636676992
	140360636677136 [label=ReluBackward0]
	140360636675888 -> 140360636677136
	140360636675888 [label=AddBackward0]
	140360636676080 -> 140360636675888
	140360636676080 [label=NativeBatchNormBackward0]
	140360636675696 -> 140360636676080
	140360636675696 [label=ConvolutionBackward0]
	140360636674688 -> 140360636675696
	140360636674688 [label=ReluBackward0]
	140360636674928 -> 140360636674688
	140360636674928 [label=NativeBatchNormBackward0]
	140360636673632 -> 140360636674928
	140360636673632 [label=ConvolutionBackward0]
	140360636676464 -> 140360636673632
	140360636676464 [label=ReluBackward0]
	140360636666912 -> 140360636676464
	140360636666912 [label=AddBackward0]
	140360636667104 -> 140360636666912
	140360636667104 [label=NativeBatchNormBackward0]
	140360636366368 -> 140360636667104
	140360636366368 [label=ConvolutionBackward0]
	140360676020128 -> 140360636366368
	140360676020128 [label=ReluBackward0]
	140360633424320 -> 140360676020128
	140360633424320 [label=NativeBatchNormBackward0]
	140360635794816 -> 140360633424320
	140360635794816 [label=ConvolutionBackward0]
	140360636671520 -> 140360635794816
	140360636671520 [label=ReluBackward0]
	140360635808112 -> 140360636671520
	140360635808112 [label=AddBackward0]
	140360635807968 -> 140360635808112
	140360635807968 [label=NativeBatchNormBackward0]
	140360635808304 -> 140360635807968
	140360635808304 [label=ConvolutionBackward0]
	140360635805760 -> 140360635808304
	140360635805760 [label=ReluBackward0]
	140360635805664 -> 140360635805760
	140360635805664 [label=NativeBatchNormBackward0]
	140360635804944 -> 140360635805664
	140360635804944 [label=ConvolutionBackward0]
	140360635809168 -> 140360635804944
	140360635809168 [label=ReluBackward0]
	140360635803744 -> 140360635809168
	140360635803744 [label=AddBackward0]
	140360635804224 -> 140360635803744
	140360635804224 [label=NativeBatchNormBackward0]
	140360635803120 -> 140360635804224
	140360635803120 [label=ConvolutionBackward0]
	140360635803408 -> 140360635803120
	140360635803408 [label=ReluBackward0]
	140360635803072 -> 140360635803408
	140360635803072 [label=NativeBatchNormBackward0]
	140360635802400 -> 140360635803072
	140360635802400 [label=ConvolutionBackward0]
	140360635804080 -> 140360635802400
	140360635804080 [label=ReluBackward0]
	140360635802592 -> 140360635804080
	140360635802592 [label=AddBackward0]
	140360635802256 -> 140360635802592
	140360635802256 [label=AddBackward0]
	140360635802064 -> 140360635802256
	140360635802064 [label=NativeBatchNormBackward0]
	140360635801200 -> 140360635802064
	140360635801200 [label=ConvolutionBackward0]
	140360636673344 -> 140360635801200
	140360635801584 -> 140360635801200
	140360634933136 [label="stage3.3.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140360634933136 -> 140360635801584
	140360635801584 [label=AccumulateGrad]
	140360635802208 -> 140360635802064
	140360634932896 [label="stage3.3.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140360634932896 -> 140360635802208
	140360635802208 [label=AccumulateGrad]
	140360635802448 -> 140360635802064
	140360634933216 [label="stage3.3.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140360634933216 -> 140360635802448
	140360635802448 [label=AccumulateGrad]
	140360636671232 -> 140360635802256
	140360635801776 -> 140360635802592
	140360635801776 [label=UpsampleBilinear2DBackward0]
	140360635801920 -> 140360635801776
	140360635801920 [label=NativeBatchNormBackward0]
	140360635801104 -> 140360635801920
	140360635801104 [label=ConvolutionBackward0]
	140360636666144 -> 140360635801104
	140360635801056 -> 140360635801104
	140360634933456 [label="stage3.3.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140360634933456 -> 140360635801056
	140360635801056 [label=AccumulateGrad]
	140360635801392 -> 140360635801920
	140360634931616 [label="stage3.3.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140360634931616 -> 140360635801392
	140360635801392 [label=AccumulateGrad]
	140360635801632 -> 140360635801920
	140360634933376 [label="stage3.3.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140360634933376 -> 140360635801632
	140360635801632 [label=AccumulateGrad]
	140360635802880 -> 140360635802400
	140360634869760 [label="stage4.0.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634869760 -> 140360635802880
	140360635802880 [label=AccumulateGrad]
	140360635803264 -> 140360635803072
	140360634869520 [label="stage4.0.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140360634869520 -> 140360635803264
	140360635803264 [label=AccumulateGrad]
	140360635803552 -> 140360635803072
	140360634869840 [label="stage4.0.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140360634869840 -> 140360635803552
	140360635803552 [label=AccumulateGrad]
	140360635802976 -> 140360635803120
	140360634868320 [label="stage4.0.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634868320 -> 140360635802976
	140360635802976 [label=AccumulateGrad]
	140360635803936 -> 140360635804224
	140360634868000 [label="stage4.0.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140360634868000 -> 140360635803936
	140360635803936 [label=AccumulateGrad]
	140360635803216 -> 140360635804224
	140360634868160 [label="stage4.0.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140360634868160 -> 140360635803216
	140360635803216 [label=AccumulateGrad]
	140360635804080 -> 140360635803744
	140360635804272 -> 140360635804944
	140360634866720 [label="stage4.0.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634866720 -> 140360635804272
	140360635804272 [label=AccumulateGrad]
	140360635805808 -> 140360635805664
	140360634866480 [label="stage4.0.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140360634866480 -> 140360635805808
	140360635805808 [label=AccumulateGrad]
	140360635806576 -> 140360635805664
	140360634866800 [label="stage4.0.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140360634866800 -> 140360635806576
	140360635806576 [label=AccumulateGrad]
	140360635807440 -> 140360635808304
	140360634865280 [label="stage4.0.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634865280 -> 140360635807440
	140360635807440 [label=AccumulateGrad]
	140360635808496 -> 140360635807968
	140360634864960 [label="stage4.0.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140360634864960 -> 140360635808496
	140360635808496 [label=AccumulateGrad]
	140360635806912 -> 140360635807968
	140360634865200 [label="stage4.0.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140360634865200 -> 140360635806912
	140360635806912 [label=AccumulateGrad]
	140360635809168 -> 140360635808112
	140360635793664 -> 140360635794816
	140360634863680 [label="stage4.0.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634863680 -> 140360635793664
	140360635793664 [label=AccumulateGrad]
	140360635809312 -> 140360633424320
	140360634863440 [label="stage4.0.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140360634863440 -> 140360635809312
	140360635809312 [label=AccumulateGrad]
	140360635794000 -> 140360633424320
	140360634863760 [label="stage4.0.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140360634863760 -> 140360635794000
	140360635794000 [label=AccumulateGrad]
	140360668834560 -> 140360636366368
	140360634862240 [label="stage4.0.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634862240 -> 140360668834560
	140360668834560 [label=AccumulateGrad]
	140360636353456 -> 140360636667104
	140360634861920 [label="stage4.0.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140360634861920 -> 140360636353456
	140360636353456 [label=AccumulateGrad]
	140360636358496 -> 140360636667104
	140360634862160 [label="stage4.0.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140360634862160 -> 140360636358496
	140360636358496 [label=AccumulateGrad]
	140360636671520 -> 140360636666912
	140360636673728 -> 140360636673632
	140360634860640 [label="stage4.0.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634860640 -> 140360636673728
	140360636673728 [label=AccumulateGrad]
	140360636674160 -> 140360636674928
	140360634860400 [label="stage4.0.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140360634860400 -> 140360636674160
	140360636674160 [label=AccumulateGrad]
	140360636674448 -> 140360636674928
	140360634860720 [label="stage4.0.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140360634860720 -> 140360636674448
	140360636674448 [label=AccumulateGrad]
	140360636675456 -> 140360636675696
	140360634874960 [label="stage4.0.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634874960 -> 140360636675456
	140360636675456 [label=AccumulateGrad]
	140360636675984 -> 140360636676080
	140360634874480 [label="stage4.0.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140360634874480 -> 140360636675984
	140360636675984 [label=AccumulateGrad]
	140360636675504 -> 140360636676080
	140360634874720 [label="stage4.0.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140360634874720 -> 140360636675504
	140360636675504 [label=AccumulateGrad]
	140360636676464 -> 140360636675888
	140360636676512 -> 140360636676992
	140360634770176 [label="stage4.0.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140360634770176 -> 140360636676512
	140360636676512 [label=AccumulateGrad]
	140360636677424 -> 140360636677376
	140360634769936 [label="stage4.0.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140360634769936 -> 140360636677424
	140360636677424 [label=AccumulateGrad]
	140360636677088 -> 140360636677376
	140360634770576 [label="stage4.0.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140360634770576 -> 140360636677088
	140360636677088 [label=AccumulateGrad]
	140360637334000 -> 140360637334192
	140360637334000 [label=UpsampleBilinear2DBackward0]
	140360636677616 -> 140360637334000
	140360636677616 [label=NativeBatchNormBackward0]
	140360636675168 -> 140360636677616
	140360636675168 [label=ConvolutionBackward0]
	140360636673776 -> 140360636675168
	140360636673776 [label=ReluBackward0]
	140360636673824 -> 140360636673776
	140360636673824 [label=AddBackward0]
	140360636672816 -> 140360636673824
	140360636672816 [label=NativeBatchNormBackward0]
	140360636362480 -> 140360636672816
	140360636362480 [label=ConvolutionBackward0]
	140360635808448 -> 140360636362480
	140360635808448 [label=ReluBackward0]
	140360635806480 -> 140360635808448
	140360635806480 [label=NativeBatchNormBackward0]
	140360635803600 -> 140360635806480
	140360635803600 [label=ConvolutionBackward0]
	140360636674784 -> 140360635803600
	140360636674784 [label=ReluBackward0]
	140360635802928 -> 140360636674784
	140360635802928 [label=AddBackward0]
	140360635802736 -> 140360635802928
	140360635802736 [label=NativeBatchNormBackward0]
	140360635801536 -> 140360635802736
	140360635801536 [label=ConvolutionBackward0]
	140360635800912 -> 140360635801536
	140360635800912 [label=ReluBackward0]
	140360635800048 -> 140360635800912
	140360635800048 [label=NativeBatchNormBackward0]
	140360635800528 -> 140360635800048
	140360635800528 [label=ConvolutionBackward0]
	140360635801728 -> 140360635800528
	140360635801728 [label=ReluBackward0]
	140360635799520 -> 140360635801728
	140360635799520 [label=AddBackward0]
	140360635799856 -> 140360635799520
	140360635799856 [label=NativeBatchNormBackward0]
	140360635799184 -> 140360635799856
	140360635799184 [label=ConvolutionBackward0]
	140360635798560 -> 140360635799184
	140360635798560 [label=ReluBackward0]
	140360635798224 -> 140360635798560
	140360635798224 [label=NativeBatchNormBackward0]
	140360635798896 -> 140360635798224
	140360635798896 [label=ConvolutionBackward0]
	140360635799904 -> 140360635798896
	140360635799904 [label=ReluBackward0]
	140360635798368 -> 140360635799904
	140360635798368 [label=AddBackward0]
	140360635798176 -> 140360635798368
	140360635798176 [label=NativeBatchNormBackward0]
	140360635797888 -> 140360635798176
	140360635797888 [label=ConvolutionBackward0]
	140360635797744 -> 140360635797888
	140360635797744 [label=ReluBackward0]
	140360635797504 -> 140360635797744
	140360635797504 [label=NativeBatchNormBackward0]
	140360635797024 -> 140360635797504
	140360635797024 [label=ConvolutionBackward0]
	140360635797600 -> 140360635797024
	140360635797600 [label=ReluBackward0]
	140360635796688 -> 140360635797600
	140360635796688 [label=AddBackward0]
	140360635796352 -> 140360635796688
	140360635796352 [label=AddBackward0]
	140360635796112 -> 140360635796352
	140360635796112 [label=NativeBatchNormBackward0]
	140360635796448 -> 140360635796112
	140360635796448 [label=ConvolutionBackward0]
	140360635796976 -> 140360635796448
	140360635796976 [label=ReluBackward0]
	140360635797408 -> 140360635796976
	140360635797408 [label=NativeBatchNormBackward0]
	140360635796592 -> 140360635797408
	140360635796592 [label=ConvolutionBackward0]
	140360636673344 -> 140360635796592
	140360635797264 -> 140360635796592
	140360634930096 [label="stage3.3.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634930096 -> 140360635797264
	140360635797264 [label=AccumulateGrad]
	140360635796736 -> 140360635797408
	140360634929856 [label="stage3.3.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140360634929856 -> 140360635796736
	140360635796736 [label=AccumulateGrad]
	140360635796304 -> 140360635797408
	140360634930176 [label="stage3.3.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140360634930176 -> 140360635796304
	140360635796304 [label=AccumulateGrad]
	140360635796064 -> 140360635796448
	140360634929936 [label="stage3.3.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140360634929936 -> 140360635796064
	140360635796064 [label=AccumulateGrad]
	140360635796208 -> 140360635796112
	140360634928336 [label="stage3.3.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140360634928336 -> 140360635796208
	140360635796208 [label=AccumulateGrad]
	140360635796256 -> 140360635796112
	140360634928416 [label="stage3.3.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140360634928416 -> 140360635796256
	140360635796256 [label=AccumulateGrad]
	140360635796544 -> 140360635796352
	140360635796544 [label=NativeBatchNormBackward0]
	140360635796784 -> 140360635796544
	140360635796784 [label=ConvolutionBackward0]
	140360636671232 -> 140360635796784
	140360635798080 -> 140360635796784
	140360634926896 [label="stage3.3.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140360634926896 -> 140360635798080
	140360635798080 [label=AccumulateGrad]
	140360635795968 -> 140360635796544
	140360634926816 [label="stage3.3.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140360634926816 -> 140360635795968
	140360635795968 [label=AccumulateGrad]
	140360635796016 -> 140360635796544
	140360634927056 [label="stage3.3.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140360634927056 -> 140360635796016
	140360635796016 [label=AccumulateGrad]
	140360636666144 -> 140360635796688
	140360635796880 -> 140360635797024
	140360634871200 [label="stage4.0.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634871200 -> 140360635796880
	140360635796880 [label=AccumulateGrad]
	140360635796832 -> 140360635797504
	140360634870800 [label="stage4.0.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140360634870800 -> 140360635796832
	140360635796832 [label=AccumulateGrad]
	140360635797072 -> 140360635797504
	140360634871440 [label="stage4.0.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140360634871440 -> 140360635797072
	140360635797072 [label=AccumulateGrad]
	140360635797552 -> 140360635797888
	140360634867760 [label="stage4.0.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634867760 -> 140360635797552
	140360635797552 [label=AccumulateGrad]
	140360635797168 -> 140360635798176
	140360634867120 [label="stage4.0.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140360634867120 -> 140360635797168
	140360635797168 [label=AccumulateGrad]
	140360635798272 -> 140360635798176
	140360634867360 [label="stage4.0.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140360634867360 -> 140360635798272
	140360635798272 [label=AccumulateGrad]
	140360635797600 -> 140360635798368
	140360635797696 -> 140360635798896
	140360634863840 [label="stage4.0.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634863840 -> 140360635797696
	140360635797696 [label=AccumulateGrad]
	140360635798944 -> 140360635798224
	140360634863600 [label="stage4.0.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140360634863600 -> 140360635798944
	140360635798944 [label=AccumulateGrad]
	140360635799040 -> 140360635798224
	140360634864080 [label="stage4.0.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140360634864080 -> 140360635799040
	140360635799040 [label=AccumulateGrad]
	140360635799376 -> 140360635799184
	140360634860560 [label="stage4.0.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634860560 -> 140360635799376
	140360635799376 [label=AccumulateGrad]
	140360635799760 -> 140360635799856
	140360634859760 [label="stage4.0.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140360634859760 -> 140360635799760
	140360635799760 [label=AccumulateGrad]
	140360635799088 -> 140360635799856
	140360634860160 [label="stage4.0.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140360634860160 -> 140360635799088
	140360635799088 [label=AccumulateGrad]
	140360635799904 -> 140360635799520
	140360635799568 -> 140360635800528
	140360634776176 [label="stage4.0.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634776176 -> 140360635799568
	140360635799568 [label=AccumulateGrad]
	140360635800576 -> 140360635800048
	140360634776096 [label="stage4.0.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140360634776096 -> 140360635800576
	140360635800576 [label=AccumulateGrad]
	140360635800288 -> 140360635800048
	140360634776336 [label="stage4.0.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140360634776336 -> 140360635800288
	140360635800288 [label=AccumulateGrad]
	140360635801248 -> 140360635801536
	140360634774816 [label="stage4.0.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634774816 -> 140360635801248
	140360635801248 [label=AccumulateGrad]
	140360635800720 -> 140360635802736
	140360634774576 [label="stage4.0.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140360634774576 -> 140360635800720
	140360635800720 [label=AccumulateGrad]
	140360635802304 -> 140360635802736
	140360634774656 [label="stage4.0.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140360634774656 -> 140360635802304
	140360635802304 [label=AccumulateGrad]
	140360635801728 -> 140360635802928
	140360635801872 -> 140360635803600
	140360634773136 [label="stage4.0.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634773136 -> 140360635801872
	140360635801872 [label=AccumulateGrad]
	140360635803888 -> 140360635806480
	140360634773056 [label="stage4.0.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140360634773056 -> 140360635803888
	140360635803888 [label=AccumulateGrad]
	140360635806768 -> 140360635806480
	140360634773296 [label="stage4.0.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140360634773296 -> 140360635806768
	140360635806768 [label=AccumulateGrad]
	140360635793616 -> 140360636362480
	140360634771776 [label="stage4.0.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634771776 -> 140360635793616
	140360635793616 [label=AccumulateGrad]
	140360635809024 -> 140360636672816
	140360634771536 [label="stage4.0.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140360634771536 -> 140360635809024
	140360635809024 [label=AccumulateGrad]
	140360635794192 -> 140360636672816
	140360634771616 [label="stage4.0.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140360634771616 -> 140360635794192
	140360635794192 [label=AccumulateGrad]
	140360636674784 -> 140360636673824
	140360636674880 -> 140360636675168
	140360634766656 [label="stage4.0.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140360634766656 -> 140360636674880
	140360636674880 [label=AccumulateGrad]
	140360636676272 -> 140360636677616
	140360634766416 [label="stage4.0.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140360634766416 -> 140360636676272
	140360636676272 [label=AccumulateGrad]
	140360636672576 -> 140360636677616
	140360634766896 [label="stage4.0.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140360634766896 -> 140360636672576
	140360636672576 [label=AccumulateGrad]
	140360637334240 -> 140360637334384
	140360637334240 [label=UpsampleBilinear2DBackward0]
	140360637334144 -> 140360637334240
	140360637334144 [label=NativeBatchNormBackward0]
	140360636677184 -> 140360637334144
	140360636677184 [label=ConvolutionBackward0]
	140360635803792 -> 140360636677184
	140360635803792 [label=ReluBackward0]
	140360635800384 -> 140360635803792
	140360635800384 [label=AddBackward0]
	140360635804560 -> 140360635800384
	140360635804560 [label=NativeBatchNormBackward0]
	140360635800960 -> 140360635804560
	140360635800960 [label=ConvolutionBackward0]
	140360635800240 -> 140360635800960
	140360635800240 [label=ReluBackward0]
	140360635798848 -> 140360635800240
	140360635798848 [label=NativeBatchNormBackward0]
	140360635797840 -> 140360635798848
	140360635797840 [label=ConvolutionBackward0]
	140360635802544 -> 140360635797840
	140360635802544 [label=ReluBackward0]
	140360635797216 -> 140360635802544
	140360635797216 [label=AddBackward0]
	140360635796928 -> 140360635797216
	140360635796928 [label=NativeBatchNormBackward0]
	140360635797648 -> 140360635796928
	140360635797648 [label=ConvolutionBackward0]
	140360635797312 -> 140360635797648
	140360635797312 [label=ReluBackward0]
	140360635797792 -> 140360635797312
	140360635797792 [label=NativeBatchNormBackward0]
	140360635797984 -> 140360635797792
	140360635797984 [label=ConvolutionBackward0]
	140360635796400 -> 140360635797984
	140360635796400 [label=ReluBackward0]
	140360635798752 -> 140360635796400
	140360635798752 [label=AddBackward0]
	140360635799136 -> 140360635798752
	140360635799136 [label=NativeBatchNormBackward0]
	140360635799328 -> 140360635799136
	140360635799328 [label=ConvolutionBackward0]
	140360635799664 -> 140360635799328
	140360635799664 [label=ReluBackward0]
	140360635800096 -> 140360635799664
	140360635800096 [label=NativeBatchNormBackward0]
	140360635800480 -> 140360635800096
	140360635800480 [label=ConvolutionBackward0]
	140360635799952 -> 140360635800480
	140360635799952 [label=ReluBackward0]
	140360635800816 -> 140360635799952
	140360635800816 [label=AddBackward0]
	140360635801296 -> 140360635800816
	140360635801296 [label=NativeBatchNormBackward0]
	140360635801344 -> 140360635801296
	140360635801344 [label=ConvolutionBackward0]
	140360635802688 -> 140360635801344
	140360635802688 [label=ReluBackward0]
	140360635803168 -> 140360635802688
	140360635803168 [label=NativeBatchNormBackward0]
	140360635803984 -> 140360635803168
	140360635803984 [label=ConvolutionBackward0]
	140360635802112 -> 140360635803984
	140360635802112 [label=ReluBackward0]
	140360635803312 -> 140360635802112
	140360635803312 [label=NativeBatchNormBackward0]
	140360635803504 -> 140360635803312
	140360635803504 [label=ConvolutionBackward0]
	140360635797600 -> 140360635803504
	140360635804848 -> 140360635803504
	140360633390320 [label="transition3.3.0.0.weight
 (144, 72, 3, 3)" fillcolor=lightblue]
	140360633390320 -> 140360635804848
	140360635804848 [label=AccumulateGrad]
	140360635804176 -> 140360635803312
	140360633390080 [label="transition3.3.0.1.weight
 (144)" fillcolor=lightblue]
	140360633390080 -> 140360635804176
	140360635804176 [label=AccumulateGrad]
	140360635803456 -> 140360635803312
	140360633390240 [label="transition3.3.0.1.bias
 (144)" fillcolor=lightblue]
	140360633390240 -> 140360635803456
	140360635803456 [label=AccumulateGrad]
	140360635802832 -> 140360635803984
	140360634770096 [label="stage4.0.branches.3.0.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634770096 -> 140360635802832
	140360635802832 [label=AccumulateGrad]
	140360635802496 -> 140360635803168
	140360634770016 [label="stage4.0.branches.3.0.bn1.weight
 (144)" fillcolor=lightblue]
	140360634770016 -> 140360635802496
	140360635802496 [label=AccumulateGrad]
	140360635802160 -> 140360635803168
	140360634770256 [label="stage4.0.branches.3.0.bn1.bias
 (144)" fillcolor=lightblue]
	140360634770256 -> 140360635802160
	140360635802160 [label=AccumulateGrad]
	140360635801824 -> 140360635801344
	140360634768736 [label="stage4.0.branches.3.0.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634768736 -> 140360635801824
	140360635801824 [label=AccumulateGrad]
	140360635801488 -> 140360635801296
	140360634768496 [label="stage4.0.branches.3.0.bn2.weight
 (144)" fillcolor=lightblue]
	140360634768496 -> 140360635801488
	140360635801488 [label=AccumulateGrad]
	140360635802352 -> 140360635801296
	140360634768576 [label="stage4.0.branches.3.0.bn2.bias
 (144)" fillcolor=lightblue]
	140360634768576 -> 140360635802352
	140360635802352 [label=AccumulateGrad]
	140360635802112 -> 140360635800816
	140360635801680 -> 140360635800480
	140360634767056 [label="stage4.0.branches.3.1.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634767056 -> 140360635801680
	140360635801680 [label=AccumulateGrad]
	140360635801440 -> 140360635800096
	140360634766976 [label="stage4.0.branches.3.1.bn1.weight
 (144)" fillcolor=lightblue]
	140360634766976 -> 140360635801440
	140360635801440 [label=AccumulateGrad]
	140360635800672 -> 140360635800096
	140360634767216 [label="stage4.0.branches.3.1.bn1.bias
 (144)" fillcolor=lightblue]
	140360634767216 -> 140360635800672
	140360635800672 [label=AccumulateGrad]
	140360635799808 -> 140360635799328
	140360634765696 [label="stage4.0.branches.3.1.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634765696 -> 140360635799808
	140360635799808 [label=AccumulateGrad]
	140360635800192 -> 140360635799136
	140360634765456 [label="stage4.0.branches.3.1.bn2.weight
 (144)" fillcolor=lightblue]
	140360634765456 -> 140360635800192
	140360635800192 [label=AccumulateGrad]
	140360635798992 -> 140360635799136
	140360634765536 [label="stage4.0.branches.3.1.bn2.bias
 (144)" fillcolor=lightblue]
	140360634765536 -> 140360635798992
	140360635798992 [label=AccumulateGrad]
	140360635799952 -> 140360635798752
	140360635799472 -> 140360635797984
	140360634763936 [label="stage4.0.branches.3.2.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634763936 -> 140360635799472
	140360635799472 [label=AccumulateGrad]
	140360635798608 -> 140360635797792
	140360634763856 [label="stage4.0.branches.3.2.bn1.weight
 (144)" fillcolor=lightblue]
	140360634763856 -> 140360635798608
	140360635798608 [label=AccumulateGrad]
	140360635798800 -> 140360635797792
	140360634764096 [label="stage4.0.branches.3.2.bn1.bias
 (144)" fillcolor=lightblue]
	140360634764096 -> 140360635798800
	140360635798800 [label=AccumulateGrad]
	140360635797120 -> 140360635797648
	140360634762656 [label="stage4.0.branches.3.2.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634762656 -> 140360635797120
	140360635797120 [label=AccumulateGrad]
	140360635796640 -> 140360635796928
	140360634762496 [label="stage4.0.branches.3.2.bn2.weight
 (144)" fillcolor=lightblue]
	140360634762496 -> 140360635796640
	140360635796640 [label=AccumulateGrad]
	140360635795728 -> 140360635796928
	140360634762576 [label="stage4.0.branches.3.2.bn2.bias
 (144)" fillcolor=lightblue]
	140360634762576 -> 140360635795728
	140360635795728 [label=AccumulateGrad]
	140360635796400 -> 140360635797216
	140360635796160 -> 140360635797840
	140360634777536 [label="stage4.0.branches.3.3.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634777536 -> 140360635796160
	140360635796160 [label=AccumulateGrad]
	140360635798032 -> 140360635798848
	140360634777296 [label="stage4.0.branches.3.3.bn1.weight
 (144)" fillcolor=lightblue]
	140360634777296 -> 140360635798032
	140360635798032 [label=AccumulateGrad]
	140360635799232 -> 140360635798848
	140360634761296 [label="stage4.0.branches.3.3.bn1.bias
 (144)" fillcolor=lightblue]
	140360634761296 -> 140360635799232
	140360635799232 [label=AccumulateGrad]
	140360635800432 -> 140360635800960
	140360634774256 [label="stage4.0.branches.3.3.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634774256 -> 140360635800432
	140360635800432 [label=AccumulateGrad]
	140360635800144 -> 140360635804560
	140360634773616 [label="stage4.0.branches.3.3.bn2.weight
 (144)" fillcolor=lightblue]
	140360634773616 -> 140360635800144
	140360635800144 [label=AccumulateGrad]
	140360635800864 -> 140360635804560
	140360634774016 [label="stage4.0.branches.3.3.bn2.bias
 (144)" fillcolor=lightblue]
	140360634774016 -> 140360635800864
	140360635800864 [label=AccumulateGrad]
	140360635802544 -> 140360635800384
	140360635804464 -> 140360636677184
	140360634762976 [label="stage4.0.fuse_layers.0.3.0.weight
 (18, 144, 1, 1)" fillcolor=lightblue]
	140360634762976 -> 140360635804464
	140360635804464 [label=AccumulateGrad]
	140360636673872 -> 140360637334144
	140360634762256 [label="stage4.0.fuse_layers.0.3.1.weight
 (18)" fillcolor=lightblue]
	140360634762256 -> 140360636673872
	140360636673872 [label=AccumulateGrad]
	140360636672672 -> 140360637334144
	140360634763376 [label="stage4.0.fuse_layers.0.3.1.bias
 (18)" fillcolor=lightblue]
	140360634763376 -> 140360636672672
	140360636672672 [label=AccumulateGrad]
	140360637333856 -> 140360637334816
	140360634684256 [label="stage4.1.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634684256 -> 140360637333856
	140360637333856 [label=AccumulateGrad]
	140360637334960 -> 140360637335152
	140360634683936 [label="stage4.1.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140360634683936 -> 140360637334960
	140360637334960 [label=AccumulateGrad]
	140360637335248 -> 140360637335152
	140360634684416 [label="stage4.1.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140360634684416 -> 140360637335248
	140360637335248 [label=AccumulateGrad]
	140360637335440 -> 140360637335920
	140360634681296 [label="stage4.1.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634681296 -> 140360637335440
	140360637335440 [label=AccumulateGrad]
	140360637335968 -> 140360637336064
	140360634680656 [label="stage4.1.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140360634680656 -> 140360637335968
	140360637335968 [label=AccumulateGrad]
	140360637336016 -> 140360637336064
	140360634680896 [label="stage4.1.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140360634680896 -> 140360637336016
	140360637336016 [label=AccumulateGrad]
	140360637336256 -> 140360637336304
	140360637336352 -> 140360637336736
	140360634629280 [label="stage4.1.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634629280 -> 140360637336352
	140360637336352 [label=AccumulateGrad]
	140360637336928 -> 140360637336976
	140360634629120 [label="stage4.1.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140360634629120 -> 140360637336928
	140360637336928 [label=AccumulateGrad]
	140360637337024 -> 140360637336976
	140360634629520 [label="stage4.1.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140360634629520 -> 140360637337024
	140360637337024 [label=AccumulateGrad]
	140360637337456 -> 140360637337744
	140360634628000 [label="stage4.1.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634628000 -> 140360637337456
	140360637337456 [label=AccumulateGrad]
	140360637337792 -> 140360637337888
	140360634627600 [label="stage4.1.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140360634627600 -> 140360637337792
	140360637337792 [label=AccumulateGrad]
	140360637337840 -> 140360637337888
	140360634627760 [label="stage4.1.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140360634627760 -> 140360637337840
	140360637337840 [label=AccumulateGrad]
	140360637338080 -> 140360637338128
	140360637338176 -> 140360637338656
	140360634626240 [label="stage4.1.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634626240 -> 140360637338176
	140360637338176 [label=AccumulateGrad]
	140360637338848 -> 140360637338896
	140360634626080 [label="stage4.1.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140360634626080 -> 140360637338848
	140360637338848 [label=AccumulateGrad]
	140360637338944 -> 140360637338896
	140360634626480 [label="stage4.1.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140360634626480 -> 140360637338944
	140360637338944 [label=AccumulateGrad]
	140360637339280 -> 140360637333808
	140360634624960 [label="stage4.1.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634624960 -> 140360637339280
	140360637339280 [label=AccumulateGrad]
	140360637339328 -> 140360637340096
	140360634624560 [label="stage4.1.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140360634624560 -> 140360637339328
	140360637339328 [label=AccumulateGrad]
	140360637340048 -> 140360637340096
	140360634624720 [label="stage4.1.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140360634624720 -> 140360637340048
	140360637340048 [label=AccumulateGrad]
	140360637340144 -> 140360637340192
	140360637339952 -> 140360637340528
	140360634623200 [label="stage4.1.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634623200 -> 140360637339952
	140360637339952 [label=AccumulateGrad]
	140360637340576 -> 140360637340288
	140360634623040 [label="stage4.1.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140360634623040 -> 140360637340576
	140360637340576 [label=AccumulateGrad]
	140360637340720 -> 140360637340288
	140360634623440 [label="stage4.1.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140360634623440 -> 140360637340720
	140360637340720 [label=AccumulateGrad]
	140360637340816 -> 140360637340960
	140360634621920 [label="stage4.1.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634621920 -> 140360637340816
	140360637340816 [label=AccumulateGrad]
	140360637341008 -> 140360637341104
	140360634621520 [label="stage4.1.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140360634621520 -> 140360637341008
	140360637341008 [label=AccumulateGrad]
	140360637341056 -> 140360637341104
	140360634621680 [label="stage4.1.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140360634621680 -> 140360637341056
	140360637341056 [label=AccumulateGrad]
	140360637341152 -> 140360637340912
	140360637341488 -> 140360637341584
	140360637341488 [label=UpsampleBilinear2DBackward0]
	140360637340624 -> 140360637341488
	140360637340624 [label=NativeBatchNormBackward0]
	140360637340240 -> 140360637340624
	140360637340240 [label=ConvolutionBackward0]
	140360637340384 -> 140360637340240
	140360637340384 [label=ReluBackward0]
	140360637337360 -> 140360637340384
	140360637337360 [label=AddBackward0]
	140360637338608 -> 140360637337360
	140360637338608 [label=NativeBatchNormBackward0]
	140360637338560 -> 140360637338608
	140360637338560 [label=ConvolutionBackward0]
	140360637336592 -> 140360637338560
	140360637336592 [label=ReluBackward0]
	140360637336688 -> 140360637336592
	140360637336688 [label=NativeBatchNormBackward0]
	140360637334432 -> 140360637336688
	140360637334432 [label=ConvolutionBackward0]
	140360637339184 -> 140360637334432
	140360637339184 [label=ReluBackward0]
	140360636350672 -> 140360637339184
	140360636350672 [label=AddBackward0]
	140360637334912 -> 140360636350672
	140360637334912 [label=NativeBatchNormBackward0]
	140360635798416 -> 140360637334912
	140360635798416 [label=ConvolutionBackward0]
	140360635797456 -> 140360635798416
	140360635797456 [label=ReluBackward0]
	140360635797936 -> 140360635797456
	140360635797936 [label=NativeBatchNormBackward0]
	140360635798128 -> 140360635797936
	140360635798128 [label=ConvolutionBackward0]
	140360635799712 -> 140360635798128
	140360635799712 [label=ReluBackward0]
	140360635801008 -> 140360635799712
	140360635801008 [label=AddBackward0]
	140360635800336 -> 140360635801008
	140360635800336 [label=NativeBatchNormBackward0]
	140360635801152 -> 140360635800336
	140360635801152 [label=ConvolutionBackward0]
	140360635802784 -> 140360635801152
	140360635802784 [label=ReluBackward0]
	140360635803360 -> 140360635802784
	140360635803360 [label=NativeBatchNormBackward0]
	140360635803840 -> 140360635803360
	140360635803840 [label=ConvolutionBackward0]
	140360635800624 -> 140360635803840
	140360635800624 [label=ReluBackward0]
	140360635804704 -> 140360635800624
	140360635804704 [label=AddBackward0]
	140360635805856 -> 140360635804704
	140360635805856 [label=NativeBatchNormBackward0]
	140360635806048 -> 140360635805856
	140360635806048 [label=ConvolutionBackward0]
	140360635805520 -> 140360635806048
	140360635805520 [label=ReluBackward0]
	140360635806000 -> 140360635805520
	140360635806000 [label=NativeBatchNormBackward0]
	140360635806384 -> 140360635806000
	140360635806384 [label=ConvolutionBackward0]
	140360635804800 -> 140360635806384
	140360635804800 [label=ReluBackward0]
	140360635807056 -> 140360635804800
	140360635807056 [label=AddBackward0]
	140360635808160 -> 140360635807056
	140360635808160 [label=AddBackward0]
	140360635808400 -> 140360635808160
	140360635808400 [label=AddBackward0]
	140360635808016 -> 140360635808400
	140360635808016 [label=NativeBatchNormBackward0]
	140360635809072 -> 140360635808016
	140360635809072 [label=ConvolutionBackward0]
	140360637333904 -> 140360635809072
	140360635808688 -> 140360635809072
	140360634694416 [label="stage4.0.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140360634694416 -> 140360635808688
	140360635808688 [label=AccumulateGrad]
	140360635807872 -> 140360635808016
	140360634694256 [label="stage4.0.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140360634694256 -> 140360635807872
	140360635807872 [label=AccumulateGrad]
	140360635807536 -> 140360635808016
	140360634694496 [label="stage4.0.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140360634694496 -> 140360635807536
	140360635807536 [label=AccumulateGrad]
	140360636677136 -> 140360635808400
	140360635807344 -> 140360635808160
	140360635807344 [label=UpsampleBilinear2DBackward0]
	140360635808064 -> 140360635807344
	140360635808064 [label=NativeBatchNormBackward0]
	140360635809552 -> 140360635808064
	140360635809552 [label=ConvolutionBackward0]
	140360636673776 -> 140360635809552
	140360635809216 -> 140360635809552
	140360634694736 [label="stage4.0.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140360634694736 -> 140360635809216
	140360635809216 [label=AccumulateGrad]
	140360635809360 -> 140360635808064
	140360634693056 [label="stage4.0.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140360634693056 -> 140360635809360
	140360635809360 [label=AccumulateGrad]
	140360635808832 -> 140360635808064
	140360634694576 [label="stage4.0.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140360634694576 -> 140360635808832
	140360635808832 [label=AccumulateGrad]
	140360635806864 -> 140360635807056
	140360635806864 [label=UpsampleBilinear2DBackward0]
	140360635808544 -> 140360635806864
	140360635808544 [label=NativeBatchNormBackward0]
	140360635809504 -> 140360635808544
	140360635809504 [label=ConvolutionBackward0]
	140360635803792 -> 140360635809504
	140360635809744 -> 140360635809504
	140360634691696 [label="stage4.0.fuse_layers.1.3.0.weight
 (36, 144, 1, 1)" fillcolor=lightblue]
	140360634691696 -> 140360635809744
	140360635809744 [label=AccumulateGrad]
	140360635808880 -> 140360635808544
	140360634691616 [label="stage4.0.fuse_layers.1.3.1.weight
 (36)" fillcolor=lightblue]
	140360634691616 -> 140360635808880
	140360635808880 [label=AccumulateGrad]
	140360635807488 -> 140360635808544
	140360634691856 [label="stage4.0.fuse_layers.1.3.1.bias
 (36)" fillcolor=lightblue]
	140360634691856 -> 140360635807488
	140360635807488 [label=AccumulateGrad]
	140360635806672 -> 140360635806384
	140360634620160 [label="stage4.1.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634620160 -> 140360635806672
	140360635806672 [label=AccumulateGrad]
	140360635806720 -> 140360635806000
	140360634620000 [label="stage4.1.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140360634620000 -> 140360635806720
	140360635806720 [label=AccumulateGrad]
	140360635807200 -> 140360635806000
	140360634620400 [label="stage4.1.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140360634620400 -> 140360635807200
	140360635807200 [label=AccumulateGrad]
	140360635805712 -> 140360635806048
	140360634618880 [label="stage4.1.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634618880 -> 140360635805712
	140360635805712 [label=AccumulateGrad]
	140360635805040 -> 140360635805856
	140360634618480 [label="stage4.1.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140360634618480 -> 140360635805040
	140360635805040 [label=AccumulateGrad]
	140360635805184 -> 140360635805856
	140360634618640 [label="stage4.1.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140360634618640 -> 140360635805184
	140360635805184 [label=AccumulateGrad]
	140360635804800 -> 140360635804704
	140360635804368 -> 140360635803840
	140360634617120 [label="stage4.1.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634617120 -> 140360635804368
	140360635804368 [label=AccumulateGrad]
	140360635804128 -> 140360635803360
	140360634616960 [label="stage4.1.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140360634616960 -> 140360635804128
	140360635804128 [label=AccumulateGrad]
	140360635804656 -> 140360635803360
	140360634617360 [label="stage4.1.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140360634617360 -> 140360635804656
	140360635804656 [label=AccumulateGrad]
	140360635801968 -> 140360635801152
	140360634615840 [label="stage4.1.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634615840 -> 140360635801968
	140360635801968 [label=AccumulateGrad]
	140360635800768 -> 140360635800336
	140360634615440 [label="stage4.1.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140360634615440 -> 140360635800768
	140360635800768 [label=AccumulateGrad]
	140360635802640 -> 140360635800336
	140360634615600 [label="stage4.1.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140360634615600 -> 140360635802640
	140360635802640 [label=AccumulateGrad]
	140360635800624 -> 140360635801008
	140360635798464 -> 140360635798128
	140360634614080 [label="stage4.1.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634614080 -> 140360635798464
	140360635798464 [label=AccumulateGrad]
	140360635798656 -> 140360635797936
	140360634613920 [label="stage4.1.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140360634613920 -> 140360635798656
	140360635798656 [label=AccumulateGrad]
	140360635797360 -> 140360635797936
	140360634614320 [label="stage4.1.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140360634614320 -> 140360635797360
	140360635797360 [label=AccumulateGrad]
	140360635798704 -> 140360635798416
	140360634627120 [label="stage4.1.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634627120 -> 140360635798704
	140360635798704 [label=AccumulateGrad]
	140360635807296 -> 140360637334912
	140360634626640 [label="stage4.1.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140360634626640 -> 140360635807296
	140360635807296 [label=AccumulateGrad]
	140360635793712 -> 140360637334912
	140360634626880 [label="stage4.1.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140360634626880 -> 140360635793712
	140360635793712 [label=AccumulateGrad]
	140360635799712 -> 140360636350672
	140360637334480 -> 140360637334432
	140360634623360 [label="stage4.1.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634623360 -> 140360637334480
	140360637334480 [label=AccumulateGrad]
	140360637335200 -> 140360637336688
	140360634622960 [label="stage4.1.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140360634622960 -> 140360637335200
	140360637335200 [label=AccumulateGrad]
	140360637335488 -> 140360637336688
	140360634623600 [label="stage4.1.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140360634623600 -> 140360637335488
	140360637335488 [label=AccumulateGrad]
	140360637337504 -> 140360637338560
	140360634619920 [label="stage4.1.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634619920 -> 140360637337504
	140360637337504 [label=AccumulateGrad]
	140360637338512 -> 140360637338608
	140360634619280 [label="stage4.1.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140360634619280 -> 140360637338512
	140360637338512 [label=AccumulateGrad]
	140360637337552 -> 140360637338608
	140360634619520 [label="stage4.1.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140360634619520 -> 140360637337552
	140360637337552 [label=AccumulateGrad]
	140360637339184 -> 140360637337360
	140360637337312 -> 140360637340240
	140360634498848 [label="stage4.1.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140360634498848 -> 140360637337312
	140360637337312 [label=AccumulateGrad]
	140360637340672 -> 140360637340624
	140360634498688 [label="stage4.1.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140360634498688 -> 140360637340672
	140360637340672 [label=AccumulateGrad]
	140360637340336 -> 140360637340624
	140360634498928 [label="stage4.1.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140360634498928 -> 140360637340336
	140360637340336 [label=AccumulateGrad]
	140360637341200 -> 140360637341776
	140360637341200 [label=UpsampleBilinear2DBackward0]
	140360637340864 -> 140360637341200
	140360637340864 [label=NativeBatchNormBackward0]
	140360637335824 -> 140360637340864
	140360637335824 [label=ConvolutionBackward0]
	140360637334864 -> 140360637335824
	140360637334864 [label=ReluBackward0]
	140360636677232 -> 140360637334864
	140360636677232 [label=AddBackward0]
	140360637335872 -> 140360636677232
	140360637335872 [label=NativeBatchNormBackward0]
	140360635799616 -> 140360637335872
	140360635799616 [label=ConvolutionBackward0]
	140360635799424 -> 140360635799616
	140360635799424 [label=ReluBackward0]
	140360635803696 -> 140360635799424
	140360635803696 [label=NativeBatchNormBackward0]
	140360635805472 -> 140360635803696
	140360635805472 [label=ConvolutionBackward0]
	140360635804608 -> 140360635805472
	140360635804608 [label=ReluBackward0]
	140360635806192 -> 140360635804608
	140360635806192 [label=AddBackward0]
	140360635806816 -> 140360635806192
	140360635806816 [label=NativeBatchNormBackward0]
	140360635809408 -> 140360635806816
	140360635809408 [label=ConvolutionBackward0]
	140360643100736 -> 140360635809408
	140360643100736 [label=ReluBackward0]
	140360643105632 -> 140360643100736
	140360643105632 [label=NativeBatchNormBackward0]
	140360643109712 -> 140360643105632
	140360643109712 [label=ConvolutionBackward0]
	140360635808208 -> 140360643109712
	140360635808208 [label=ReluBackward0]
	140360643110336 -> 140360635808208
	140360643110336 [label=AddBackward0]
	140360643105584 -> 140360643110336
	140360643105584 [label=NativeBatchNormBackward0]
	140360910404048 -> 140360643105584
	140360910404048 [label=ConvolutionBackward0]
	140360910403376 -> 140360910404048
	140360910403376 [label=ReluBackward0]
	140360910403520 -> 140360910403376
	140360910403520 [label=NativeBatchNormBackward0]
	140360634883792 -> 140360910403520
	140360634883792 [label=ConvolutionBackward0]
	140360910393584 -> 140360634883792
	140360910393584 [label=ReluBackward0]
	140360634882304 -> 140360910393584
	140360634882304 [label=AddBackward0]
	140360634889888 -> 140360634882304
	140360634889888 [label=NativeBatchNormBackward0]
	140360634887824 -> 140360634889888
	140360634887824 [label=ConvolutionBackward0]
	140360634883168 -> 140360634887824
	140360634883168 [label=ReluBackward0]
	140360634883120 -> 140360634883168
	140360634883120 [label=NativeBatchNormBackward0]
	140360634890512 -> 140360634883120
	140360634890512 [label=ConvolutionBackward0]
	140360634887344 -> 140360634890512
	140360634887344 [label=ReluBackward0]
	140360639261920 -> 140360634887344
	140360639261920 [label=AddBackward0]
	140360639261776 -> 140360639261920
	140360639261776 [label=AddBackward0]
	140360639264752 -> 140360639261776
	140360639264752 [label=AddBackward0]
	140360639262256 -> 140360639264752
	140360639262256 [label=NativeBatchNormBackward0]
	140360639262064 -> 140360639262256
	140360639262064 [label=ConvolutionBackward0]
	140360639266288 -> 140360639262064
	140360639266288 [label=ReluBackward0]
	140360639266576 -> 140360639266288
	140360639266576 [label=NativeBatchNormBackward0]
	140360639266528 -> 140360639266576
	140360639266528 [label=ConvolutionBackward0]
	140360637333904 -> 140360639266528
	140360639262304 -> 140360639266528
	140360634690176 [label="stage4.0.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634690176 -> 140360639262304
	140360639262304 [label=AccumulateGrad]
	140360639264512 -> 140360639266576
	140360634689936 [label="stage4.0.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140360634689936 -> 140360639264512
	140360639264512 [label=AccumulateGrad]
	140360639266000 -> 140360639266576
	140360634690256 [label="stage4.0.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140360634690256 -> 140360639266000
	140360639266000 [label=AccumulateGrad]
	140360639263936 -> 140360639262064
	140360634690096 [label="stage4.0.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140360634690096 -> 140360639263936
	140360639263936 [label=AccumulateGrad]
	140360639262544 -> 140360639262256
	140360634688416 [label="stage4.0.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140360634688416 -> 140360639262544
	140360639262544 [label=AccumulateGrad]
	140360639264368 -> 140360639262256
	140360634688576 [label="stage4.0.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140360634688576 -> 140360639264368
	140360639264368 [label=AccumulateGrad]
	140360639257264 -> 140360639264752
	140360639257264 [label=NativeBatchNormBackward0]
	140360639261680 -> 140360639257264
	140360639261680 [label=ConvolutionBackward0]
	140360636677136 -> 140360639261680
	140360639266336 -> 140360639261680
	140360634687056 [label="stage4.0.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140360634687056 -> 140360639266336
	140360639266336 [label=AccumulateGrad]
	140360639265904 -> 140360639257264
	140360634686896 [label="stage4.0.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140360634686896 -> 140360639265904
	140360639265904 [label=AccumulateGrad]
	140360639263168 -> 140360639257264
	140360634687136 [label="stage4.0.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140360634687136 -> 140360639263168
	140360639263168 [label=AccumulateGrad]
	140360636673776 -> 140360639261776
	140360639262688 -> 140360639261920
	140360639262688 [label=UpsampleBilinear2DBackward0]
	140360639262448 -> 140360639262688
	140360639262448 [label=NativeBatchNormBackward0]
	140360639266624 -> 140360639262448
	140360639266624 [label=ConvolutionBackward0]
	140360635803792 -> 140360639266624
	140360662909520 -> 140360639266624
	140360634690496 [label="stage4.0.fuse_layers.2.3.0.weight
 (72, 144, 1, 1)" fillcolor=lightblue]
	140360634690496 -> 140360662909520
	140360662909520 [label=AccumulateGrad]
	140360639262736 -> 140360639262448
	140360634685616 [label="stage4.0.fuse_layers.2.3.1.weight
 (72)" fillcolor=lightblue]
	140360634685616 -> 140360639262736
	140360639262736 [label=AccumulateGrad]
	140360639266384 -> 140360639262448
	140360634690336 [label="stage4.0.fuse_layers.2.3.1.bias
 (72)" fillcolor=lightblue]
	140360634690336 -> 140360639266384
	140360639266384 [label=AccumulateGrad]
	140360639262208 -> 140360634890512
	140360634616000 [label="stage4.1.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634616000 -> 140360639262208
	140360639262208 [label=AccumulateGrad]
	140360874338832 -> 140360634883120
	140360634615760 [label="stage4.1.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140360634615760 -> 140360874338832
	140360874338832 [label=AccumulateGrad]
	140360874338688 -> 140360634883120
	140360634616240 [label="stage4.1.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140360634616240 -> 140360874338688
	140360874338688 [label=AccumulateGrad]
	140360634888496 -> 140360634887824
	140360634580688 [label="stage4.1.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634580688 -> 140360634888496
	140360634888496 [label=AccumulateGrad]
	140360634881632 -> 140360634889888
	140360634580448 [label="stage4.1.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140360634580448 -> 140360634881632
	140360634881632 [label=AccumulateGrad]
	140360634885328 -> 140360634889888
	140360634580528 [label="stage4.1.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140360634580528 -> 140360634885328
	140360634885328 [label=AccumulateGrad]
	140360634887344 -> 140360634882304
	140360634882976 -> 140360634883792
	140360634579008 [label="stage4.1.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634579008 -> 140360634882976
	140360634882976 [label=AccumulateGrad]
	140360634892000 -> 140360910403520
	140360634578928 [label="stage4.1.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140360634578928 -> 140360634892000
	140360634892000 [label=AccumulateGrad]
	140360634891856 -> 140360910403520
	140360634579168 [label="stage4.1.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140360634579168 -> 140360634891856
	140360634891856 [label=AccumulateGrad]
	140360910396224 -> 140360910404048
	140360634577648 [label="stage4.1.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634577648 -> 140360910396224
	140360910396224 [label=AccumulateGrad]
	140360910404096 -> 140360643105584
	140360634577408 [label="stage4.1.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140360634577408 -> 140360910404096
	140360910404096 [label=AccumulateGrad]
	140360910393680 -> 140360643105584
	140360634577488 [label="stage4.1.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140360634577488 -> 140360910393680
	140360910393680 [label=AccumulateGrad]
	140360910393584 -> 140360643110336
	140360643106016 -> 140360643109712
	140360634575968 [label="stage4.1.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634575968 -> 140360643106016
	140360643106016 [label=AccumulateGrad]
	140360643105824 -> 140360643105632
	140360634575888 [label="stage4.1.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140360634575888 -> 140360643105824
	140360643105824 [label=AccumulateGrad]
	140360643100832 -> 140360643105632
	140360634576128 [label="stage4.1.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140360634576128 -> 140360643100832
	140360643100832 [label=AccumulateGrad]
	140360643113552 -> 140360635809408
	140360634574608 [label="stage4.1.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634574608 -> 140360643113552
	140360643113552 [label=AccumulateGrad]
	140360635808736 -> 140360635806816
	140360634574368 [label="stage4.1.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140360634574368 -> 140360635808736
	140360635808736 [label=AccumulateGrad]
	140360635807392 -> 140360635806816
	140360634574448 [label="stage4.1.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140360634574448 -> 140360635807392
	140360635807392 [label=AccumulateGrad]
	140360635808208 -> 140360635806192
	140360635807728 -> 140360635805472
	140360634572928 [label="stage4.1.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634572928 -> 140360635807728
	140360635807728 [label=AccumulateGrad]
	140360635804032 -> 140360635803696
	140360634572848 [label="stage4.1.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140360634572848 -> 140360635804032
	140360635804032 [label=AccumulateGrad]
	140360635803024 -> 140360635803696
	140360634573088 [label="stage4.1.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140360634573088 -> 140360635803024
	140360635803024 [label=AccumulateGrad]
	140360635798320 -> 140360635799616
	140360634571568 [label="stage4.1.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634571568 -> 140360635798320
	140360635798320 [label=AccumulateGrad]
	140360635800000 -> 140360637335872
	140360634571328 [label="stage4.1.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140360634571328 -> 140360635800000
	140360635800000 [label=AccumulateGrad]
	140360635798512 -> 140360637335872
	140360634571408 [label="stage4.1.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140360634571408 -> 140360635798512
	140360635798512 [label=AccumulateGrad]
	140360635804608 -> 140360636677232
	140360637336640 -> 140360637335824
	140360634497328 [label="stage4.1.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140360634497328 -> 140360637336640
	140360637336640 [label=AccumulateGrad]
	140360637338464 -> 140360637340864
	140360634497248 [label="stage4.1.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140360634497248 -> 140360637338464
	140360637338464 [label=AccumulateGrad]
	140360637341536 -> 140360637340864
	140360634497408 [label="stage4.1.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140360634497408 -> 140360637341536
	140360637341536 [label=AccumulateGrad]
	140360637341824 -> 140360637341872
	140360637341824 [label=UpsampleBilinear2DBackward0]
	140360637340480 -> 140360637341824
	140360637340480 [label=NativeBatchNormBackward0]
	140360637334768 -> 140360637340480
	140360637334768 [label=ConvolutionBackward0]
	140360635806528 -> 140360637334768
	140360635806528 [label=ReluBackward0]
	140360635805328 -> 140360635806528
	140360635805328 [label=AddBackward0]
	140360635806144 -> 140360635805328
	140360635806144 [label=NativeBatchNormBackward0]
	140360643101888 -> 140360635806144
	140360643101888 [label=ConvolutionBackward0]
	140360643105872 -> 140360643101888
	140360643105872 [label=ReluBackward0]
	140360910393872 -> 140360643105872
	140360910393872 [label=NativeBatchNormBackward0]
	140360634889312 -> 140360910393872
	140360634889312 [label=ConvolutionBackward0]
	140360635802016 -> 140360634889312
	140360635802016 [label=ReluBackward0]
	140360874338784 -> 140360635802016
	140360874338784 [label=AddBackward0]
	140360639264320 -> 140360874338784
	140360639264320 [label=NativeBatchNormBackward0]
	140360662912736 -> 140360639264320
	140360662912736 [label=ConvolutionBackward0]
	140360639347008 -> 140360662912736
	140360639347008 [label=ReluBackward0]
	140360639348448 -> 140360639347008
	140360639348448 [label=NativeBatchNormBackward0]
	140360639348544 -> 140360639348448
	140360639348544 [label=ConvolutionBackward0]
	140360639264992 -> 140360639348544
	140360639264992 [label=ReluBackward0]
	140360639347440 -> 140360639264992
	140360639347440 [label=AddBackward0]
	140360639347824 -> 140360639347440
	140360639347824 [label=NativeBatchNormBackward0]
	140360639346336 -> 140360639347824
	140360639346336 [label=ConvolutionBackward0]
	140360639347104 -> 140360639346336
	140360639347104 [label=ReluBackward0]
	140360639346480 -> 140360639347104
	140360639346480 [label=NativeBatchNormBackward0]
	140360639346768 -> 140360639346480
	140360639346768 [label=ConvolutionBackward0]
	140360639347632 -> 140360639346768
	140360639347632 [label=ReluBackward0]
	140360639346528 -> 140360639347632
	140360639346528 [label=AddBackward0]
	140360639346288 -> 140360639346528
	140360639346288 [label=NativeBatchNormBackward0]
	140360639344944 -> 140360639346288
	140360639344944 [label=ConvolutionBackward0]
	140360639345088 -> 140360639344944
	140360639345088 [label=ReluBackward0]
	140360639346192 -> 140360639345088
	140360639346192 [label=NativeBatchNormBackward0]
	140360639345376 -> 140360639346192
	140360639345376 [label=ConvolutionBackward0]
	140360639346048 -> 140360639345376
	140360639346048 [label=ReluBackward0]
	140360639345280 -> 140360639346048
	140360639345280 [label=AddBackward0]
	140360639344752 -> 140360639345280
	140360639344752 [label=AddBackward0]
	140360639345184 -> 140360639344752
	140360639345184 [label=AddBackward0]
	140360639344080 -> 140360639345184
	140360639344080 [label=NativeBatchNormBackward0]
	140360639344848 -> 140360639344080
	140360639344848 [label=ConvolutionBackward0]
	140360639343840 -> 140360639344848
	140360639343840 [label=ReluBackward0]
	140360639343888 -> 140360639343840
	140360639343888 [label=NativeBatchNormBackward0]
	140360639344176 -> 140360639343888
	140360639344176 [label=ConvolutionBackward0]
	140360639342448 -> 140360639344176
	140360639342448 [label=ReluBackward0]
	140360639343456 -> 140360639342448
	140360639343456 [label=NativeBatchNormBackward0]
	140360639343792 -> 140360639343456
	140360639343792 [label=ConvolutionBackward0]
	140360637333904 -> 140360639343792
	140360639342496 -> 140360639343792
	140360634684096 [label="stage4.0.fuse_layers.3.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634684096 -> 140360639342496
	140360639342496 [label=AccumulateGrad]
	140360639343648 -> 140360639343456
	140360634683856 [label="stage4.0.fuse_layers.3.0.0.1.weight
 (18)" fillcolor=lightblue]
	140360634683856 -> 140360639343648
	140360639343648 [label=AccumulateGrad]
	140360639343744 -> 140360639343456
	140360634684176 [label="stage4.0.fuse_layers.3.0.0.1.bias
 (18)" fillcolor=lightblue]
	140360634684176 -> 140360639343744
	140360639343744 [label=AccumulateGrad]
	140360639344032 -> 140360639344176
	140360634684016 [label="stage4.0.fuse_layers.3.0.1.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634684016 -> 140360639344032
	140360639344032 [label=AccumulateGrad]
	140360639343552 -> 140360639343888
	140360634682336 [label="stage4.0.fuse_layers.3.0.1.1.weight
 (18)" fillcolor=lightblue]
	140360634682336 -> 140360639343552
	140360639343552 [label=AccumulateGrad]
	140360639344272 -> 140360639343888
	140360634682496 [label="stage4.0.fuse_layers.3.0.1.1.bias
 (18)" fillcolor=lightblue]
	140360634682496 -> 140360639344272
	140360639344272 [label=AccumulateGrad]
	140360639343360 -> 140360639344848
	140360634682576 [label="stage4.0.fuse_layers.3.0.2.0.weight
 (144, 18, 3, 3)" fillcolor=lightblue]
	140360634682576 -> 140360639343360
	140360639343360 [label=AccumulateGrad]
	140360639345232 -> 140360639344080
	140360634680816 [label="stage4.0.fuse_layers.3.0.2.1.weight
 (144)" fillcolor=lightblue]
	140360634680816 -> 140360639345232
	140360639345232 [label=AccumulateGrad]
	140360639344464 -> 140360639344080
	140360634680976 [label="stage4.0.fuse_layers.3.0.2.1.bias
 (144)" fillcolor=lightblue]
	140360634680976 -> 140360639344464
	140360639344464 [label=AccumulateGrad]
	140360639345040 -> 140360639345184
	140360639345040 [label=NativeBatchNormBackward0]
	140360639343936 -> 140360639345040
	140360639343936 [label=ConvolutionBackward0]
	140360639343696 -> 140360639343936
	140360639343696 [label=ReluBackward0]
	140360639343600 -> 140360639343696
	140360639343600 [label=NativeBatchNormBackward0]
	140360639343120 -> 140360639343600
	140360639343120 [label=ConvolutionBackward0]
	140360636677136 -> 140360639343120
	140360639340384 -> 140360639343120
	140360634679456 [label="stage4.0.fuse_layers.3.1.0.0.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634679456 -> 140360639340384
	140360639340384 [label=AccumulateGrad]
	140360639339952 -> 140360639343600
	140360634695296 [label="stage4.0.fuse_layers.3.1.0.1.weight
 (36)" fillcolor=lightblue]
	140360634695296 -> 140360639339952
	140360639339952 [label=AccumulateGrad]
	140360639343264 -> 140360639343600
	140360634679536 [label="stage4.0.fuse_layers.3.1.0.1.bias
 (36)" fillcolor=lightblue]
	140360634679536 -> 140360639343264
	140360639343264 [label=AccumulateGrad]
	140360639346864 -> 140360639343936
	140360634681056 [label="stage4.0.fuse_layers.3.1.1.0.weight
 (144, 36, 3, 3)" fillcolor=lightblue]
	140360634681056 -> 140360639346864
	140360639346864 [label=AccumulateGrad]
	140360639344368 -> 140360639345040
	140360634690816 [label="stage4.0.fuse_layers.3.1.1.1.weight
 (144)" fillcolor=lightblue]
	140360634690816 -> 140360639344368
	140360639344368 [label=AccumulateGrad]
	140360639344416 -> 140360639345040
	140360634691056 [label="stage4.0.fuse_layers.3.1.1.1.bias
 (144)" fillcolor=lightblue]
	140360634691056 -> 140360639344416
	140360639344416 [label=AccumulateGrad]
	140360639344800 -> 140360639344752
	140360639344800 [label=NativeBatchNormBackward0]
	140360639343024 -> 140360639344800
	140360639343024 [label=ConvolutionBackward0]
	140360636673776 -> 140360639343024
	140360639342160 -> 140360639343024
	140360634687376 [label="stage4.0.fuse_layers.3.2.0.0.weight
 (144, 72, 3, 3)" fillcolor=lightblue]
	140360634687376 -> 140360639342160
	140360639342160 [label=AccumulateGrad]
	140360639344560 -> 140360639344800
	140360634686976 [label="stage4.0.fuse_layers.3.2.0.1.weight
 (144)" fillcolor=lightblue]
	140360634686976 -> 140360639344560
	140360639344560 [label=AccumulateGrad]
	140360639344896 -> 140360639344800
	140360634687776 [label="stage4.0.fuse_layers.3.2.0.1.bias
 (144)" fillcolor=lightblue]
	140360634687776 -> 140360639344896
	140360639344896 [label=AccumulateGrad]
	140360635803792 -> 140360639345280
	140360639345472 -> 140360639345376
	140360634569888 [label="stage4.1.branches.3.0.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634569888 -> 140360639345472
	140360639345472 [label=AccumulateGrad]
	140360639345712 -> 140360639346192
	140360634569808 [label="stage4.1.branches.3.0.bn1.weight
 (144)" fillcolor=lightblue]
	140360634569808 -> 140360639345712
	140360639345712 [label=AccumulateGrad]
	140360639344992 -> 140360639346192
	140360634570048 [label="stage4.1.branches.3.0.bn1.bias
 (144)" fillcolor=lightblue]
	140360634570048 -> 140360639344992
	140360639344992 [label=AccumulateGrad]
	140360639344656 -> 140360639344944
	140360634568528 [label="stage4.1.branches.3.0.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634568528 -> 140360639344656
	140360639344656 [label=AccumulateGrad]
	140360639346096 -> 140360639346288
	140360634568368 [label="stage4.1.branches.3.0.bn2.weight
 (144)" fillcolor=lightblue]
	140360634568368 -> 140360639346096
	140360639346096 [label=AccumulateGrad]
	140360639346240 -> 140360639346288
	140360634568448 [label="stage4.1.branches.3.0.bn2.bias
 (144)" fillcolor=lightblue]
	140360634568448 -> 140360639346240
	140360639346240 [label=AccumulateGrad]
	140360639346048 -> 140360639346528
	140360639345664 -> 140360639346768
	140360634567088 [label="stage4.1.branches.3.1.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634567088 -> 140360639345664
	140360639345664 [label=AccumulateGrad]
	140360639346672 -> 140360639346480
	140360634567008 [label="stage4.1.branches.3.1.bn1.weight
 (144)" fillcolor=lightblue]
	140360634567008 -> 140360639346672
	140360639346672 [label=AccumulateGrad]
	140360639347200 -> 140360639346480
	140360634567168 [label="stage4.1.branches.3.1.bn1.bias
 (144)" fillcolor=lightblue]
	140360634567168 -> 140360639347200
	140360639347200 [label=AccumulateGrad]
	140360639343168 -> 140360639346336
	140360634565808 [label="stage4.1.branches.3.1.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634565808 -> 140360639343168
	140360639343168 [label=AccumulateGrad]
	140360639343072 -> 140360639347824
	140360634565648 [label="stage4.1.branches.3.1.bn2.weight
 (144)" fillcolor=lightblue]
	140360634565648 -> 140360639343072
	140360639343072 [label=AccumulateGrad]
	140360639347344 -> 140360639347824
	140360634565728 [label="stage4.1.branches.3.1.bn2.bias
 (144)" fillcolor=lightblue]
	140360634565728 -> 140360639347344
	140360639347344 [label=AccumulateGrad]
	140360639347632 -> 140360639347440
	140360639347920 -> 140360639348544
	140360634579888 [label="stage4.1.branches.3.2.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634579888 -> 140360639347920
	140360639347920 [label=AccumulateGrad]
	140360639348112 -> 140360639348448
	140360634579488 [label="stage4.1.branches.3.2.bn1.weight
 (144)" fillcolor=lightblue]
	140360634579488 -> 140360639348112
	140360639348112 [label=AccumulateGrad]
	140360639348064 -> 140360639348448
	140360634580128 [label="stage4.1.branches.3.2.bn1.bias
 (144)" fillcolor=lightblue]
	140360634580128 -> 140360639348064
	140360639348064 [label=AccumulateGrad]
	140360639342928 -> 140360662912736
	140360634576448 [label="stage4.1.branches.3.2.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634576448 -> 140360639342928
	140360639342928 [label=AccumulateGrad]
	140360662909328 -> 140360639264320
	140360634575808 [label="stage4.1.branches.3.2.bn2.weight
 (144)" fillcolor=lightblue]
	140360634575808 -> 140360662909328
	140360662909328 [label=AccumulateGrad]
	140360639264176 -> 140360639264320
	140360634576048 [label="stage4.1.branches.3.2.bn2.bias
 (144)" fillcolor=lightblue]
	140360634576048 -> 140360639264176
	140360639264176 [label=AccumulateGrad]
	140360639264992 -> 140360874338784
	140360634877600 -> 140360634889312
	140360634572528 [label="stage4.1.branches.3.3.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634572528 -> 140360634877600
	140360634877600 [label=AccumulateGrad]
	140360634887008 -> 140360910393872
	140360634572288 [label="stage4.1.branches.3.3.bn1.weight
 (144)" fillcolor=lightblue]
	140360634572288 -> 140360634887008
	140360634887008 [label=AccumulateGrad]
	140360634880144 -> 140360910393872
	140360634572768 [label="stage4.1.branches.3.3.bn1.bias
 (144)" fillcolor=lightblue]
	140360634572768 -> 140360634880144
	140360634880144 [label=AccumulateGrad]
	140360910403856 -> 140360643101888
	140360634569248 [label="stage4.1.branches.3.3.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634569248 -> 140360910403856
	140360910403856 [label=AccumulateGrad]
	140360643110240 -> 140360635806144
	140360634568128 [label="stage4.1.branches.3.3.bn2.weight
 (144)" fillcolor=lightblue]
	140360634568128 -> 140360643110240
	140360643110240 [label=AccumulateGrad]
	140360643105680 -> 140360635806144
	140360634568848 [label="stage4.1.branches.3.3.bn2.bias
 (144)" fillcolor=lightblue]
	140360634568848 -> 140360643105680
	140360643105680 [label=AccumulateGrad]
	140360635802016 -> 140360635805328
	140360635805376 -> 140360637334768
	140360634495968 [label="stage4.1.fuse_layers.0.3.0.weight
 (18, 144, 1, 1)" fillcolor=lightblue]
	140360634495968 -> 140360635805376
	140360635805376 [label=AccumulateGrad]
	140360637340432 -> 140360637340480
	140360634495808 [label="stage4.1.fuse_layers.0.3.1.weight
 (18)" fillcolor=lightblue]
	140360634495808 -> 140360637340432
	140360637340432 [label=AccumulateGrad]
	140360637341728 -> 140360637340480
	140360634496048 [label="stage4.1.fuse_layers.0.3.1.bias
 (18)" fillcolor=lightblue]
	140360634496048 -> 140360637341728
	140360637341728 [label=AccumulateGrad]
	140360637341968 -> 140360637342160
	140360634483808 [label="stage4.2.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634483808 -> 140360637341968
	140360637341968 [label=AccumulateGrad]
	140360637341920 -> 140360637342256
	140360634485648 [label="stage4.2.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140360634485648 -> 140360637341920
	140360637341920 [label=AccumulateGrad]
	140360637342352 -> 140360637342256
	140360634483888 [label="stage4.2.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140360634483888 -> 140360637342352
	140360637342352 [label=AccumulateGrad]
	140360637342448 -> 140360637342736
	140360634446976 [label="stage4.2.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634446976 -> 140360637342448
	140360637342448 [label=AccumulateGrad]
	140360637342784 -> 140360637342880
	140360634446656 [label="stage4.2.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140360634446656 -> 140360637342784
	140360637342784 [label=AccumulateGrad]
	140360637342832 -> 140360637342880
	140360634446816 [label="stage4.2.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140360634446816 -> 140360637342832
	140360637342832 [label=AccumulateGrad]
	140360637342928 -> 140360637342496
	140360637343120 -> 140360637342976
	140360634445296 [label="stage4.2.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634445296 -> 140360637343120
	140360637343120 [label=AccumulateGrad]
	140360637343360 -> 140360637343408
	140360634445136 [label="stage4.2.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140360634445136 -> 140360637343360
	140360637343360 [label=AccumulateGrad]
	140360637343504 -> 140360637343408
	140360634445456 [label="stage4.2.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140360634445456 -> 140360637343504
	140360637343504 [label=AccumulateGrad]
	140360637343312 -> 140360637343744
	140360634443936 [label="stage4.2.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634443936 -> 140360637343312
	140360637343312 [label=AccumulateGrad]
	140360637343792 -> 140360637343600
	140360634443616 [label="stage4.2.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140360634443616 -> 140360637343792
	140360637343792 [label=AccumulateGrad]
	140360637343840 -> 140360637343600
	140360634443776 [label="stage4.2.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140360634443776 -> 140360637343840
	140360637343840 [label=AccumulateGrad]
	140360637343024 -> 140360637344128
	140360637344224 -> 140360637344464
	140360634442256 [label="stage4.2.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634442256 -> 140360637344224
	140360637344224 [label=AccumulateGrad]
	140360637344512 -> 140360637344560
	140360634442096 [label="stage4.2.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140360634442096 -> 140360637344512
	140360637344512 [label=AccumulateGrad]
	140360637344656 -> 140360637344560
	140360634442416 [label="stage4.2.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140360634442416 -> 140360637344656
	140360637344656 [label=AccumulateGrad]
	140360637344752 -> 140360637344896
	140360634440896 [label="stage4.2.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634440896 -> 140360637344752
	140360637344752 [label=AccumulateGrad]
	140360637344944 -> 140360637345040
	140360634440576 [label="stage4.2.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140360634440576 -> 140360637344944
	140360637344944 [label=AccumulateGrad]
	140360637344704 -> 140360637345040
	140360634440736 [label="stage4.2.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140360634440736 -> 140360637344704
	140360637344704 [label=AccumulateGrad]
	140360637345088 -> 140360637345136
	140360637345232 -> 140360637345280
	140360634439216 [label="stage4.2.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634439216 -> 140360637345232
	140360637345232 [label=AccumulateGrad]
	140360637345808 -> 140360637345856
	140360634439056 [label="stage4.2.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140360634439056 -> 140360637345808
	140360637345808 [label=AccumulateGrad]
	140360637346048 -> 140360637345856
	140360634439376 [label="stage4.2.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140360634439376 -> 140360637346048
	140360637346048 [label=AccumulateGrad]
	140360637346144 -> 140360637345760
	140360634437856 [label="stage4.2.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634437856 -> 140360637346144
	140360637346144 [label=AccumulateGrad]
	140360637346384 -> 140360637346864
	140360634437536 [label="stage4.2.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140360634437536 -> 140360637346384
	140360637346384 [label=AccumulateGrad]
	140360637346816 -> 140360637346864
	140360634437696 [label="stage4.2.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140360634437696 -> 140360637346816
	140360637346816 [label=AccumulateGrad]
	140360637346768 -> 140360637346912
	140360637347344 -> 140360637346720
	140360637347344 [label=UpsampleBilinear2DBackward0]
	140360637346336 -> 140360637347344
	140360637346336 [label=NativeBatchNormBackward0]
	140360637345184 -> 140360637346336
	140360637345184 [label=ConvolutionBackward0]
	140360637344992 -> 140360637345184
	140360637344992 [label=ReluBackward0]
	140360637344176 -> 140360637344992
	140360637344176 [label=AddBackward0]
	140360637343888 -> 140360637344176
	140360637343888 [label=NativeBatchNormBackward0]
	140360637344320 -> 140360637343888
	140360637344320 [label=ConvolutionBackward0]
	140360637343264 -> 140360637344320
	140360637343264 [label=ReluBackward0]
	140360637343216 -> 140360637343264
	140360637343216 [label=NativeBatchNormBackward0]
	140360637341632 -> 140360637343216
	140360637341632 [label=ConvolutionBackward0]
	140360637344800 -> 140360637341632
	140360637344800 [label=ReluBackward0]
	140360637342064 -> 140360637344800
	140360637342064 [label=AddBackward0]
	140360635804512 -> 140360637342064
	140360635804512 [label=NativeBatchNormBackward0]
	140360910404000 -> 140360635804512
	140360910404000 [label=ConvolutionBackward0]
	140360634877936 -> 140360910404000
	140360634877936 [label=ReluBackward0]
	140360639262592 -> 140360634877936
	140360639262592 [label=NativeBatchNormBackward0]
	140360639347584 -> 140360639262592
	140360639347584 [label=ConvolutionBackward0]
	140360635796496 -> 140360639347584
	140360635796496 [label=ReluBackward0]
	140360639346432 -> 140360635796496
	140360639346432 [label=AddBackward0]
	140360639346384 -> 140360639346432
	140360639346384 [label=NativeBatchNormBackward0]
	140360639346624 -> 140360639346384
	140360639346624 [label=ConvolutionBackward0]
	140360639345568 -> 140360639346624
	140360639345568 [label=ReluBackward0]
	140360639344608 -> 140360639345568
	140360639344608 [label=NativeBatchNormBackward0]
	140360639343504 -> 140360639344608
	140360639343504 [label=ConvolutionBackward0]
	140360639347056 -> 140360639343504
	140360639347056 [label=ReluBackward0]
	140360639341776 -> 140360639347056
	140360639341776 [label=AddBackward0]
	140360639342064 -> 140360639341776
	140360639342064 [label=NativeBatchNormBackward0]
	140360639341824 -> 140360639342064
	140360639341824 [label=ConvolutionBackward0]
	140360639340816 -> 140360639341824
	140360639340816 [label=ReluBackward0]
	140360639340336 -> 140360639340816
	140360639340336 [label=NativeBatchNormBackward0]
	140360639340960 -> 140360639340336
	140360639340960 [label=ConvolutionBackward0]
	140360639341248 -> 140360639340960
	140360639341248 [label=ReluBackward0]
	140360639340048 -> 140360639341248
	140360639340048 [label=AddBackward0]
	140360639335008 -> 140360639340048
	140360639335008 [label=AddBackward0]
	140360639339712 -> 140360639335008
	140360639339712 [label=AddBackward0]
	140360639339376 -> 140360639339712
	140360639339376 [label=NativeBatchNormBackward0]
	140360639339568 -> 140360639339376
	140360639339568 [label=ConvolutionBackward0]
	140360637341440 -> 140360639339568
	140360639339136 -> 140360639339568
	140360634494208 [label="stage4.1.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140360634494208 -> 140360639339136
	140360639339136 [label=AccumulateGrad]
	140360639339664 -> 140360639339376
	140360634493968 [label="stage4.1.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140360634493968 -> 140360639339664
	140360639339664 [label=AccumulateGrad]
	140360639338848 -> 140360639339376
	140360634494288 [label="stage4.1.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140360634494288 -> 140360639338848
	140360639338848 [label=AccumulateGrad]
	140360637340384 -> 140360639339712
	140360639339472 -> 140360639335008
	140360639339472 [label=UpsampleBilinear2DBackward0]
	140360639339616 -> 140360639339472
	140360639339616 [label=NativeBatchNormBackward0]
	140360639338656 -> 140360639339616
	140360639338656 [label=ConvolutionBackward0]
	140360637334864 -> 140360639338656
	140360639338896 -> 140360639338656
	140360634494528 [label="stage4.1.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140360634494528 -> 140360639338896
	140360639338896 [label=AccumulateGrad]
	140360639339328 -> 140360639339616
	140360634492688 [label="stage4.1.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140360634492688 -> 140360639339328
	140360639339328 [label=AccumulateGrad]
	140360639339760 -> 140360639339616
	140360634494448 [label="stage4.1.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140360634494448 -> 140360639339760
	140360639339760 [label=AccumulateGrad]
	140360639339856 -> 140360639340048
	140360639339856 [label=UpsampleBilinear2DBackward0]
	140360639338800 -> 140360639339856
	140360639338800 [label=NativeBatchNormBackward0]
	140360639338032 -> 140360639338800
	140360639338032 [label=ConvolutionBackward0]
	140360635806528 -> 140360639338032
	140360639338992 -> 140360639338032
	140360634491408 [label="stage4.1.fuse_layers.1.3.0.weight
 (36, 144, 1, 1)" fillcolor=lightblue]
	140360634491408 -> 140360639338992
	140360639338992 [label=AccumulateGrad]
	140360639338560 -> 140360639338800
	140360634491248 [label="stage4.1.fuse_layers.1.3.1.weight
 (36)" fillcolor=lightblue]
	140360634491248 -> 140360639338560
	140360639338560 [label=AccumulateGrad]
	140360639339088 -> 140360639338800
	140360634491488 [label="stage4.1.fuse_layers.1.3.1.bias
 (36)" fillcolor=lightblue]
	140360634491488 -> 140360639339088
	140360639339088 [label=AccumulateGrad]
	140360639340432 -> 140360639340960
	140360634436176 [label="stage4.2.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634436176 -> 140360639340432
	140360639340432 [label=AccumulateGrad]
	140360639340480 -> 140360639340336
	140360634436016 [label="stage4.2.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140360634436016 -> 140360639340480
	140360639340480 [label=AccumulateGrad]
	140360639341296 -> 140360639340336
	140360634436336 [label="stage4.2.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140360634436336 -> 140360639341296
	140360639341296 [label=AccumulateGrad]
	140360639341104 -> 140360639341824
	140360634434816 [label="stage4.2.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634434816 -> 140360639341104
	140360639341104 [label=AccumulateGrad]
	140360639341680 -> 140360639342064
	140360634434496 [label="stage4.2.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140360634434496 -> 140360639341680
	140360639341680 [label=AccumulateGrad]
	140360639342112 -> 140360639342064
	140360634434656 [label="stage4.2.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140360634434656 -> 140360639342112
	140360639342112 [label=AccumulateGrad]
	140360639341248 -> 140360639341776
	140360639342640 -> 140360639343504
	140360634449136 [label="stage4.2.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634449136 -> 140360639342640
	140360639342640 [label=AccumulateGrad]
	140360639342832 -> 140360639344608
	140360634448896 [label="stage4.2.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140360634448896 -> 140360639342832
	140360639342832 [label=AccumulateGrad]
	140360639345328 -> 140360639344608
	140360634449376 [label="stage4.2.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140360634449376 -> 140360639345328
	140360639345328 [label=AccumulateGrad]
	140360639345760 -> 140360639346624
	140360634445856 [label="stage4.2.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634445856 -> 140360639345760
	140360639345760 [label=AccumulateGrad]
	140360639345856 -> 140360639346384
	140360634445216 [label="stage4.2.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140360634445216 -> 140360639345856
	140360639345856 [label=AccumulateGrad]
	140360639346144 -> 140360639346384
	140360634445616 [label="stage4.2.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140360634445616 -> 140360639346144
	140360639346144 [label=AccumulateGrad]
	140360639347056 -> 140360639346432
	140360639347968 -> 140360639347584
	140360634441776 [label="stage4.2.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634441776 -> 140360639347968
	140360639347968 [label=AccumulateGrad]
	140360639347728 -> 140360639262592
	140360634441536 [label="stage4.2.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140360634441536 -> 140360639347728
	140360639347728 [label=AccumulateGrad]
	140360639335536 -> 140360639262592
	140360634442176 [label="stage4.2.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140360634442176 -> 140360639335536
	140360639335536 [label=AccumulateGrad]
	140360634886480 -> 140360910404000
	140360634438496 [label="stage4.2.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634438496 -> 140360634886480
	140360634886480 [label=AccumulateGrad]
	140360643116624 -> 140360635804512
	140360634438016 [label="stage4.2.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140360634438016 -> 140360643116624
	140360643116624 [label=AccumulateGrad]
	140360643110528 -> 140360635804512
	140360634438256 [label="stage4.2.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140360634438256 -> 140360643110528
	140360643110528 [label=AccumulateGrad]
	140360635796496 -> 140360637342064
	140360637342016 -> 140360637341632
	140360634434576 [label="stage4.2.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634434576 -> 140360637342016
	140360637342016 [label=AccumulateGrad]
	140360637342304 -> 140360637343216
	140360634434176 [label="stage4.2.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140360634434176 -> 140360637342304
	140360637342304 [label=AccumulateGrad]
	140360637341680 -> 140360637343216
	140360634434976 [label="stage4.2.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140360634434976 -> 140360637341680
	140360637341680 [label=AccumulateGrad]
	140360637343648 -> 140360637344320
	140360634366976 [label="stage4.2.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634366976 -> 140360637343648
	140360637343648 [label=AccumulateGrad]
	140360637344272 -> 140360637343888
	140360634366736 [label="stage4.2.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140360634366736 -> 140360637344272
	140360637344272 [label=AccumulateGrad]
	140360637343696 -> 140360637343888
	140360634366896 [label="stage4.2.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140360634366896 -> 140360637343696
	140360637343696 [label=AccumulateGrad]
	140360637344800 -> 140360637344176
	140360637344848 -> 140360637345184
	140360636395792 [label="stage4.2.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140360636395792 -> 140360637344848
	140360637344848 [label=AccumulateGrad]
	140360637345904 -> 140360637346336
	140360636395712 [label="stage4.2.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140360636395712 -> 140360637345904
	140360637345904 [label=AccumulateGrad]
	140360637347104 -> 140360637346336
	140360636395952 [label="stage4.2.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140360636395952 -> 140360637347104
	140360637347104 [label=AccumulateGrad]
	140360637348688 -> 140360637349456
	140360637348688 [label=UpsampleBilinear2DBackward0]
	140360637346288 -> 140360637348688
	140360637346288 [label=NativeBatchNormBackward0]
	140360637343456 -> 140360637346288
	140360637343456 [label=ConvolutionBackward0]
	140360637342112 -> 140360637343456
	140360637342112 [label=ReluBackward0]
	140360637341392 -> 140360637342112
	140360637341392 [label=AddBackward0]
	140360635799280 -> 140360637341392
	140360635799280 [label=NativeBatchNormBackward0]
	140360634886192 -> 140360635799280
	140360634886192 [label=ConvolutionBackward0]
	140360639346576 -> 140360634886192
	140360639346576 [label=ReluBackward0]
	140360639345136 -> 140360639346576
	140360639345136 [label=NativeBatchNormBackward0]
	140360639341872 -> 140360639345136
	140360639341872 [label=ConvolutionBackward0]
	140360637343072 -> 140360639341872
	140360637343072 [label=ReluBackward0]
	140360639340624 -> 140360637343072
	140360639340624 [label=AddBackward0]
	140360639340528 -> 140360639340624
	140360639340528 [label=NativeBatchNormBackward0]
	140360639338704 -> 140360639340528
	140360639338704 [label=ConvolutionBackward0]
	140360639339040 -> 140360639338704
	140360639339040 [label=ReluBackward0]
	140360639338224 -> 140360639339040
	140360639338224 [label=NativeBatchNormBackward0]
	140360639337984 -> 140360639338224
	140360639337984 [label=ConvolutionBackward0]
	140360639339520 -> 140360639337984
	140360639339520 [label=ReluBackward0]
	140360639337600 -> 140360639339520
	140360639337600 [label=AddBackward0]
	140360639337168 -> 140360639337600
	140360639337168 [label=NativeBatchNormBackward0]
	140360639337840 -> 140360639337168
	140360639337840 [label=ConvolutionBackward0]
	140360639340096 -> 140360639337840
	140360639340096 [label=ReluBackward0]
	140360639337264 -> 140360639340096
	140360639337264 [label=NativeBatchNormBackward0]
	140360639336160 -> 140360639337264
	140360639336160 [label=ConvolutionBackward0]
	140360639337936 -> 140360639336160
	140360639337936 [label=ReluBackward0]
	140360639336064 -> 140360639337936
	140360639336064 [label=AddBackward0]
	140360639336304 -> 140360639336064
	140360639336304 [label=NativeBatchNormBackward0]
	140360639336592 -> 140360639336304
	140360639336592 [label=ConvolutionBackward0]
	140360639336448 -> 140360639336592
	140360639336448 [label=ReluBackward0]
	140360639336496 -> 140360639336448
	140360639336496 [label=NativeBatchNormBackward0]
	140360639336016 -> 140360639336496
	140360639336016 [label=ConvolutionBackward0]
	140360639336400 -> 140360639336016
	140360639336400 [label=ReluBackward0]
	140360639335248 -> 140360639336400
	140360639335248 [label=AddBackward0]
	140360639334816 -> 140360639335248
	140360639334816 [label=AddBackward0]
	140360639334096 -> 140360639334816
	140360639334096 [label=AddBackward0]
	140360639334336 -> 140360639334096
	140360639334336 [label=NativeBatchNormBackward0]
	140360639334000 -> 140360639334336
	140360639334000 [label=ConvolutionBackward0]
	140360639333232 -> 140360639334000
	140360639333232 [label=ReluBackward0]
	140360639332944 -> 140360639333232
	140360639332944 [label=NativeBatchNormBackward0]
	140360639332992 -> 140360639332944
	140360639332992 [label=ConvolutionBackward0]
	140360637341440 -> 140360639332992
	140360639334672 -> 140360639332992
	140360634489648 [label="stage4.1.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634489648 -> 140360639334672
	140360639334672 [label=AccumulateGrad]
	140360639333568 -> 140360639332944
	140360634489408 [label="stage4.1.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140360634489408 -> 140360639333568
	140360639333568 [label=AccumulateGrad]
	140360639333280 -> 140360639332944
	140360634489728 [label="stage4.1.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140360634489728 -> 140360639333280
	140360639333280 [label=AccumulateGrad]
	140360639333856 -> 140360639334000
	140360634489488 [label="stage4.1.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140360634489488 -> 140360639333856
	140360639333856 [label=AccumulateGrad]
	140360639334192 -> 140360639334336
	140360634487888 [label="stage4.1.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140360634487888 -> 140360639334192
	140360639334192 [label=AccumulateGrad]
	140360639334288 -> 140360639334336
	140360634487968 [label="stage4.1.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140360634487968 -> 140360639334288
	140360639334288 [label=AccumulateGrad]
	140360639334528 -> 140360639334096
	140360639334528 [label=NativeBatchNormBackward0]
	140360639333376 -> 140360639334528
	140360639333376 [label=ConvolutionBackward0]
	140360637340384 -> 140360639333376
	140360639340768 -> 140360639333376
	140360634486448 [label="stage4.1.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140360634486448 -> 140360639340768
	140360639340768 [label=AccumulateGrad]
	140360639333616 -> 140360639334528
	140360634486368 [label="stage4.1.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140360634486368 -> 140360639333616
	140360639333616 [label=AccumulateGrad]
	140360639333520 -> 140360639334528
	140360634486608 [label="stage4.1.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140360634486608 -> 140360639333520
	140360639333520 [label=AccumulateGrad]
	140360637334864 -> 140360639334816
	140360639335104 -> 140360639335248
	140360639335104 [label=UpsampleBilinear2DBackward0]
	140360639334240 -> 140360639335104
	140360639334240 [label=NativeBatchNormBackward0]
	140360639337888 -> 140360639334240
	140360639337888 [label=ConvolutionBackward0]
	140360635806528 -> 140360639337888
	140360639332560 -> 140360639337888
	140360634489968 [label="stage4.1.fuse_layers.2.3.0.weight
 (72, 144, 1, 1)" fillcolor=lightblue]
	140360634489968 -> 140360639332560
	140360639332560 [label=AccumulateGrad]
	140360639333184 -> 140360639334240
	140360634485088 [label="stage4.1.fuse_layers.2.3.1.weight
 (72)" fillcolor=lightblue]
	140360634485088 -> 140360639333184
	140360639333184 [label=AccumulateGrad]
	140360639334720 -> 140360639334240
	140360634489888 [label="stage4.1.fuse_layers.2.3.1.bias
 (72)" fillcolor=lightblue]
	140360634489888 -> 140360639334720
	140360639334720 [label=AccumulateGrad]
	140360639335920 -> 140360639336016
	140360634365456 [label="stage4.2.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634365456 -> 140360639335920
	140360639335920 [label=AccumulateGrad]
	140360639335488 -> 140360639336496
	140360634365376 [label="stage4.2.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140360634365376 -> 140360639335488
	140360639335488 [label=AccumulateGrad]
	140360639335632 -> 140360639336496
	140360634365616 [label="stage4.2.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140360634365616 -> 140360639335632
	140360639335632 [label=AccumulateGrad]
	140360639336352 -> 140360639336592
	140360634364096 [label="stage4.2.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634364096 -> 140360639336352
	140360639336352 [label=AccumulateGrad]
	140360639335680 -> 140360639336304
	140360634363856 [label="stage4.2.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140360634363856 -> 140360639335680
	140360639335680 [label=AccumulateGrad]
	140360639336544 -> 140360639336304
	140360634363936 [label="stage4.2.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140360634363936 -> 140360639336544
	140360639336544 [label=AccumulateGrad]
	140360639336400 -> 140360639336064
	140360639346720 -> 140360639336160
	140360634362416 [label="stage4.2.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634362416 -> 140360639346720
	140360639346720 [label=AccumulateGrad]
	140360639337360 -> 140360639337264
	140360634362336 [label="stage4.2.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140360634362336 -> 140360639337360
	140360639337360 [label=AccumulateGrad]
	140360639337504 -> 140360639337264
	140360634362576 [label="stage4.2.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140360634362576 -> 140360639337504
	140360639337504 [label=AccumulateGrad]
	140360639336928 -> 140360639337840
	140360634361056 [label="stage4.2.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634361056 -> 140360639336928
	140360639336928 [label=AccumulateGrad]
	140360639337648 -> 140360639337168
	140360634360816 [label="stage4.2.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140360634360816 -> 140360639337648
	140360639337648 [label=AccumulateGrad]
	140360639337456 -> 140360639337168
	140360634360896 [label="stage4.2.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140360634360896 -> 140360639337456
	140360639337456 [label=AccumulateGrad]
	140360639337936 -> 140360639337600
	140360639338080 -> 140360639337984
	140360634359376 [label="stage4.2.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634359376 -> 140360639338080
	140360639338080 [label=AccumulateGrad]
	140360639338416 -> 140360639338224
	140360634359296 [label="stage4.2.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140360634359296 -> 140360639338416
	140360639338416 [label=AccumulateGrad]
	140360639337696 -> 140360639338224
	140360634359536 [label="stage4.2.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140360634359536 -> 140360639337696
	140360639337696 [label=AccumulateGrad]
	140360639338512 -> 140360639338704
	140360634358016 [label="stage4.2.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634358016 -> 140360639338512
	140360639338512 [label=AccumulateGrad]
	140360639339184 -> 140360639340528
	140360634357856 [label="stage4.2.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140360634357856 -> 140360639339184
	140360639339184 [label=AccumulateGrad]
	140360639339424 -> 140360639340528
	140360634357936 [label="stage4.2.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140360634357936 -> 140360639339424
	140360639339424 [label=AccumulateGrad]
	140360639339520 -> 140360639340624
	140360639340576 -> 140360639341872
	140360634356576 [label="stage4.2.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634356576 -> 140360639340576
	140360639340576 [label=AccumulateGrad]
	140360639341440 -> 140360639345136
	140360634356496 [label="stage4.2.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140360634356496 -> 140360639341440
	140360639341440 [label=AccumulateGrad]
	140360639345424 -> 140360639345136
	140360634356656 [label="stage4.2.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140360634356656 -> 140360639345424
	140360639345424 [label=AccumulateGrad]
	140360639347392 -> 140360634886192
	140360634355296 [label="stage4.2.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140360634355296 -> 140360639347392
	140360639347392 [label=AccumulateGrad]
	140360639333088 -> 140360635799280
	140360634355136 [label="stage4.2.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140360634355136 -> 140360639333088
	140360639333088 [label=AccumulateGrad]
	140360639348496 -> 140360635799280
	140360634355216 [label="stage4.2.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140360634355216 -> 140360639348496
	140360639348496 [label=AccumulateGrad]
	140360637343072 -> 140360637341392
	140360637343168 -> 140360637343456
	140360636394272 [label="stage4.2.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140360636394272 -> 140360637343168
	140360637343168 [label=AccumulateGrad]
	140360637344608 -> 140360637346288
	140360636394192 [label="stage4.2.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140360636394192 -> 140360637344608
	140360637344608 [label=AccumulateGrad]
	140360637347392 -> 140360637346288
	140360636394432 [label="stage4.2.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140360636394432 -> 140360637347392
	140360637347392 [label=AccumulateGrad]
	140360637347920 -> 140360637348256
	140360637347920 [label=UpsampleBilinear2DBackward0]
	140360637340000 -> 140360637347920
	140360637340000 [label=NativeBatchNormBackward0]
	140360637344416 -> 140360637340000
	140360637344416 [label=ConvolutionBackward0]
	140360639341392 -> 140360637344416
	140360639341392 [label=ReluBackward0]
	140360639338368 -> 140360639341392
	140360639338368 [label=AddBackward0]
	140360639343216 -> 140360639338368
	140360639343216 [label=NativeBatchNormBackward0]
	140360639338944 -> 140360639343216
	140360639338944 [label=ConvolutionBackward0]
	140360639338272 -> 140360639338944
	140360639338272 [label=ReluBackward0]
	140360639337552 -> 140360639338272
	140360639337552 [label=NativeBatchNormBackward0]
	140360639336208 -> 140360639337552
	140360639336208 [label=ConvolutionBackward0]
	140360639340864 -> 140360639336208
	140360639340864 [label=ReluBackward0]
	140360639335728 -> 140360639340864
	140360639335728 [label=AddBackward0]
	140360639335584 -> 140360639335728
	140360639335584 [label=NativeBatchNormBackward0]
	140360639336688 -> 140360639335584
	140360639336688 [label=ConvolutionBackward0]
	140360639347152 -> 140360639336688
	140360639347152 [label=ReluBackward0]
	140360639332512 -> 140360639347152
	140360639332512 [label=NativeBatchNormBackward0]
	140360639332896 -> 140360639332512
	140360639332896 [label=ConvolutionBackward0]
	140360639334912 -> 140360639332896
	140360639334912 [label=ReluBackward0]
	140360639333328 -> 140360639334912
	140360639333328 [label=AddBackward0]
	140360887643120 -> 140360639333328
	140360887643120 [label=NativeBatchNormBackward0]
	140360634552608 -> 140360887643120
	140360634552608 [label=ConvolutionBackward0]
	140360634555344 -> 140360634552608
	140360634555344 [label=ReluBackward0]
	140360634554864 -> 140360634555344
	140360634554864 [label=NativeBatchNormBackward0]
	140360634559856 -> 140360634554864
	140360634559856 [label=ConvolutionBackward0]
	140360887638128 -> 140360634559856
	140360887638128 [label=ReluBackward0]
	140360634555536 -> 140360887638128
	140360634555536 [label=AddBackward0]
	140360634560672 -> 140360634555536
	140360634560672 [label=NativeBatchNormBackward0]
	140360634554000 -> 140360634560672
	140360634554000 [label=ConvolutionBackward0]
	140360643270384 -> 140360634554000
	140360643270384 [label=ReluBackward0]
	140360643265296 -> 140360643270384
	140360643265296 [label=NativeBatchNormBackward0]
	140360643270480 -> 140360643265296
	140360643270480 [label=ConvolutionBackward0]
	140360634557552 -> 140360643270480
	140360634557552 [label=ReluBackward0]
	140360634407408 -> 140360634557552
	140360634407408 [label=AddBackward0]
	140360634404000 -> 140360634407408
	140360634404000 [label=AddBackward0]
	140360634416624 -> 140360634404000
	140360634416624 [label=AddBackward0]
	140360634401312 -> 140360634416624
	140360634401312 [label=NativeBatchNormBackward0]
	140360634404720 -> 140360634401312
	140360634404720 [label=ConvolutionBackward0]
	140360652204752 -> 140360634404720
	140360652204752 [label=ReluBackward0]
	140360652199712 -> 140360652204752
	140360652199712 [label=NativeBatchNormBackward0]
	140360652199856 -> 140360652199712
	140360652199856 [label=ConvolutionBackward0]
	140360652379888 -> 140360652199856
	140360652379888 [label=ReluBackward0]
	140360662618112 -> 140360652379888
	140360662618112 [label=NativeBatchNormBackward0]
	140360662629104 -> 140360662618112
	140360662629104 [label=ConvolutionBackward0]
	140360637341440 -> 140360662629104
	140360662625744 -> 140360662629104
	140360634483568 [label="stage4.1.fuse_layers.3.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634483568 -> 140360662625744
	140360662625744 [label=AccumulateGrad]
	140360662617632 -> 140360662618112
	140360634483328 [label="stage4.1.fuse_layers.3.0.0.1.weight
 (18)" fillcolor=lightblue]
	140360634483328 -> 140360662617632
	140360662617632 [label=AccumulateGrad]
	140360662628720 -> 140360662618112
	140360634483648 [label="stage4.1.fuse_layers.3.0.0.1.bias
 (18)" fillcolor=lightblue]
	140360634483648 -> 140360662628720
	140360662628720 [label=AccumulateGrad]
	140360662619888 -> 140360652199856
	140360634483408 [label="stage4.1.fuse_layers.3.0.1.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360634483408 -> 140360662619888
	140360662619888 [label=AccumulateGrad]
	140360652201008 -> 140360652199712
	140360634495888 [label="stage4.1.fuse_layers.3.0.1.1.weight
 (18)" fillcolor=lightblue]
	140360634495888 -> 140360652201008
	140360652201008 [label=AccumulateGrad]
	140360652376720 -> 140360652199712
	140360634496288 [label="stage4.1.fuse_layers.3.0.1.1.bias
 (18)" fillcolor=lightblue]
	140360634496288 -> 140360652376720
	140360652376720 [label=AccumulateGrad]
	140360652204656 -> 140360634404720
	140360634496688 [label="stage4.1.fuse_layers.3.0.2.0.weight
 (144, 18, 3, 3)" fillcolor=lightblue]
	140360634496688 -> 140360652204656
	140360652204656 [label=AccumulateGrad]
	140360652204608 -> 140360634401312
	140360634492368 [label="stage4.1.fuse_layers.3.0.2.1.weight
 (144)" fillcolor=lightblue]
	140360634492368 -> 140360652204608
	140360652204608 [label=AccumulateGrad]
	140360652200864 -> 140360634401312
	140360634492608 [label="stage4.1.fuse_layers.3.0.2.1.bias
 (144)" fillcolor=lightblue]
	140360634492608 -> 140360652200864
	140360652200864 [label=AccumulateGrad]
	140360634412112 -> 140360634416624
	140360634412112 [label=NativeBatchNormBackward0]
	140360652200048 -> 140360634412112
	140360652200048 [label=ConvolutionBackward0]
	140360662614944 -> 140360652200048
	140360662614944 [label=ReluBackward0]
	140360635028224 -> 140360662614944
	140360635028224 [label=NativeBatchNormBackward0]
	140360635027408 -> 140360635028224
	140360635027408 [label=ConvolutionBackward0]
	140360637340384 -> 140360635027408
	140360635025008 -> 140360635027408
	140360634489088 [label="stage4.1.fuse_layers.3.1.0.0.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360634489088 -> 140360635025008
	140360635025008 [label=AccumulateGrad]
	140360635029904 -> 140360635028224
	140360634488688 [label="stage4.1.fuse_layers.3.1.0.1.weight
 (36)" fillcolor=lightblue]
	140360634488688 -> 140360635029904
	140360635029904 [label=AccumulateGrad]
	140360635025200 -> 140360635028224
	140360634489328 [label="stage4.1.fuse_layers.3.1.0.1.bias
 (36)" fillcolor=lightblue]
	140360634489328 -> 140360635025200
	140360635025200 [label=AccumulateGrad]
	140360662627664 -> 140360652200048
	140360634492848 [label="stage4.1.fuse_layers.3.1.1.0.weight
 (144, 36, 3, 3)" fillcolor=lightblue]
	140360634492848 -> 140360662627664
	140360662627664 [label=AccumulateGrad]
	140360652204896 -> 140360634412112
	140360634485008 [label="stage4.1.fuse_layers.3.1.1.1.weight
 (144)" fillcolor=lightblue]
	140360634485008 -> 140360652204896
	140360652204896 [label=AccumulateGrad]
	140360652200096 -> 140360634412112
	140360634485248 [label="stage4.1.fuse_layers.3.1.1.1.bias
 (144)" fillcolor=lightblue]
	140360634485248 -> 140360652200096
	140360652200096 [label=AccumulateGrad]
	140360634409232 -> 140360634404000
	140360634409232 [label=NativeBatchNormBackward0]
	140360662629488 -> 140360634409232
	140360662629488 [label=ConvolutionBackward0]
	140360637334864 -> 140360662629488
	140360635031776 -> 140360662629488
	140360634449536 [label="stage4.1.fuse_layers.3.2.0.0.weight
 (144, 72, 3, 3)" fillcolor=lightblue]
	140360634449536 -> 140360635031776
	140360635031776 [label=AccumulateGrad]
	140360652381616 -> 140360634409232
	140360634449456 [label="stage4.1.fuse_layers.3.2.0.1.weight
 (144)" fillcolor=lightblue]
	140360634449456 -> 140360652381616
	140360652381616 [label=AccumulateGrad]
	140360634405584 -> 140360634409232
	140360634449616 [label="stage4.1.fuse_layers.3.2.0.1.bias
 (144)" fillcolor=lightblue]
	140360634449616 -> 140360634405584
	140360634405584 [label=AccumulateGrad]
	140360635806528 -> 140360634407408
	140360634406928 -> 140360643270480
	140360634353776 [label="stage4.2.branches.3.0.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634353776 -> 140360634406928
	140360634406928 [label=AccumulateGrad]
	140360643279936 -> 140360643265296
	140360634353696 [label="stage4.2.branches.3.0.bn1.weight
 (144)" fillcolor=lightblue]
	140360634353696 -> 140360643279936
	140360643279936 [label=AccumulateGrad]
	140360643270720 -> 140360643265296
	140360634353936 [label="stage4.2.branches.3.0.bn1.bias
 (144)" fillcolor=lightblue]
	140360634353936 -> 140360643270720
	140360643270720 [label=AccumulateGrad]
	140360643277584 -> 140360634554000
	140360634352416 [label="stage4.2.branches.3.0.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634352416 -> 140360643277584
	140360643277584 [label=AccumulateGrad]
	140360634555872 -> 140360634560672
	140360634352256 [label="stage4.2.branches.3.0.bn2.weight
 (144)" fillcolor=lightblue]
	140360634352256 -> 140360634555872
	140360634555872 [label=AccumulateGrad]
	140360643275952 -> 140360634560672
	140360634352336 [label="stage4.2.branches.3.0.bn2.bias
 (144)" fillcolor=lightblue]
	140360634352336 -> 140360643275952
	140360643275952 [label=AccumulateGrad]
	140360634557552 -> 140360634555536
	140360634551504 -> 140360634559856
	140360634365936 [label="stage4.2.branches.3.1.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634365936 -> 140360634551504
	140360634551504 [label=AccumulateGrad]
	140360634562400 -> 140360634554864
	140360634365536 [label="stage4.2.branches.3.1.bn1.weight
 (144)" fillcolor=lightblue]
	140360634365536 -> 140360634562400
	140360634562400 [label=AccumulateGrad]
	140360634562016 -> 140360634554864
	140360634366336 [label="stage4.2.branches.3.1.bn1.bias
 (144)" fillcolor=lightblue]
	140360634366336 -> 140360634562016
	140360634562016 [label=AccumulateGrad]
	140360634560240 -> 140360634552608
	140360634362496 [label="stage4.2.branches.3.1.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634362496 -> 140360634560240
	140360634560240 [label=AccumulateGrad]
	140360634557840 -> 140360887643120
	140360634362016 [label="stage4.2.branches.3.1.bn2.weight
 (144)" fillcolor=lightblue]
	140360634362016 -> 140360634557840
	140360634557840 [label=AccumulateGrad]
	140360634564272 -> 140360887643120
	140360634362256 [label="stage4.2.branches.3.1.bn2.bias
 (144)" fillcolor=lightblue]
	140360634362256 -> 140360634564272
	140360634564272 [label=AccumulateGrad]
	140360887638128 -> 140360639333328
	140360639333424 -> 140360639332896
	140360634358736 [label="stage4.2.branches.3.2.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634358736 -> 140360639333424
	140360639333424 [label=AccumulateGrad]
	140360639332704 -> 140360639332512
	140360634358336 [label="stage4.2.branches.3.2.bn1.weight
 (144)" fillcolor=lightblue]
	140360634358336 -> 140360639332704
	140360639332704 [label=AccumulateGrad]
	140360639336112 -> 140360639332512
	140360634358976 [label="stage4.2.branches.3.2.bn1.bias
 (144)" fillcolor=lightblue]
	140360634358976 -> 140360639336112
	140360639336112 [label=AccumulateGrad]
	140360639343408 -> 140360639336688
	140360634353856 [label="stage4.2.branches.3.2.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360634353856 -> 140360639343408
	140360639343408 [label=AccumulateGrad]
	140360639336976 -> 140360639335584
	140360634353376 [label="stage4.2.branches.3.2.bn2.weight
 (144)" fillcolor=lightblue]
	140360634353376 -> 140360639336976
	140360639336976 [label=AccumulateGrad]
	140360639335872 -> 140360639335584
	140360634353616 [label="stage4.2.branches.3.2.bn2.bias
 (144)" fillcolor=lightblue]
	140360634353616 -> 140360639335872
	140360639335872 [label=AccumulateGrad]
	140360639334912 -> 140360639335728
	140360639334768 -> 140360639336208
	140360636398832 [label="stage4.2.branches.3.3.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360636398832 -> 140360639334768
	140360639334768 [label=AccumulateGrad]
	140360639336736 -> 140360639337552
	140360636398752 [label="stage4.2.branches.3.3.bn1.weight
 (144)" fillcolor=lightblue]
	140360636398752 -> 140360639336736
	140360639336736 [label=AccumulateGrad]
	140360639337120 -> 140360639337552
	140360636398992 [label="stage4.2.branches.3.3.bn1.bias
 (144)" fillcolor=lightblue]
	140360636398992 -> 140360639337120
	140360639337120 [label=AccumulateGrad]
	140360639337408 -> 140360639338944
	140360636397392 [label="stage4.2.branches.3.3.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140360636397392 -> 140360639337408
	140360639337408 [label=AccumulateGrad]
	140360639337744 -> 140360639343216
	140360636397232 [label="stage4.2.branches.3.3.bn2.weight
 (144)" fillcolor=lightblue]
	140360636397232 -> 140360639337744
	140360639337744 [label=AccumulateGrad]
	140360639337792 -> 140360639343216
	140360636397312 [label="stage4.2.branches.3.3.bn2.bias
 (144)" fillcolor=lightblue]
	140360636397312 -> 140360639337792
	140360639337792 [label=AccumulateGrad]
	140360639340864 -> 140360639338368
	140360639341920 -> 140360637344416
	140360636392752 [label="stage4.2.fuse_layers.0.3.0.weight
 (18, 144, 1, 1)" fillcolor=lightblue]
	140360636392752 -> 140360639341920
	140360639341920 [label=AccumulateGrad]
	140360637342208 -> 140360637340000
	140360636392672 [label="stage4.2.fuse_layers.0.3.1.weight
 (18)" fillcolor=lightblue]
	140360636392672 -> 140360637342208
	140360637342208 [label=AccumulateGrad]
	140360637347440 -> 140360637340000
	140360636392912 [label="stage4.2.fuse_layers.0.3.1.bias
 (18)" fillcolor=lightblue]
	140360636392912 -> 140360637347440
	140360637347440 [label=AccumulateGrad]
	140360637349744 -> 140360637347824
	140360637349744 [label=UpsampleBilinear2DBackward0]
	140360637347152 -> 140360637349744
	140360637347152 [label=ReluBackward0]
	140360634887968 -> 140360637347152
	140360634887968 [label=AddBackward0]
	140360639348352 -> 140360634887968
	140360639348352 [label=AddBackward0]
	140360639335344 -> 140360639348352
	140360639335344 [label=AddBackward0]
	140360639343984 -> 140360639335344
	140360639343984 [label=NativeBatchNormBackward0]
	140360639337072 -> 140360639343984
	140360639337072 [label=ConvolutionBackward0]
	140360637347200 -> 140360639337072
	140360639332464 -> 140360639337072
	140360636390992 [label="stage4.2.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140360636390992 -> 140360639332464
	140360639332464 [label=AccumulateGrad]
	140360639335968 -> 140360639343984
	140360636390752 [label="stage4.2.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140360636390752 -> 140360639335968
	140360639335968 [label=AccumulateGrad]
	140360639337312 -> 140360639343984
	140360636391152 [label="stage4.2.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140360636391152 -> 140360639337312
	140360639337312 [label=AccumulateGrad]
	140360637344992 -> 140360639335344
	140360639336880 -> 140360639348352
	140360639336880 [label=UpsampleBilinear2DBackward0]
	140360639333040 -> 140360639336880
	140360639333040 [label=NativeBatchNormBackward0]
	140360639340192 -> 140360639333040
	140360639340192 [label=ConvolutionBackward0]
	140360637342112 -> 140360639340192
	140360634552992 -> 140360639340192
	140360636391392 [label="stage4.2.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140360636391392 -> 140360634552992
	140360634552992 [label=AccumulateGrad]
	140360639332848 -> 140360639333040
	140360636389472 [label="stage4.2.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140360636389472 -> 140360639332848
	140360639332848 [label=AccumulateGrad]
	140360639336640 -> 140360639333040
	140360636391232 [label="stage4.2.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140360636391232 -> 140360639336640
	140360639336640 [label=AccumulateGrad]
	140360639338176 -> 140360634887968
	140360639338176 [label=UpsampleBilinear2DBackward0]
	140360639348208 -> 140360639338176
	140360639348208 [label=NativeBatchNormBackward0]
	140360634559184 -> 140360639348208
	140360634559184 [label=ConvolutionBackward0]
	140360639341392 -> 140360634559184
	140360634549968 -> 140360634559184
	140360636388352 [label="stage4.2.fuse_layers.1.3.0.weight
 (36, 144, 1, 1)" fillcolor=lightblue]
	140360636388352 -> 140360634549968
	140360634549968 [label=AccumulateGrad]
	140360634563360 -> 140360639348208
	140360636388192 [label="stage4.2.fuse_layers.1.3.1.weight
 (36)" fillcolor=lightblue]
	140360636388192 -> 140360634563360
	140360634563360 [label=AccumulateGrad]
	140360634559376 -> 140360639348208
	140360636388432 [label="stage4.2.fuse_layers.1.3.1.bias
 (36)" fillcolor=lightblue]
	140360636388432 -> 140360634559376
	140360634559376 [label=AccumulateGrad]
	140360637349360 -> 140360637347824
	140360637349360 [label=UpsampleBilinear2DBackward0]
	140360637348016 -> 140360637349360
	140360637348016 [label=ReluBackward0]
	140360639345520 -> 140360637348016
	140360639345520 [label=AddBackward0]
	140360634561584 -> 140360639345520
	140360634561584 [label=AddBackward0]
	140360643265152 -> 140360634561584
	140360643265152 [label=AddBackward0]
	140360643276528 -> 140360643265152
	140360643276528 [label=NativeBatchNormBackward0]
	140360634406544 -> 140360643276528
	140360634406544 [label=ConvolutionBackward0]
	140360635025872 -> 140360634406544
	140360635025872 [label=ReluBackward0]
	140360635038304 -> 140360635025872
	140360635038304 [label=NativeBatchNormBackward0]
	140360635031248 -> 140360635038304
	140360635031248 [label=ConvolutionBackward0]
	140360637347200 -> 140360635031248
	140360635023520 -> 140360635031248
	140360636386592 [label="stage4.2.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360636386592 -> 140360635023520
	140360635023520 [label=AccumulateGrad]
	140360635029088 -> 140360635038304
	140360636386352 [label="stage4.2.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140360636386352 -> 140360635029088
	140360635029088 [label=AccumulateGrad]
	140360635035136 -> 140360635038304
	140360636386672 [label="stage4.2.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140360636386672 -> 140360635035136
	140360635035136 [label=AccumulateGrad]
	140360635025680 -> 140360634406544
	140360636386432 [label="stage4.2.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140360636386432 -> 140360635025680
	140360635025680 [label=AccumulateGrad]
	140360634408416 -> 140360643276528
	140360636384832 [label="stage4.2.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140360636384832 -> 140360634408416
	140360634408416 [label=AccumulateGrad]
	140360634404240 -> 140360643276528
	140360636384912 [label="stage4.2.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140360636384912 -> 140360634404240
	140360634404240 [label=AccumulateGrad]
	140360634410960 -> 140360643265152
	140360634410960 [label=NativeBatchNormBackward0]
	140360635027840 -> 140360634410960
	140360635027840 [label=ConvolutionBackward0]
	140360637344992 -> 140360635027840
	140360635028560 -> 140360635027840
	140360636383392 [label="stage4.2.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140360636383392 -> 140360635028560
	140360635028560 [label=AccumulateGrad]
	140360635035760 -> 140360634410960
	140360636383312 [label="stage4.2.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140360636383312 -> 140360635035760
	140360635035760 [label=AccumulateGrad]
	140360635030432 -> 140360634410960
	140360636383552 [label="stage4.2.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140360636383552 -> 140360635030432
	140360635030432 [label=AccumulateGrad]
	140360637342112 -> 140360634561584
	140360634554528 -> 140360639345520
	140360634554528 [label=UpsampleBilinear2DBackward0]
	140360634407264 -> 140360634554528
	140360634407264 [label=NativeBatchNormBackward0]
	140360635035808 -> 140360634407264
	140360635035808 [label=ConvolutionBackward0]
	140360639341392 -> 140360635035808
	140364036292464 -> 140360635035808
	140360636386912 [label="stage4.2.fuse_layers.2.3.0.weight
 (72, 144, 1, 1)" fillcolor=lightblue]
	140360636386912 -> 140364036292464
	140364036292464 [label=AccumulateGrad]
	140360635032784 -> 140360634407264
	140360636396672 [label="stage4.2.fuse_layers.2.3.1.weight
 (72)" fillcolor=lightblue]
	140360636396672 -> 140360635032784
	140360635032784 [label=AccumulateGrad]
	140360668142016 -> 140360634407264
	140360636386832 [label="stage4.2.fuse_layers.2.3.1.bias
 (72)" fillcolor=lightblue]
	140360636386832 -> 140360668142016
	140360668142016 [label=AccumulateGrad]
	140360637349504 -> 140360637347824
	140360637349504 [label=UpsampleBilinear2DBackward0]
	140360634555152 -> 140360637349504
	140360634555152 [label=ReluBackward0]
	140360643265104 -> 140360634555152
	140360643265104 [label=AddBackward0]
	140360668143936 -> 140360643265104
	140360668143936 [label=AddBackward0]
	140360865683760 -> 140360668143936
	140360865683760 [label=AddBackward0]
	140360633559280 -> 140360865683760
	140360633559280 [label=NativeBatchNormBackward0]
	140360633555728 -> 140360633559280
	140360633555728 [label=ConvolutionBackward0]
	140360633550544 -> 140360633555728
	140360633550544 [label=ReluBackward0]
	140360676105408 -> 140360633550544
	140360676105408 [label=NativeBatchNormBackward0]
	140360676104880 -> 140360676105408
	140360676104880 [label=ConvolutionBackward0]
	140360635324624 -> 140360676104880
	140360635324624 [label=ReluBackward0]
	140360635323424 -> 140360635324624
	140360635323424 [label=NativeBatchNormBackward0]
	140360635323040 -> 140360635323424
	140360635323040 [label=ConvolutionBackward0]
	140360637347200 -> 140360635323040
	140360635326304 -> 140360635323040
	140360636392832 [label="stage4.2.fuse_layers.3.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360636392832 -> 140360635326304
	140360635326304 [label=AccumulateGrad]
	140360635331680 -> 140360635323424
	140360636392352 [label="stage4.2.fuse_layers.3.0.0.1.weight
 (18)" fillcolor=lightblue]
	140360636392352 -> 140360635331680
	140360635331680 [label=AccumulateGrad]
	140360635324960 -> 140360635323424
	140360636393232 [label="stage4.2.fuse_layers.3.0.0.1.bias
 (18)" fillcolor=lightblue]
	140360636393232 -> 140360635324960
	140360635324960 [label=AccumulateGrad]
	140360635326256 -> 140360676104880
	140360636392592 [label="stage4.2.fuse_layers.3.0.1.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140360636392592 -> 140360635326256
	140360635326256 [label=AccumulateGrad]
	140360676103200 -> 140360676105408
	140360636388672 [label="stage4.2.fuse_layers.3.0.1.1.weight
 (18)" fillcolor=lightblue]
	140360636388672 -> 140360676103200
	140360676103200 [label=AccumulateGrad]
	140360635326928 -> 140360676105408
	140360636389072 [label="stage4.2.fuse_layers.3.0.1.1.bias
 (18)" fillcolor=lightblue]
	140360636389072 -> 140360635326928
	140360635326928 [label=AccumulateGrad]
	140360633551024 -> 140360633555728
	140360636389312 [label="stage4.2.fuse_layers.3.0.2.0.weight
 (144, 18, 3, 3)" fillcolor=lightblue]
	140360636389312 -> 140360633551024
	140360633551024 [label=AccumulateGrad]
	140360633556592 -> 140360633559280
	140360636384992 [label="stage4.2.fuse_layers.3.0.2.1.weight
 (144)" fillcolor=lightblue]
	140360636384992 -> 140360633556592
	140360633556592 [label=AccumulateGrad]
	140360633556256 -> 140360633559280
	140360636385232 [label="stage4.2.fuse_layers.3.0.2.1.bias
 (144)" fillcolor=lightblue]
	140360636385232 -> 140360633556256
	140360633556256 [label=AccumulateGrad]
	140360633562448 -> 140360865683760
	140360633562448 [label=NativeBatchNormBackward0]
	140360676105504 -> 140360633562448
	140360676105504 [label=ConvolutionBackward0]
	140360635325776 -> 140360676105504
	140360635325776 [label=ReluBackward0]
	140360635325584 -> 140360635325776
	140360635325584 [label=NativeBatchNormBackward0]
	140360634722832 -> 140360635325584
	140360634722832 [label=ConvolutionBackward0]
	140360637344992 -> 140360634722832
	140360634719472 -> 140360634722832
	140360636316832 [label="stage4.2.fuse_layers.3.1.0.0.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140360636316832 -> 140360634719472
	140360634719472 [label=AccumulateGrad]
	140360634728352 -> 140360635325584
	140360636316752 [label="stage4.2.fuse_layers.3.1.0.1.weight
 (36)" fillcolor=lightblue]
	140360636316752 -> 140360634728352
	140360634728352 [label=AccumulateGrad]
	140360634716640 -> 140360635325584
	140360636316912 [label="stage4.2.fuse_layers.3.1.0.1.bias
 (36)" fillcolor=lightblue]
	140360636316912 -> 140360634716640
	140360634716640 [label=AccumulateGrad]
	140360635328992 -> 140360676105504
	140360636315392 [label="stage4.2.fuse_layers.3.1.1.0.weight
 (144, 36, 3, 3)" fillcolor=lightblue]
	140360636315392 -> 140360635328992
	140360635328992 [label=AccumulateGrad]
	140360633563120 -> 140360633562448
	140360636315232 [label="stage4.2.fuse_layers.3.1.1.1.weight
 (144)" fillcolor=lightblue]
	140360636315232 -> 140360633563120
	140360633563120 [label=AccumulateGrad]
	140360633563792 -> 140360633562448
	140360636315312 [label="stage4.2.fuse_layers.3.1.1.1.bias
 (144)" fillcolor=lightblue]
	140360636315312 -> 140360633563792
	140360633563792 [label=AccumulateGrad]
	140360865685728 -> 140360668143936
	140360865685728 [label=NativeBatchNormBackward0]
	140360635321936 -> 140360865685728
	140360635321936 [label=ConvolutionBackward0]
	140360637342112 -> 140360635321936
	140360634725232 -> 140360635321936
	140360636313792 [label="stage4.2.fuse_layers.3.2.0.0.weight
 (144, 72, 3, 3)" fillcolor=lightblue]
	140360636313792 -> 140360634725232
	140360634725232 [label=AccumulateGrad]
	140360635325104 -> 140360865685728
	140360636313712 [label="stage4.2.fuse_layers.3.2.0.1.weight
 (144)" fillcolor=lightblue]
	140360636313712 -> 140360635325104
	140360635325104 [label=AccumulateGrad]
	140360633564176 -> 140360865685728
	140360636313872 [label="stage4.2.fuse_layers.3.2.0.1.bias
 (144)" fillcolor=lightblue]
	140360636313872 -> 140360633564176
	140360633564176 [label=AccumulateGrad]
	140360639341392 -> 140360643265104
	140360637348640 -> 140360637345712
	140360633528592 [label="head.0.weight
 (270, 270, 1, 1)" fillcolor=lightblue]
	140360633528592 -> 140360637348640
	140360637348640 [label=AccumulateGrad]
	140360637348544 -> 140360637345712
	140360633528912 [label="head.0.bias
 (270)" fillcolor=lightblue]
	140360633528912 -> 140360637348544
	140360637348544 [label=AccumulateGrad]
	140360637349408 -> 140360637348880
	140360633523792 [label="head.1.weight
 (270)" fillcolor=lightblue]
	140360633523792 -> 140360637349408
	140360637349408 [label=AccumulateGrad]
	140360637348928 -> 140360637348880
	140360633463616 [label="head.1.bias
 (270)" fillcolor=lightblue]
	140360633463616 -> 140360637348928
	140360637348928 [label=AccumulateGrad]
	140360637349840 -> 140360637349792
	140360636393872 [label="head.3.weight
 (9, 270, 1, 1)" fillcolor=lightblue]
	140360636393872 -> 140360637349840
	140360637349840 [label=AccumulateGrad]
	140360637348304 -> 140360637349792
	140360636385632 [label="head.3.bias
 (9)" fillcolor=lightblue]
	140360636385632 -> 140360637348304
	140360637348304 [label=AccumulateGrad]
	140360637349792 -> 140360636698128
}
