digraph {
	graph [size="904.8,904.8"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140321213736400 [label="
 (1, 9, 64, 64)" fillcolor=darkolivegreen1]
	140321440313600 [label=ConvolutionBackward0]
	140321259550752 -> 140321440313600
	140321259550752 [label=ReluBackward0]
	140321474227712 -> 140321259550752
	140321474227712 [label=NativeBatchNormBackward0]
	140321255077680 -> 140321474227712
	140321255077680 [label=ConvolutionBackward0]
	140321454072320 -> 140321255077680
	140321454072320 [label=CatBackward0]
	140321474593600 -> 140321454072320
	140321474593600 [label=ReluBackward0]
	140321223224256 -> 140321474593600
	140321223224256 [label=AddBackward0]
	140321223224688 -> 140321223224256
	140321223224688 [label=AddBackward0]
	140321223225888 -> 140321223224688
	140321223225888 [label=AddBackward0]
	140321259687168 -> 140321223225888
	140321259687168 [label=ReluBackward0]
	140321223781840 -> 140321259687168
	140321223781840 [label=AddBackward0]
	140321223782032 -> 140321223781840
	140321223782032 [label=NativeBatchNormBackward0]
	140324613969264 -> 140321223782032
	140324613969264 [label=ConvolutionBackward0]
	140321242824608 -> 140324613969264
	140321242824608 [label=ReluBackward0]
	140321242822592 -> 140321242824608
	140321242822592 [label=NativeBatchNormBackward0]
	140321467203888 -> 140321242822592
	140321467203888 [label=ConvolutionBackward0]
	140321255674432 -> 140321467203888
	140321255674432 [label=ReluBackward0]
	140321242579776 -> 140321255674432
	140321242579776 [label=AddBackward0]
	140321223060992 -> 140321242579776
	140321223060992 [label=NativeBatchNormBackward0]
	140321223061376 -> 140321223060992
	140321223061376 [label=ConvolutionBackward0]
	140321223061088 -> 140321223061376
	140321223061088 [label=ReluBackward0]
	140321213906368 -> 140321223061088
	140321213906368 [label=NativeBatchNormBackward0]
	140321213906656 -> 140321213906368
	140321213906656 [label=ConvolutionBackward0]
	140321223061232 -> 140321213906656
	140321223061232 [label=ReluBackward0]
	140321213905696 -> 140321223061232
	140321213905696 [label=AddBackward0]
	140321213905456 -> 140321213905696
	140321213905456 [label=NativeBatchNormBackward0]
	140321213905312 -> 140321213905456
	140321213905312 [label=ConvolutionBackward0]
	140321213904640 -> 140321213905312
	140321213904640 [label=ReluBackward0]
	140321213904160 -> 140321213904640
	140321213904160 [label=NativeBatchNormBackward0]
	140321213904112 -> 140321213904160
	140321213904112 [label=ConvolutionBackward0]
	140321213905840 -> 140321213904112
	140321213905840 [label=ReluBackward0]
	140321213903440 -> 140321213905840
	140321213903440 [label=AddBackward0]
	140321213903152 -> 140321213903440
	140321213903152 [label=NativeBatchNormBackward0]
	140321213902672 -> 140321213903152
	140321213902672 [label=ConvolutionBackward0]
	140321213902336 -> 140321213902672
	140321213902336 [label=ReluBackward0]
	140321213902096 -> 140321213902336
	140321213902096 [label=NativeBatchNormBackward0]
	140321213901808 -> 140321213902096
	140321213901808 [label=ConvolutionBackward0]
	140321213903296 -> 140321213901808
	140321213903296 [label=ReluBackward0]
	140321213901136 -> 140321213903296
	140321213901136 [label=AddBackward0]
	140321213900800 -> 140321213901136
	140321213900800 [label=AddBackward0]
	140321213900608 -> 140321213900800
	140321213900608 [label=AddBackward0]
	140321213900128 -> 140321213900608
	140321213900128 [label=ReluBackward0]
	140321213899936 -> 140321213900128
	140321213899936 [label=AddBackward0]
	140321213899648 -> 140321213899936
	140321213899648 [label=NativeBatchNormBackward0]
	140321213899408 -> 140321213899648
	140321213899408 [label=ConvolutionBackward0]
	140321213898784 -> 140321213899408
	140321213898784 [label=ReluBackward0]
	140321213898592 -> 140321213898784
	140321213898592 [label=NativeBatchNormBackward0]
	140321213898304 -> 140321213898592
	140321213898304 [label=ConvolutionBackward0]
	140321213899792 -> 140321213898304
	140321213899792 [label=ReluBackward0]
	140321213897632 -> 140321213899792
	140321213897632 [label=AddBackward0]
	140321213897296 -> 140321213897632
	140321213897296 [label=NativeBatchNormBackward0]
	140321213897104 -> 140321213897296
	140321213897104 [label=ConvolutionBackward0]
	140321213896720 -> 140321213897104
	140321213896720 [label=ReluBackward0]
	140321213896288 -> 140321213896720
	140321213896288 [label=NativeBatchNormBackward0]
	140321213895952 -> 140321213896288
	140321213895952 [label=ConvolutionBackward0]
	140321213897440 -> 140321213895952
	140321213897440 [label=ReluBackward0]
	140321213895280 -> 140321213897440
	140321213895280 [label=AddBackward0]
	140321213895232 -> 140321213895280
	140321213895232 [label=NativeBatchNormBackward0]
	140321213894752 -> 140321213895232
	140321213894752 [label=ConvolutionBackward0]
	140321213894416 -> 140321213894752
	140321213894416 [label=ReluBackward0]
	140321213893936 -> 140321213894416
	140321213893936 [label=NativeBatchNormBackward0]
	140321213893888 -> 140321213893936
	140321213893888 [label=ConvolutionBackward0]
	140321213895376 -> 140321213893888
	140321213895376 [label=ReluBackward0]
	140321213893216 -> 140321213895376
	140321213893216 [label=AddBackward0]
	140321213892928 -> 140321213893216
	140321213892928 [label=NativeBatchNormBackward0]
	140321213892688 -> 140321213892928
	140321213892688 [label=ConvolutionBackward0]
	140321213892064 -> 140321213892688
	140321213892064 [label=ReluBackward0]
	140321213891872 -> 140321213892064
	140321213891872 [label=NativeBatchNormBackward0]
	140321213891584 -> 140321213891872
	140321213891584 [label=ConvolutionBackward0]
	140321213893072 -> 140321213891584
	140321213893072 [label=ReluBackward0]
	140321213890912 -> 140321213893072
	140321213890912 [label=AddBackward0]
	140321213890624 -> 140321213890912
	140321213890624 [label=AddBackward0]
	140321213890672 -> 140321213890624
	140321213890672 [label=AddBackward0]
	140321213775152 -> 140321213890672
	140321213775152 [label=ReluBackward0]
	140321213774960 -> 140321213775152
	140321213774960 [label=AddBackward0]
	140321213774624 -> 140321213774960
	140321213774624 [label=NativeBatchNormBackward0]
	140321213774432 -> 140321213774624
	140321213774432 [label=ConvolutionBackward0]
	140321213773808 -> 140321213774432
	140321213773808 [label=ReluBackward0]
	140321213773616 -> 140321213773808
	140321213773616 [label=NativeBatchNormBackward0]
	140321213773280 -> 140321213773616
	140321213773280 [label=ConvolutionBackward0]
	140321213774816 -> 140321213773280
	140321213774816 [label=ReluBackward0]
	140321213772608 -> 140321213774816
	140321213772608 [label=AddBackward0]
	140321213772560 -> 140321213772608
	140321213772560 [label=NativeBatchNormBackward0]
	140321213772128 -> 140321213772560
	140321213772128 [label=ConvolutionBackward0]
	140321213771744 -> 140321213772128
	140321213771744 [label=ReluBackward0]
	140321213771264 -> 140321213771744
	140321213771264 [label=NativeBatchNormBackward0]
	140321213771216 -> 140321213771264
	140321213771216 [label=ConvolutionBackward0]
	140321213772464 -> 140321213771216
	140321213772464 [label=ReluBackward0]
	140321213770544 -> 140321213772464
	140321213770544 [label=AddBackward0]
	140321213770256 -> 140321213770544
	140321213770256 [label=NativeBatchNormBackward0]
	140321213769776 -> 140321213770256
	140321213769776 [label=ConvolutionBackward0]
	140321213769440 -> 140321213769776
	140321213769440 [label=ReluBackward0]
	140321213769200 -> 140321213769440
	140321213769200 [label=NativeBatchNormBackward0]
	140321213768912 -> 140321213769200
	140321213768912 [label=ConvolutionBackward0]
	140321213770400 -> 140321213768912
	140321213770400 [label=ReluBackward0]
	140321213768240 -> 140321213770400
	140321213768240 [label=AddBackward0]
	140321213767904 -> 140321213768240
	140321213767904 [label=NativeBatchNormBackward0]
	140321213767712 -> 140321213767904
	140321213767712 [label=ConvolutionBackward0]
	140321213767088 -> 140321213767712
	140321213767088 [label=ReluBackward0]
	140321213766896 -> 140321213767088
	140321213766896 [label=NativeBatchNormBackward0]
	140321213766560 -> 140321213766896
	140321213766560 [label=ConvolutionBackward0]
	140321213768096 -> 140321213766560
	140321213768096 [label=ReluBackward0]
	140321213765888 -> 140321213768096
	140321213765888 [label=AddBackward0]
	140321213765840 -> 140321213765888
	140321213765840 [label=AddBackward0]
	140321213765408 -> 140321213765840
	140321213765408 [label=ReluBackward0]
	140321213765168 -> 140321213765408
	140321213765168 [label=AddBackward0]
	140321213764880 -> 140321213765168
	140321213764880 [label=NativeBatchNormBackward0]
	140321213764400 -> 140321213764880
	140321213764400 [label=ConvolutionBackward0]
	140321213764064 -> 140321213764400
	140321213764064 [label=ReluBackward0]
	140321213763824 -> 140321213764064
	140321213763824 [label=NativeBatchNormBackward0]
	140321213763536 -> 140321213763824
	140321213763536 [label=ConvolutionBackward0]
	140321213765024 -> 140321213763536
	140321213765024 [label=ReluBackward0]
	140321213762864 -> 140321213765024
	140321213762864 [label=AddBackward0]
	140321213762528 -> 140321213762864
	140321213762528 [label=NativeBatchNormBackward0]
	140321213762336 -> 140321213762528
	140321213762336 [label=ConvolutionBackward0]
	140321213761712 -> 140321213762336
	140321213761712 [label=ReluBackward0]
	140321213761520 -> 140321213761712
	140321213761520 [label=NativeBatchNormBackward0]
	140321213761184 -> 140321213761520
	140321213761184 [label=ConvolutionBackward0]
	140321213762720 -> 140321213761184
	140321213762720 [label=ReluBackward0]
	140321213760512 -> 140321213762720
	140321213760512 [label=AddBackward0]
	140321213760464 -> 140321213760512
	140321213760464 [label=NativeBatchNormBackward0]
	140321213760032 -> 140321213760464
	140321213760032 [label=ConvolutionBackward0]
	140321213759648 -> 140321213760032
	140321213759648 [label=ReluBackward0]
	140321215692416 -> 140321213759648
	140321215692416 [label=NativeBatchNormBackward0]
	140321215692368 -> 140321215692416
	140321215692368 [label=ConvolutionBackward0]
	140321213760368 -> 140321215692368
	140321213760368 [label=ReluBackward0]
	140321215691696 -> 140321213760368
	140321215691696 [label=AddBackward0]
	140321215691408 -> 140321215691696
	140321215691408 [label=NativeBatchNormBackward0]
	140321215690928 -> 140321215691408
	140321215690928 [label=ConvolutionBackward0]
	140321215690592 -> 140321215690928
	140321215690592 [label=ReluBackward0]
	140321215690352 -> 140321215690592
	140321215690352 [label=NativeBatchNormBackward0]
	140321215690064 -> 140321215690352
	140321215690064 [label=ConvolutionBackward0]
	140321215691552 -> 140321215690064
	140321215691552 [label=ReluBackward0]
	140321215689392 -> 140321215691552
	140321215689392 [label=AddBackward0]
	140321215689056 -> 140321215689392
	140321215689056 [label=AddBackward0]
	140321215688864 -> 140321215689056
	140321215688864 [label=ReluBackward0]
	140321215688384 -> 140321215688864
	140321215688384 [label=AddBackward0]
	140321215688336 -> 140321215688384
	140321215688336 [label=NativeBatchNormBackward0]
	140321215687904 -> 140321215688336
	140321215687904 [label=ConvolutionBackward0]
	140321215687520 -> 140321215687904
	140321215687520 [label=ReluBackward0]
	140321215687040 -> 140321215687520
	140321215687040 [label=NativeBatchNormBackward0]
	140321215686992 -> 140321215687040
	140321215686992 [label=ConvolutionBackward0]
	140321215688240 -> 140321215686992
	140321215688240 [label=ReluBackward0]
	140321215686320 -> 140321215688240
	140321215686320 [label=AddBackward0]
	140321215686032 -> 140321215686320
	140321215686032 [label=NativeBatchNormBackward0]
	140321215685552 -> 140321215686032
	140321215685552 [label=ConvolutionBackward0]
	140321215685216 -> 140321215685552
	140321215685216 [label=ReluBackward0]
	140321215684976 -> 140321215685216
	140321215684976 [label=NativeBatchNormBackward0]
	140321215684688 -> 140321215684976
	140321215684688 [label=ConvolutionBackward0]
	140321215686176 -> 140321215684688
	140321215686176 [label=ReluBackward0]
	140321215684016 -> 140321215686176
	140321215684016 [label=AddBackward0]
	140321215683680 -> 140321215684016
	140321215683680 [label=NativeBatchNormBackward0]
	140321215683488 -> 140321215683680
	140321215683488 [label=ConvolutionBackward0]
	140321215682864 -> 140321215683488
	140321215682864 [label=ReluBackward0]
	140321215682672 -> 140321215682864
	140321215682672 [label=NativeBatchNormBackward0]
	140321215682336 -> 140321215682672
	140321215682336 [label=ConvolutionBackward0]
	140321215683872 -> 140321215682336
	140321215683872 [label=ReluBackward0]
	140321215681664 -> 140321215683872
	140321215681664 [label=AddBackward0]
	140321215681616 -> 140321215681664
	140321215681616 [label=NativeBatchNormBackward0]
	140321215681184 -> 140321215681616
	140321215681184 [label=ConvolutionBackward0]
	140321215680800 -> 140321215681184
	140321215680800 [label=ReluBackward0]
	140321215680320 -> 140321215680800
	140321215680320 [label=NativeBatchNormBackward0]
	140321215680272 -> 140321215680320
	140321215680272 [label=ConvolutionBackward0]
	140321215681520 -> 140321215680272
	140321215681520 [label=ReluBackward0]
	140321215679600 -> 140321215681520
	140321215679600 [label=AddBackward0]
	140321215679312 -> 140321215679600
	140321215679312 [label=AddBackward0]
	140321215678832 -> 140321215679312
	140321215678832 [label=ReluBackward0]
	140321215678640 -> 140321215678832
	140321215678640 [label=AddBackward0]
	140321215678304 -> 140321215678640
	140321215678304 [label=NativeBatchNormBackward0]
	140321215678112 -> 140321215678304
	140321215678112 [label=ConvolutionBackward0]
	140321215677488 -> 140321215678112
	140321215677488 [label=ReluBackward0]
	140321215677296 -> 140321215677488
	140321215677296 [label=NativeBatchNormBackward0]
	140321215676960 -> 140321215677296
	140321215676960 [label=ConvolutionBackward0]
	140321215678496 -> 140321215676960
	140321215678496 [label=ReluBackward0]
	140321215676480 -> 140321215678496
	140321215676480 [label=AddBackward0]
	140321215528720 -> 140321215676480
	140321215528720 [label=NativeBatchNormBackward0]
	140321215528288 -> 140321215528720
	140321215528288 [label=ConvolutionBackward0]
	140321215527904 -> 140321215528288
	140321215527904 [label=ReluBackward0]
	140321215527424 -> 140321215527904
	140321215527424 [label=NativeBatchNormBackward0]
	140321215527376 -> 140321215527424
	140321215527376 [label=ConvolutionBackward0]
	140321215528624 -> 140321215527376
	140321215528624 [label=ReluBackward0]
	140321215526704 -> 140321215528624
	140321215526704 [label=AddBackward0]
	140321215526416 -> 140321215526704
	140321215526416 [label=NativeBatchNormBackward0]
	140321215525936 -> 140321215526416
	140321215525936 [label=ConvolutionBackward0]
	140321215525600 -> 140321215525936
	140321215525600 [label=ReluBackward0]
	140321215525360 -> 140321215525600
	140321215525360 [label=NativeBatchNormBackward0]
	140321215525072 -> 140321215525360
	140321215525072 [label=ConvolutionBackward0]
	140321215526560 -> 140321215525072
	140321215526560 [label=ReluBackward0]
	140321215524400 -> 140321215526560
	140321215524400 [label=AddBackward0]
	140321215524064 -> 140321215524400
	140321215524064 [label=NativeBatchNormBackward0]
	140321215523872 -> 140321215524064
	140321215523872 [label=ConvolutionBackward0]
	140321215523248 -> 140321215523872
	140321215523248 [label=ReluBackward0]
	140321215523056 -> 140321215523248
	140321215523056 [label=NativeBatchNormBackward0]
	140321215522720 -> 140321215523056
	140321215522720 [label=ConvolutionBackward0]
	140321215524256 -> 140321215522720
	140321215524256 [label=ReluBackward0]
	140321215522048 -> 140321215524256
	140321215522048 [label=AddBackward0]
	140321215522000 -> 140321215522048
	140321215522000 [label=AddBackward0]
	140321215521568 -> 140321215522000
	140321215521568 [label=ReluBackward0]
	140321215521328 -> 140321215521568
	140321215521328 [label=AddBackward0]
	140321215521040 -> 140321215521328
	140321215521040 [label=NativeBatchNormBackward0]
	140321215520560 -> 140321215521040
	140321215520560 [label=ConvolutionBackward0]
	140321215520224 -> 140321215520560
	140321215520224 [label=ReluBackward0]
	140321215519984 -> 140321215520224
	140321215519984 [label=NativeBatchNormBackward0]
	140321215519696 -> 140321215519984
	140321215519696 [label=ConvolutionBackward0]
	140321215521184 -> 140321215519696
	140321215521184 [label=ReluBackward0]
	140321215519024 -> 140321215521184
	140321215519024 [label=AddBackward0]
	140321215518688 -> 140321215519024
	140321215518688 [label=NativeBatchNormBackward0]
	140321215518496 -> 140321215518688
	140321215518496 [label=ConvolutionBackward0]
	140321215517872 -> 140321215518496
	140321215517872 [label=ReluBackward0]
	140321215517680 -> 140321215517872
	140321215517680 [label=NativeBatchNormBackward0]
	140321215517344 -> 140321215517680
	140321215517344 [label=ConvolutionBackward0]
	140321215518880 -> 140321215517344
	140321215518880 [label=ReluBackward0]
	140321215516672 -> 140321215518880
	140321215516672 [label=AddBackward0]
	140321215516624 -> 140321215516672
	140321215516624 [label=NativeBatchNormBackward0]
	140321215516192 -> 140321215516624
	140321215516192 [label=ConvolutionBackward0]
	140321215515808 -> 140321215516192
	140321215515808 [label=ReluBackward0]
	140321215515328 -> 140321215515808
	140321215515328 [label=NativeBatchNormBackward0]
	140321215515280 -> 140321215515328
	140321215515280 [label=ConvolutionBackward0]
	140321215516528 -> 140321215515280
	140321215516528 [label=ReluBackward0]
	140321215514608 -> 140321215516528
	140321215514608 [label=AddBackward0]
	140321215514320 -> 140321215514608
	140321215514320 [label=NativeBatchNormBackward0]
	140321215513840 -> 140321215514320
	140321215513840 [label=ConvolutionBackward0]
	140321215513504 -> 140321215513840
	140321215513504 [label=ReluBackward0]
	140321215513264 -> 140321215513504
	140321215513264 [label=NativeBatchNormBackward0]
	140321215512976 -> 140321215513264
	140321215512976 [label=ConvolutionBackward0]
	140321215514464 -> 140321215512976
	140321215514464 [label=ReluBackward0]
	140321215381168 -> 140321215514464
	140321215381168 [label=AddBackward0]
	140321215380832 -> 140321215381168
	140321215380832 [label=ReluBackward0]
	140321215380640 -> 140321215380832
	140321215380640 [label=AddBackward0]
	140321215380352 -> 140321215380640
	140321215380352 [label=NativeBatchNormBackward0]
	140321215380112 -> 140321215380352
	140321215380112 [label=ConvolutionBackward0]
	140321215379488 -> 140321215380112
	140321215379488 [label=ReluBackward0]
	140321215379296 -> 140321215379488
	140321215379296 [label=NativeBatchNormBackward0]
	140321215379008 -> 140321215379296
	140321215379008 [label=ConvolutionBackward0]
	140321215380496 -> 140321215379008
	140321215380496 [label=ReluBackward0]
	140321215378336 -> 140321215380496
	140321215378336 [label=AddBackward0]
	140321215378000 -> 140321215378336
	140321215378000 [label=NativeBatchNormBackward0]
	140321215377808 -> 140321215378000
	140321215377808 [label=ConvolutionBackward0]
	140321215377424 -> 140321215377808
	140321215377424 [label=ReluBackward0]
	140321215376992 -> 140321215377424
	140321215376992 [label=NativeBatchNormBackward0]
	140321215376656 -> 140321215376992
	140321215376656 [label=ConvolutionBackward0]
	140321215378144 -> 140321215376656
	140321215378144 [label=ReluBackward0]
	140321215375984 -> 140321215378144
	140321215375984 [label=AddBackward0]
	140321215375936 -> 140321215375984
	140321215375936 [label=NativeBatchNormBackward0]
	140321215375456 -> 140321215375936
	140321215375456 [label=ConvolutionBackward0]
	140321215375120 -> 140321215375456
	140321215375120 [label=ReluBackward0]
	140321215374640 -> 140321215375120
	140321215374640 [label=NativeBatchNormBackward0]
	140321215374592 -> 140321215374640
	140321215374592 [label=ConvolutionBackward0]
	140321215376080 -> 140321215374592
	140321215376080 [label=ReluBackward0]
	140321215373920 -> 140321215376080
	140321215373920 [label=AddBackward0]
	140321215373632 -> 140321215373920
	140321215373632 [label=NativeBatchNormBackward0]
	140321215373392 -> 140321215373632
	140321215373392 [label=ConvolutionBackward0]
	140321215372768 -> 140321215373392
	140321215372768 [label=ReluBackward0]
	140321215372576 -> 140321215372768
	140321215372576 [label=NativeBatchNormBackward0]
	140321215372288 -> 140321215372576
	140321215372288 [label=ConvolutionBackward0]
	140321215373776 -> 140321215372288
	140321215373776 [label=ReluBackward0]
	140321215371616 -> 140321215373776
	140321215371616 [label=NativeBatchNormBackward0]
	140321215371280 -> 140321215371616
	140321215371280 [label=ConvolutionBackward0]
	140321215370944 -> 140321215371280
	140321215370944 [label=ReluBackward0]
	140321215370704 -> 140321215370944
	140321215370704 [label=AddBackward0]
	140321215370416 -> 140321215370704
	140321215370416 [label=NativeBatchNormBackward0]
	140321215369936 -> 140321215370416
	140321215369936 [label=ConvolutionBackward0]
	140321215369600 -> 140321215369936
	140321215369600 [label=ReluBackward0]
	140321215369360 -> 140321215369600
	140321215369360 [label=NativeBatchNormBackward0]
	140321215369072 -> 140321215369360
	140321215369072 [label=ConvolutionBackward0]
	140321215368688 -> 140321215369072
	140321215368688 [label=ReluBackward0]
	140321215368256 -> 140321215368688
	140321215368256 [label=NativeBatchNormBackward0]
	140321215367920 -> 140321215368256
	140321215367920 [label=ConvolutionBackward0]
	140321215370560 -> 140321215367920
	140321215370560 [label=ReluBackward0]
	140321215367248 -> 140321215370560
	140321215367248 [label=AddBackward0]
	140321215367200 -> 140321215367248
	140321215367200 [label=NativeBatchNormBackward0]
	140321215366720 -> 140321215367200
	140321215366720 [label=ConvolutionBackward0]
	140321215366384 -> 140321215366720
	140321215366384 [label=ReluBackward0]
	140321215365904 -> 140321215366384
	140321215365904 [label=NativeBatchNormBackward0]
	140321215365856 -> 140321215365904
	140321215365856 [label=ConvolutionBackward0]
	140321215365232 -> 140321215365856
	140321215365232 [label=ReluBackward0]
	140321215365184 -> 140321215365232
	140321215365184 [label=NativeBatchNormBackward0]
	140321215233568 -> 140321215365184
	140321215233568 [label=ConvolutionBackward0]
	140321215367344 -> 140321215233568
	140321215367344 [label=ReluBackward0]
	140321215232896 -> 140321215367344
	140321215232896 [label=AddBackward0]
	140321215232848 -> 140321215232896
	140321215232848 [label=NativeBatchNormBackward0]
	140321215232416 -> 140321215232848
	140321215232416 [label=ConvolutionBackward0]
	140321215232032 -> 140321215232416
	140321215232032 [label=ReluBackward0]
	140321215231552 -> 140321215232032
	140321215231552 [label=NativeBatchNormBackward0]
	140321215231504 -> 140321215231552
	140321215231504 [label=ConvolutionBackward0]
	140321215230880 -> 140321215231504
	140321215230880 [label=ReluBackward0]
	140321215230688 -> 140321215230880
	140321215230688 [label=NativeBatchNormBackward0]
	140321215230400 -> 140321215230688
	140321215230400 [label=ConvolutionBackward0]
	140321215232752 -> 140321215230400
	140321215232752 [label=ReluBackward0]
	140321215229728 -> 140321215232752
	140321215229728 [label=AddBackward0]
	140321215229392 -> 140321215229728
	140321215229392 [label=NativeBatchNormBackward0]
	140321215229200 -> 140321215229392
	140321215229200 [label=ConvolutionBackward0]
	140321215228816 -> 140321215229200
	140321215228816 [label=ReluBackward0]
	140321215228384 -> 140321215228816
	140321215228384 [label=NativeBatchNormBackward0]
	140321215228048 -> 140321215228384
	140321215228048 [label=ConvolutionBackward0]
	140321215227712 -> 140321215228048
	140321215227712 [label=ReluBackward0]
	140321215227472 -> 140321215227712
	140321215227472 [label=NativeBatchNormBackward0]
	140321215227184 -> 140321215227472
	140321215227184 [label=ConvolutionBackward0]
	140321215226800 -> 140321215227184
	140321215226800 [label=ReluBackward0]
	140321215226368 -> 140321215226800
	140321215226368 [label=NativeBatchNormBackward0]
	140321215226032 -> 140321215226368
	140321215226032 [label=ConvolutionBackward0]
	140321215225696 -> 140321215226032
	140321215225696 [label=ReluBackward0]
	140321215225456 -> 140321215225696
	140321215225456 [label=NativeBatchNormBackward0]
	140321215225168 -> 140321215225456
	140321215225168 [label=ConvolutionBackward0]
	140321215224784 -> 140321215225168
	140321573325312 [label="conv1.weight
 (64, 3, 3, 3)" fillcolor=lightblue]
	140321573325312 -> 140321215224784
	140321215224784 [label=AccumulateGrad]
	140321215225312 -> 140321215225456
	140321573334592 [label="bn1.weight
 (64)" fillcolor=lightblue]
	140321573334592 -> 140321215225312
	140321215225312 [label=AccumulateGrad]
	140321215225504 -> 140321215225456
	140321573325232 [label="bn1.bias
 (64)" fillcolor=lightblue]
	140321573325232 -> 140321215225504
	140321215225504 [label=AccumulateGrad]
	140321215225840 -> 140321215226032
	140321573333952 [label="conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140321573333952 -> 140321215225840
	140321215225840 [label=AccumulateGrad]
	140321215226176 -> 140321215226368
	140321573333872 [label="bn2.weight
 (64)" fillcolor=lightblue]
	140321573333872 -> 140321215226176
	140321215226176 [label=AccumulateGrad]
	140321215226656 -> 140321215226368
	140321573333792 [label="bn2.bias
 (64)" fillcolor=lightblue]
	140321573333792 -> 140321215226656
	140321215226656 [label=AccumulateGrad]
	140321215226704 -> 140321215227184
	140321573332912 [label="layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	140321573332912 -> 140321215226704
	140321215226704 [label=AccumulateGrad]
	140321215227328 -> 140321215227472
	140321573332832 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	140321573332832 -> 140321215227328
	140321215227328 [label=AccumulateGrad]
	140321215227520 -> 140321215227472
	140321573332752 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	140321573332752 -> 140321215227520
	140321215227520 [label=AccumulateGrad]
	140321215227856 -> 140321215228048
	140321573338912 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140321573338912 -> 140321215227856
	140321215227856 [label=AccumulateGrad]
	140321215228192 -> 140321215228384
	140321573338832 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	140321573338832 -> 140321215228192
	140321215228192 [label=AccumulateGrad]
	140321215228672 -> 140321215228384
	140321573332352 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	140321573332352 -> 140321215228672
	140321215228672 [label=AccumulateGrad]
	140321215228720 -> 140321215229200
	140321573338432 [label="layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140321573338432 -> 140321215228720
	140321215228720 [label=AccumulateGrad]
	140321215229344 -> 140321215229392
	140321573338352 [label="layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	140321573338352 -> 140321215229344
	140321215229344 [label=AccumulateGrad]
	140321215229488 -> 140321215229392
	140321573332192 [label="layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	140321573332192 -> 140321215229488
	140321215229488 [label=AccumulateGrad]
	140321215229536 -> 140321215229728
	140321215229536 [label=NativeBatchNormBackward0]
	140321215227376 -> 140321215229536
	140321215227376 [label=ConvolutionBackward0]
	140321215226800 -> 140321215227376
	140321215228000 -> 140321215227376
	140321573323552 [label="layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140321573323552 -> 140321215228000
	140321215228000 [label=AccumulateGrad]
	140321215228528 -> 140321215229536
	140321573333392 [label="layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	140321573333392 -> 140321215228528
	140321215228528 [label=AccumulateGrad]
	140321215229056 -> 140321215229536
	140321573333312 [label="layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	140321573333312 -> 140321215229056
	140321215229056 [label=AccumulateGrad]
	140321215230016 -> 140321215230400
	140321573338272 [label="layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	140321573338272 -> 140321215230016
	140321215230016 [label=AccumulateGrad]
	140321215230544 -> 140321215230688
	140321573338192 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	140321573338192 -> 140321215230544
	140321215230544 [label=AccumulateGrad]
	140321215230736 -> 140321215230688
	140321573331712 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	140321573331712 -> 140321215230736
	140321215230736 [label=AccumulateGrad]
	140321215231072 -> 140321215231504
	140321573337952 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140321573337952 -> 140321215231072
	140321215231072 [label=AccumulateGrad]
	140321215231408 -> 140321215231552
	140321573337872 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	140321573337872 -> 140321215231408
	140321215231408 [label=AccumulateGrad]
	140321215231888 -> 140321215231552
	140321573331232 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	140321573331232 -> 140321215231888
	140321215231888 [label=AccumulateGrad]
	140321215232176 -> 140321215232416
	140321573337472 [label="layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140321573337472 -> 140321215232176
	140321215232176 [label=AccumulateGrad]
	140321215232560 -> 140321215232848
	140321573337392 [label="layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	140321573337392 -> 140321215232560
	140321215232560 [label=AccumulateGrad]
	140321215232704 -> 140321215232848
	140321573330912 [label="layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	140321573330912 -> 140321215232704
	140321215232704 [label=AccumulateGrad]
	140321215232752 -> 140321215232896
	140321215233232 -> 140321215233568
	140321573337152 [label="layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	140321573337152 -> 140321215233232
	140321215233232 [label=AccumulateGrad]
	140321215233760 -> 140321215365184
	140321573337072 [label="layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	140321573337072 -> 140321215233760
	140321215233760 [label=AccumulateGrad]
	140321215233904 -> 140321215365184
	140321573330592 [label="layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	140321573330592 -> 140321215233904
	140321215233904 [label=AccumulateGrad]
	140321215365376 -> 140321215365856
	140321573336832 [label="layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140321573336832 -> 140321215365376
	140321215365376 [label=AccumulateGrad]
	140321215366000 -> 140321215365904
	140321573336752 [label="layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	140321573336752 -> 140321215366000
	140321215366000 [label=AccumulateGrad]
	140321215366240 -> 140321215365904
	140321573331392 [label="layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	140321573331392 -> 140321215366240
	140321215366240 [label=AccumulateGrad]
	140321215366528 -> 140321215366720
	140321573326832 [label="layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140321573326832 -> 140321215366528
	140321215366528 [label=AccumulateGrad]
	140321215366912 -> 140321215367200
	140321573335872 [label="layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	140321573335872 -> 140321215366912
	140321215366912 [label=AccumulateGrad]
	140321215367056 -> 140321215367200
	140321573335792 [label="layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	140321573335792 -> 140321215367056
	140321215367056 [label=AccumulateGrad]
	140321215367344 -> 140321215367248
	140321215367584 -> 140321215367920
	140321573423856 [label="layer1.3.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	140321573423856 -> 140321215367584
	140321215367584 [label=AccumulateGrad]
	140321215368064 -> 140321215368256
	140321573430736 [label="layer1.3.bn1.weight
 (64)" fillcolor=lightblue]
	140321573430736 -> 140321215368064
	140321215368064 [label=AccumulateGrad]
	140321215368544 -> 140321215368256
	140321573430656 [label="layer1.3.bn1.bias
 (64)" fillcolor=lightblue]
	140321573430656 -> 140321215368544
	140321215368544 [label=AccumulateGrad]
	140321215368592 -> 140321215369072
	140321573423536 [label="layer1.3.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140321573423536 -> 140321215368592
	140321215368592 [label=AccumulateGrad]
	140321215369216 -> 140321215369360
	140321573430416 [label="layer1.3.bn2.weight
 (64)" fillcolor=lightblue]
	140321573430416 -> 140321215369216
	140321215369216 [label=AccumulateGrad]
	140321215369408 -> 140321215369360
	140321573430336 [label="layer1.3.bn2.bias
 (64)" fillcolor=lightblue]
	140321573430336 -> 140321215369408
	140321215369408 [label=AccumulateGrad]
	140321215369744 -> 140321215369936
	140321573423216 [label="layer1.3.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140321573423216 -> 140321215369744
	140321215369744 [label=AccumulateGrad]
	140321215370080 -> 140321215370416
	140321573430096 [label="layer1.3.bn3.weight
 (256)" fillcolor=lightblue]
	140321573430096 -> 140321215370080
	140321215370080 [label=AccumulateGrad]
	140321215370272 -> 140321215370416
	140321573430016 [label="layer1.3.bn3.bias
 (256)" fillcolor=lightblue]
	140321573430016 -> 140321215370272
	140321215370272 [label=AccumulateGrad]
	140321215370560 -> 140321215370704
	140321215371088 -> 140321215371280
	140321573422736 [label="transition1.0.0.weight
 (18, 256, 3, 3)" fillcolor=lightblue]
	140321573422736 -> 140321215371088
	140321215371088 [label=AccumulateGrad]
	140321215371424 -> 140321215371616
	140321573429616 [label="transition1.0.1.weight
 (18)" fillcolor=lightblue]
	140321573429616 -> 140321215371424
	140321215371424 [label=AccumulateGrad]
	140321215371952 -> 140321215371616
	140321573429536 [label="transition1.0.1.bias
 (18)" fillcolor=lightblue]
	140321573429536 -> 140321215371952
	140321215371952 [label=AccumulateGrad]
	140321215371904 -> 140321215372288
	140321573422336 [label="stage2.0.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321573422336 -> 140321215371904
	140321215371904 [label=AccumulateGrad]
	140321215372432 -> 140321215372576
	140321573422256 [label="stage2.0.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140321573422256 -> 140321215372432
	140321215372432 [label=AccumulateGrad]
	140321215372624 -> 140321215372576
	140321573429136 [label="stage2.0.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140321573429136 -> 140321215372624
	140321215372624 [label=AccumulateGrad]
	140321215372960 -> 140321215373392
	140321573422016 [label="stage2.0.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321573422016 -> 140321215372960
	140321215372960 [label=AccumulateGrad]
	140321215373296 -> 140321215373632
	140321573421936 [label="stage2.0.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140321573421936 -> 140321215373296
	140321215373296 [label=AccumulateGrad]
	140321215373440 -> 140321215373632
	140321573428816 [label="stage2.0.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140321573428816 -> 140321215373440
	140321215373440 [label=AccumulateGrad]
	140321215373776 -> 140321215373920
	140321215373968 -> 140321215374592
	140321573421616 [label="stage2.0.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321573421616 -> 140321215373968
	140321215373968 [label=AccumulateGrad]
	140321215374736 -> 140321215374640
	140321573428576 [label="stage2.0.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140321573428576 -> 140321215374736
	140321215374736 [label=AccumulateGrad]
	140321215374976 -> 140321215374640
	140321573428496 [label="stage2.0.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140321573428496 -> 140321215374976
	140321215374976 [label=AccumulateGrad]
	140321215375264 -> 140321215375456
	140321573421296 [label="stage2.0.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321573421296 -> 140321215375264
	140321215375264 [label=AccumulateGrad]
	140321215375648 -> 140321215375936
	140321573428256 [label="stage2.0.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140321573428256 -> 140321215375648
	140321215375648 [label=AccumulateGrad]
	140321215375792 -> 140321215375936
	140321573428176 [label="stage2.0.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140321573428176 -> 140321215375792
	140321215375792 [label=AccumulateGrad]
	140321215376080 -> 140321215375984
	140321215376320 -> 140321215376656
	140321573427856 [label="stage2.0.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321573427856 -> 140321215376320
	140321215376320 [label=AccumulateGrad]
	140321215376800 -> 140321215376992
	140321573427776 [label="stage2.0.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140321573427776 -> 140321215376800
	140321215376800 [label=AccumulateGrad]
	140321215377280 -> 140321215376992
	140321573427696 [label="stage2.0.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140321573427696 -> 140321215377280
	140321215377280 [label=AccumulateGrad]
	140321215377328 -> 140321215377808
	140321573427376 [label="stage2.0.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321573427376 -> 140321215377328
	140321215377328 [label=AccumulateGrad]
	140321215377952 -> 140321215378000
	140321573427136 [label="stage2.0.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140321573427136 -> 140321215377952
	140321215377952 [label=AccumulateGrad]
	140321215378096 -> 140321215378000
	140321573427056 [label="stage2.0.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140321573427056 -> 140321215378096
	140321215378096 [label=AccumulateGrad]
	140321215378144 -> 140321215378336
	140321215378624 -> 140321215379008
	140321573426416 [label="stage2.0.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321573426416 -> 140321215378624
	140321215378624 [label=AccumulateGrad]
	140321215379152 -> 140321215379296
	140321573426336 [label="stage2.0.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140321573426336 -> 140321215379152
	140321215379152 [label=AccumulateGrad]
	140321215379344 -> 140321215379296
	140321573426256 [label="stage2.0.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140321573426256 -> 140321215379344
	140321215379344 [label=AccumulateGrad]
	140321215379680 -> 140321215380112
	140321573425776 [label="stage2.0.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321573425776 -> 140321215379680
	140321215379680 [label=AccumulateGrad]
	140321215380016 -> 140321215380352
	140321573425696 [label="stage2.0.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140321573425696 -> 140321215380016
	140321215380016 [label=AccumulateGrad]
	140321215380160 -> 140321215380352
	140321573425616 [label="stage2.0.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140321573425616 -> 140321215380160
	140321215380160 [label=AccumulateGrad]
	140321215380496 -> 140321215380640
	140321215381024 -> 140321215381168
	140321215381024 [label=UpsampleBilinear2DBackward0]
	140321215379968 -> 140321215381024
	140321215379968 [label=NativeBatchNormBackward0]
	140321215378480 -> 140321215379968
	140321215378480 [label=ConvolutionBackward0]
	140321215378768 -> 140321215378480
	140321215378768 [label=ReluBackward0]
	140321215376128 -> 140321215378768
	140321215376128 [label=AddBackward0]
	140321215376752 -> 140321215376128
	140321215376752 [label=NativeBatchNormBackward0]
	140321215376608 -> 140321215376752
	140321215376608 [label=ConvolutionBackward0]
	140321215374448 -> 140321215376608
	140321215374448 [label=ReluBackward0]
	140321215374304 -> 140321215374448
	140321215374304 [label=NativeBatchNormBackward0]
	140321215371760 -> 140321215374304
	140321215371760 [label=ConvolutionBackward0]
	140321215377472 -> 140321215371760
	140321215377472 [label=ReluBackward0]
	140321215370032 -> 140321215377472
	140321215370032 [label=AddBackward0]
	140321215370752 -> 140321215370032
	140321215370752 [label=NativeBatchNormBackward0]
	140321215369888 -> 140321215370752
	140321215369888 [label=ConvolutionBackward0]
	140321215368016 -> 140321215369888
	140321215368016 [label=ReluBackward0]
	140321215367872 -> 140321215368016
	140321215367872 [label=NativeBatchNormBackward0]
	140321215365568 -> 140321215367872
	140321215365568 [label=ConvolutionBackward0]
	140321215371232 -> 140321215365568
	140321215371232 [label=ReluBackward0]
	140321215232224 -> 140321215371232
	140321215232224 [label=AddBackward0]
	140321215233520 -> 140321215232224
	140321215233520 [label=NativeBatchNormBackward0]
	140321215232080 -> 140321215233520
	140321215232080 [label=ConvolutionBackward0]
	140321215230208 -> 140321215232080
	140321215230208 [label=ReluBackward0]
	140321215230064 -> 140321215230208
	140321215230064 [label=NativeBatchNormBackward0]
	140321215225360 -> 140321215230064
	140321215225360 [label=ConvolutionBackward0]
	140321215233376 -> 140321215225360
	140321215233376 [label=ReluBackward0]
	140321215225984 -> 140321215233376
	140321215225984 [label=AddBackward0]
	140321215224832 -> 140321215225984
	140321215224832 [label=NativeBatchNormBackward0]
	140321215224352 -> 140321215224832
	140321215224352 [label=ConvolutionBackward0]
	140321215223968 -> 140321215224352
	140321215223968 [label=ReluBackward0]
	140321215223488 -> 140321215223968
	140321215223488 [label=NativeBatchNormBackward0]
	140321215223440 -> 140321215223488
	140321215223440 [label=ConvolutionBackward0]
	140321215225024 -> 140321215223440
	140321215225024 [label=ReluBackward0]
	140321215222768 -> 140321215225024
	140321215222768 [label=NativeBatchNormBackward0]
	140321215222480 -> 140321215222768
	140321215222480 [label=ConvolutionBackward0]
	140321215370944 -> 140321215222480
	140321215222096 -> 140321215222480
	140321573422576 [label="transition1.1.0.0.weight
 (36, 256, 3, 3)" fillcolor=lightblue]
	140321573422576 -> 140321215222096
	140321215222096 [label=AccumulateGrad]
	140321215222624 -> 140321215222768
	140321573429456 [label="transition1.1.0.1.weight
 (36)" fillcolor=lightblue]
	140321573429456 -> 140321215222624
	140321215222624 [label=AccumulateGrad]
	140321215223152 -> 140321215222768
	140321573429376 [label="transition1.1.0.1.bias
 (36)" fillcolor=lightblue]
	140321573429376 -> 140321215223152
	140321215223152 [label=AccumulateGrad]
	140321215222816 -> 140321215223440
	140321573431056 [label="stage2.0.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321573431056 -> 140321215222816
	140321215222816 [label=AccumulateGrad]
	140321215223344 -> 140321215223488
	140321573430976 [label="stage2.0.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140321573430976 -> 140321215223344
	140321215223344 [label=AccumulateGrad]
	140321215223824 -> 140321215223488
	140321500471344 [label="stage2.0.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140321500471344 -> 140321215223824
	140321215223824 [label=AccumulateGrad]
	140321215224112 -> 140321215224352
	140321500464864 [label="stage2.0.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321500464864 -> 140321215224112
	140321215224112 [label=AccumulateGrad]
	140321215224640 -> 140321215224832
	140321500471664 [label="stage2.0.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140321500471664 -> 140321215224640
	140321215224640 [label=AccumulateGrad]
	140321215224688 -> 140321215224832
	140321500465024 [label="stage2.0.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140321500465024 -> 140321215224688
	140321215224688 [label=AccumulateGrad]
	140321215225024 -> 140321215225984
	140321215226128 -> 140321215225360
	140321500471904 [label="stage2.0.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321500471904 -> 140321215226128
	140321215226128 [label=AccumulateGrad]
	140321215228144 -> 140321215230064
	140321500471984 [label="stage2.0.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140321500471984 -> 140321215228144
	140321215228144 [label=AccumulateGrad]
	140321215228864 -> 140321215230064
	140321500465344 [label="stage2.0.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140321500465344 -> 140321215228864
	140321215228864 [label=AccumulateGrad]
	140321215231216 -> 140321215232080
	140321500472224 [label="stage2.0.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321500472224 -> 140321215231216
	140321215231216 [label=AccumulateGrad]
	140321215230832 -> 140321215233520
	140321500472304 [label="stage2.0.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140321500472304 -> 140321215230832
	140321215230832 [label=AccumulateGrad]
	140321215231744 -> 140321215233520
	140321500464944 [label="stage2.0.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140321500464944 -> 140321215231744
	140321215231744 [label=AccumulateGrad]
	140321215233376 -> 140321215232224
	140321215365328 -> 140321215365568
	140321219572064 [label="stage2.0.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321219572064 -> 140321215365328
	140321215365328 [label=AccumulateGrad]
	140321215366048 -> 140321215367872
	140321219571824 [label="stage2.0.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140321219571824 -> 140321215366048
	140321215366048 [label=AccumulateGrad]
	140321215366576 -> 140321215367872
	140321219572464 [label="stage2.0.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140321219572464 -> 140321215366576
	140321215366576 [label=AccumulateGrad]
	140321215368736 -> 140321215369888
	140321219572624 [label="stage2.0.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321219572624 -> 140321215368736
	140321215368736 [label=AccumulateGrad]
	140321215368400 -> 140321215370752
	140321219572704 [label="stage2.0.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140321219572704 -> 140321215368400
	140321215368400 [label=AccumulateGrad]
	140321215369264 -> 140321215370752
	140321219573264 [label="stage2.0.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140321219573264 -> 140321215369264
	140321215369264 [label=AccumulateGrad]
	140321215371232 -> 140321215370032
	140321215372048 -> 140321215371760
	140321219573584 [label="stage2.0.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321219573584 -> 140321215372048
	140321215372048 [label=AccumulateGrad]
	140321215372720 -> 140321215374304
	140321219573424 [label="stage2.0.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140321219573424 -> 140321215372720
	140321215372720 [label=AccumulateGrad]
	140321215373248 -> 140321215374304
	140321219573504 [label="stage2.0.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140321219573504 -> 140321215373248
	140321215373248 [label=AccumulateGrad]
	140321215375408 -> 140321215376608
	140321219574224 [label="stage2.0.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321219574224 -> 140321215375408
	140321215375408 [label=AccumulateGrad]
	140321215376464 -> 140321215376752
	140321219574384 [label="stage2.0.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140321219574384 -> 140321215376464
	140321215376464 [label=AccumulateGrad]
	140321215375312 -> 140321215376752
	140321219574064 [label="stage2.0.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140321219574064 -> 140321215375312
	140321215375312 [label=AccumulateGrad]
	140321215377472 -> 140321215376128
	140321215377664 -> 140321215378480
	140321219575024 [label="stage2.0.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140321219575024 -> 140321215377664
	140321215377664 [label=AccumulateGrad]
	140321215379440 -> 140321215379968
	140321219574784 [label="stage2.0.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140321219574784 -> 140321215379440
	140321215379440 [label=AccumulateGrad]
	140321215380784 -> 140321215379968
	140321219575104 [label="stage2.0.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140321219575104 -> 140321215380784
	140321215380784 [label=AccumulateGrad]
	140321215512640 -> 140321215512976
	140321219757232 [label="stage3.0.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321219757232 -> 140321215512640
	140321215512640 [label=AccumulateGrad]
	140321215513120 -> 140321215513264
	140321219757312 [label="stage3.0.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140321219757312 -> 140321215513120
	140321215513120 [label=AccumulateGrad]
	140321215513312 -> 140321215513264
	140321219757392 [label="stage3.0.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140321219757392 -> 140321215513312
	140321215513312 [label=AccumulateGrad]
	140321215513648 -> 140321215513840
	140321219757872 [label="stage3.0.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321219757872 -> 140321215513648
	140321215513648 [label=AccumulateGrad]
	140321215513984 -> 140321215514320
	140321219757952 [label="stage3.0.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140321219757952 -> 140321215513984
	140321215513984 [label=AccumulateGrad]
	140321215514176 -> 140321215514320
	140321219758032 [label="stage3.0.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140321219758032 -> 140321215514176
	140321215514176 [label=AccumulateGrad]
	140321215514464 -> 140321215514608
	140321215514656 -> 140321215515280
	140321219758512 [label="stage3.0.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321219758512 -> 140321215514656
	140321215514656 [label=AccumulateGrad]
	140321215515184 -> 140321215515328
	140321219758592 [label="stage3.0.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140321219758592 -> 140321215515184
	140321215515184 [label=AccumulateGrad]
	140321215515664 -> 140321215515328
	140321219758672 [label="stage3.0.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140321219758672 -> 140321215515664
	140321215515664 [label=AccumulateGrad]
	140321215515952 -> 140321215516192
	140321219759152 [label="stage3.0.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321219759152 -> 140321215515952
	140321215515952 [label=AccumulateGrad]
	140321215516336 -> 140321215516624
	140321219759232 [label="stage3.0.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140321219759232 -> 140321215516336
	140321215516336 [label=AccumulateGrad]
	140321215516480 -> 140321215516624
	140321219759312 [label="stage3.0.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140321219759312 -> 140321215516480
	140321215516480 [label=AccumulateGrad]
	140321215516528 -> 140321215516672
	140321215517008 -> 140321215517344
	140321219759712 [label="stage3.0.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321219759712 -> 140321215517008
	140321215517008 [label=AccumulateGrad]
	140321215517536 -> 140321215517680
	140321219759792 [label="stage3.0.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140321219759792 -> 140321215517536
	140321215517536 [label=AccumulateGrad]
	140321215517968 -> 140321215517680
	140321219759872 [label="stage3.0.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140321219759872 -> 140321215517968
	140321215517968 [label=AccumulateGrad]
	140321215518016 -> 140321215518496
	140321219760352 [label="stage3.0.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321219760352 -> 140321215518016
	140321215518016 [label=AccumulateGrad]
	140321215518640 -> 140321215518688
	140321219760432 [label="stage3.0.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140321219760432 -> 140321215518640
	140321215518640 [label=AccumulateGrad]
	140321215518544 -> 140321215518688
	140321219760512 [label="stage3.0.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140321219760512 -> 140321215518544
	140321215518544 [label=AccumulateGrad]
	140321215518880 -> 140321215519024
	140321215519312 -> 140321215519696
	140321219760992 [label="stage3.0.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321219760992 -> 140321215519312
	140321215519312 [label=AccumulateGrad]
	140321215519840 -> 140321215519984
	140321219761072 [label="stage3.0.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140321219761072 -> 140321215519840
	140321215519840 [label=AccumulateGrad]
	140321215520032 -> 140321215519984
	140321219761152 [label="stage3.0.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140321219761152 -> 140321215520032
	140321215520032 [label=AccumulateGrad]
	140321215520368 -> 140321215520560
	140321219761632 [label="stage3.0.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321219761632 -> 140321215520368
	140321215520368 [label=AccumulateGrad]
	140321215520704 -> 140321215521040
	140321219761712 [label="stage3.0.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140321219761712 -> 140321215520704
	140321215520704 [label=AccumulateGrad]
	140321215520896 -> 140321215521040
	140321219761792 [label="stage3.0.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140321219761792 -> 140321215520896
	140321215520896 [label=AccumulateGrad]
	140321215521184 -> 140321215521328
	140321215521712 -> 140321215522000
	140321215521712 [label=UpsampleBilinear2DBackward0]
	140321215520656 -> 140321215521712
	140321215520656 [label=NativeBatchNormBackward0]
	140321215519168 -> 140321215520656
	140321215519168 [label=ConvolutionBackward0]
	140321215519216 -> 140321215519168
	140321215519216 [label=ReluBackward0]
	140321215516864 -> 140321215519216
	140321215516864 [label=AddBackward0]
	140321215517200 -> 140321215516864
	140321215517200 [label=NativeBatchNormBackward0]
	140321215517296 -> 140321215517200
	140321215517296 [label=ConvolutionBackward0]
	140321215515136 -> 140321215517296
	140321215515136 [label=ReluBackward0]
	140321215514992 -> 140321215515136
	140321215514992 [label=NativeBatchNormBackward0]
	140321215512688 -> 140321215514992
	140321215512688 [label=ConvolutionBackward0]
	140321215518208 -> 140321215512688
	140321215518208 [label=ReluBackward0]
	140321215379824 -> 140321215518208
	140321215379824 [label=AddBackward0]
	140321215374784 -> 140321215379824
	140321215374784 [label=NativeBatchNormBackward0]
	140321215374112 -> 140321215374784
	140321215374112 [label=ConvolutionBackward0]
	140321215368928 -> 140321215374112
	140321215368928 [label=ReluBackward0]
	140321215367728 -> 140321215368928
	140321215367728 [label=NativeBatchNormBackward0]
	140321215367392 -> 140321215367728
	140321215367392 [label=ConvolutionBackward0]
	140321215377136 -> 140321215367392
	140321215377136 [label=ReluBackward0]
	140321215224496 -> 140321215377136
	140321215224496 [label=AddBackward0]
	140321215226512 -> 140321215224496
	140321215226512 [label=NativeBatchNormBackward0]
	140321215227040 -> 140321215226512
	140321215227040 [label=ConvolutionBackward0]
	140321215223296 -> 140321215227040
	140321215223296 [label=ReluBackward0]
	140321215222336 -> 140321215223296
	140321215222336 [label=NativeBatchNormBackward0]
	140321215222000 -> 140321215222336
	140321215222000 [label=ConvolutionBackward0]
	140321215229872 -> 140321215222000
	140321215229872 [label=ReluBackward0]
	140321215221280 -> 140321215229872
	140321215221280 [label=AddBackward0]
	140321215220992 -> 140321215221280
	140321215220992 [label=NativeBatchNormBackward0]
	140321215220752 -> 140321215220992
	140321215220752 [label=ConvolutionBackward0]
	140321215220128 -> 140321215220752
	140321215220128 [label=ReluBackward0]
	140321215219936 -> 140321215220128
	140321215219936 [label=NativeBatchNormBackward0]
	140321215219648 -> 140321215219936
	140321215219648 [label=ConvolutionBackward0]
	140321215221136 -> 140321215219648
	140321215221136 [label=ReluBackward0]
	140321215218976 -> 140321215221136
	140321215218976 [label=AddBackward0]
	140321215218640 -> 140321215218976
	140321215218640 [label=NativeBatchNormBackward0]
	140321215218592 -> 140321215218640
	140321215218592 [label=ConvolutionBackward0]
	140321215380832 -> 140321215218592
	140321215217968 -> 140321215218592
	140321219575504 [label="stage2.0.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140321219575504 -> 140321215217968
	140321215217968 [label=AccumulateGrad]
	140321215218736 -> 140321215218640
	140321219575584 [label="stage2.0.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140321219575584 -> 140321215218736
	140321215218736 [label=AccumulateGrad]
	140321215219312 -> 140321215218640
	140321219574944 [label="stage2.0.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140321219574944 -> 140321215219312
	140321215219312 [label=AccumulateGrad]
	140321215378768 -> 140321215218976
	140321215219264 -> 140321215219648
	140321219762272 [label="stage3.0.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321219762272 -> 140321215219264
	140321215219264 [label=AccumulateGrad]
	140321215219792 -> 140321215219936
	140321219762352 [label="stage3.0.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140321219762352 -> 140321215219792
	140321215219792 [label=AccumulateGrad]
	140321215219984 -> 140321215219936
	140321219762432 [label="stage3.0.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140321219762432 -> 140321215219984
	140321215219984 [label=AccumulateGrad]
	140321215220320 -> 140321215220752
	140321219762912 [label="stage3.0.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321219762912 -> 140321215220320
	140321215220320 [label=AccumulateGrad]
	140321215220656 -> 140321215220992
	140321219762992 [label="stage3.0.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140321219762992 -> 140321215220656
	140321215220656 [label=AccumulateGrad]
	140321215220800 -> 140321215220992
	140321219763072 [label="stage3.0.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140321219763072 -> 140321215220800
	140321215220800 [label=AccumulateGrad]
	140321215221136 -> 140321215221280
	140321215221328 -> 140321215222000
	140321219763552 [label="stage3.0.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321219763552 -> 140321215221328
	140321215221328 [label=AccumulateGrad]
	140321215221808 -> 140321215222336
	140321219763632 [label="stage3.0.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140321219763632 -> 140321215221808
	140321215221808 [label=AccumulateGrad]
	140321215222144 -> 140321215222336
	140321219763712 [label="stage3.0.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140321219763712 -> 140321215222144
	140321215222144 [label=AccumulateGrad]
	140321215224016 -> 140321215227040
	140321219764192 [label="stage3.0.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321219764192 -> 140321215224016
	140321215224016 [label=AccumulateGrad]
	140321215226848 -> 140321215226512
	140321219764272 [label="stage3.0.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140321219764272 -> 140321215226848
	140321215226848 [label=AccumulateGrad]
	140321215224160 -> 140321215226512
	140321219764352 [label="stage3.0.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140321219764352 -> 140321215224160
	140321215224160 [label=AccumulateGrad]
	140321215229872 -> 140321215224496
	140321215233088 -> 140321215367392
	140321219764832 [label="stage3.0.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321219764832 -> 140321215233088
	140321215233088 [label=AccumulateGrad]
	140321215365712 -> 140321215367728
	140321219764912 [label="stage3.0.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140321219764912 -> 140321215365712
	140321215365712 [label=AccumulateGrad]
	140321215370608 -> 140321215367728
	140321219764992 [label="stage3.0.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140321219764992 -> 140321215370608
	140321215370608 [label=AccumulateGrad]
	140321215373104 -> 140321215374112
	140321219765472 [label="stage3.0.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321219765472 -> 140321215373104
	140321215373104 [label=AccumulateGrad]
	140321215378672 -> 140321215374784
	140321219765552 [label="stage3.0.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140321219765552 -> 140321215378672
	140321215378672 [label=AccumulateGrad]
	140321215378816 -> 140321215374784
	140321219765632 [label="stage3.0.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140321219765632 -> 140321215378816
	140321215378816 [label=AccumulateGrad]
	140321215377136 -> 140321215379824
	140321215512832 -> 140321215512688
	140321219766112 [label="stage3.0.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321219766112 -> 140321215512832
	140321215512832 [label=AccumulateGrad]
	140321215513168 -> 140321215514992
	140321219766192 [label="stage3.0.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140321219766192 -> 140321215513168
	140321215513168 [label=AccumulateGrad]
	140321215513936 -> 140321215514992
	140321219766272 [label="stage3.0.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140321219766272 -> 140321215513936
	140321215513936 [label=AccumulateGrad]
	140321215515856 -> 140321215517296
	140321219766672 [label="stage3.0.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321219766672 -> 140321215515856
	140321215515856 [label=AccumulateGrad]
	140321215517152 -> 140321215517200
	140321219766752 [label="stage3.0.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140321219766752 -> 140321215517152
	140321215517152 [label=AccumulateGrad]
	140321215516000 -> 140321215517200
	140321219766832 [label="stage3.0.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140321219766832 -> 140321215516000
	140321215516000 [label=AccumulateGrad]
	140321215518208 -> 140321215516864
	140321215518352 -> 140321215519168
	140321219772272 [label="stage3.0.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140321219772272 -> 140321215518352
	140321215518352 [label=AccumulateGrad]
	140321215519888 -> 140321215520656
	140321219772352 [label="stage3.0.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140321219772352 -> 140321215519888
	140321215519888 [label=AccumulateGrad]
	140321215521232 -> 140321215520656
	140321218150480 [label="stage3.0.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140321218150480 -> 140321215521232
	140321215521232 [label=AccumulateGrad]
	140321215521904 -> 140321215522048
	140321215521904 [label=UpsampleBilinear2DBackward0]
	140321215520512 -> 140321215521904
	140321215520512 [label=NativeBatchNormBackward0]
	140321215515520 -> 140321215520512
	140321215515520 [label=ConvolutionBackward0]
	140321215513792 -> 140321215515520
	140321215513792 [label=ReluBackward0]
	140321215514512 -> 140321215513792
	140321215514512 [label=AddBackward0]
	140321215381312 -> 140321215514512
	140321215381312 [label=NativeBatchNormBackward0]
	140321215374064 -> 140321215381312
	140321215374064 [label=ConvolutionBackward0]
	140321215233424 -> 140321215374064
	140321215233424 [label=ReluBackward0]
	140321215222672 -> 140321215233424
	140321215222672 [label=NativeBatchNormBackward0]
	140321215220608 -> 140321215222672
	140321215220608 [label=ConvolutionBackward0]
	140321215380688 -> 140321215220608
	140321215380688 [label=ReluBackward0]
	140321215219456 -> 140321215380688
	140321215219456 [label=AddBackward0]
	140321215219408 -> 140321215219456
	140321215219408 [label=NativeBatchNormBackward0]
	140321215217920 -> 140321215219408
	140321215217920 [label=ConvolutionBackward0]
	140321215217776 -> 140321215217920
	140321215217776 [label=ReluBackward0]
	140321215069872 -> 140321215217776
	140321215069872 [label=NativeBatchNormBackward0]
	140321215069584 -> 140321215069872
	140321215069584 [label=ConvolutionBackward0]
	140321215218448 -> 140321215069584
	140321215218448 [label=ReluBackward0]
	140321215068912 -> 140321215218448
	140321215068912 [label=AddBackward0]
	140321215068576 -> 140321215068912
	140321215068576 [label=NativeBatchNormBackward0]
	140321215068384 -> 140321215068576
	140321215068384 [label=ConvolutionBackward0]
	140321215067760 -> 140321215068384
	140321215067760 [label=ReluBackward0]
	140321215067568 -> 140321215067760
	140321215067568 [label=NativeBatchNormBackward0]
	140321215067232 -> 140321215067568
	140321215067232 [label=ConvolutionBackward0]
	140321215068768 -> 140321215067232
	140321215068768 [label=ReluBackward0]
	140321215066560 -> 140321215068768
	140321215066560 [label=AddBackward0]
	140321215066512 -> 140321215066560
	140321215066512 [label=NativeBatchNormBackward0]
	140321215066080 -> 140321215066512
	140321215066080 [label=ConvolutionBackward0]
	140321215065696 -> 140321215066080
	140321215065696 [label=ReluBackward0]
	140321215065216 -> 140321215065696
	140321215065216 [label=NativeBatchNormBackward0]
	140321215065168 -> 140321215065216
	140321215065168 [label=ConvolutionBackward0]
	140321215066416 -> 140321215065168
	140321215066416 [label=ReluBackward0]
	140321215064496 -> 140321215066416
	140321215064496 [label=NativeBatchNormBackward0]
	140321215064208 -> 140321215064496
	140321215064208 [label=ConvolutionBackward0]
	140321215221136 -> 140321215064208
	140321215063824 -> 140321215064208
	140321219756272 [label="transition2.2.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140321219756272 -> 140321215063824
	140321215063824 [label=AccumulateGrad]
	140321215064352 -> 140321215064496
	140321219756192 [label="transition2.2.0.1.weight
 (72)" fillcolor=lightblue]
	140321219756192 -> 140321215064352
	140321215064352 [label=AccumulateGrad]
	140321215064880 -> 140321215064496
	140321219756752 [label="transition2.2.0.1.bias
 (72)" fillcolor=lightblue]
	140321219756752 -> 140321215064880
	140321215064880 [label=AccumulateGrad]
	140321215064544 -> 140321215065168
	140321219767312 [label="stage3.0.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321219767312 -> 140321215064544
	140321215064544 [label=AccumulateGrad]
	140321215065072 -> 140321215065216
	140321219767392 [label="stage3.0.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140321219767392 -> 140321215065072
	140321215065072 [label=AccumulateGrad]
	140321215065552 -> 140321215065216
	140321219767472 [label="stage3.0.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140321219767472 -> 140321215065552
	140321215065552 [label=AccumulateGrad]
	140321215065840 -> 140321215066080
	140321219767952 [label="stage3.0.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321219767952 -> 140321215065840
	140321215065840 [label=AccumulateGrad]
	140321215066224 -> 140321215066512
	140321219768032 [label="stage3.0.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140321219768032 -> 140321215066224
	140321215066224 [label=AccumulateGrad]
	140321215066368 -> 140321215066512
	140321219768112 [label="stage3.0.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140321219768112 -> 140321215066368
	140321215066368 [label=AccumulateGrad]
	140321215066416 -> 140321215066560
	140321215066896 -> 140321215067232
	140321219768592 [label="stage3.0.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321219768592 -> 140321215066896
	140321215066896 [label=AccumulateGrad]
	140321215067424 -> 140321215067568
	140321219768672 [label="stage3.0.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140321219768672 -> 140321215067424
	140321215067424 [label=AccumulateGrad]
	140321215067856 -> 140321215067568
	140321219768752 [label="stage3.0.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140321219768752 -> 140321215067856
	140321215067856 [label=AccumulateGrad]
	140321215067904 -> 140321215068384
	140321219769232 [label="stage3.0.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321219769232 -> 140321215067904
	140321215067904 [label=AccumulateGrad]
	140321215068528 -> 140321215068576
	140321219769312 [label="stage3.0.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140321219769312 -> 140321215068528
	140321215068528 [label=AccumulateGrad]
	140321215068432 -> 140321215068576
	140321219769392 [label="stage3.0.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140321219769392 -> 140321215068432
	140321215068432 [label=AccumulateGrad]
	140321215068768 -> 140321215068912
	140321215069200 -> 140321215069584
	140321219769872 [label="stage3.0.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321219769872 -> 140321215069200
	140321215069200 [label=AccumulateGrad]
	140321215069728 -> 140321215069872
	140321219769952 [label="stage3.0.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140321219769952 -> 140321215069728
	140321215069728 [label=AccumulateGrad]
	140321215069920 -> 140321215069872
	140321219770032 [label="stage3.0.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140321219770032 -> 140321215069920
	140321215069920 [label=AccumulateGrad]
	140321215218064 -> 140321215217920
	140321219770512 [label="stage3.0.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321219770512 -> 140321215218064
	140321215218064 [label=AccumulateGrad]
	140321215218304 -> 140321215219408
	140321219770592 [label="stage3.0.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140321219770592 -> 140321215218304
	140321215218304 [label=AccumulateGrad]
	140321215218784 -> 140321215219408
	140321219770672 [label="stage3.0.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140321219770672 -> 140321215218784
	140321215218784 [label=AccumulateGrad]
	140321215218448 -> 140321215219456
	140321215219120 -> 140321215220608
	140321219771152 [label="stage3.0.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321219771152 -> 140321215219120
	140321215219120 [label=AccumulateGrad]
	140321215221952 -> 140321215222672
	140321219771232 [label="stage3.0.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140321219771232 -> 140321215221952
	140321215221952 [label=AccumulateGrad]
	140321215223008 -> 140321215222672
	140321219771312 [label="stage3.0.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140321219771312 -> 140321215223008
	140321215223008 [label=AccumulateGrad]
	140321215231360 -> 140321215374064
	140321219771792 [label="stage3.0.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321219771792 -> 140321215231360
	140321215231360 [label=AccumulateGrad]
	140321215366672 -> 140321215381312
	140321219771872 [label="stage3.0.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140321219771872 -> 140321215366672
	140321215366672 [label=AccumulateGrad]
	140321215372096 -> 140321215381312
	140321219771952 [label="stage3.0.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140321219771952 -> 140321215372096
	140321215372096 [label=AccumulateGrad]
	140321215380688 -> 140321215514512
	140321215514848 -> 140321215515520
	140321218150960 [label="stage3.0.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140321218150960 -> 140321215514848
	140321215514848 [label=AccumulateGrad]
	140321215517824 -> 140321215520512
	140321218151040 [label="stage3.0.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140321218151040 -> 140321215517824
	140321215517824 [label=AccumulateGrad]
	140321215521856 -> 140321215520512
	140321218151120 [label="stage3.0.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140321218151120 -> 140321215521856
	140321215521856 [label=AccumulateGrad]
	140321215522384 -> 140321215522720
	140321218154480 [label="stage3.1.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218154480 -> 140321215522384
	140321215522384 [label=AccumulateGrad]
	140321215522912 -> 140321215523056
	140321218154560 [label="stage3.1.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140321218154560 -> 140321215522912
	140321215522912 [label=AccumulateGrad]
	140321215523344 -> 140321215523056
	140321218154640 [label="stage3.1.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140321218154640 -> 140321215523344
	140321215523344 [label=AccumulateGrad]
	140321215523392 -> 140321215523872
	140321218155120 [label="stage3.1.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218155120 -> 140321215523392
	140321215523392 [label=AccumulateGrad]
	140321215524016 -> 140321215524064
	140321218155200 [label="stage3.1.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140321218155200 -> 140321215524016
	140321215524016 [label=AccumulateGrad]
	140321215523920 -> 140321215524064
	140321218155280 [label="stage3.1.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140321218155280 -> 140321215523920
	140321215523920 [label=AccumulateGrad]
	140321215524256 -> 140321215524400
	140321215524688 -> 140321215525072
	140321218155680 [label="stage3.1.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218155680 -> 140321215524688
	140321215524688 [label=AccumulateGrad]
	140321215525216 -> 140321215525360
	140321218155760 [label="stage3.1.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140321218155760 -> 140321215525216
	140321215525216 [label=AccumulateGrad]
	140321215525408 -> 140321215525360
	140321218155840 [label="stage3.1.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140321218155840 -> 140321215525408
	140321215525408 [label=AccumulateGrad]
	140321215525744 -> 140321215525936
	140321218156320 [label="stage3.1.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218156320 -> 140321215525744
	140321215525744 [label=AccumulateGrad]
	140321215526080 -> 140321215526416
	140321218156400 [label="stage3.1.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140321218156400 -> 140321215526080
	140321215526080 [label=AccumulateGrad]
	140321215526272 -> 140321215526416
	140321218156480 [label="stage3.1.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140321218156480 -> 140321215526272
	140321215526272 [label=AccumulateGrad]
	140321215526560 -> 140321215526704
	140321215526752 -> 140321215527376
	140321218156960 [label="stage3.1.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218156960 -> 140321215526752
	140321215526752 [label=AccumulateGrad]
	140321215527280 -> 140321215527424
	140321218157040 [label="stage3.1.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140321218157040 -> 140321215527280
	140321215527280 [label=AccumulateGrad]
	140321215527760 -> 140321215527424
	140321218157120 [label="stage3.1.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140321218157120 -> 140321215527760
	140321215527760 [label=AccumulateGrad]
	140321215528048 -> 140321215528288
	140321218157600 [label="stage3.1.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218157600 -> 140321215528048
	140321215528048 [label=AccumulateGrad]
	140321215528432 -> 140321215528720
	140321218157680 [label="stage3.1.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140321218157680 -> 140321215528432
	140321215528432 [label=AccumulateGrad]
	140321215528576 -> 140321215528720
	140321218157760 [label="stage3.1.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140321218157760 -> 140321215528576
	140321215528576 [label=AccumulateGrad]
	140321215528624 -> 140321215676480
	140321215676624 -> 140321215676960
	140321218158240 [label="stage3.1.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218158240 -> 140321215676624
	140321215676624 [label=AccumulateGrad]
	140321215677152 -> 140321215677296
	140321218158320 [label="stage3.1.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140321218158320 -> 140321215677152
	140321215677152 [label=AccumulateGrad]
	140321215677584 -> 140321215677296
	140321218158400 [label="stage3.1.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140321218158400 -> 140321215677584
	140321215677584 [label=AccumulateGrad]
	140321215677632 -> 140321215678112
	140321218158880 [label="stage3.1.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218158880 -> 140321215677632
	140321215677632 [label=AccumulateGrad]
	140321215678256 -> 140321215678304
	140321218158960 [label="stage3.1.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140321218158960 -> 140321215678256
	140321215678256 [label=AccumulateGrad]
	140321215678160 -> 140321215678304
	140321218159040 [label="stage3.1.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140321218159040 -> 140321215678160
	140321215678160 [label=AccumulateGrad]
	140321215678496 -> 140321215678640
	140321215678976 -> 140321215679312
	140321215678976 [label=UpsampleBilinear2DBackward0]
	140321215677968 -> 140321215678976
	140321215677968 [label=NativeBatchNormBackward0]
	140321215676768 -> 140321215677968
	140321215676768 [label=ConvolutionBackward0]
	140321215676912 -> 140321215676768
	140321215676912 [label=ReluBackward0]
	140321215526608 -> 140321215676912
	140321215526608 [label=AddBackward0]
	140321215527232 -> 140321215526608
	140321215527232 [label=NativeBatchNormBackward0]
	140321215527088 -> 140321215527232
	140321215527088 [label=ConvolutionBackward0]
	140321215524928 -> 140321215527088
	140321215524928 [label=ReluBackward0]
	140321215524736 -> 140321215524928
	140321215524736 [label=NativeBatchNormBackward0]
	140321215522240 -> 140321215524736
	140321215522240 [label=ConvolutionBackward0]
	140321215527952 -> 140321215522240
	140321215527952 [label=ReluBackward0]
	140321215519552 -> 140321215527952
	140321215519552 [label=AddBackward0]
	140321215519360 -> 140321215519552
	140321215519360 [label=NativeBatchNormBackward0]
	140321215371376 -> 140321215519360
	140321215371376 [label=ConvolutionBackward0]
	140321215218112 -> 140321215371376
	140321215218112 [label=ReluBackward0]
	140321215221664 -> 140321215218112
	140321215221664 [label=NativeBatchNormBackward0]
	140321215070112 -> 140321215221664
	140321215070112 [label=ConvolutionBackward0]
	140321215522576 -> 140321215070112
	140321215522576 [label=ReluBackward0]
	140321215066752 -> 140321215522576
	140321215066752 [label=AddBackward0]
	140321215067088 -> 140321215066752
	140321215067088 [label=NativeBatchNormBackward0]
	140321215067184 -> 140321215067088
	140321215067184 [label=ConvolutionBackward0]
	140321215065024 -> 140321215067184
	140321215065024 [label=ReluBackward0]
	140321215064064 -> 140321215065024
	140321215064064 [label=NativeBatchNormBackward0]
	140321215063728 -> 140321215064064
	140321215063728 [label=ConvolutionBackward0]
	140321215068096 -> 140321215063728
	140321215068096 [label=ReluBackward0]
	140321215063008 -> 140321215068096
	140321215063008 [label=AddBackward0]
	140321215062720 -> 140321215063008
	140321215062720 [label=NativeBatchNormBackward0]
	140321215062480 -> 140321215062720
	140321215062480 [label=ConvolutionBackward0]
	140321215061856 -> 140321215062480
	140321215061856 [label=ReluBackward0]
	140321215061664 -> 140321215061856
	140321215061664 [label=NativeBatchNormBackward0]
	140321215061376 -> 140321215061664
	140321215061376 [label=ConvolutionBackward0]
	140321215062864 -> 140321215061376
	140321215062864 [label=ReluBackward0]
	140321215060704 -> 140321215062864
	140321215060704 [label=AddBackward0]
	140321215060368 -> 140321215060704
	140321215060368 [label=AddBackward0]
	140321215060176 -> 140321215060368
	140321215060176 [label=NativeBatchNormBackward0]
	140321215059840 -> 140321215060176
	140321215059840 [label=ConvolutionBackward0]
	140321215521568 -> 140321215059840
	140321215059504 -> 140321215059840
	140321218151520 [label="stage3.0.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140321218151520 -> 140321215059504
	140321215059504 [label=AccumulateGrad]
	140321215060032 -> 140321215060176
	140321218151600 [label="stage3.0.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140321218151600 -> 140321215060032
	140321215060032 [label=AccumulateGrad]
	140321215060464 -> 140321215060176
	140321218151680 [label="stage3.0.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140321218151680 -> 140321215060464
	140321215060464 [label=AccumulateGrad]
	140321215519216 -> 140321215060368
	140321215060512 -> 140321215060704
	140321215060512 [label=UpsampleBilinear2DBackward0]
	140321215059792 -> 140321215060512
	140321215059792 [label=NativeBatchNormBackward0]
	140321215059648 -> 140321215059792
	140321215059648 [label=ConvolutionBackward0]
	140321215513792 -> 140321215059648
	140321215058976 -> 140321215059648
	140321218152080 [label="stage3.0.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140321218152080 -> 140321215058976
	140321215058976 [label=AccumulateGrad]
	140321215059168 -> 140321215059792
	140321218152160 [label="stage3.0.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140321218152160 -> 140321215059168
	140321215059168 [label=AccumulateGrad]
	140321215060320 -> 140321215059792
	140321218152240 [label="stage3.0.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140321218152240 -> 140321215060320
	140321215060320 [label=AccumulateGrad]
	140321215060992 -> 140321215061376
	140321218159520 [label="stage3.1.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218159520 -> 140321215060992
	140321215060992 [label=AccumulateGrad]
	140321215061520 -> 140321215061664
	140321218159600 [label="stage3.1.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140321218159600 -> 140321215061520
	140321215061520 [label=AccumulateGrad]
	140321215061712 -> 140321215061664
	140321218159680 [label="stage3.1.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140321218159680 -> 140321215061712
	140321215061712 [label=AccumulateGrad]
	140321215062048 -> 140321215062480
	140321218160160 [label="stage3.1.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218160160 -> 140321215062048
	140321215062048 [label=AccumulateGrad]
	140321215062384 -> 140321215062720
	140321218160240 [label="stage3.1.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140321218160240 -> 140321215062384
	140321215062384 [label=AccumulateGrad]
	140321215062528 -> 140321215062720
	140321218160320 [label="stage3.1.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140321218160320 -> 140321215062528
	140321215062528 [label=AccumulateGrad]
	140321215062864 -> 140321215063008
	140321215063056 -> 140321215063728
	140321218160800 [label="stage3.1.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218160800 -> 140321215063056
	140321215063056 [label=AccumulateGrad]
	140321215063536 -> 140321215064064
	140321218160880 [label="stage3.1.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140321218160880 -> 140321215063536
	140321215063536 [label=AccumulateGrad]
	140321215063872 -> 140321215064064
	140321218160960 [label="stage3.1.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140321218160960 -> 140321215063872
	140321215063872 [label=AccumulateGrad]
	140321215065744 -> 140321215067184
	140321218161440 [label="stage3.1.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218161440 -> 140321215065744
	140321215065744 [label=AccumulateGrad]
	140321215067040 -> 140321215067088
	140321218161520 [label="stage3.1.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140321218161520 -> 140321215067040
	140321215067040 [label=AccumulateGrad]
	140321215065888 -> 140321215067088
	140321218161600 [label="stage3.1.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140321218161600 -> 140321215065888
	140321215065888 [label=AccumulateGrad]
	140321215068096 -> 140321215066752
	140321215069248 -> 140321215070112
	140321218162080 [label="stage3.1.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218162080 -> 140321215069248
	140321215069248 [label=AccumulateGrad]
	140321215069056 -> 140321215221664
	140321218162160 [label="stage3.1.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140321218162160 -> 140321215069056
	140321215069056 [label=AccumulateGrad]
	140321215069776 -> 140321215221664
	140321218162240 [label="stage3.1.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140321218162240 -> 140321215069776
	140321215069776 [label=AccumulateGrad]
	140321215221472 -> 140321215371376
	140321218162720 [label="stage3.1.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218162720 -> 140321215221472
	140321215221472 [label=AccumulateGrad]
	140321215221424 -> 140321215519360
	140321218162800 [label="stage3.1.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140321218162800 -> 140321215221424
	140321215221424 [label=AccumulateGrad]
	140321215230160 -> 140321215519360
	140321218162880 [label="stage3.1.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140321218162880 -> 140321215230160
	140321215230160 [label=AccumulateGrad]
	140321215522576 -> 140321215519552
	140321215522528 -> 140321215522240
	140321218163360 [label="stage3.1.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218163360 -> 140321215522528
	140321215522528 [label=AccumulateGrad]
	140321215523200 -> 140321215524736
	140321218163440 [label="stage3.1.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140321218163440 -> 140321215523200
	140321215523200 [label=AccumulateGrad]
	140321215523728 -> 140321215524736
	140321218163520 [label="stage3.1.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140321218163520 -> 140321215523728
	140321215523728 [label=AccumulateGrad]
	140321215525888 -> 140321215527088
	140321218164000 [label="stage3.1.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218164000 -> 140321215525888
	140321215525888 [label=AccumulateGrad]
	140321215526944 -> 140321215527232
	140321218164080 [label="stage3.1.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140321218164080 -> 140321215526944
	140321215526944 [label=AccumulateGrad]
	140321215526032 -> 140321215527232
	140321218164160 [label="stage3.1.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140321218164160 -> 140321215526032
	140321215526032 [label=AccumulateGrad]
	140321215527952 -> 140321215526608
	140321215676816 -> 140321215676768
	140321218382496 [label="stage3.1.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140321218382496 -> 140321215676816
	140321215676816 [label=AccumulateGrad]
	140321215677440 -> 140321215677968
	140321218382576 [label="stage3.1.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140321218382576 -> 140321215677440
	140321215677440 [label=AccumulateGrad]
	140321215678784 -> 140321215677968
	140321218382656 [label="stage3.1.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140321218382656 -> 140321215678784
	140321215678784 [label=AccumulateGrad]
	140321215679456 -> 140321215679600
	140321215679456 [label=UpsampleBilinear2DBackward0]
	140321215677824 -> 140321215679456
	140321215677824 [label=NativeBatchNormBackward0]
	140321215679168 -> 140321215677824
	140321215679168 [label=ConvolutionBackward0]
	140321215522672 -> 140321215679168
	140321215522672 [label=ReluBackward0]
	140321215521376 -> 140321215522672
	140321215521376 [label=AddBackward0]
	140321215381456 -> 140321215521376
	140321215381456 [label=NativeBatchNormBackward0]
	140321215220080 -> 140321215381456
	140321215220080 [label=ConvolutionBackward0]
	140321215068240 -> 140321215220080
	140321215068240 [label=ReluBackward0]
	140321215064400 -> 140321215068240
	140321215064400 [label=NativeBatchNormBackward0]
	140321215062336 -> 140321215064400
	140321215062336 [label=ConvolutionBackward0]
	140321215524544 -> 140321215062336
	140321215524544 [label=ReluBackward0]
	140321215061184 -> 140321215524544
	140321215061184 [label=AddBackward0]
	140321215061136 -> 140321215061184
	140321215061136 [label=NativeBatchNormBackward0]
	140321215059024 -> 140321215061136
	140321215059024 [label=ConvolutionBackward0]
	140321215058496 -> 140321215059024
	140321215058496 [label=ReluBackward0]
	140321215058304 -> 140321215058496
	140321215058304 [label=NativeBatchNormBackward0]
	140321215058016 -> 140321215058304
	140321215058016 [label=ConvolutionBackward0]
	140321215059696 -> 140321215058016
	140321215059696 [label=ReluBackward0]
	140321215057344 -> 140321215059696
	140321215057344 [label=AddBackward0]
	140321215057008 -> 140321215057344
	140321215057008 [label=NativeBatchNormBackward0]
	140321215056816 -> 140321215057008
	140321215056816 [label=ConvolutionBackward0]
	140321215056432 -> 140321215056816
	140321215056432 [label=ReluBackward0]
	140321215056000 -> 140321215056432
	140321215056000 [label=NativeBatchNormBackward0]
	140321215055664 -> 140321215056000
	140321215055664 [label=ConvolutionBackward0]
	140321215057152 -> 140321215055664
	140321215057152 [label=ReluBackward0]
	140321215054992 -> 140321215057152
	140321215054992 [label=AddBackward0]
	140321215054944 -> 140321215054992
	140321215054944 [label=NativeBatchNormBackward0]
	140321215054464 -> 140321215054944
	140321215054464 [label=ConvolutionBackward0]
	140321215054128 -> 140321215054464
	140321215054128 [label=ReluBackward0]
	140321215053984 -> 140321215054128
	140321215053984 [label=NativeBatchNormBackward0]
	140321214906080 -> 140321215053984
	140321214906080 [label=ConvolutionBackward0]
	140321215055088 -> 140321214906080
	140321215055088 [label=ReluBackward0]
	140321214905408 -> 140321215055088
	140321214905408 [label=AddBackward0]
	140321214905120 -> 140321214905408
	140321214905120 [label=AddBackward0]
	140321214904784 -> 140321214905120
	140321214904784 [label=NativeBatchNormBackward0]
	140321214904592 -> 140321214904784
	140321214904592 [label=ConvolutionBackward0]
	140321214904208 -> 140321214904592
	140321214904208 [label=ReluBackward0]
	140321214903776 -> 140321214904208
	140321214903776 [label=NativeBatchNormBackward0]
	140321214903440 -> 140321214903776
	140321214903440 [label=ConvolutionBackward0]
	140321215521568 -> 140321214903440
	140321214903104 -> 140321214903440
	140321218152640 [label="stage3.0.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218152640 -> 140321214903104
	140321214903104 [label=AccumulateGrad]
	140321214903584 -> 140321214903776
	140321218152720 [label="stage3.0.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140321218152720 -> 140321214903584
	140321214903584 [label=AccumulateGrad]
	140321214904064 -> 140321214903776
	140321218152800 [label="stage3.0.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140321218152800 -> 140321214904064
	140321214904064 [label=AccumulateGrad]
	140321214904112 -> 140321214904592
	140321218153280 [label="stage3.0.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140321218153280 -> 140321214904112
	140321214904112 [label=AccumulateGrad]
	140321214904736 -> 140321214904784
	140321218153360 [label="stage3.0.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140321218153360 -> 140321214904736
	140321214904736 [label=AccumulateGrad]
	140321214904880 -> 140321214904784
	140321218153440 [label="stage3.0.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140321218153440 -> 140321214904880
	140321214904880 [label=AccumulateGrad]
	140321214904928 -> 140321214905120
	140321214904928 [label=NativeBatchNormBackward0]
	140321214903392 -> 140321214904928
	140321214903392 [label=ConvolutionBackward0]
	140321215519216 -> 140321214903392
	140321214903248 -> 140321214903392
	140321218153840 [label="stage3.0.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140321218153840 -> 140321214903248
	140321214903248 [label=AccumulateGrad]
	140321214903920 -> 140321214904928
	140321218153920 [label="stage3.0.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140321218153920 -> 140321214903920
	140321214903920 [label=AccumulateGrad]
	140321214904448 -> 140321214904928
	140321218154000 [label="stage3.0.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140321218154000 -> 140321214904448
	140321214904448 [label=AccumulateGrad]
	140321215513792 -> 140321214905408
	140321214905456 -> 140321214906080
	140321218164640 [label="stage3.1.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218164640 -> 140321214905456
	140321214905456 [label=AccumulateGrad]
	140321214906224 -> 140321215053984
	140321218164720 [label="stage3.1.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140321218164720 -> 140321214906224
	140321214906224 [label=AccumulateGrad]
	140321214906272 -> 140321215053984
	140321218164800 [label="stage3.1.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140321218164800 -> 140321214906272
	140321214906272 [label=AccumulateGrad]
	140321215054272 -> 140321215054464
	140321218165200 [label="stage3.1.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218165200 -> 140321215054272
	140321215054272 [label=AccumulateGrad]
	140321215054656 -> 140321215054944
	140321218165280 [label="stage3.1.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140321218165280 -> 140321215054656
	140321215054656 [label=AccumulateGrad]
	140321215054800 -> 140321215054944
	140321218165360 [label="stage3.1.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140321218165360 -> 140321215054800
	140321215054800 [label=AccumulateGrad]
	140321215055088 -> 140321215054992
	140321215055328 -> 140321215055664
	140321218165840 [label="stage3.1.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218165840 -> 140321215055328
	140321215055328 [label=AccumulateGrad]
	140321215055808 -> 140321215056000
	140321218165920 [label="stage3.1.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140321218165920 -> 140321215055808
	140321215055808 [label=AccumulateGrad]
	140321215056288 -> 140321215056000
	140321218166000 [label="stage3.1.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140321218166000 -> 140321215056288
	140321215056288 [label=AccumulateGrad]
	140321215056336 -> 140321215056816
	140321218166400 [label="stage3.1.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218166400 -> 140321215056336
	140321215056336 [label=AccumulateGrad]
	140321215056960 -> 140321215057008
	140321218166480 [label="stage3.1.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140321218166480 -> 140321215056960
	140321215056960 [label=AccumulateGrad]
	140321215057104 -> 140321215057008
	140321218166560 [label="stage3.1.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140321218166560 -> 140321215057104
	140321215057104 [label=AccumulateGrad]
	140321215057152 -> 140321215057344
	140321215057632 -> 140321215058016
	140321218380016 [label="stage3.1.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218380016 -> 140321215057632
	140321215057632 [label=AccumulateGrad]
	140321215058160 -> 140321215058304
	140321218380096 [label="stage3.1.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140321218380096 -> 140321215058160
	140321215058160 [label=AccumulateGrad]
	140321215058352 -> 140321215058304
	140321218380176 [label="stage3.1.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140321218380176 -> 140321215058352
	140321215058352 [label=AccumulateGrad]
	140321215058832 -> 140321215059024
	140321218380656 [label="stage3.1.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218380656 -> 140321215058832
	140321215058832 [label=AccumulateGrad]
	140321215059360 -> 140321215061136
	140321218380736 [label="stage3.1.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140321218380736 -> 140321215059360
	140321215059360 [label=AccumulateGrad]
	140321215061040 -> 140321215061136
	140321218380816 [label="stage3.1.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140321218380816 -> 140321215061040
	140321215061040 [label=AccumulateGrad]
	140321215059696 -> 140321215061184
	140321215060848 -> 140321215062336
	140321218381296 [label="stage3.1.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218381296 -> 140321215060848
	140321215060848 [label=AccumulateGrad]
	140321215063680 -> 140321215064400
	140321218381376 [label="stage3.1.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140321218381376 -> 140321215063680
	140321215063680 [label=AccumulateGrad]
	140321215064736 -> 140321215064400
	140321218381456 [label="stage3.1.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140321218381456 -> 140321215064736
	140321215064736 [label=AccumulateGrad]
	140321215069104 -> 140321215220080
	140321218381856 [label="stage3.1.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218381856 -> 140321215069104
	140321215069104 [label=AccumulateGrad]
	140321215223680 -> 140321215381456
	140321218381936 [label="stage3.1.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140321218381936 -> 140321215223680
	140321215223680 [label=AccumulateGrad]
	140321215067712 -> 140321215381456
	140321218382016 [label="stage3.1.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140321218382016 -> 140321215067712
	140321215067712 [label=AccumulateGrad]
	140321215524544 -> 140321215521376
	140321215524592 -> 140321215679168
	140321218383136 [label="stage3.1.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140321218383136 -> 140321215524592
	140321215524592 [label=AccumulateGrad]
	140321215525264 -> 140321215677824
	140321218383216 [label="stage3.1.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140321218383216 -> 140321215525264
	140321215525264 [label=AccumulateGrad]
	140321215527616 -> 140321215677824
	140321218383296 [label="stage3.1.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140321218383296 -> 140321215527616
	140321215527616 [label=AccumulateGrad]
	140321215679648 -> 140321215680272
	140321218386896 [label="stage3.2.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218386896 -> 140321215679648
	140321215679648 [label=AccumulateGrad]
	140321215680176 -> 140321215680320
	140321218386976 [label="stage3.2.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140321218386976 -> 140321215680176
	140321215680176 [label=AccumulateGrad]
	140321215680656 -> 140321215680320
	140321218387056 [label="stage3.2.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140321218387056 -> 140321215680656
	140321215680656 [label=AccumulateGrad]
	140321215680944 -> 140321215681184
	140321218387536 [label="stage3.2.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218387536 -> 140321215680944
	140321215680944 [label=AccumulateGrad]
	140321215681328 -> 140321215681616
	140321218387616 [label="stage3.2.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140321218387616 -> 140321215681328
	140321215681328 [label=AccumulateGrad]
	140321215681472 -> 140321215681616
	140321218387696 [label="stage3.2.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140321218387696 -> 140321215681472
	140321215681472 [label=AccumulateGrad]
	140321215681520 -> 140321215681664
	140321215682000 -> 140321215682336
	140321218388176 [label="stage3.2.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218388176 -> 140321215682000
	140321215682000 [label=AccumulateGrad]
	140321215682528 -> 140321215682672
	140321218388256 [label="stage3.2.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140321218388256 -> 140321215682528
	140321215682528 [label=AccumulateGrad]
	140321215682960 -> 140321215682672
	140321218388336 [label="stage3.2.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140321218388336 -> 140321215682960
	140321215682960 [label=AccumulateGrad]
	140321215683008 -> 140321215683488
	140321218388816 [label="stage3.2.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218388816 -> 140321215683008
	140321215683008 [label=AccumulateGrad]
	140321215683632 -> 140321215683680
	140321218388896 [label="stage3.2.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140321218388896 -> 140321215683632
	140321215683632 [label=AccumulateGrad]
	140321215683536 -> 140321215683680
	140321218388976 [label="stage3.2.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140321218388976 -> 140321215683536
	140321215683536 [label=AccumulateGrad]
	140321215683872 -> 140321215684016
	140321215684304 -> 140321215684688
	140321218389456 [label="stage3.2.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218389456 -> 140321215684304
	140321215684304 [label=AccumulateGrad]
	140321215684832 -> 140321215684976
	140321218389536 [label="stage3.2.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140321218389536 -> 140321215684832
	140321215684832 [label=AccumulateGrad]
	140321215685024 -> 140321215684976
	140321218389616 [label="stage3.2.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140321218389616 -> 140321215685024
	140321215685024 [label=AccumulateGrad]
	140321215685360 -> 140321215685552
	140321218390096 [label="stage3.2.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218390096 -> 140321215685360
	140321215685360 [label=AccumulateGrad]
	140321215685696 -> 140321215686032
	140321218390176 [label="stage3.2.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140321218390176 -> 140321215685696
	140321215685696 [label=AccumulateGrad]
	140321215685888 -> 140321215686032
	140321218390256 [label="stage3.2.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140321218390256 -> 140321215685888
	140321215685888 [label=AccumulateGrad]
	140321215686176 -> 140321215686320
	140321215686368 -> 140321215686992
	140321218390736 [label="stage3.2.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218390736 -> 140321215686368
	140321215686368 [label=AccumulateGrad]
	140321215686896 -> 140321215687040
	140321218390816 [label="stage3.2.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140321218390816 -> 140321215686896
	140321215686896 [label=AccumulateGrad]
	140321215687376 -> 140321215687040
	140321218390896 [label="stage3.2.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140321218390896 -> 140321215687376
	140321215687376 [label=AccumulateGrad]
	140321215687664 -> 140321215687904
	140321218391376 [label="stage3.2.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218391376 -> 140321215687664
	140321215687664 [label=AccumulateGrad]
	140321215688048 -> 140321215688336
	140321218391456 [label="stage3.2.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140321218391456 -> 140321215688048
	140321215688048 [label=AccumulateGrad]
	140321215688192 -> 140321215688336
	140321218391536 [label="stage3.2.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140321218391536 -> 140321215688192
	140321215688192 [label=AccumulateGrad]
	140321215688240 -> 140321215688384
	140321215689008 -> 140321215689056
	140321215689008 [label=UpsampleBilinear2DBackward0]
	140321215687712 -> 140321215689008
	140321215687712 [label=NativeBatchNormBackward0]
	140321215686224 -> 140321215687712
	140321215686224 [label=ConvolutionBackward0]
	140321215686560 -> 140321215686224
	140321215686560 [label=ReluBackward0]
	140321215684160 -> 140321215686560
	140321215684160 [label=AddBackward0]
	140321215684544 -> 140321215684160
	140321215684544 [label=NativeBatchNormBackward0]
	140321215684352 -> 140321215684544
	140321215684352 [label=ConvolutionBackward0]
	140321215682192 -> 140321215684352
	140321215682192 [label=ReluBackward0]
	140321215682288 -> 140321215682192
	140321215682288 [label=NativeBatchNormBackward0]
	140321215679504 -> 140321215682288
	140321215679504 [label=ConvolutionBackward0]
	140321215685504 -> 140321215679504
	140321215685504 [label=ReluBackward0]
	140321215679984 -> 140321215685504
	140321215679984 [label=AddBackward0]
	140321215528768 -> 140321215679984
	140321215528768 [label=NativeBatchNormBackward0]
	140321215220464 -> 140321215528768
	140321215220464 [label=ConvolutionBackward0]
	140321215058688 -> 140321215220464
	140321215058688 [label=ReluBackward0]
	140321215058448 -> 140321215058688
	140321215058448 [label=NativeBatchNormBackward0]
	140321215059120 -> 140321215058448
	140321215059120 [label=ConvolutionBackward0]
	140321215523584 -> 140321215059120
	140321215523584 [label=ReluBackward0]
	140321215055136 -> 140321215523584
	140321215055136 [label=AddBackward0]
	140321215055760 -> 140321215055136
	140321215055760 [label=NativeBatchNormBackward0]
	140321215055616 -> 140321215055760
	140321215055616 [label=ConvolutionBackward0]
	140321214905936 -> 140321215055616
	140321214905936 [label=ReluBackward0]
	140321214905264 -> 140321214905936
	140321214905264 [label=NativeBatchNormBackward0]
	140321214903536 -> 140321214905264
	140321214903536 [label=ConvolutionBackward0]
	140321215056480 -> 140321214903536
	140321215056480 [label=ReluBackward0]
	140321214902432 -> 140321215056480
	140321214902432 [label=AddBackward0]
	140321214902096 -> 140321214902432
	140321214902096 [label=NativeBatchNormBackward0]
	140321214901904 -> 140321214902096
	140321214901904 [label=ConvolutionBackward0]
	140321214901520 -> 140321214901904
	140321214901520 [label=ReluBackward0]
	140321214901088 -> 140321214901520
	140321214901088 [label=NativeBatchNormBackward0]
	140321214900752 -> 140321214901088
	140321214900752 [label=ConvolutionBackward0]
	140321214902240 -> 140321214900752
	140321214902240 [label=ReluBackward0]
	140321214900080 -> 140321214902240
	140321214900080 [label=AddBackward0]
	140321214900032 -> 140321214900080
	140321214900032 [label=AddBackward0]
	140321214899552 -> 140321214900032
	140321214899552 [label=NativeBatchNormBackward0]
	140321214899504 -> 140321214899552
	140321214899504 [label=ConvolutionBackward0]
	140321215678832 -> 140321214899504
	140321214898880 -> 140321214899504
	140321218383776 [label="stage3.1.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140321218383776 -> 140321214898880
	140321214898880 [label=AccumulateGrad]
	140321214899408 -> 140321214899552
	140321218383856 [label="stage3.1.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140321218383856 -> 140321214899408
	140321214899408 [label=AccumulateGrad]
	140321214899888 -> 140321214899552
	140321218383936 [label="stage3.1.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140321218383936 -> 140321214899888
	140321214899888 [label=AccumulateGrad]
	140321215676912 -> 140321214900032
	140321214900176 -> 140321214900080
	140321214900176 [label=UpsampleBilinear2DBackward0]
	140321214899216 -> 140321214900176
	140321214899216 [label=NativeBatchNormBackward0]
	140321214899072 -> 140321214899216
	140321214899072 [label=ConvolutionBackward0]
	140321215522672 -> 140321214899072
	140321214898400 -> 140321214899072
	140321218384416 [label="stage3.1.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140321218384416 -> 140321214898400
	140321214898400 [label=AccumulateGrad]
	140321214898832 -> 140321214899216
	140321218384496 [label="stage3.1.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140321218384496 -> 140321214898832
	140321214898832 [label=AccumulateGrad]
	140321214899744 -> 140321214899216
	140321218384576 [label="stage3.1.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140321218384576 -> 140321214899744
	140321214899744 [label=AccumulateGrad]
	140321214900416 -> 140321214900752
	140321218392016 [label="stage3.2.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218392016 -> 140321214900416
	140321214900416 [label=AccumulateGrad]
	140321214900896 -> 140321214901088
	140321218392096 [label="stage3.2.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140321218392096 -> 140321214900896
	140321214900896 [label=AccumulateGrad]
	140321214901376 -> 140321214901088
	140321218392176 [label="stage3.2.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140321218392176 -> 140321214901376
	140321214901376 [label=AccumulateGrad]
	140321214901424 -> 140321214901904
	140321218392576 [label="stage3.2.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218392576 -> 140321214901424
	140321214901424 [label=AccumulateGrad]
	140321214902048 -> 140321214902096
	140321218392656 [label="stage3.2.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140321218392656 -> 140321214902048
	140321214902048 [label=AccumulateGrad]
	140321214902192 -> 140321214902096
	140321218392736 [label="stage3.2.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140321218392736 -> 140321214902192
	140321214902192 [label=AccumulateGrad]
	140321214902240 -> 140321214902432
	140321214902720 -> 140321214903536
	140321218393216 [label="stage3.2.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218393216 -> 140321214902720
	140321214902720 [label=AccumulateGrad]
	140321214904256 -> 140321214905264
	140321218393296 [label="stage3.2.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140321218393296 -> 140321214904256
	140321214904256 [label=AccumulateGrad]
	140321214905792 -> 140321214905264
	140321218393376 [label="stage3.2.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140321218393376 -> 140321214905792
	140321214905792 [label=AccumulateGrad]
	140321214905552 -> 140321215055616
	140321218393856 [label="stage3.2.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218393856 -> 140321214905552
	140321214905552 [label=AccumulateGrad]
	140321215055472 -> 140321215055760
	140321218393936 [label="stage3.2.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140321218393936 -> 140321215055472
	140321215055472 [label=AccumulateGrad]
	140321215054320 -> 140321215055760
	140321218394016 [label="stage3.2.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140321218394016 -> 140321215054320
	140321215054320 [label=AccumulateGrad]
	140321215056480 -> 140321215055136
	140321215057680 -> 140321215059120
	140321218394496 [label="stage3.2.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218394496 -> 140321215057680
	140321215057680 [label=AccumulateGrad]
	140321215057488 -> 140321215058448
	140321218394576 [label="stage3.2.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140321218394576 -> 140321215057488
	140321215057488 [label=AccumulateGrad]
	140321215061808 -> 140321215058448
	140321218394656 [label="stage3.2.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140321218394656 -> 140321215061808
	140321215061808 [label=AccumulateGrad]
	140321215063200 -> 140321215220464
	140321218395056 [label="stage3.2.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218395056 -> 140321215063200
	140321215063200 [label=AccumulateGrad]
	140321215063152 -> 140321215528768
	140321218395136 [label="stage3.2.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140321218395136 -> 140321215063152
	140321215063152 [label=AccumulateGrad]
	140321215069440 -> 140321215528768
	140321218395216 [label="stage3.2.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140321218395216 -> 140321215069440
	140321215069440 [label=AccumulateGrad]
	140321215523584 -> 140321215679984
	140321215679840 -> 140321215679504
	140321218395696 [label="stage3.2.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218395696 -> 140321215679840
	140321215679840 [label=AccumulateGrad]
	140321215680512 -> 140321215682288
	140321218395776 [label="stage3.2.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140321218395776 -> 140321215680512
	140321215680512 [label=AccumulateGrad]
	140321215680992 -> 140321215682288
	140321218395856 [label="stage3.2.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140321218395856 -> 140321215680992
	140321215680992 [label=AccumulateGrad]
	140321215683200 -> 140321215684352
	140321218625776 [label="stage3.2.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218625776 -> 140321215683200
	140321215683200 [label=AccumulateGrad]
	140321215684208 -> 140321215684544
	140321218625856 [label="stage3.2.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140321218625856 -> 140321215684208
	140321215684208 [label=AccumulateGrad]
	140321215683344 -> 140321215684544
	140321218625936 [label="stage3.2.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140321218625936 -> 140321215683344
	140321215683344 [label=AccumulateGrad]
	140321215685504 -> 140321215684160
	140321215685648 -> 140321215686224
	140321218631456 [label="stage3.2.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140321218631456 -> 140321215685648
	140321215685648 [label=AccumulateGrad]
	140321215687232 -> 140321215687712
	140321218631536 [label="stage3.2.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140321218631536 -> 140321215687232
	140321215687232 [label=AccumulateGrad]
	140321215688576 -> 140321215687712
	140321218631616 [label="stage3.2.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140321218631616 -> 140321215688576
	140321215688576 [label=AccumulateGrad]
	140321215689248 -> 140321215689392
	140321215689248 [label=UpsampleBilinear2DBackward0]
	140321215687568 -> 140321215689248
	140321215687568 [label=NativeBatchNormBackward0]
	140321215682816 -> 140321215687568
	140321215682816 [label=ConvolutionBackward0]
	140321215680128 -> 140321215682816
	140321215680128 [label=ReluBackward0]
	140321215678928 -> 140321215680128
	140321215678928 [label=AddBackward0]
	140321215528096 -> 140321215678928
	140321215528096 [label=NativeBatchNormBackward0]
	140321215065408 -> 140321215528096
	140321215065408 [label=ConvolutionBackward0]
	140321215056672 -> 140321215065408
	140321215056672 [label=ReluBackward0]
	140321214906128 -> 140321215056672
	140321214906128 [label=NativeBatchNormBackward0]
	140321214901760 -> 140321214906128
	140321214901760 [label=ConvolutionBackward0]
	140321215681856 -> 140321214901760
	140321215681856 [label=ReluBackward0]
	140321214900848 -> 140321215681856
	140321214900848 [label=AddBackward0]
	140321214900560 -> 140321214900848
	140321214900560 [label=NativeBatchNormBackward0]
	140321214898688 -> 140321214900560
	140321214898688 [label=ConvolutionBackward0]
	140321214898160 -> 140321214898688
	140321214898160 [label=ReluBackward0]
	140321214897728 -> 140321214898160
	140321214897728 [label=NativeBatchNormBackward0]
	140321214897392 -> 140321214897728
	140321214897392 [label=ConvolutionBackward0]
	140321214899360 -> 140321214897392
	140321214899360 [label=ReluBackward0]
	140321214896720 -> 140321214899360
	140321214896720 [label=AddBackward0]
	140321214896672 -> 140321214896720
	140321214896672 [label=NativeBatchNormBackward0]
	140321214896192 -> 140321214896672
	140321214896192 [label=ConvolutionBackward0]
	140321214895856 -> 140321214896192
	140321214895856 [label=ReluBackward0]
	140321214895376 -> 140321214895856
	140321214895376 [label=NativeBatchNormBackward0]
	140321214895328 -> 140321214895376
	140321214895328 [label=ConvolutionBackward0]
	140321214896816 -> 140321214895328
	140321214896816 [label=ReluBackward0]
	140321214894656 -> 140321214896816
	140321214894656 [label=AddBackward0]
	140321214894368 -> 140321214894656
	140321214894368 [label=NativeBatchNormBackward0]
	140321214894128 -> 140321214894368
	140321214894128 [label=ConvolutionBackward0]
	140321214893504 -> 140321214894128
	140321214893504 [label=ReluBackward0]
	140321214893312 -> 140321214893504
	140321214893312 [label=NativeBatchNormBackward0]
	140321214893024 -> 140321214893312
	140321214893024 [label=ConvolutionBackward0]
	140321214894512 -> 140321214893024
	140321214894512 [label=ReluBackward0]
	140321214892352 -> 140321214894512
	140321214892352 [label=AddBackward0]
	140321214892016 -> 140321214892352
	140321214892016 [label=AddBackward0]
	140321214891968 -> 140321214892016
	140321214891968 [label=NativeBatchNormBackward0]
	140321214891488 -> 140321214891968
	140321214891488 [label=ConvolutionBackward0]
	140321214891152 -> 140321214891488
	140321214891152 [label=ReluBackward0]
	140321214890672 -> 140321214891152
	140321214890672 [label=NativeBatchNormBackward0]
	140321214890624 -> 140321214890672
	140321214890624 [label=ConvolutionBackward0]
	140321215678832 -> 140321214890624
	140321214890144 -> 140321214890624
	140321218385056 [label="stage3.1.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218385056 -> 140321214890144
	140321214890144 [label=AccumulateGrad]
	140321214890768 -> 140321214890672
	140321218385136 [label="stage3.1.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140321218385136 -> 140321214890768
	140321214890768 [label=AccumulateGrad]
	140321214891008 -> 140321214890672
	140321218385216 [label="stage3.1.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140321218385216 -> 140321214891008
	140321214891008 [label=AccumulateGrad]
	140321214891296 -> 140321214891488
	140321218385616 [label="stage3.1.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140321218385616 -> 140321214891296
	140321214891296 [label=AccumulateGrad]
	140321214891680 -> 140321214891968
	140321218385696 [label="stage3.1.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140321218385696 -> 140321214891680
	140321214891680 [label=AccumulateGrad]
	140321214891824 -> 140321214891968
	140321218385776 [label="stage3.1.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140321218385776 -> 140321214891824
	140321214891824 [label=AccumulateGrad]
	140321214892112 -> 140321214892016
	140321214892112 [label=NativeBatchNormBackward0]
	140321214890336 -> 140321214892112
	140321214890336 [label=ConvolutionBackward0]
	140321215676912 -> 140321214890336
	140321214890048 -> 140321214890336
	140321218386256 [label="stage3.1.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140321218386256 -> 140321214890048
	140321214890048 [label=AccumulateGrad]
	140321214890816 -> 140321214892112
	140321218386336 [label="stage3.1.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140321218386336 -> 140321214890816
	140321214890816 [label=AccumulateGrad]
	140321214891344 -> 140321214892112
	140321218386416 [label="stage3.1.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140321218386416 -> 140321214891344
	140321214891344 [label=AccumulateGrad]
	140321215522672 -> 140321214892352
	140321214892640 -> 140321214893024
	140321218626416 [label="stage3.2.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218626416 -> 140321214892640
	140321214892640 [label=AccumulateGrad]
	140321214893168 -> 140321214893312
	140321218626496 [label="stage3.2.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140321218626496 -> 140321214893168
	140321214893168 [label=AccumulateGrad]
	140321214893360 -> 140321214893312
	140321218626576 [label="stage3.2.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140321218626576 -> 140321214893360
	140321214893360 [label=AccumulateGrad]
	140321214893696 -> 140321214894128
	140321218627056 [label="stage3.2.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218627056 -> 140321214893696
	140321214893696 [label=AccumulateGrad]
	140321214894032 -> 140321214894368
	140321218627136 [label="stage3.2.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140321218627136 -> 140321214894032
	140321214894032 [label=AccumulateGrad]
	140321214894176 -> 140321214894368
	140321218627216 [label="stage3.2.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140321218627216 -> 140321214894176
	140321214894176 [label=AccumulateGrad]
	140321214894512 -> 140321214894656
	140321214894704 -> 140321214895328
	140321218627696 [label="stage3.2.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218627696 -> 140321214894704
	140321214894704 [label=AccumulateGrad]
	140321214895472 -> 140321214895376
	140321218627776 [label="stage3.2.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140321218627776 -> 140321214895472
	140321214895472 [label=AccumulateGrad]
	140321214895712 -> 140321214895376
	140321218627856 [label="stage3.2.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140321218627856 -> 140321214895712
	140321214895712 [label=AccumulateGrad]
	140321214896000 -> 140321214896192
	140321218628256 [label="stage3.2.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218628256 -> 140321214896000
	140321214896000 [label=AccumulateGrad]
	140321214896384 -> 140321214896672
	140321218628336 [label="stage3.2.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140321218628336 -> 140321214896384
	140321214896384 [label=AccumulateGrad]
	140321214896528 -> 140321214896672
	140321218628416 [label="stage3.2.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140321218628416 -> 140321214896528
	140321214896528 [label=AccumulateGrad]
	140321214896816 -> 140321214896720
	140321214897056 -> 140321214897392
	140321218628896 [label="stage3.2.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218628896 -> 140321214897056
	140321214897056 [label=AccumulateGrad]
	140321214897536 -> 140321214897728
	140321218628976 [label="stage3.2.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140321218628976 -> 140321214897536
	140321214897536 [label=AccumulateGrad]
	140321214898016 -> 140321214897728
	140321218629056 [label="stage3.2.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140321218629056 -> 140321214898016
	140321214898016 [label=AccumulateGrad]
	140321214898208 -> 140321214898688
	140321218629536 [label="stage3.2.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218629536 -> 140321214898208
	140321214898208 [label=AccumulateGrad]
	140321214898736 -> 140321214900560
	140321218629616 [label="stage3.2.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140321218629616 -> 140321214898736
	140321214898736 [label=AccumulateGrad]
	140321214900704 -> 140321214900560
	140321218629696 [label="stage3.2.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140321218629696 -> 140321214900704
	140321214900704 [label=AccumulateGrad]
	140321214899360 -> 140321214900848
	140321214900224 -> 140321214901760
	140321218630176 [label="stage3.2.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218630176 -> 140321214900224
	140321214900224 [label=AccumulateGrad]
	140321214902864 -> 140321214906128
	140321218630256 [label="stage3.2.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140321218630256 -> 140321214902864
	140321214902864 [label=AccumulateGrad]
	140321214905600 -> 140321214906128
	140321218630336 [label="stage3.2.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140321218630336 -> 140321214905600
	140321214905600 [label=AccumulateGrad]
	140321215057776 -> 140321215065408
	140321218630816 [label="stage3.2.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218630816 -> 140321215057776
	140321215057776 [label=AccumulateGrad]
	140321215056144 -> 140321215528096
	140321218630896 [label="stage3.2.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140321218630896 -> 140321215056144
	140321215056144 [label=AccumulateGrad]
	140321215063392 -> 140321215528096
	140321218630976 [label="stage3.2.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140321218630976 -> 140321215063392
	140321215063392 [label=AccumulateGrad]
	140321215681856 -> 140321215678928
	140321215682144 -> 140321215682816
	140321218632096 [label="stage3.2.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140321218632096 -> 140321215682144
	140321215682144 [label=AccumulateGrad]
	140321215684880 -> 140321215687568
	140321218632176 [label="stage3.2.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140321218632176 -> 140321215684880
	140321215684880 [label=AccumulateGrad]
	140321215688912 -> 140321215687568
	140321218632256 [label="stage3.2.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140321218632256 -> 140321215688912
	140321215688912 [label=AccumulateGrad]
	140321215689680 -> 140321215690064
	140321218631136 [label="stage3.3.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218631136 -> 140321215689680
	140321215689680 [label=AccumulateGrad]
	140321215690208 -> 140321215690352
	140321218635776 [label="stage3.3.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140321218635776 -> 140321215690208
	140321215690208 [label=AccumulateGrad]
	140321215690400 -> 140321215690352
	140321218635856 [label="stage3.3.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140321218635856 -> 140321215690400
	140321215690400 [label=AccumulateGrad]
	140321215690736 -> 140321215690928
	140321218636336 [label="stage3.3.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218636336 -> 140321215690736
	140321215690736 [label=AccumulateGrad]
	140321215691072 -> 140321215691408
	140321218636416 [label="stage3.3.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140321218636416 -> 140321215691072
	140321215691072 [label=AccumulateGrad]
	140321215691264 -> 140321215691408
	140321218636496 [label="stage3.3.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140321218636496 -> 140321215691264
	140321215691264 [label=AccumulateGrad]
	140321215691552 -> 140321215691696
	140321215691744 -> 140321215692368
	140321218636976 [label="stage3.3.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218636976 -> 140321215691744
	140321215691744 [label=AccumulateGrad]
	140321215692272 -> 140321215692416
	140321218637056 [label="stage3.3.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140321218637056 -> 140321215692272
	140321215692272 [label=AccumulateGrad]
	140321215692752 -> 140321215692416
	140321218637136 [label="stage3.3.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140321218637136 -> 140321215692752
	140321215692752 [label=AccumulateGrad]
	140321213759792 -> 140321213760032
	140321218637616 [label="stage3.3.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218637616 -> 140321213759792
	140321213759792 [label=AccumulateGrad]
	140321213760176 -> 140321213760464
	140321218637696 [label="stage3.3.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140321218637696 -> 140321213760176
	140321213760176 [label=AccumulateGrad]
	140321213760320 -> 140321213760464
	140321218637776 [label="stage3.3.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140321218637776 -> 140321213760320
	140321213760320 [label=AccumulateGrad]
	140321213760368 -> 140321213760512
	140321213760848 -> 140321213761184
	140321218638256 [label="stage3.3.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218638256 -> 140321213760848
	140321213760848 [label=AccumulateGrad]
	140321213761376 -> 140321213761520
	140321218638336 [label="stage3.3.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140321218638336 -> 140321213761376
	140321213761376 [label=AccumulateGrad]
	140321213761808 -> 140321213761520
	140321218638416 [label="stage3.3.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140321218638416 -> 140321213761808
	140321213761808 [label=AccumulateGrad]
	140321213761856 -> 140321213762336
	140321218638896 [label="stage3.3.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218638896 -> 140321213761856
	140321213761856 [label=AccumulateGrad]
	140321213762480 -> 140321213762528
	140321218638976 [label="stage3.3.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140321218638976 -> 140321213762480
	140321213762480 [label=AccumulateGrad]
	140321213762384 -> 140321213762528
	140321218639056 [label="stage3.3.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140321218639056 -> 140321213762384
	140321213762384 [label=AccumulateGrad]
	140321213762720 -> 140321213762864
	140321213763152 -> 140321213763536
	140321218639536 [label="stage3.3.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218639536 -> 140321213763152
	140321213763152 [label=AccumulateGrad]
	140321213763680 -> 140321213763824
	140321218639616 [label="stage3.3.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140321218639616 -> 140321213763680
	140321213763680 [label=AccumulateGrad]
	140321213763872 -> 140321213763824
	140321218639696 [label="stage3.3.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140321218639696 -> 140321213763872
	140321213763872 [label=AccumulateGrad]
	140321213764208 -> 140321213764400
	140321218640176 [label="stage3.3.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218640176 -> 140321213764208
	140321213764208 [label=AccumulateGrad]
	140321213764544 -> 140321213764880
	140321218640256 [label="stage3.3.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140321218640256 -> 140321213764544
	140321213764544 [label=AccumulateGrad]
	140321213764736 -> 140321213764880
	140321218640336 [label="stage3.3.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140321218640336 -> 140321213764736
	140321213764736 [label=AccumulateGrad]
	140321213765024 -> 140321213765168
	140321213765552 -> 140321213765840
	140321213765552 [label=UpsampleBilinear2DBackward0]
	140321213764496 -> 140321213765552
	140321213764496 [label=NativeBatchNormBackward0]
	140321213763008 -> 140321213764496
	140321213763008 [label=ConvolutionBackward0]
	140321213763056 -> 140321213763008
	140321213763056 [label=ReluBackward0]
	140321213760704 -> 140321213763056
	140321213760704 [label=AddBackward0]
	140321213761040 -> 140321213760704
	140321213761040 [label=NativeBatchNormBackward0]
	140321213761136 -> 140321213761040
	140321213761136 [label=ConvolutionBackward0]
	140321215692224 -> 140321213761136
	140321215692224 [label=ReluBackward0]
	140321215692080 -> 140321215692224
	140321215692080 [label=NativeBatchNormBackward0]
	140321215689536 -> 140321215692080
	140321215689536 [label=ConvolutionBackward0]
	140321213762048 -> 140321215689536
	140321213762048 [label=ReluBackward0]
	140321215686848 -> 140321213762048
	140321215686848 [label=AddBackward0]
	140321215680848 -> 140321215686848
	140321215680848 [label=NativeBatchNormBackward0]
	140321215054416 -> 140321215680848
	140321215054416 [label=ConvolutionBackward0]
	140321214898064 -> 140321215054416
	140321214898064 [label=ReluBackward0]
	140321214897872 -> 140321214898064
	140321214897872 [label=NativeBatchNormBackward0]
	140321214898544 -> 140321214897872
	140321214898544 [label=ConvolutionBackward0]
	140321215686704 -> 140321214898544
	140321215686704 [label=ReluBackward0]
	140321214894800 -> 140321215686704
	140321214894800 [label=AddBackward0]
	140321214895184 -> 140321214894800
	140321214895184 [label=NativeBatchNormBackward0]
	140321214895040 -> 140321214895184
	140321214895040 [label=ConvolutionBackward0]
	140321214892832 -> 140321214895040
	140321214892832 [label=ReluBackward0]
	140321214892160 -> 140321214892832
	140321214892160 [label=NativeBatchNormBackward0]
	140321214890096 -> 140321214892160
	140321214890096 [label=ConvolutionBackward0]
	140321214896144 -> 140321214890096
	140321214896144 [label=ReluBackward0]
	140321214774576 -> 140321214896144
	140321214774576 [label=AddBackward0]
	140321214774528 -> 140321214774576
	140321214774528 [label=NativeBatchNormBackward0]
	140321214774048 -> 140321214774528
	140321214774048 [label=ConvolutionBackward0]
	140321214773712 -> 140321214774048
	140321214773712 [label=ReluBackward0]
	140321214773232 -> 140321214773712
	140321214773232 [label=NativeBatchNormBackward0]
	140321214773184 -> 140321214773232
	140321214773184 [label=ConvolutionBackward0]
	140321214774672 -> 140321214773184
	140321214774672 [label=ReluBackward0]
	140321214772512 -> 140321214774672
	140321214772512 [label=AddBackward0]
	140321214772224 -> 140321214772512
	140321214772224 [label=AddBackward0]
	140321214771984 -> 140321214772224
	140321214771984 [label=NativeBatchNormBackward0]
	140321214771696 -> 140321214771984
	140321214771696 [label=ConvolutionBackward0]
	140321215688864 -> 140321214771696
	140321214771312 -> 140321214771696
	140321218632656 [label="stage3.2.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140321218632656 -> 140321214771312
	140321214771312 [label=AccumulateGrad]
	140321214771840 -> 140321214771984
	140321218632736 [label="stage3.2.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140321218632736 -> 140321214771840
	140321214771840 [label=AccumulateGrad]
	140321214772032 -> 140321214771984
	140321218632816 [label="stage3.2.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140321218632816 -> 140321214772032
	140321214772032 [label=AccumulateGrad]
	140321215686560 -> 140321214772224
	140321214772368 -> 140321214772512
	140321214772368 [label=UpsampleBilinear2DBackward0]
	140321214771360 -> 140321214772368
	140321214771360 [label=NativeBatchNormBackward0]
	140321214771216 -> 140321214771360
	140321214771216 [label=ConvolutionBackward0]
	140321215680128 -> 140321214771216
	140321214770544 -> 140321214771216
	140321218633296 [label="stage3.2.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140321218633296 -> 140321214770544
	140321214770544 [label=AccumulateGrad]
	140321214771024 -> 140321214771360
	140321218633376 [label="stage3.2.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140321218633376 -> 140321214771024
	140321214771024 [label=AccumulateGrad]
	140321214771888 -> 140321214771360
	140321218633456 [label="stage3.2.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140321218633456 -> 140321214771888
	140321214771888 [label=AccumulateGrad]
	140321214772560 -> 140321214773184
	140321218640816 [label="stage3.3.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218640816 -> 140321214772560
	140321214772560 [label=AccumulateGrad]
	140321214773328 -> 140321214773232
	140321218640896 [label="stage3.3.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140321218640896 -> 140321214773328
	140321214773328 [label=AccumulateGrad]
	140321214773568 -> 140321214773232
	140321218640976 [label="stage3.3.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140321218640976 -> 140321214773568
	140321214773568 [label=AccumulateGrad]
	140321214773856 -> 140321214774048
	140321218641456 [label="stage3.3.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218641456 -> 140321214773856
	140321214773856 [label=AccumulateGrad]
	140321214774240 -> 140321214774528
	140321218641536 [label="stage3.3.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140321218641536 -> 140321214774240
	140321214774240 [label=AccumulateGrad]
	140321214774384 -> 140321214774528
	140321218641616 [label="stage3.3.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140321218641616 -> 140321214774384
	140321214774384 [label=AccumulateGrad]
	140321214774672 -> 140321214774576
	140321214774912 -> 140321214890096
	140321218855152 [label="stage3.3.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218855152 -> 140321214774912
	140321214774912 [label=AccumulateGrad]
	140321214891440 -> 140321214892160
	140321218855232 [label="stage3.3.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140321218855232 -> 140321214891440
	140321214891440 [label=AccumulateGrad]
	140321214892688 -> 140321214892160
	140321218855312 [label="stage3.3.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140321218855312 -> 140321214892688
	140321214892688 [label=AccumulateGrad]
	140321214893840 -> 140321214895040
	140321218855712 [label="stage3.3.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218855712 -> 140321214893840
	140321214893840 [label=AccumulateGrad]
	140321214894848 -> 140321214895184
	140321218855792 [label="stage3.3.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140321218855792 -> 140321214894848
	140321214894848 [label=AccumulateGrad]
	140321214893984 -> 140321214895184
	140321218855872 [label="stage3.3.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140321218855872 -> 140321214893984
	140321214893984 [label=AccumulateGrad]
	140321214896144 -> 140321214894800
	140321214897344 -> 140321214898544
	140321218856352 [label="stage3.3.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218856352 -> 140321214897344
	140321214897344 [label=AccumulateGrad]
	140321214896864 -> 140321214897872
	140321218856432 [label="stage3.3.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140321218856432 -> 140321214896864
	140321214896864 [label=AccumulateGrad]
	140321214901232 -> 140321214897872
	140321218856512 [label="stage3.3.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140321218856512 -> 140321214901232
	140321214901232 [label=AccumulateGrad]
	140321214902912 -> 140321215054416
	140321218856992 [label="stage3.3.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218856992 -> 140321214902912
	140321214902912 [label=AccumulateGrad]
	140321215062192 -> 140321215680848
	140321218857072 [label="stage3.3.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140321218857072 -> 140321215062192
	140321215062192 [label=AccumulateGrad]
	140321215057824 -> 140321215680848
	140321218857152 [label="stage3.3.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140321218857152 -> 140321215057824
	140321215057824 [label=AccumulateGrad]
	140321215686704 -> 140321215686848
	140321215689584 -> 140321215689536
	140321218857632 [label="stage3.3.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218857632 -> 140321215689584
	140321215689584 [label=AccumulateGrad]
	140321215690256 -> 140321215692080
	140321218857712 [label="stage3.3.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140321218857712 -> 140321215690256
	140321215690256 [label=AccumulateGrad]
	140321215691024 -> 140321215692080
	140321218857792 [label="stage3.3.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140321218857792 -> 140321215691024
	140321215691024 [label=AccumulateGrad]
	140321215691600 -> 140321213761136
	140321218858192 [label="stage3.3.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321218858192 -> 140321215691600
	140321215691600 [label=AccumulateGrad]
	140321213760992 -> 140321213761040
	140321218858272 [label="stage3.3.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140321218858272 -> 140321213760992
	140321213760992 [label=AccumulateGrad]
	140321213759840 -> 140321213761040
	140321218858352 [label="stage3.3.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140321218858352 -> 140321213759840
	140321213759840 [label=AccumulateGrad]
	140321213762048 -> 140321213760704
	140321213762192 -> 140321213763008
	140321218863712 [label="stage3.3.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140321218863712 -> 140321213762192
	140321213762192 [label=AccumulateGrad]
	140321213763728 -> 140321213764496
	140321218863792 [label="stage3.3.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140321218863792 -> 140321213763728
	140321213763728 [label=AccumulateGrad]
	140321213765072 -> 140321213764496
	140321218863872 [label="stage3.3.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140321218863872 -> 140321213765072
	140321213765072 [label=AccumulateGrad]
	140321213765744 -> 140321213765888
	140321213765744 [label=UpsampleBilinear2DBackward0]
	140321213764352 -> 140321213765744
	140321213764352 [label=NativeBatchNormBackward0]
	140321213759696 -> 140321213764352
	140321213759696 [label=ConvolutionBackward0]
	140321213763200 -> 140321213759696
	140321213763200 [label=ReluBackward0]
	140321215689920 -> 140321213763200
	140321215689920 [label=AddBackward0]
	140321215688720 -> 140321215689920
	140321215688720 [label=NativeBatchNormBackward0]
	140321214901568 -> 140321215688720
	140321214901568 [label=ConvolutionBackward0]
	140321214896048 -> 140321214901568
	140321214896048 [label=ReluBackward0]
	140321214892496 -> 140321214896048
	140321214892496 [label=NativeBatchNormBackward0]
	140321214892784 -> 140321214892496
	140321214892784 [label=ConvolutionBackward0]
	140321215692608 -> 140321214892784
	140321215692608 [label=ReluBackward0]
	140321214773040 -> 140321215692608
	140321214773040 [label=AddBackward0]
	140321214772704 -> 140321214773040
	140321214772704 [label=NativeBatchNormBackward0]
	140321214770880 -> 140321214772704
	140321214770880 [label=ConvolutionBackward0]
	140321214770352 -> 140321214770880
	140321214770352 [label=ReluBackward0]
	140321214769872 -> 140321214770352
	140321214769872 [label=NativeBatchNormBackward0]
	140321214769824 -> 140321214769872
	140321214769824 [label=ConvolutionBackward0]
	140321214771552 -> 140321214769824
	140321214771552 [label=ReluBackward0]
	140321214769152 -> 140321214771552
	140321214769152 [label=AddBackward0]
	140321214768864 -> 140321214769152
	140321214768864 [label=NativeBatchNormBackward0]
	140321214768624 -> 140321214768864
	140321214768624 [label=ConvolutionBackward0]
	140321214768000 -> 140321214768624
	140321214768000 [label=ReluBackward0]
	140321214767808 -> 140321214768000
	140321214767808 [label=NativeBatchNormBackward0]
	140321214767520 -> 140321214767808
	140321214767520 [label=ConvolutionBackward0]
	140321214769008 -> 140321214767520
	140321214769008 [label=ReluBackward0]
	140321214766848 -> 140321214769008
	140321214766848 [label=AddBackward0]
	140321214766512 -> 140321214766848
	140321214766512 [label=NativeBatchNormBackward0]
	140321214766320 -> 140321214766512
	140321214766320 [label=ConvolutionBackward0]
	140321214765936 -> 140321214766320
	140321214765936 [label=ReluBackward0]
	140321214765504 -> 140321214765936
	140321214765504 [label=NativeBatchNormBackward0]
	140321214765168 -> 140321214765504
	140321214765168 [label=ConvolutionBackward0]
	140321214766656 -> 140321214765168
	140321214766656 [label=ReluBackward0]
	140321214764496 -> 140321214766656
	140321214764496 [label=AddBackward0]
	140321214764448 -> 140321214764496
	140321214764448 [label=AddBackward0]
	140321214764160 -> 140321214764448
	140321214764160 [label=NativeBatchNormBackward0]
	140321214763920 -> 140321214764160
	140321214763920 [label=ConvolutionBackward0]
	140321214763296 -> 140321214763920
	140321214763296 [label=ReluBackward0]
	140321214763104 -> 140321214763296
	140321214763104 [label=NativeBatchNormBackward0]
	140321214762816 -> 140321214763104
	140321214762816 [label=ConvolutionBackward0]
	140321215688864 -> 140321214762816
	140321214762432 -> 140321214762816
	140321218633936 [label="stage3.2.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218633936 -> 140321214762432
	140321214762432 [label=AccumulateGrad]
	140321214762960 -> 140321214763104
	140321218634016 [label="stage3.2.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140321218634016 -> 140321214762960
	140321214762960 [label=AccumulateGrad]
	140321214763152 -> 140321214763104
	140321218634096 [label="stage3.2.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140321218634096 -> 140321214763152
	140321214763152 [label=AccumulateGrad]
	140321214763488 -> 140321214763920
	140321218634576 [label="stage3.2.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140321218634576 -> 140321214763488
	140321214763488 [label=AccumulateGrad]
	140321214763824 -> 140321214764160
	140321218634656 [label="stage3.2.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140321218634656 -> 140321214763824
	140321214763824 [label=AccumulateGrad]
	140321214763968 -> 140321214764160
	140321218634736 [label="stage3.2.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140321218634736 -> 140321214763968
	140321214763968 [label=AccumulateGrad]
	140321214764304 -> 140321214764448
	140321214764304 [label=NativeBatchNormBackward0]
	140321214762480 -> 140321214764304
	140321214762480 [label=ConvolutionBackward0]
	140321215686560 -> 140321214762480
	140321214762576 -> 140321214762480
	140321218635216 [label="stage3.2.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140321218635216 -> 140321214762576
	140321214762576 [label=AccumulateGrad]
	140321214763248 -> 140321214764304
	140321218635296 [label="stage3.2.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140321218635296 -> 140321214763248
	140321214763248 [label=AccumulateGrad]
	140321214763776 -> 140321214764304
	140321218635376 [label="stage3.2.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140321218635376 -> 140321214763776
	140321214763776 [label=AccumulateGrad]
	140321215680128 -> 140321214764496
	140321214764832 -> 140321214765168
	140321218858832 [label="stage3.3.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218858832 -> 140321214764832
	140321214764832 [label=AccumulateGrad]
	140321214765312 -> 140321214765504
	140321218858912 [label="stage3.3.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140321218858912 -> 140321214765312
	140321214765312 [label=AccumulateGrad]
	140321214765792 -> 140321214765504
	140321218858992 [label="stage3.3.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140321218858992 -> 140321214765792
	140321214765792 [label=AccumulateGrad]
	140321214765840 -> 140321214766320
	140321218859472 [label="stage3.3.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218859472 -> 140321214765840
	140321214765840 [label=AccumulateGrad]
	140321214766464 -> 140321214766512
	140321218859552 [label="stage3.3.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140321218859552 -> 140321214766464
	140321214766464 [label=AccumulateGrad]
	140321214766608 -> 140321214766512
	140321218859632 [label="stage3.3.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140321218859632 -> 140321214766608
	140321214766608 [label=AccumulateGrad]
	140321214766656 -> 140321214766848
	140321214767136 -> 140321214767520
	140321218860112 [label="stage3.3.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218860112 -> 140321214767136
	140321214767136 [label=AccumulateGrad]
	140321214767664 -> 140321214767808
	140321218860192 [label="stage3.3.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140321218860192 -> 140321214767664
	140321214767664 [label=AccumulateGrad]
	140321214767856 -> 140321214767808
	140321218860272 [label="stage3.3.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140321218860272 -> 140321214767856
	140321214767856 [label=AccumulateGrad]
	140321214768192 -> 140321214768624
	140321218860752 [label="stage3.3.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218860752 -> 140321214768192
	140321214768192 [label=AccumulateGrad]
	140321214768528 -> 140321214768864
	140321218860832 [label="stage3.3.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140321218860832 -> 140321214768528
	140321214768528 [label=AccumulateGrad]
	140321214768672 -> 140321214768864
	140321218860912 [label="stage3.3.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140321218860912 -> 140321214768672
	140321214768672 [label=AccumulateGrad]
	140321214769008 -> 140321214769152
	140321214769200 -> 140321214769824
	140321218861392 [label="stage3.3.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218861392 -> 140321214769200
	140321214769200 [label=AccumulateGrad]
	140321214769968 -> 140321214769872
	140321218861472 [label="stage3.3.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140321218861472 -> 140321214769968
	140321214769968 [label=AccumulateGrad]
	140321214770208 -> 140321214769872
	140321218861552 [label="stage3.3.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140321218861552 -> 140321214770208
	140321214770208 [label=AccumulateGrad]
	140321214770640 -> 140321214770880
	140321218862032 [label="stage3.3.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218862032 -> 140321214770640
	140321214770640 [label=AccumulateGrad]
	140321214771168 -> 140321214772704
	140321218862112 [label="stage3.3.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140321218862112 -> 140321214771168
	140321214771168 [label=AccumulateGrad]
	140321214772896 -> 140321214772704
	140321218862192 [label="stage3.3.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140321218862192 -> 140321214772896
	140321214772896 [label=AccumulateGrad]
	140321214771552 -> 140321214773040
	140321214772656 -> 140321214892784
	140321218862592 [label="stage3.3.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218862592 -> 140321214772656
	140321214772656 [label=AccumulateGrad]
	140321214773904 -> 140321214892496
	140321218862672 [label="stage3.3.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140321218862672 -> 140321214773904
	140321214773904 [label=AccumulateGrad]
	140321214774720 -> 140321214892496
	140321218862752 [label="stage3.3.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140321218862752 -> 140321214774720
	140321214774720 [label=AccumulateGrad]
	140321214897200 -> 140321214901568
	140321218863232 [label="stage3.3.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321218863232 -> 140321214897200
	140321214897200 [label=AccumulateGrad]
	140321214895520 -> 140321215688720
	140321218863312 [label="stage3.3.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140321218863312 -> 140321214895520
	140321214895520 [label=AccumulateGrad]
	140321214902768 -> 140321215688720
	140321218863392 [label="stage3.3.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140321218863392 -> 140321214902768
	140321214902768 [label=AccumulateGrad]
	140321215692608 -> 140321215689920
	140321215689728 -> 140321213759696
	140321218864272 [label="stage3.3.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140321218864272 -> 140321215689728
	140321215689728 [label=AccumulateGrad]
	140321213761664 -> 140321213764352
	140321218864352 [label="stage3.3.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140321218864352 -> 140321213761664
	140321213761664 [label=AccumulateGrad]
	140321213765696 -> 140321213764352
	140321218864432 [label="stage3.3.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140321218864432 -> 140321213765696
	140321213765696 [label=AccumulateGrad]
	140321213766224 -> 140321213766560
	140321218868272 [label="stage4.0.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218868272 -> 140321213766224
	140321213766224 [label=AccumulateGrad]
	140321213766752 -> 140321213766896
	140321218868352 [label="stage4.0.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140321218868352 -> 140321213766752
	140321213766752 [label=AccumulateGrad]
	140321213767184 -> 140321213766896
	140321218868432 [label="stage4.0.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140321218868432 -> 140321213767184
	140321213767184 [label=AccumulateGrad]
	140321213767232 -> 140321213767712
	140321218868832 [label="stage4.0.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218868832 -> 140321213767232
	140321213767232 [label=AccumulateGrad]
	140321213767856 -> 140321213767904
	140321218868912 [label="stage4.0.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140321218868912 -> 140321213767856
	140321213767856 [label=AccumulateGrad]
	140321213767760 -> 140321213767904
	140321218868992 [label="stage4.0.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140321218868992 -> 140321213767760
	140321213767760 [label=AccumulateGrad]
	140321213768096 -> 140321213768240
	140321213768528 -> 140321213768912
	140321218869472 [label="stage4.0.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218869472 -> 140321213768528
	140321213768528 [label=AccumulateGrad]
	140321213769056 -> 140321213769200
	140321218869552 [label="stage4.0.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140321218869552 -> 140321213769056
	140321213769056 [label=AccumulateGrad]
	140321213769248 -> 140321213769200
	140321218869632 [label="stage4.0.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140321218869632 -> 140321213769248
	140321213769248 [label=AccumulateGrad]
	140321213769584 -> 140321213769776
	140321218870112 [label="stage4.0.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218870112 -> 140321213769584
	140321213769584 [label=AccumulateGrad]
	140321213769968 -> 140321213770256
	140321218870192 [label="stage4.0.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140321218870192 -> 140321213769968
	140321213769968 [label=AccumulateGrad]
	140321213770112 -> 140321213770256
	140321218870272 [label="stage4.0.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140321218870272 -> 140321213770112
	140321213770112 [label=AccumulateGrad]
	140321213770400 -> 140321213770544
	140321213770592 -> 140321213771216
	140321218870752 [label="stage4.0.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218870752 -> 140321213770592
	140321213770592 [label=AccumulateGrad]
	140321213771120 -> 140321213771264
	140321218870832 [label="stage4.0.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140321218870832 -> 140321213771120
	140321213771120 [label=AccumulateGrad]
	140321213771600 -> 140321213771264
	140321218870912 [label="stage4.0.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140321218870912 -> 140321213771600
	140321213771600 [label=AccumulateGrad]
	140321213771888 -> 140321213772128
	140321217020064 [label="stage4.0.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217020064 -> 140321213771888
	140321213771888 [label=AccumulateGrad]
	140321213772272 -> 140321213772560
	140321217020144 [label="stage4.0.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140321217020144 -> 140321213772272
	140321213772272 [label=AccumulateGrad]
	140321213772416 -> 140321213772560
	140321217020224 [label="stage4.0.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140321217020224 -> 140321213772416
	140321213772416 [label=AccumulateGrad]
	140321213772464 -> 140321213772608
	140321213772944 -> 140321213773280
	140321217020704 [label="stage4.0.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217020704 -> 140321213772944
	140321213772944 [label=AccumulateGrad]
	140321213773472 -> 140321213773616
	140321217020784 [label="stage4.0.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140321217020784 -> 140321213773472
	140321213773472 [label=AccumulateGrad]
	140321213773904 -> 140321213773616
	140321217020864 [label="stage4.0.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140321217020864 -> 140321213773904
	140321213773904 [label=AccumulateGrad]
	140321213773952 -> 140321213774432
	140321217021264 [label="stage4.0.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217021264 -> 140321213773952
	140321213773952 [label=AccumulateGrad]
	140321213774576 -> 140321213774624
	140321217021344 [label="stage4.0.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140321217021344 -> 140321213774576
	140321213774576 [label=AccumulateGrad]
	140321213774480 -> 140321213774624
	140321217021424 [label="stage4.0.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140321217021424 -> 140321213774480
	140321213774480 [label=AccumulateGrad]
	140321213774816 -> 140321213774960
	140321213775296 -> 140321213890672
	140321213775296 [label=UpsampleBilinear2DBackward0]
	140321213774288 -> 140321213775296
	140321213774288 [label=NativeBatchNormBackward0]
	140321213772800 -> 140321213774288
	140321213772800 [label=ConvolutionBackward0]
	140321213773088 -> 140321213772800
	140321213773088 [label=ReluBackward0]
	140321213770448 -> 140321213773088
	140321213770448 [label=AddBackward0]
	140321213771072 -> 140321213770448
	140321213771072 [label=NativeBatchNormBackward0]
	140321213770928 -> 140321213771072
	140321213770928 [label=ConvolutionBackward0]
	140321213768768 -> 140321213770928
	140321213768768 [label=ReluBackward0]
	140321213768576 -> 140321213768768
	140321213768576 [label=NativeBatchNormBackward0]
	140321213766080 -> 140321213768576
	140321213766080 [label=ConvolutionBackward0]
	140321213771792 -> 140321213766080
	140321213771792 [label=ReluBackward0]
	140321213763392 -> 140321213771792
	140321213763392 [label=AddBackward0]
	140321215690880 -> 140321213763392
	140321215690880 [label=NativeBatchNormBackward0]
	140321214893456 -> 140321215690880
	140321214893456 [label=ConvolutionBackward0]
	140321214770496 -> 140321214893456
	140321214770496 [label=ReluBackward0]
	140321214770016 -> 140321214770496
	140321214770016 [label=NativeBatchNormBackward0]
	140321214770688 -> 140321214770016
	140321214770688 [label=ConvolutionBackward0]
	140321215691936 -> 140321214770688
	140321215691936 [label=ReluBackward0]
	140321214766992 -> 140321215691936
	140321214766992 [label=AddBackward0]
	140321214767328 -> 140321214766992
	140321214767328 [label=NativeBatchNormBackward0]
	140321214767184 -> 140321214767328
	140321214767184 [label=ConvolutionBackward0]
	140321214765264 -> 140321214767184
	140321214765264 [label=ReluBackward0]
	140321214764592 -> 140321214765264
	140321214764592 [label=NativeBatchNormBackward0]
	140321214762624 -> 140321214764592
	140321214762624 [label=ConvolutionBackward0]
	140321214768336 -> 140321214762624
	140321214768336 [label=ReluBackward0]
	140321214761760 -> 140321214768336
	140321214761760 [label=AddBackward0]
	140321214761472 -> 140321214761760
	140321214761472 [label=NativeBatchNormBackward0]
	140321214761232 -> 140321214761472
	140321214761232 [label=ConvolutionBackward0]
	140321214760608 -> 140321214761232
	140321214760608 [label=ReluBackward0]
	140321214760416 -> 140321214760608
	140321214760416 [label=NativeBatchNormBackward0]
	140321214760128 -> 140321214760416
	140321214760128 [label=ConvolutionBackward0]
	140321214761616 -> 140321214760128
	140321214761616 [label=ReluBackward0]
	140321214759456 -> 140321214761616
	140321214759456 [label=AddBackward0]
	140321214759120 -> 140321214759456
	140321214759120 [label=AddBackward0]
	140321214759072 -> 140321214759120
	140321214759072 [label=NativeBatchNormBackward0]
	140321216708224 -> 140321214759072
	140321216708224 [label=ConvolutionBackward0]
	140321213765408 -> 140321216708224
	140321216707888 -> 140321216708224
	140321218862912 [label="stage3.3.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140321218862912 -> 140321216707888
	140321216707888 [label=AccumulateGrad]
	140321216708416 -> 140321214759072
	140321218864832 [label="stage3.3.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140321218864832 -> 140321216708416
	140321216708416 [label=AccumulateGrad]
	140321216708560 -> 140321214759072
	140321218864912 [label="stage3.3.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140321218864912 -> 140321216708560
	140321216708560 [label=AccumulateGrad]
	140321213763056 -> 140321214759120
	140321214759264 -> 140321214759456
	140321214759264 [label=UpsampleBilinear2DBackward0]
	140321214759216 -> 140321214759264
	140321214759216 [label=NativeBatchNormBackward0]
	140321216708032 -> 140321214759216
	140321216708032 [label=ConvolutionBackward0]
	140321213763200 -> 140321216708032
	140321216707360 -> 140321216708032
	140321218865392 [label="stage3.3.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140321218865392 -> 140321216707360
	140321216707360 [label=AccumulateGrad]
	140321216707552 -> 140321214759216
	140321218865472 [label="stage3.3.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140321218865472 -> 140321216707552
	140321216707552 [label=AccumulateGrad]
	140321216708080 -> 140321214759216
	140321218865552 [label="stage3.3.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140321218865552 -> 140321216708080
	140321216708080 [label=AccumulateGrad]
	140321214759744 -> 140321214760128
	140321217021904 [label="stage4.0.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217021904 -> 140321214759744
	140321214759744 [label=AccumulateGrad]
	140321214760272 -> 140321214760416
	140321217021984 [label="stage4.0.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140321217021984 -> 140321214760272
	140321214760272 [label=AccumulateGrad]
	140321214760464 -> 140321214760416
	140321217022064 [label="stage4.0.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140321217022064 -> 140321214760464
	140321214760464 [label=AccumulateGrad]
	140321214760800 -> 140321214761232
	140321217022544 [label="stage4.0.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217022544 -> 140321214760800
	140321214760800 [label=AccumulateGrad]
	140321214761136 -> 140321214761472
	140321217022624 [label="stage4.0.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140321217022624 -> 140321214761136
	140321214761136 [label=AccumulateGrad]
	140321214761280 -> 140321214761472
	140321217022704 [label="stage4.0.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140321217022704 -> 140321214761280
	140321214761280 [label=AccumulateGrad]
	140321214761616 -> 140321214761760
	140321214761808 -> 140321214762624
	140321217023184 [label="stage4.0.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217023184 -> 140321214761808
	140321214761808 [label=AccumulateGrad]
	140321214763632 -> 140321214764592
	140321217023264 [label="stage4.0.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140321217023264 -> 140321214763632
	140321214763632 [label=AccumulateGrad]
	140321214765120 -> 140321214764592
	140321217023344 [label="stage4.0.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140321217023344 -> 140321214765120
	140321214765120 [label=AccumulateGrad]
	140321214765984 -> 140321214767184
	140321217023744 [label="stage4.0.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217023744 -> 140321214765984
	140321214765984 [label=AccumulateGrad]
	140321214767280 -> 140321214767328
	140321217023824 [label="stage4.0.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140321217023824 -> 140321214767280
	140321214767280 [label=AccumulateGrad]
	140321214766176 -> 140321214767328
	140321217023904 [label="stage4.0.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140321217023904 -> 140321214766176
	140321214766176 [label=AccumulateGrad]
	140321214768336 -> 140321214766992
	140321214769536 -> 140321214770688
	140321217024384 [label="stage4.0.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217024384 -> 140321214769536
	140321214769536 [label=AccumulateGrad]
	140321214769296 -> 140321214770016
	140321217024464 [label="stage4.0.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140321217024464 -> 140321214769296
	140321214769296 [label=AccumulateGrad]
	140321214773376 -> 140321214770016
	140321217024544 [label="stage4.0.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140321217024544 -> 140321214773376
	140321214773376 [label=AccumulateGrad]
	140321214775200 -> 140321214893456
	140321217025024 [label="stage4.0.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217025024 -> 140321214775200
	140321214775200 [label=AccumulateGrad]
	140321214902576 -> 140321215690880
	140321217025104 [label="stage4.0.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140321217025104 -> 140321214902576
	140321214902576 [label=AccumulateGrad]
	140321214897488 -> 140321215690880
	140321217025184 [label="stage4.0.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140321217025184 -> 140321214897488
	140321214897488 [label=AccumulateGrad]
	140321215691936 -> 140321213763392
	140321213766368 -> 140321213766080
	140321217025664 [label="stage4.0.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217025664 -> 140321213766368
	140321213766368 [label=AccumulateGrad]
	140321213767040 -> 140321213768576
	140321217025744 [label="stage4.0.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140321217025744 -> 140321213767040
	140321213767040 [label=AccumulateGrad]
	140321213767568 -> 140321213768576
	140321217025824 [label="stage4.0.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140321217025824 -> 140321213767568
	140321213767568 [label=AccumulateGrad]
	140321213769728 -> 140321213770928
	140321217026304 [label="stage4.0.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217026304 -> 140321213769728
	140321213769728 [label=AccumulateGrad]
	140321213770784 -> 140321213771072
	140321217026384 [label="stage4.0.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140321217026384 -> 140321213770784
	140321213770784 [label=AccumulateGrad]
	140321213769872 -> 140321213771072
	140321217026464 [label="stage4.0.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140321217026464 -> 140321213769872
	140321213769872 [label=AccumulateGrad]
	140321213771792 -> 140321213770448
	140321213771936 -> 140321213772800
	140321217249840 [label="stage4.0.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140321217249840 -> 140321213771936
	140321213771936 [label=AccumulateGrad]
	140321213773760 -> 140321213774288
	140321217249920 [label="stage4.0.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140321217249920 -> 140321213773760
	140321213773760 [label=AccumulateGrad]
	140321213775104 -> 140321213774288
	140321217250000 [label="stage4.0.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140321217250000 -> 140321213775104
	140321213775104 [label=AccumulateGrad]
	140321213775632 -> 140321213890624
	140321213775632 [label=UpsampleBilinear2DBackward0]
	140321213774144 -> 140321213775632
	140321213774144 [label=NativeBatchNormBackward0]
	140321213769104 -> 140321213774144
	140321213769104 [label=ConvolutionBackward0]
	140321213766512 -> 140321213769104
	140321213766512 [label=ReluBackward0]
	140321213766416 -> 140321213766512
	140321213766416 [label=AddBackward0]
	140321214890480 -> 140321213766416
	140321214890480 [label=NativeBatchNormBackward0]
	140321214774000 -> 140321214890480
	140321214774000 [label=ConvolutionBackward0]
	140321214768480 -> 140321214774000
	140321214768480 [label=ReluBackward0]
	140321214764640 -> 140321214768480
	140321214764640 [label=NativeBatchNormBackward0]
	140321214761088 -> 140321214764640
	140321214761088 [label=ConvolutionBackward0]
	140321213765216 -> 140321214761088
	140321213765216 [label=ReluBackward0]
	140321214759936 -> 140321213765216
	140321214759936 [label=AddBackward0]
	140321214759888 -> 140321214759936
	140321214759888 [label=NativeBatchNormBackward0]
	140321216707408 -> 140321214759888
	140321216707408 [label=ConvolutionBackward0]
	140321216706880 -> 140321216707408
	140321216706880 [label=ReluBackward0]
	140321216706688 -> 140321216706880
	140321216706688 [label=NativeBatchNormBackward0]
	140321216706400 -> 140321216706688
	140321216706400 [label=ConvolutionBackward0]
	140321214759792 -> 140321216706400
	140321214759792 [label=ReluBackward0]
	140321216705728 -> 140321214759792
	140321216705728 [label=AddBackward0]
	140321216705392 -> 140321216705728
	140321216705392 [label=NativeBatchNormBackward0]
	140321216705200 -> 140321216705392
	140321216705200 [label=ConvolutionBackward0]
	140321216704816 -> 140321216705200
	140321216704816 [label=ReluBackward0]
	140321216704384 -> 140321216704816
	140321216704384 [label=NativeBatchNormBackward0]
	140321216704048 -> 140321216704384
	140321216704048 [label=ConvolutionBackward0]
	140321216705536 -> 140321216704048
	140321216705536 [label=ReluBackward0]
	140321216703376 -> 140321216705536
	140321216703376 [label=AddBackward0]
	140321216703328 -> 140321216703376
	140321216703328 [label=NativeBatchNormBackward0]
	140321216702848 -> 140321216703328
	140321216702848 [label=ConvolutionBackward0]
	140321216702512 -> 140321216702848
	140321216702512 [label=ReluBackward0]
	140321216702032 -> 140321216702512
	140321216702032 [label=NativeBatchNormBackward0]
	140321216701984 -> 140321216702032
	140321216701984 [label=ConvolutionBackward0]
	140321216703472 -> 140321216701984
	140321216703472 [label=ReluBackward0]
	140321216701312 -> 140321216703472
	140321216701312 [label=AddBackward0]
	140321216701024 -> 140321216701312
	140321216701024 [label=AddBackward0]
	140321216700688 -> 140321216701024
	140321216700688 [label=NativeBatchNormBackward0]
	140321216700496 -> 140321216700688
	140321216700496 [label=ConvolutionBackward0]
	140321216700112 -> 140321216700496
	140321216700112 [label=ReluBackward0]
	140321216699680 -> 140321216700112
	140321216699680 [label=NativeBatchNormBackward0]
	140321216699344 -> 140321216699680
	140321216699344 [label=ConvolutionBackward0]
	140321213765408 -> 140321216699344
	140321216699008 -> 140321216699344
	140321218865952 [label="stage3.3.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321218865952 -> 140321216699008
	140321216699008 [label=AccumulateGrad]
	140321216699488 -> 140321216699680
	140321218866032 [label="stage3.3.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140321218866032 -> 140321216699488
	140321216699488 [label=AccumulateGrad]
	140321216699968 -> 140321216699680
	140321218866112 [label="stage3.3.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140321218866112 -> 140321216699968
	140321216699968 [label=AccumulateGrad]
	140321216700016 -> 140321216700496
	140321218866592 [label="stage3.3.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140321218866592 -> 140321216700016
	140321216700016 [label=AccumulateGrad]
	140321216700640 -> 140321216700688
	140321218866672 [label="stage3.3.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140321218866672 -> 140321216700640
	140321216700640 [label=AccumulateGrad]
	140321216700784 -> 140321216700688
	140321218866752 [label="stage3.3.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140321218866752 -> 140321216700784
	140321216700784 [label=AccumulateGrad]
	140321216700832 -> 140321216701024
	140321216700832 [label=NativeBatchNormBackward0]
	140321216699296 -> 140321216700832
	140321216699296 [label=ConvolutionBackward0]
	140321213763056 -> 140321216699296
	140321216699152 -> 140321216699296
	140321218867232 [label="stage3.3.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140321218867232 -> 140321216699152
	140321216699152 [label=AccumulateGrad]
	140321216699824 -> 140321216700832
	140321218867312 [label="stage3.3.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140321218867312 -> 140321216699824
	140321216699824 [label=AccumulateGrad]
	140321216700352 -> 140321216700832
	140321218867392 [label="stage3.3.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140321218867392 -> 140321216700352
	140321216700352 [label=AccumulateGrad]
	140321213763200 -> 140321216701312
	140321216701360 -> 140321216701984
	140321217026864 [label="stage4.0.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321217026864 -> 140321216701360
	140321216701360 [label=AccumulateGrad]
	140321216702128 -> 140321216702032
	140321217026944 [label="stage4.0.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140321217026944 -> 140321216702128
	140321216702128 [label=AccumulateGrad]
	140321216702368 -> 140321216702032
	140321217027024 [label="stage4.0.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140321217027024 -> 140321216702368
	140321216702368 [label=AccumulateGrad]
	140321216702656 -> 140321216702848
	140321217027504 [label="stage4.0.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321217027504 -> 140321216702656
	140321216702656 [label=AccumulateGrad]
	140321216703040 -> 140321216703328
	140321217027584 [label="stage4.0.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140321217027584 -> 140321216703040
	140321216703040 [label=AccumulateGrad]
	140321216703184 -> 140321216703328
	140321217027664 [label="stage4.0.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140321217027664 -> 140321216703184
	140321216703184 [label=AccumulateGrad]
	140321216703472 -> 140321216703376
	140321216703712 -> 140321216704048
	140321217028144 [label="stage4.0.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321217028144 -> 140321216703712
	140321216703712 [label=AccumulateGrad]
	140321216704192 -> 140321216704384
	140321217028224 [label="stage4.0.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140321217028224 -> 140321216704192
	140321216704192 [label=AccumulateGrad]
	140321216704672 -> 140321216704384
	140321217028304 [label="stage4.0.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140321217028304 -> 140321216704672
	140321216704672 [label=AccumulateGrad]
	140321216704720 -> 140321216705200
	140321217028704 [label="stage4.0.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321217028704 -> 140321216704720
	140321216704720 [label=AccumulateGrad]
	140321216705344 -> 140321216705392
	140321217028784 [label="stage4.0.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140321217028784 -> 140321216705344
	140321216705344 [label=AccumulateGrad]
	140321216705488 -> 140321216705392
	140321217028864 [label="stage4.0.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140321217028864 -> 140321216705488
	140321216705488 [label=AccumulateGrad]
	140321216705536 -> 140321216705728
	140321216706016 -> 140321216706400
	140321217029264 [label="stage4.0.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321217029264 -> 140321216706016
	140321216706016 [label=AccumulateGrad]
	140321216706544 -> 140321216706688
	140321217029344 [label="stage4.0.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140321217029344 -> 140321216706544
	140321216706544 [label=AccumulateGrad]
	140321216706736 -> 140321216706688
	140321217029424 [label="stage4.0.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140321217029424 -> 140321216706736
	140321216706736 [label=AccumulateGrad]
	140321216707216 -> 140321216707408
	140321217029824 [label="stage4.0.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321217029824 -> 140321216707216
	140321216707216 [label=AccumulateGrad]
	140321216707744 -> 140321214759888
	140321217029904 [label="stage4.0.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140321217029904 -> 140321216707744
	140321216707744 [label=AccumulateGrad]
	140321216708176 -> 140321214759888
	140321217029984 [label="stage4.0.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140321217029984 -> 140321216708176
	140321216708176 [label=AccumulateGrad]
	140321214759792 -> 140321214759936
	140321214759600 -> 140321214761088
	140321217030464 [label="stage4.0.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321217030464 -> 140321214759600
	140321214759600 [label=AccumulateGrad]
	140321214761952 -> 140321214764640
	140321217030544 [label="stage4.0.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140321217030544 -> 140321214761952
	140321214761952 [label=AccumulateGrad]
	140321214764976 -> 140321214764640
	140321217030624 [label="stage4.0.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140321217030624 -> 140321214764976
	140321214764976 [label=AccumulateGrad]
	140321214769344 -> 140321214774000
	140321217031104 [label="stage4.0.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321217031104 -> 140321214769344
	140321214769344 [label=AccumulateGrad]
	140321214767952 -> 140321214890480
	140321217031184 [label="stage4.0.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140321217031184 -> 140321214767952
	140321214767952 [label=AccumulateGrad]
	140321214775056 -> 140321214890480
	140321217031264 [label="stage4.0.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140321217031264 -> 140321214775056
	140321214775056 [label=AccumulateGrad]
	140321213765216 -> 140321213766416
	140321213768432 -> 140321213769104
	140321217250400 [label="stage4.0.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140321217250400 -> 140321213768432
	140321213768432 [label=AccumulateGrad]
	140321213771456 -> 140321213774144
	140321217250480 [label="stage4.0.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140321217250480 -> 140321213771456
	140321213771456 [label=AccumulateGrad]
	140321213775488 -> 140321213774144
	140321217250560 [label="stage4.0.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140321217250560 -> 140321213775488
	140321213775488 [label=AccumulateGrad]
	140321213890720 -> 140321213890912
	140321213890720 [label=UpsampleBilinear2DBackward0]
	140321213773136 -> 140321213890720
	140321213773136 [label=NativeBatchNormBackward0]
	140321213768384 -> 140321213773136
	140321213768384 [label=ConvolutionBackward0]
	140321214760944 -> 140321213768384
	140321214760944 [label=ReluBackward0]
	140321214762144 -> 140321214760944
	140321214762144 [label=AddBackward0]
	140321214760560 -> 140321214762144
	140321214760560 [label=NativeBatchNormBackward0]
	140321216707504 -> 140321214760560
	140321216707504 [label=ConvolutionBackward0]
	140321216706064 -> 140321216707504
	140321216706064 [label=ReluBackward0]
	140321216704864 -> 140321216706064
	140321216704864 [label=NativeBatchNormBackward0]
	140321216702704 -> 140321216704864
	140321216702704 [label=ConvolutionBackward0]
	140321214765648 -> 140321216702704
	140321214765648 [label=ReluBackward0]
	140321216701840 -> 140321214765648
	140321216701840 [label=AddBackward0]
	140321216701504 -> 140321216701840
	140321216701504 [label=NativeBatchNormBackward0]
	140321216699440 -> 140321216701504
	140321216699440 [label=ConvolutionBackward0]
	140321216698624 -> 140321216699440
	140321216698624 [label=ReluBackward0]
	140321216698144 -> 140321216698624
	140321216698144 [label=NativeBatchNormBackward0]
	140321216698096 -> 140321216698144
	140321216698096 [label=ConvolutionBackward0]
	140321216701696 -> 140321216698096
	140321216701696 [label=ReluBackward0]
	140321216697424 -> 140321216701696
	140321216697424 [label=AddBackward0]
	140321216697136 -> 140321216697424
	140321216697136 [label=NativeBatchNormBackward0]
	140321216696656 -> 140321216697136
	140321216696656 [label=ConvolutionBackward0]
	140321216696320 -> 140321216696656
	140321216696320 [label=ReluBackward0]
	140321216696080 -> 140321216696320
	140321216696080 [label=NativeBatchNormBackward0]
	140321216695792 -> 140321216696080
	140321216695792 [label=ConvolutionBackward0]
	140321216697280 -> 140321216695792
	140321216697280 [label=ReluBackward0]
	140321216695120 -> 140321216697280
	140321216695120 [label=AddBackward0]
	140321216694784 -> 140321216695120
	140321216694784 [label=NativeBatchNormBackward0]
	140321216694592 -> 140321216694784
	140321216694592 [label=ConvolutionBackward0]
	140321216693968 -> 140321216694592
	140321216693968 [label=ReluBackward0]
	140321216693776 -> 140321216693968
	140321216693776 [label=NativeBatchNormBackward0]
	140321216693440 -> 140321216693776
	140321216693440 [label=ConvolutionBackward0]
	140321216694976 -> 140321216693440
	140321216694976 [label=ReluBackward0]
	140321216692768 -> 140321216694976
	140321216692768 [label=NativeBatchNormBackward0]
	140321216692720 -> 140321216692768
	140321216692720 [label=ConvolutionBackward0]
	140321216703472 -> 140321216692720
	140321494750096 -> 140321216692720
	140321218856672 [label="transition3.3.0.0.weight
 (144, 72, 3, 3)" fillcolor=lightblue]
	140321218856672 -> 140321494750096
	140321494750096 [label=AccumulateGrad]
	140321216692624 -> 140321216692768
	140321218867792 [label="transition3.3.0.1.weight
 (144)" fillcolor=lightblue]
	140321218867792 -> 140321216692624
	140321216692624 [label=AccumulateGrad]
	140321216693392 -> 140321216692768
	140321218867872 [label="transition3.3.0.1.bias
 (144)" fillcolor=lightblue]
	140321218867872 -> 140321216693392
	140321216693392 [label=AccumulateGrad]
	140321216693104 -> 140321216693440
	140321217031744 [label="stage4.0.branches.3.0.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321217031744 -> 140321216693104
	140321216693104 [label=AccumulateGrad]
	140321216693632 -> 140321216693776
	140321217031824 [label="stage4.0.branches.3.0.bn1.weight
 (144)" fillcolor=lightblue]
	140321217031824 -> 140321216693632
	140321216693632 [label=AccumulateGrad]
	140321216694064 -> 140321216693776
	140321217031904 [label="stage4.0.branches.3.0.bn1.bias
 (144)" fillcolor=lightblue]
	140321217031904 -> 140321216694064
	140321216694064 [label=AccumulateGrad]
	140321216694112 -> 140321216694592
	140321217032384 [label="stage4.0.branches.3.0.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321217032384 -> 140321216694112
	140321216694112 [label=AccumulateGrad]
	140321216694736 -> 140321216694784
	140321217032464 [label="stage4.0.branches.3.0.bn2.weight
 (144)" fillcolor=lightblue]
	140321217032464 -> 140321216694736
	140321216694736 [label=AccumulateGrad]
	140321216694640 -> 140321216694784
	140321217032544 [label="stage4.0.branches.3.0.bn2.bias
 (144)" fillcolor=lightblue]
	140321217032544 -> 140321216694640
	140321216694640 [label=AccumulateGrad]
	140321216694976 -> 140321216695120
	140321216695408 -> 140321216695792
	140321217033024 [label="stage4.0.branches.3.1.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321217033024 -> 140321216695408
	140321216695408 [label=AccumulateGrad]
	140321216695936 -> 140321216696080
	140321217033104 [label="stage4.0.branches.3.1.bn1.weight
 (144)" fillcolor=lightblue]
	140321217033104 -> 140321216695936
	140321216695936 [label=AccumulateGrad]
	140321216696128 -> 140321216696080
	140321217033184 [label="stage4.0.branches.3.1.bn1.bias
 (144)" fillcolor=lightblue]
	140321217033184 -> 140321216696128
	140321216696128 [label=AccumulateGrad]
	140321216696464 -> 140321216696656
	140321217033664 [label="stage4.0.branches.3.1.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321217033664 -> 140321216696464
	140321216696464 [label=AccumulateGrad]
	140321216696800 -> 140321216697136
	140321217033744 [label="stage4.0.branches.3.1.bn2.weight
 (144)" fillcolor=lightblue]
	140321217033744 -> 140321216696800
	140321216696800 [label=AccumulateGrad]
	140321216696992 -> 140321216697136
	140321217033824 [label="stage4.0.branches.3.1.bn2.bias
 (144)" fillcolor=lightblue]
	140321217033824 -> 140321216696992
	140321216696992 [label=AccumulateGrad]
	140321216697280 -> 140321216697424
	140321216697472 -> 140321216698096
	140321217034304 [label="stage4.0.branches.3.2.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321217034304 -> 140321216697472
	140321216697472 [label=AccumulateGrad]
	140321216698000 -> 140321216698144
	140321217034384 [label="stage4.0.branches.3.2.bn1.weight
 (144)" fillcolor=lightblue]
	140321217034384 -> 140321216698000
	140321216698000 [label=AccumulateGrad]
	140321216698480 -> 140321216698144
	140321217034464 [label="stage4.0.branches.3.2.bn1.bias
 (144)" fillcolor=lightblue]
	140321217034464 -> 140321216698480
	140321216698480 [label=AccumulateGrad]
	140321216698816 -> 140321216699440
	140321217034944 [label="stage4.0.branches.3.2.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321217034944 -> 140321216698816
	140321216698816 [label=AccumulateGrad]
	140321216700160 -> 140321216701504
	140321217035024 [label="stage4.0.branches.3.2.bn2.weight
 (144)" fillcolor=lightblue]
	140321217035024 -> 140321216700160
	140321216700160 [label=AccumulateGrad]
	140321216701168 -> 140321216701504
	140321217035104 [label="stage4.0.branches.3.2.bn2.bias
 (144)" fillcolor=lightblue]
	140321217035104 -> 140321216701168
	140321216701168 [label=AccumulateGrad]
	140321216701696 -> 140321216701840
	140321216701456 -> 140321216702704
	140321217035584 [label="stage4.0.branches.3.3.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321217035584 -> 140321216701456
	140321216701456 [label=AccumulateGrad]
	140321216704144 -> 140321216704864
	140321217035664 [label="stage4.0.branches.3.3.bn1.weight
 (144)" fillcolor=lightblue]
	140321217035664 -> 140321216704144
	140321216704144 [label=AccumulateGrad]
	140321216704528 -> 140321216704864
	140321217035744 [label="stage4.0.branches.3.3.bn1.bias
 (144)" fillcolor=lightblue]
	140321217035744 -> 140321216704528
	140321216704528 [label=AccumulateGrad]
	140321216706160 -> 140321216707504
	140321217036224 [label="stage4.0.branches.3.3.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321217036224 -> 140321216706160
	140321216706160 [label=AccumulateGrad]
	140321216705872 -> 140321214760560
	140321217249360 [label="stage4.0.branches.3.3.bn2.weight
 (144)" fillcolor=lightblue]
	140321217249360 -> 140321216705872
	140321216705872 [label=AccumulateGrad]
	140321216706832 -> 140321214760560
	140321217249440 [label="stage4.0.branches.3.3.bn2.bias
 (144)" fillcolor=lightblue]
	140321217249440 -> 140321216706832
	140321216706832 [label=AccumulateGrad]
	140321214765648 -> 140321214762144
	140321214761904 -> 140321213768384
	140321217251040 [label="stage4.0.fuse_layers.0.3.0.weight
 (18, 144, 1, 1)" fillcolor=lightblue]
	140321217251040 -> 140321214761904
	140321214761904 [label=AccumulateGrad]
	140321213767424 -> 140321213773136
	140321217251120 [label="stage4.0.fuse_layers.0.3.1.weight
 (18)" fillcolor=lightblue]
	140321217251120 -> 140321213767424
	140321213767424 [label=AccumulateGrad]
	140321213775776 -> 140321213773136
	140321217251200 [label="stage4.0.fuse_layers.0.3.1.bias
 (18)" fillcolor=lightblue]
	140321217251200 -> 140321213775776
	140321213775776 [label=AccumulateGrad]
	140321213891200 -> 140321213891584
	140321217259120 [label="stage4.1.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217259120 -> 140321213891200
	140321213891200 [label=AccumulateGrad]
	140321213891728 -> 140321213891872
	140321217259200 [label="stage4.1.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140321217259200 -> 140321213891728
	140321213891728 [label=AccumulateGrad]
	140321213891920 -> 140321213891872
	140321217259280 [label="stage4.1.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140321217259280 -> 140321213891920
	140321213891920 [label=AccumulateGrad]
	140321213892256 -> 140321213892688
	140321217259680 [label="stage4.1.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217259680 -> 140321213892256
	140321213892256 [label=AccumulateGrad]
	140321213892592 -> 140321213892928
	140321217259760 [label="stage4.1.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140321217259760 -> 140321213892592
	140321213892592 [label=AccumulateGrad]
	140321213892736 -> 140321213892928
	140321217259840 [label="stage4.1.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140321217259840 -> 140321213892736
	140321213892736 [label=AccumulateGrad]
	140321213893072 -> 140321213893216
	140321213893264 -> 140321213893888
	140321217260320 [label="stage4.1.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217260320 -> 140321213893264
	140321213893264 [label=AccumulateGrad]
	140321213894032 -> 140321213893936
	140321217260400 [label="stage4.1.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140321217260400 -> 140321213894032
	140321213894032 [label=AccumulateGrad]
	140321213894272 -> 140321213893936
	140321217260480 [label="stage4.1.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140321217260480 -> 140321213894272
	140321213894272 [label=AccumulateGrad]
	140321213894560 -> 140321213894752
	140321217260880 [label="stage4.1.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217260880 -> 140321213894560
	140321213894560 [label=AccumulateGrad]
	140321213894944 -> 140321213895232
	140321217260960 [label="stage4.1.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140321217260960 -> 140321213894944
	140321213894944 [label=AccumulateGrad]
	140321213895088 -> 140321213895232
	140321217261040 [label="stage4.1.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140321217261040 -> 140321213895088
	140321213895088 [label=AccumulateGrad]
	140321213895376 -> 140321213895280
	140321213895616 -> 140321213895952
	140321217261440 [label="stage4.1.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217261440 -> 140321213895616
	140321213895616 [label=AccumulateGrad]
	140321213896096 -> 140321213896288
	140321217261520 [label="stage4.1.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140321217261520 -> 140321213896096
	140321213896096 [label=AccumulateGrad]
	140321213896576 -> 140321213896288
	140321217261600 [label="stage4.1.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140321217261600 -> 140321213896576
	140321213896576 [label=AccumulateGrad]
	140321213896624 -> 140321213897104
	140321217262080 [label="stage4.1.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217262080 -> 140321213896624
	140321213896624 [label=AccumulateGrad]
	140321213897248 -> 140321213897296
	140321217262160 [label="stage4.1.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140321217262160 -> 140321213897248
	140321213897248 [label=AccumulateGrad]
	140321213897392 -> 140321213897296
	140321217262240 [label="stage4.1.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140321217262240 -> 140321213897392
	140321213897392 [label=AccumulateGrad]
	140321213897440 -> 140321213897632
	140321213897920 -> 140321213898304
	140321217262640 [label="stage4.1.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217262640 -> 140321213897920
	140321213897920 [label=AccumulateGrad]
	140321213898448 -> 140321213898592
	140321217262720 [label="stage4.1.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140321217262720 -> 140321213898448
	140321213898448 [label=AccumulateGrad]
	140321213898640 -> 140321213898592
	140321217262800 [label="stage4.1.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140321217262800 -> 140321213898640
	140321213898640 [label=AccumulateGrad]
	140321213898976 -> 140321213899408
	140321217263200 [label="stage4.1.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217263200 -> 140321213898976
	140321213898976 [label=AccumulateGrad]
	140321213899312 -> 140321213899648
	140321217263280 [label="stage4.1.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140321217263280 -> 140321213899312
	140321213899312 [label=AccumulateGrad]
	140321213899456 -> 140321213899648
	140321217263360 [label="stage4.1.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140321217263360 -> 140321213899456
	140321213899456 [label=AccumulateGrad]
	140321213899792 -> 140321213899936
	140321213900320 -> 140321213900608
	140321213900320 [label=UpsampleBilinear2DBackward0]
	140321213899264 -> 140321213900320
	140321213899264 [label=NativeBatchNormBackward0]
	140321213897776 -> 140321213899264
	140321213897776 [label=ConvolutionBackward0]
	140321213898064 -> 140321213897776
	140321213898064 [label=ReluBackward0]
	140321213895424 -> 140321213898064
	140321213895424 [label=AddBackward0]
	140321213896048 -> 140321213895424
	140321213896048 [label=NativeBatchNormBackward0]
	140321213895904 -> 140321213896048
	140321213895904 [label=ConvolutionBackward0]
	140321213893744 -> 140321213895904
	140321213893744 [label=ReluBackward0]
	140321213893600 -> 140321213893744
	140321213893600 [label=NativeBatchNormBackward0]
	140321213891056 -> 140321213893600
	140321213891056 [label=ConvolutionBackward0]
	140321213896768 -> 140321213891056
	140321213896768 [label=ReluBackward0]
	140321213773232 -> 140321213896768
	140321213773232 [label=AddBackward0]
	140321214762288 -> 140321213773232
	140321214762288 [label=NativeBatchNormBackward0]
	140321216703520 -> 140321214762288
	140321216703520 [label=ConvolutionBackward0]
	140321216698768 -> 140321216703520
	140321216698768 [label=ReluBackward0]
	140321216698336 -> 140321216698768
	140321216698336 [label=NativeBatchNormBackward0]
	140321216698672 -> 140321216698336
	140321216698672 [label=ConvolutionBackward0]
	140321214769680 -> 140321216698672
	140321214769680 [label=ReluBackward0]
	140321216695264 -> 140321214769680
	140321216695264 [label=AddBackward0]
	140321216695648 -> 140321216695264
	140321216695648 [label=NativeBatchNormBackward0]
	140321216695456 -> 140321216695648
	140321216695456 [label=ConvolutionBackward0]
	140321216693296 -> 140321216695456
	140321216693296 [label=ReluBackward0]
	140321216692576 -> 140321216693296
	140321216692576 [label=NativeBatchNormBackward0]
	140321216692432 -> 140321216692576
	140321216692432 [label=ConvolutionBackward0]
	140321216696608 -> 140321216692432
	140321216696608 [label=ReluBackward0]
	140321548248272 -> 140321216696608
	140321548248272 [label=AddBackward0]
	140321450051856 -> 140321548248272
	140321450051856 [label=NativeBatchNormBackward0]
	140321248911296 -> 140321450051856
	140321248911296 [label=ConvolutionBackward0]
	140321243565936 -> 140321248911296
	140321243565936 [label=ReluBackward0]
	140321219586576 -> 140321243565936
	140321219586576 [label=NativeBatchNormBackward0]
	140321219591952 -> 140321219586576
	140321219591952 [label=ConvolutionBackward0]
	140321242977408 -> 140321219591952
	140321242977408 [label=ReluBackward0]
	140321219590752 -> 140321242977408
	140321219590752 [label=AddBackward0]
	140321219589312 -> 140321219590752
	140321219589312 [label=AddBackward0]
	140321219590416 -> 140321219589312
	140321219590416 [label=AddBackward0]
	140321219589456 -> 140321219590416
	140321219589456 [label=NativeBatchNormBackward0]
	140321219589696 -> 140321219589456
	140321219589696 [label=ConvolutionBackward0]
	140321213775152 -> 140321219589696
	140321219589072 -> 140321219589696
	140321217251680 [label="stage4.0.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140321217251680 -> 140321219589072
	140321219589072 [label=AccumulateGrad]
	140321219588448 -> 140321219589456
	140321217251760 [label="stage4.0.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140321217251760 -> 140321219588448
	140321219588448 [label=AccumulateGrad]
	140321219589408 -> 140321219589456
	140321217251840 [label="stage4.0.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140321217251840 -> 140321219589408
	140321219589408 [label=AccumulateGrad]
	140321213773088 -> 140321219590416
	140321219589168 -> 140321219589312
	140321219589168 [label=UpsampleBilinear2DBackward0]
	140321219588304 -> 140321219589168
	140321219588304 [label=NativeBatchNormBackward0]
	140321219589648 -> 140321219588304
	140321219589648 [label=ConvolutionBackward0]
	140321213766512 -> 140321219589648
	140321219587440 -> 140321219589648
	140321217252240 [label="stage4.0.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140321217252240 -> 140321219587440
	140321219587440 [label=AccumulateGrad]
	140321219588352 -> 140321219588304
	140321217252320 [label="stage4.0.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140321217252320 -> 140321219588352
	140321219588352 [label=AccumulateGrad]
	140321219589840 -> 140321219588304
	140321217252400 [label="stage4.0.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140321217252400 -> 140321219589840
	140321219589840 [label=AccumulateGrad]
	140321219586960 -> 140321219590752
	140321219586960 [label=UpsampleBilinear2DBackward0]
	140321219588256 -> 140321219586960
	140321219588256 [label=NativeBatchNormBackward0]
	140321219587344 -> 140321219588256
	140321219587344 [label=ConvolutionBackward0]
	140321214760944 -> 140321219587344
	140321219586144 -> 140321219587344
	140321217252880 [label="stage4.0.fuse_layers.1.3.0.weight
 (36, 144, 1, 1)" fillcolor=lightblue]
	140321217252880 -> 140321219586144
	140321219586144 [label=AccumulateGrad]
	140321219588160 -> 140321219588256
	140321217252960 [label="stage4.0.fuse_layers.1.3.1.weight
 (36)" fillcolor=lightblue]
	140321217252960 -> 140321219588160
	140321219588160 [label=AccumulateGrad]
	140321219590896 -> 140321219588256
	140321217253040 [label="stage4.0.fuse_layers.1.3.1.bias
 (36)" fillcolor=lightblue]
	140321217253040 -> 140321219590896
	140321219590896 [label=AccumulateGrad]
	140321219589504 -> 140321219591952
	140321217263760 [label="stage4.1.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217263760 -> 140321219589504
	140321219589504 [label=AccumulateGrad]
	140321219591136 -> 140321219586576
	140321217263840 [label="stage4.1.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140321217263840 -> 140321219591136
	140321219591136 [label=AccumulateGrad]
	140321219586384 -> 140321219586576
	140321217263920 [label="stage4.1.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140321217263920 -> 140321219586384
	140321219586384 [label=AccumulateGrad]
	140321243573328 -> 140321248911296
	140321217264400 [label="stage4.1.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217264400 -> 140321243573328
	140321243573328 [label=AccumulateGrad]
	140321248915232 -> 140321450051856
	140321217264480 [label="stage4.1.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140321217264480 -> 140321248915232
	140321248915232 [label=AccumulateGrad]
	140321255596976 -> 140321450051856
	140321217264560 [label="stage4.1.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140321217264560 -> 140321255596976
	140321255596976 [label=AccumulateGrad]
	140321242977408 -> 140321548248272
	140321242984272 -> 140321216692432
	140321217265040 [label="stage4.1.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217265040 -> 140321242984272
	140321242984272 [label=AccumulateGrad]
	140321216692288 -> 140321216692576
	140321217265120 [label="stage4.1.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140321217265120 -> 140321216692288
	140321216692288 [label=AccumulateGrad]
	140321242982448 -> 140321216692576
	140321217265200 [label="stage4.1.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140321217265200 -> 140321242982448
	140321242982448 [label=AccumulateGrad]
	140321216694304 -> 140321216695456
	140321217511504 [label="stage4.1.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217511504 -> 140321216694304
	140321216694304 [label=AccumulateGrad]
	140321216695312 -> 140321216695648
	140321217511584 [label="stage4.1.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140321217511584 -> 140321216695312
	140321216695312 [label=AccumulateGrad]
	140321216694448 -> 140321216695648
	140321217511664 [label="stage4.1.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140321217511664 -> 140321216694448
	140321216694448 [label=AccumulateGrad]
	140321216696608 -> 140321216695264
	140321216697808 -> 140321216698672
	140321217512144 [label="stage4.1.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217512144 -> 140321216697808
	140321216697808 [label=AccumulateGrad]
	140321216697328 -> 140321216698336
	140321217512224 [label="stage4.1.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140321217512224 -> 140321216697328
	140321216697328 [label=AccumulateGrad]
	140321216702176 -> 140321216698336
	140321217512304 [label="stage4.1.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140321217512304 -> 140321216702176
	140321216702176 [label=AccumulateGrad]
	140321216703856 -> 140321216703520
	140321217512784 [label="stage4.1.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217512784 -> 140321216703856
	140321216703856 [label=AccumulateGrad]
	140321216707072 -> 140321214762288
	140321217512864 [label="stage4.1.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140321217512864 -> 140321216707072
	140321216707072 [label=AccumulateGrad]
	140321216706208 -> 140321214762288
	140321217512944 [label="stage4.1.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140321217512944 -> 140321216706208
	140321216706208 [label=AccumulateGrad]
	140321214769680 -> 140321213773232
	140321213891344 -> 140321213891056
	140321217513344 [label="stage4.1.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217513344 -> 140321213891344
	140321213891344 [label=AccumulateGrad]
	140321213892016 -> 140321213893600
	140321217513424 [label="stage4.1.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140321217513424 -> 140321213892016
	140321213892016 [label=AccumulateGrad]
	140321213892544 -> 140321213893600
	140321217513504 [label="stage4.1.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140321217513504 -> 140321213892544
	140321213892544 [label=AccumulateGrad]
	140321213894704 -> 140321213895904
	140321217513984 [label="stage4.1.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217513984 -> 140321213894704
	140321213894704 [label=AccumulateGrad]
	140321213895760 -> 140321213896048
	140321217514064 [label="stage4.1.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140321217514064 -> 140321213895760
	140321213895760 [label=AccumulateGrad]
	140321213894608 -> 140321213896048
	140321217514144 [label="stage4.1.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140321217514144 -> 140321213894608
	140321213894608 [label=AccumulateGrad]
	140321213896768 -> 140321213895424
	140321213896960 -> 140321213897776
	140321217524144 [label="stage4.1.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140321217524144 -> 140321213896960
	140321213896960 [label=AccumulateGrad]
	140321213898736 -> 140321213899264
	140321217524224 [label="stage4.1.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140321217524224 -> 140321213898736
	140321213898736 [label=AccumulateGrad]
	140321213900080 -> 140321213899264
	140321217524304 [label="stage4.1.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140321217524304 -> 140321213900080
	140321213900080 [label=AccumulateGrad]
	140321213900752 -> 140321213900800
	140321213900752 [label=UpsampleBilinear2DBackward0]
	140321213775248 -> 140321213900752
	140321213775248 [label=NativeBatchNormBackward0]
	140321213898112 -> 140321213775248
	140321213898112 [label=ConvolutionBackward0]
	140321213893360 -> 140321213898112
	140321213893360 [label=ReluBackward0]
	140321213891392 -> 140321213893360
	140321213891392 [label=AddBackward0]
	140321213891248 -> 140321213891392
	140321213891248 [label=NativeBatchNormBackward0]
	140321216705056 -> 140321213891248
	140321216705056 [label=ConvolutionBackward0]
	140321216696752 -> 140321216705056
	140321216696752 [label=ReluBackward0]
	140321243573280 -> 140321216696752
	140321243573280 [label=NativeBatchNormBackward0]
	140324614176528 -> 140321243573280
	140324614176528 [label=ConvolutionBackward0]
	140321213892400 -> 140324614176528
	140321213892400 [label=ReluBackward0]
	140321219592000 -> 140321213892400
	140321219592000 [label=AddBackward0]
	140321219590704 -> 140321219592000
	140321219590704 [label=NativeBatchNormBackward0]
	140321219586864 -> 140321219590704
	140321219586864 [label=ConvolutionBackward0]
	140321219587824 -> 140321219586864
	140321219587824 [label=ReluBackward0]
	140321219587968 -> 140321219587824
	140321219587968 [label=NativeBatchNormBackward0]
	140321219587920 -> 140321219587968
	140321219587920 [label=ConvolutionBackward0]
	140321219588976 -> 140321219587920
	140321219588976 [label=ReluBackward0]
	140321219588688 -> 140321219588976
	140321219588688 [label=AddBackward0]
	140321219588736 -> 140321219588688
	140321219588736 [label=NativeBatchNormBackward0]
	140321219588784 -> 140321219588736
	140321219588784 [label=ConvolutionBackward0]
	140321219589600 -> 140321219588784
	140321219589600 [label=ReluBackward0]
	140321219590560 -> 140321219589600
	140321219590560 [label=NativeBatchNormBackward0]
	140321219589888 -> 140321219590560
	140321219589888 [label=ConvolutionBackward0]
	140321219587776 -> 140321219589888
	140321219587776 [label=ReluBackward0]
	140321219586720 -> 140321219587776
	140321219586720 [label=AddBackward0]
	140321219591328 -> 140321219586720
	140321219591328 [label=NativeBatchNormBackward0]
	140321219591568 -> 140321219591328
	140321219591568 [label=ConvolutionBackward0]
	140321219591760 -> 140321219591568
	140321219591760 [label=ReluBackward0]
	140321219674800 -> 140321219591760
	140321219674800 [label=NativeBatchNormBackward0]
	140321219674176 -> 140321219674800
	140321219674176 [label=ConvolutionBackward0]
	140321219590464 -> 140321219674176
	140321219590464 [label=ReluBackward0]
	140321492645728 -> 140321219590464
	140321492645728 [label=AddBackward0]
	140321492645344 -> 140321492645728
	140321492645344 [label=AddBackward0]
	140321492645920 -> 140321492645344
	140321492645920 [label=AddBackward0]
	140321248777008 -> 140321492645920
	140321248777008 [label=NativeBatchNormBackward0]
	140321216167456 -> 140321248777008
	140321216167456 [label=ConvolutionBackward0]
	140321216167120 -> 140321216167456
	140321216167120 [label=ReluBackward0]
	140321216166640 -> 140321216167120
	140321216166640 [label=NativeBatchNormBackward0]
	140321216166592 -> 140321216166640
	140321216166592 [label=ConvolutionBackward0]
	140321213775152 -> 140321216166592
	140321216165968 -> 140321216166592
	140321217253440 [label="stage4.0.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217253440 -> 140321216165968
	140321216165968 [label=AccumulateGrad]
	140321216166736 -> 140321216166640
	140321217253520 [label="stage4.0.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140321217253520 -> 140321216166736
	140321216166736 [label=AccumulateGrad]
	140321216166976 -> 140321216166640
	140321217253600 [label="stage4.0.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140321217253600 -> 140321216166976
	140321216166976 [label=AccumulateGrad]
	140321216167264 -> 140321216167456
	140321217254080 [label="stage4.0.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140321217254080 -> 140321216167264
	140321216167264 [label=AccumulateGrad]
	140321216167648 -> 140321248777008
	140321217254160 [label="stage4.0.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140321217254160 -> 140321216167648
	140321216167648 [label=AccumulateGrad]
	140321216167792 -> 140321248777008
	140321217254240 [label="stage4.0.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140321217254240 -> 140321216167792
	140321216167792 [label=AccumulateGrad]
	140321492646256 -> 140321492645920
	140321492646256 [label=NativeBatchNormBackward0]
	140321216166304 -> 140321492646256
	140321216166304 [label=ConvolutionBackward0]
	140321213773088 -> 140321216166304
	140321216166112 -> 140321216166304
	140321217254720 [label="stage4.0.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140321217254720 -> 140321216166112
	140321216166112 [label=AccumulateGrad]
	140321216166784 -> 140321492646256
	140321217254800 [label="stage4.0.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140321217254800 -> 140321216166784
	140321216166784 [label=AccumulateGrad]
	140321216167312 -> 140321492646256
	140321217254880 [label="stage4.0.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140321217254880 -> 140321216167312
	140321216167312 [label=AccumulateGrad]
	140321213766512 -> 140321492645344
	140321492633536 -> 140321492645728
	140321492633536 [label=UpsampleBilinear2DBackward0]
	140321492633968 -> 140321492633536
	140321492633968 [label=NativeBatchNormBackward0]
	140321216165776 -> 140321492633968
	140321216165776 [label=ConvolutionBackward0]
	140321214760944 -> 140321216165776
	140321216165440 -> 140321216165776
	140321217255280 [label="stage4.0.fuse_layers.2.3.0.weight
 (72, 144, 1, 1)" fillcolor=lightblue]
	140321217255280 -> 140321216165440
	140321216165440 [label=AccumulateGrad]
	140321216166448 -> 140321492633968
	140321217255360 [label="stage4.0.fuse_layers.2.3.1.weight
 (72)" fillcolor=lightblue]
	140321217255360 -> 140321216166448
	140321216166448 [label=AccumulateGrad]
	140321216167408 -> 140321492633968
	140321217255440 [label="stage4.0.fuse_layers.2.3.1.bias
 (72)" fillcolor=lightblue]
	140321217255440 -> 140321216167408
	140321216167408 [label=AccumulateGrad]
	140321492635456 -> 140321219674176
	140321217514624 [label="stage4.1.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321217514624 -> 140321492635456
	140321492635456 [label=AccumulateGrad]
	140321219674560 -> 140321219674800
	140321217514704 [label="stage4.1.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140321217514704 -> 140321219674560
	140321219674560 [label=AccumulateGrad]
	140321219674272 -> 140321219674800
	140321217514784 [label="stage4.1.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140321217514784 -> 140321219674272
	140321219674272 [label=AccumulateGrad]
	140321219674608 -> 140321219591568
	140321217515264 [label="stage4.1.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321217515264 -> 140321219674608
	140321219674608 [label=AccumulateGrad]
	140321219591232 -> 140321219591328
	140321217515344 [label="stage4.1.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140321217515344 -> 140321219591232
	140321219591232 [label=AccumulateGrad]
	140321219590608 -> 140321219591328
	140321217515424 [label="stage4.1.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140321217515424 -> 140321219590608
	140321219590608 [label=AccumulateGrad]
	140321219590464 -> 140321219586720
	140321219590080 -> 140321219589888
	140321217515824 [label="stage4.1.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321217515824 -> 140321219590080
	140321219590080 [label=AccumulateGrad]
	140321219590176 -> 140321219590560
	140321217515904 [label="stage4.1.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140321217515904 -> 140321219590176
	140321219590176 [label=AccumulateGrad]
	140321219589936 -> 140321219590560
	140321217515984 [label="stage4.1.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140321217515984 -> 140321219589936
	140321219589936 [label=AccumulateGrad]
	140321219589552 -> 140321219588784
	140321217516464 [label="stage4.1.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321217516464 -> 140321219589552
	140321219589552 [label=AccumulateGrad]
	140321219588640 -> 140321219588736
	140321217516544 [label="stage4.1.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140321217516544 -> 140321219588640
	140321219588640 [label=AccumulateGrad]
	140321219587680 -> 140321219588736
	140321217516624 [label="stage4.1.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140321217516624 -> 140321219587680
	140321219587680 [label=AccumulateGrad]
	140321219587776 -> 140321219588688
	140321219587584 -> 140321219587920
	140321217517104 [label="stage4.1.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321217517104 -> 140321219587584
	140321219587584 [label=AccumulateGrad]
	140321219588064 -> 140321219587968
	140321217517184 [label="stage4.1.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140321217517184 -> 140321219588064
	140321219588064 [label=AccumulateGrad]
	140321219587152 -> 140321219587968
	140321217517264 [label="stage4.1.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140321217517264 -> 140321219587152
	140321219587152 [label=AccumulateGrad]
	140321219587008 -> 140321219586864
	140321217517744 [label="stage4.1.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321217517744 -> 140321219587008
	140321219587008 [label=AccumulateGrad]
	140321219587632 -> 140321219590704
	140321217517824 [label="stage4.1.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140321217517824 -> 140321219587632
	140321219587632 [label=AccumulateGrad]
	140321219590512 -> 140321219590704
	140321217517904 [label="stage4.1.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140321217517904 -> 140321219590512
	140321219590512 [label=AccumulateGrad]
	140321219588976 -> 140321219592000
	140321255593280 -> 140324614176528
	140321217518384 [label="stage4.1.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321217518384 -> 140321255593280
	140321255593280 [label=AccumulateGrad]
	140321216693248 -> 140321243573280
	140321217518464 [label="stage4.1.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140321217518464 -> 140321216693248
	140321216693248 [label=AccumulateGrad]
	140321242981440 -> 140321243573280
	140321217518544 [label="stage4.1.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140321217518544 -> 140321242981440
	140321242981440 [label=AccumulateGrad]
	140321216697664 -> 140321216705056
	140321217518944 [label="stage4.1.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321217518944 -> 140321216697664
	140321216697664 [label=AccumulateGrad]
	140321216695984 -> 140321213891248
	140321217519024 [label="stage4.1.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140321217519024 -> 140321216695984
	140321216695984 [label=AccumulateGrad]
	140321216704000 -> 140321213891248
	140321217519104 [label="stage4.1.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140321217519104 -> 140321216704000
	140321216704000 [label=AccumulateGrad]
	140321213892400 -> 140321213891392
	140321213894080 -> 140321213898112
	140321217524624 [label="stage4.1.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140321217524624 -> 140321213894080
	140321213894080 [label=AccumulateGrad]
	140321213899120 -> 140321213775248
	140321217524704 [label="stage4.1.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140321217524704 -> 140321213899120
	140321213899120 [label=AccumulateGrad]
	140321213900464 -> 140321213775248
	140321217524784 [label="stage4.1.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140321217524784 -> 140321213900464
	140321213900464 [label=AccumulateGrad]
	140321213900992 -> 140321213901136
	140321213900992 [label=UpsampleBilinear2DBackward0]
	140321213897968 -> 140321213900992
	140321213897968 [label=NativeBatchNormBackward0]
	140321213893408 -> 140321213897968
	140321213893408 [label=ConvolutionBackward0]
	140321216693920 -> 140321213893408
	140321216693920 [label=ReluBackward0]
	140321242979232 -> 140321216693920
	140321242979232 [label=AddBackward0]
	140321219586528 -> 140321242979232
	140321219586528 [label=NativeBatchNormBackward0]
	140321219584512 -> 140321219586528
	140321219584512 [label=ConvolutionBackward0]
	140321219588400 -> 140321219584512
	140321219588400 [label=ReluBackward0]
	140321219588928 -> 140321219588400
	140321219588928 [label=NativeBatchNormBackward0]
	140321219592096 -> 140321219588928
	140321219592096 [label=ConvolutionBackward0]
	140321219587536 -> 140321219592096
	140321219587536 [label=ReluBackward0]
	140321219590320 -> 140321219587536
	140321219590320 [label=AddBackward0]
	140321492646160 -> 140321219590320
	140321492646160 [label=NativeBatchNormBackward0]
	140321492633632 -> 140321492646160
	140321492633632 [label=ConvolutionBackward0]
	140321216165248 -> 140321492633632
	140321216165248 [label=ReluBackward0]
	140321216164768 -> 140321216165248
	140321216164768 [label=NativeBatchNormBackward0]
	140321216164720 -> 140321216164768
	140321216164720 [label=ConvolutionBackward0]
	140321492633776 -> 140321216164720
	140321492633776 [label=ReluBackward0]
	140321216164048 -> 140321492633776
	140321216164048 [label=AddBackward0]
	140321216163760 -> 140321216164048
	140321216163760 [label=NativeBatchNormBackward0]
	140321216163280 -> 140321216163760
	140321216163280 [label=ConvolutionBackward0]
	140321216162944 -> 140321216163280
	140321216162944 [label=ReluBackward0]
	140321216162704 -> 140321216162944
	140321216162704 [label=NativeBatchNormBackward0]
	140321216162416 -> 140321216162704
	140321216162416 [label=ConvolutionBackward0]
	140321216163904 -> 140321216162416
	140321216163904 [label=ReluBackward0]
	140321216161744 -> 140321216163904
	140321216161744 [label=AddBackward0]
	140321216161408 -> 140321216161744
	140321216161408 [label=NativeBatchNormBackward0]
	140321216161216 -> 140321216161408
	140321216161216 [label=ConvolutionBackward0]
	140321216160592 -> 140321216161216
	140321216160592 [label=ReluBackward0]
	140321216160400 -> 140321216160592
	140321216160400 [label=NativeBatchNormBackward0]
	140321216160064 -> 140321216160400
	140321216160064 [label=ConvolutionBackward0]
	140321216161600 -> 140321216160064
	140321216161600 [label=ReluBackward0]
	140321216159392 -> 140321216161600
	140321216159392 [label=AddBackward0]
	140321216159344 -> 140321216159392
	140321216159344 [label=AddBackward0]
	140321216159056 -> 140321216159344
	140321216159056 [label=AddBackward0]
	140321216158576 -> 140321216159056
	140321216158576 [label=NativeBatchNormBackward0]
	140321216158384 -> 140321216158576
	140321216158384 [label=ConvolutionBackward0]
	140321216158000 -> 140321216158384
	140321216158000 [label=ReluBackward0]
	140321216157568 -> 140321216158000
	140321216157568 [label=NativeBatchNormBackward0]
	140321216157232 -> 140321216157568
	140321216157232 [label=ConvolutionBackward0]
	140321216156896 -> 140321216157232
	140321216156896 [label=ReluBackward0]
	140321216156656 -> 140321216156896
	140321216156656 [label=NativeBatchNormBackward0]
	140321216156368 -> 140321216156656
	140321216156368 [label=ConvolutionBackward0]
	140321213775152 -> 140321216156368
	140321216155984 -> 140321216156368
	140321217255840 [label="stage4.0.fuse_layers.3.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217255840 -> 140321216155984
	140321216155984 [label=AccumulateGrad]
	140321216156512 -> 140321216156656
	140321217255920 [label="stage4.0.fuse_layers.3.0.0.1.weight
 (18)" fillcolor=lightblue]
	140321217255920 -> 140321216156512
	140321216156512 [label=AccumulateGrad]
	140321216156704 -> 140321216156656
	140321217256000 [label="stage4.0.fuse_layers.3.0.0.1.bias
 (18)" fillcolor=lightblue]
	140321217256000 -> 140321216156704
	140321216156704 [label=AccumulateGrad]
	140321216157040 -> 140321216157232
	140321217256400 [label="stage4.0.fuse_layers.3.0.1.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217256400 -> 140321216157040
	140321216157040 [label=AccumulateGrad]
	140321216157376 -> 140321216157568
	140321217256480 [label="stage4.0.fuse_layers.3.0.1.1.weight
 (18)" fillcolor=lightblue]
	140321217256480 -> 140321216157376
	140321216157376 [label=AccumulateGrad]
	140321216157856 -> 140321216157568
	140321217256560 [label="stage4.0.fuse_layers.3.0.1.1.bias
 (18)" fillcolor=lightblue]
	140321217256560 -> 140321216157856
	140321216157856 [label=AccumulateGrad]
	140321216157904 -> 140321216158384
	140321217256960 [label="stage4.0.fuse_layers.3.0.2.0.weight
 (144, 18, 3, 3)" fillcolor=lightblue]
	140321217256960 -> 140321216157904
	140321216157904 [label=AccumulateGrad]
	140321216158528 -> 140321216158576
	140321217257040 [label="stage4.0.fuse_layers.3.0.2.1.weight
 (144)" fillcolor=lightblue]
	140321217257040 -> 140321216158528
	140321216158528 [label=AccumulateGrad]
	140321216158672 -> 140321216158576
	140321217257120 [label="stage4.0.fuse_layers.3.0.2.1.bias
 (144)" fillcolor=lightblue]
	140321217257120 -> 140321216158672
	140321216158672 [label=AccumulateGrad]
	140321216158720 -> 140321216159056
	140321216158720 [label=NativeBatchNormBackward0]
	140321216156560 -> 140321216158720
	140321216156560 [label=ConvolutionBackward0]
	140321216157184 -> 140321216156560
	140321216157184 [label=ReluBackward0]
	140321216155888 -> 140321216157184
	140321216155888 [label=NativeBatchNormBackward0]
	140321216155552 -> 140321216155888
	140321216155552 [label=ConvolutionBackward0]
	140321213773088 -> 140321216155552
	140321216155168 -> 140321216155552
	140321217257600 [label="stage4.0.fuse_layers.3.1.0.0.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217257600 -> 140321216155168
	140321216155168 [label=AccumulateGrad]
	140321216155840 -> 140321216155888
	140321217257680 [label="stage4.0.fuse_layers.3.1.0.1.weight
 (36)" fillcolor=lightblue]
	140321217257680 -> 140321216155840
	140321216155840 [label=AccumulateGrad]
	140321216156224 -> 140321216155888
	140321217257760 [label="stage4.0.fuse_layers.3.1.0.1.bias
 (36)" fillcolor=lightblue]
	140321217257760 -> 140321216156224
	140321216156224 [label=AccumulateGrad]
	140321216156032 -> 140321216156560
	140321217258080 [label="stage4.0.fuse_layers.3.1.1.0.weight
 (144, 36, 3, 3)" fillcolor=lightblue]
	140321217258080 -> 140321216156032
	140321216156032 [label=AccumulateGrad]
	140321216157712 -> 140321216158720
	140321217258160 [label="stage4.0.fuse_layers.3.1.1.1.weight
 (144)" fillcolor=lightblue]
	140321217258160 -> 140321216157712
	140321216157712 [label=AccumulateGrad]
	140321216158240 -> 140321216158720
	140321217258240 [label="stage4.0.fuse_layers.3.1.1.1.bias
 (144)" fillcolor=lightblue]
	140321217258240 -> 140321216158240
	140321216158240 [label=AccumulateGrad]
	140321216159200 -> 140321216159344
	140321216159200 [label=NativeBatchNormBackward0]
	140321216155696 -> 140321216159200
	140321216155696 [label=ConvolutionBackward0]
	140321213766512 -> 140321216155696
	140321216154880 -> 140321216155696
	140321217258640 [label="stage4.0.fuse_layers.3.2.0.0.weight
 (144, 72, 3, 3)" fillcolor=lightblue]
	140321217258640 -> 140321216154880
	140321216154880 [label=AccumulateGrad]
	140321216158096 -> 140321216159200
	140321217258720 [label="stage4.0.fuse_layers.3.2.0.1.weight
 (144)" fillcolor=lightblue]
	140321217258720 -> 140321216158096
	140321216158096 [label=AccumulateGrad]
	140321216158912 -> 140321216159200
	140321217258800 [label="stage4.0.fuse_layers.3.2.0.1.bias
 (144)" fillcolor=lightblue]
	140321217258800 -> 140321216158912
	140321216158912 [label=AccumulateGrad]
	140321214760944 -> 140321216159392
	140321216159728 -> 140321216160064
	140321217519584 [label="stage4.1.branches.3.0.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321217519584 -> 140321216159728
	140321216159728 [label=AccumulateGrad]
	140321216160256 -> 140321216160400
	140321217519664 [label="stage4.1.branches.3.0.bn1.weight
 (144)" fillcolor=lightblue]
	140321217519664 -> 140321216160256
	140321216160256 [label=AccumulateGrad]
	140321216160688 -> 140321216160400
	140321217519744 [label="stage4.1.branches.3.0.bn1.bias
 (144)" fillcolor=lightblue]
	140321217519744 -> 140321216160688
	140321216160688 [label=AccumulateGrad]
	140321216160736 -> 140321216161216
	140321217520224 [label="stage4.1.branches.3.0.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321217520224 -> 140321216160736
	140321216160736 [label=AccumulateGrad]
	140321216161360 -> 140321216161408
	140321217520304 [label="stage4.1.branches.3.0.bn2.weight
 (144)" fillcolor=lightblue]
	140321217520304 -> 140321216161360
	140321216161360 [label=AccumulateGrad]
	140321216161264 -> 140321216161408
	140321217520384 [label="stage4.1.branches.3.0.bn2.bias
 (144)" fillcolor=lightblue]
	140321217520384 -> 140321216161264
	140321216161264 [label=AccumulateGrad]
	140321216161600 -> 140321216161744
	140321216162032 -> 140321216162416
	140321217520784 [label="stage4.1.branches.3.1.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321217520784 -> 140321216162032
	140321216162032 [label=AccumulateGrad]
	140321216162560 -> 140321216162704
	140321217520864 [label="stage4.1.branches.3.1.bn1.weight
 (144)" fillcolor=lightblue]
	140321217520864 -> 140321216162560
	140321216162560 [label=AccumulateGrad]
	140321216162752 -> 140321216162704
	140321217520944 [label="stage4.1.branches.3.1.bn1.bias
 (144)" fillcolor=lightblue]
	140321217520944 -> 140321216162752
	140321216162752 [label=AccumulateGrad]
	140321216163088 -> 140321216163280
	140321217521344 [label="stage4.1.branches.3.1.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321217521344 -> 140321216163088
	140321216163088 [label=AccumulateGrad]
	140321216163424 -> 140321216163760
	140321217521424 [label="stage4.1.branches.3.1.bn2.weight
 (144)" fillcolor=lightblue]
	140321217521424 -> 140321216163424
	140321216163424 [label=AccumulateGrad]
	140321216163616 -> 140321216163760
	140321217521504 [label="stage4.1.branches.3.1.bn2.bias
 (144)" fillcolor=lightblue]
	140321217521504 -> 140321216163616
	140321216163616 [label=AccumulateGrad]
	140321216163904 -> 140321216164048
	140321216164096 -> 140321216164720
	140321217521904 [label="stage4.1.branches.3.2.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321217521904 -> 140321216164096
	140321216164096 [label=AccumulateGrad]
	140321216164624 -> 140321216164768
	140321217521984 [label="stage4.1.branches.3.2.bn1.weight
 (144)" fillcolor=lightblue]
	140321217521984 -> 140321216164624
	140321216164624 [label=AccumulateGrad]
	140321216165104 -> 140321216164768
	140321217522064 [label="stage4.1.branches.3.2.bn1.bias
 (144)" fillcolor=lightblue]
	140321217522064 -> 140321216165104
	140321216165104 [label=AccumulateGrad]
	140321216165296 -> 140321492633632
	140321217522464 [label="stage4.1.branches.3.2.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321217522464 -> 140321216165296
	140321216165296 [label=AccumulateGrad]
	140321216166064 -> 140321492646160
	140321217522544 [label="stage4.1.branches.3.2.bn2.weight
 (144)" fillcolor=lightblue]
	140321217522544 -> 140321216166064
	140321216166064 [label=AccumulateGrad]
	140321216165920 -> 140321492646160
	140321217522624 [label="stage4.1.branches.3.2.bn2.bias
 (144)" fillcolor=lightblue]
	140321217522624 -> 140321216165920
	140321216165920 [label=AccumulateGrad]
	140321492633776 -> 140321219590320
	140321219674224 -> 140321219592096
	140321217523024 [label="stage4.1.branches.3.3.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321217523024 -> 140321219674224
	140321219674224 [label=AccumulateGrad]
	140321219589792 -> 140321219588928
	140321217523104 [label="stage4.1.branches.3.3.bn1.weight
 (144)" fillcolor=lightblue]
	140321217523104 -> 140321219589792
	140321219589792 [label=AccumulateGrad]
	140321219590272 -> 140321219588928
	140321217523184 [label="stage4.1.branches.3.3.bn1.bias
 (144)" fillcolor=lightblue]
	140321217523184 -> 140321219590272
	140321219590272 [label=AccumulateGrad]
	140321219588544 -> 140321219584512
	140321217523584 [label="stage4.1.branches.3.3.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321217523584 -> 140321219588544
	140321219588544 [label=AccumulateGrad]
	140321219588112 -> 140321219586528
	140321217523664 [label="stage4.1.branches.3.3.bn2.weight
 (144)" fillcolor=lightblue]
	140321217523664 -> 140321219588112
	140321219588112 [label=AccumulateGrad]
	140321219587488 -> 140321219586528
	140321217523744 [label="stage4.1.branches.3.3.bn2.bias
 (144)" fillcolor=lightblue]
	140321217523744 -> 140321219587488
	140321219587488 [label=AccumulateGrad]
	140321219587536 -> 140321242979232
	140321216692960 -> 140321213893408
	140321217525264 [label="stage4.1.fuse_layers.0.3.0.weight
 (18, 144, 1, 1)" fillcolor=lightblue]
	140321217525264 -> 140321216692960
	140321216692960 [label=AccumulateGrad]
	140321213896432 -> 140321213897968
	140321217525344 [label="stage4.1.fuse_layers.0.3.1.weight
 (18)" fillcolor=lightblue]
	140321217525344 -> 140321213896432
	140321213896432 [label=AccumulateGrad]
	140321213900656 -> 140321213897968
	140321217525424 [label="stage4.1.fuse_layers.0.3.1.bias
 (18)" fillcolor=lightblue]
	140321217525424 -> 140321213900656
	140321213900656 [label=AccumulateGrad]
	140321213901424 -> 140321213901808
	140321217762704 [label="stage4.2.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217762704 -> 140321213901424
	140321213901424 [label=AccumulateGrad]
	140321213901952 -> 140321213902096
	140321217762784 [label="stage4.2.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140321217762784 -> 140321213901952
	140321213901952 [label=AccumulateGrad]
	140321213902144 -> 140321213902096
	140321217762864 [label="stage4.2.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140321217762864 -> 140321213902144
	140321213902144 [label=AccumulateGrad]
	140321213902480 -> 140321213902672
	140321217763264 [label="stage4.2.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217763264 -> 140321213902480
	140321213902480 [label=AccumulateGrad]
	140321213902816 -> 140321213903152
	140321217763344 [label="stage4.2.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140321217763344 -> 140321213902816
	140321213902816 [label=AccumulateGrad]
	140321213903008 -> 140321213903152
	140321217763424 [label="stage4.2.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140321217763424 -> 140321213903008
	140321213903008 [label=AccumulateGrad]
	140321213903296 -> 140321213903440
	140321213903344 -> 140321213904112
	140321217763904 [label="stage4.2.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217763904 -> 140321213903344
	140321213903344 [label=AccumulateGrad]
	140321213904016 -> 140321213904160
	140321217763984 [label="stage4.2.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140321217763984 -> 140321213904016
	140321213904016 [label=AccumulateGrad]
	140321213904496 -> 140321213904160
	140321217764064 [label="stage4.2.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140321217764064 -> 140321213904496
	140321213904496 [label=AccumulateGrad]
	140321213904784 -> 140321213905312
	140321217764544 [label="stage4.2.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217764544 -> 140321213904784
	140321213904784 [label=AccumulateGrad]
	140321213904832 -> 140321213905456
	140321217764624 [label="stage4.2.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140321217764624 -> 140321213904832
	140321213904832 [label=AccumulateGrad]
	140321213905024 -> 140321213905456
	140321217764704 [label="stage4.2.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140321217764704 -> 140321213905024
	140321213905024 [label=AccumulateGrad]
	140321213905840 -> 140321213905696
	140321213905360 -> 140321213906656
	140321217765184 [label="stage4.2.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217765184 -> 140321213905360
	140321213905360 [label=AccumulateGrad]
	140321213906512 -> 140321213906368
	140321217765264 [label="stage4.2.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140321217765264 -> 140321213906512
	140321213906512 [label=AccumulateGrad]
	140321213906032 -> 140321213906368
	140321217765344 [label="stage4.2.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140321217765344 -> 140321213906032
	140321213906032 [label=AccumulateGrad]
	140321213906128 -> 140321223061376
	140321217765824 [label="stage4.2.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217765824 -> 140321213906128
	140321213906128 [label=AccumulateGrad]
	140321223062624 -> 140321223060992
	140321217765904 [label="stage4.2.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140321217765904 -> 140321223062624
	140321223062624 [label=AccumulateGrad]
	140321223060896 -> 140321223060992
	140321217765984 [label="stage4.2.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140321217765984 -> 140321223060896
	140321223060896 [label=AccumulateGrad]
	140321223061232 -> 140321242579776
	140321223616272 -> 140321467203888
	140321217766464 [label="stage4.2.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217766464 -> 140321223616272
	140321223616272 [label=AccumulateGrad]
	140321527992416 -> 140321242822592
	140321217766544 [label="stage4.2.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140321217766544 -> 140321527992416
	140321527992416 [label=AccumulateGrad]
	140321242824224 -> 140321242822592
	140321217766624 [label="stage4.2.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140321217766624 -> 140321242824224
	140321242824224 [label=AccumulateGrad]
	140321242824560 -> 140324613969264
	140321217767104 [label="stage4.2.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217767104 -> 140321242824560
	140321242824560 [label=AccumulateGrad]
	140321467377664 -> 140321223782032
	140321217767184 [label="stage4.2.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140321217767184 -> 140321467377664
	140321467377664 [label=AccumulateGrad]
	140321255679232 -> 140321223782032
	140321217767264 [label="stage4.2.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140321217767264 -> 140321255679232
	140321255679232 [label=AccumulateGrad]
	140321255674432 -> 140321223781840
	140321259686400 -> 140321223225888
	140321259686400 [label=UpsampleBilinear2DBackward0]
	140321255674048 -> 140321259686400
	140321255674048 [label=NativeBatchNormBackward0]
	140321242824656 -> 140321255674048
	140321242824656 [label=ConvolutionBackward0]
	140321223619824 -> 140321242824656
	140321223619824 [label=ReluBackward0]
	140321223061520 -> 140321223619824
	140321223061520 [label=AddBackward0]
	140321213906800 -> 140321223061520
	140321213906800 [label=NativeBatchNormBackward0]
	140321213906704 -> 140321213906800
	140321213906704 [label=ConvolutionBackward0]
	140321213903968 -> 140321213906704
	140321213903968 [label=ReluBackward0]
	140321213903824 -> 140321213903968
	140321213903824 [label=NativeBatchNormBackward0]
	140321213901280 -> 140321213903824
	140321213901280 [label=ConvolutionBackward0]
	140321213905984 -> 140321213901280
	140321213905984 [label=ReluBackward0]
	140321213901472 -> 140321213905984
	140321213901472 [label=AddBackward0]
	140321216702800 -> 140321213901472
	140321216702800 [label=NativeBatchNormBackward0]
	140321219588208 -> 140321216702800
	140321219588208 [label=ConvolutionBackward0]
	140321219674512 -> 140321219588208
	140321219674512 [label=ReluBackward0]
	140321492635648 -> 140321219674512
	140321492635648 [label=NativeBatchNormBackward0]
	140321216165632 -> 140321492635648
	140321216165632 [label=ConvolutionBackward0]
	140321216697952 -> 140321216165632
	140321216697952 [label=ReluBackward0]
	140321216161888 -> 140321216697952
	140321216161888 [label=AddBackward0]
	140321216162272 -> 140321216161888
	140321216162272 [label=NativeBatchNormBackward0]
	140321216162080 -> 140321216162272
	140321216162080 [label=ConvolutionBackward0]
	140321216159920 -> 140321216162080
	140321216159920 [label=ReluBackward0]
	140321216159248 -> 140321216159920
	140321216159248 [label=NativeBatchNormBackward0]
	140321216157328 -> 140321216159248
	140321216157328 [label=ConvolutionBackward0]
	140321216163232 -> 140321216157328
	140321216163232 [label=ReluBackward0]
	140321216154640 -> 140321216163232
	140321216154640 [label=AddBackward0]
	140321216154352 -> 140321216154640
	140321216154352 [label=NativeBatchNormBackward0]
	140321216154016 -> 140321216154352
	140321216154016 [label=ConvolutionBackward0]
	140321216153920 -> 140321216154016
	140321216153920 [label=ReluBackward0]
	140321216154112 -> 140321216153920
	140321216154112 [label=NativeBatchNormBackward0]
	140321216154256 -> 140321216154112
	140321216154256 [label=ConvolutionBackward0]
	140321216154496 -> 140321216154256
	140321216154496 [label=ReluBackward0]
	140321216154784 -> 140321216154496
	140321216154784 [label=AddBackward0]
	140321216154928 -> 140321216154784
	140321216154928 [label=AddBackward0]
	140321216155264 -> 140321216154928
	140321216155264 [label=AddBackward0]
	140321216155456 -> 140321216155264
	140321216155456 [label=NativeBatchNormBackward0]
	140321216155600 -> 140321216155456
	140321216155600 [label=ConvolutionBackward0]
	140321213900128 -> 140321216155600
	140321216156080 -> 140321216155600
	140321217525824 [label="stage4.1.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140321217525824 -> 140321216156080
	140321216156080 [label=AccumulateGrad]
	140321216155648 -> 140321216155456
	140321217525904 [label="stage4.1.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140321217525904 -> 140321216155648
	140321216155648 [label=AccumulateGrad]
	140321216155408 -> 140321216155456
	140321217525984 [label="stage4.1.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140321217525984 -> 140321216155408
	140321216155408 [label=AccumulateGrad]
	140321213898064 -> 140321216155264
	140321216155072 -> 140321216154928
	140321216155072 [label=UpsampleBilinear2DBackward0]
	140321216155744 -> 140321216155072
	140321216155744 [label=NativeBatchNormBackward0]
	140321216155936 -> 140321216155744
	140321216155936 [label=ConvolutionBackward0]
	140321213893360 -> 140321216155936
	140321216156464 -> 140321216155936
	140321217526384 [label="stage4.1.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140321217526384 -> 140321216156464
	140321216156464 [label=AccumulateGrad]
	140321216156128 -> 140321216155744
	140321217526464 [label="stage4.1.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140321217526464 -> 140321216156128
	140321216156128 [label=AccumulateGrad]
	140321216155504 -> 140321216155744
	140321217526544 [label="stage4.1.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140321217526544 -> 140321216155504
	140321216155504 [label=AccumulateGrad]
	140321216154976 -> 140321216154784
	140321216154976 [label=UpsampleBilinear2DBackward0]
	140321216156176 -> 140321216154976
	140321216156176 [label=NativeBatchNormBackward0]
	140321216156608 -> 140321216156176
	140321216156608 [label=ConvolutionBackward0]
	140321216693920 -> 140321216156608
	140321216156848 -> 140321216156608
	140321217527024 [label="stage4.1.fuse_layers.1.3.0.weight
 (36, 144, 1, 1)" fillcolor=lightblue]
	140321217527024 -> 140321216156848
	140321216156848 [label=AccumulateGrad]
	140321216156320 -> 140321216156176
	140321217527104 [label="stage4.1.fuse_layers.1.3.1.weight
 (36)" fillcolor=lightblue]
	140321217527104 -> 140321216156320
	140321216156320 [label=AccumulateGrad]
	140321216155120 -> 140321216156176
	140321217527184 [label="stage4.1.fuse_layers.1.3.1.bias
 (36)" fillcolor=lightblue]
	140321217527184 -> 140321216155120
	140321216155120 [label=AccumulateGrad]
	140321216154736 -> 140321216154256
	140321217767664 [label="stage4.2.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217767664 -> 140321216154736
	140321216154736 [label=AccumulateGrad]
	140321216154304 -> 140321216154112
	140321217767744 [label="stage4.2.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140321217767744 -> 140321216154304
	140321216154304 [label=AccumulateGrad]
	140321216154064 -> 140321216154112
	140321217767824 [label="stage4.2.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140321217767824 -> 140321216154064
	140321216154064 [label=AccumulateGrad]
	140321216153584 -> 140321216154016
	140321217768304 [label="stage4.2.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217768304 -> 140321216153584
	140321216153584 [label=AccumulateGrad]
	140321216153872 -> 140321216154352
	140321217768384 [label="stage4.2.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140321217768384 -> 140321216153872
	140321216153872 [label=AccumulateGrad]
	140321216154208 -> 140321216154352
	140321217768464 [label="stage4.2.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140321217768464 -> 140321216154208
	140321216154208 [label=AccumulateGrad]
	140321216154496 -> 140321216154640
	140321216154688 -> 140321216157328
	140321217768944 [label="stage4.2.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217768944 -> 140321216154688
	140321216154688 [label=AccumulateGrad]
	140321216155216 -> 140321216159248
	140321217769024 [label="stage4.2.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140321217769024 -> 140321216155216
	140321216155216 [label=AccumulateGrad]
	140321216160016 -> 140321216159248
	140321217769104 [label="stage4.2.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140321217769104 -> 140321216160016
	140321216160016 [label=AccumulateGrad]
	140321216160928 -> 140321216162080
	140321217769584 [label="stage4.2.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217769584 -> 140321216160928
	140321216160928 [label=AccumulateGrad]
	140321216161936 -> 140321216162272
	140321217769664 [label="stage4.2.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140321217769664 -> 140321216161936
	140321216161936 [label=AccumulateGrad]
	140321216161072 -> 140321216162272
	140321217769744 [label="stage4.2.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140321217769744 -> 140321216161072
	140321216161072 [label=AccumulateGrad]
	140321216163232 -> 140321216161888
	140321216164432 -> 140321216165632
	140321217770144 [label="stage4.2.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217770144 -> 140321216164432
	140321216164432 [label=AccumulateGrad]
	140321216163952 -> 140321492635648
	140321217770224 [label="stage4.2.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140321217770224 -> 140321216163952
	140321216163952 [label=AccumulateGrad]
	140321216165392 -> 140321492635648
	140321217770304 [label="stage4.2.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140321217770304 -> 140321216165392
	140321216165392 [label=AccumulateGrad]
	140321219588880 -> 140321219588208
	140321217770704 [label="stage4.2.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217770704 -> 140321219588880
	140321219588880 [label=AccumulateGrad]
	140321219585520 -> 140321216702800
	140321217770784 [label="stage4.2.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140321217770784 -> 140321219585520
	140321219585520 [label=AccumulateGrad]
	140321219588016 -> 140321216702800
	140321217770864 [label="stage4.2.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140321217770864 -> 140321219588016
	140321219588016 [label=AccumulateGrad]
	140321216697952 -> 140321213901472
	140321213901328 -> 140321213901280
	140321217771344 [label="stage4.2.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217771344 -> 140321213901328
	140321213901328 [label=AccumulateGrad]
	140321213902000 -> 140321213903824
	140321217771424 [label="stage4.2.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140321217771424 -> 140321213902000
	140321213902000 [label=AccumulateGrad]
	140321213902768 -> 140321213903824
	140321217771504 [label="stage4.2.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140321217771504 -> 140321213902768
	140321213902768 [label=AccumulateGrad]
	140321213904688 -> 140321213906704
	140321217771904 [label="stage4.2.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217771904 -> 140321213904688
	140321213904688 [label=AccumulateGrad]
	140321213906848 -> 140321213906800
	140321217771984 [label="stage4.2.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140321217771984 -> 140321213906848
	140321213906848 [label=AccumulateGrad]
	140321213905168 -> 140321213906800
	140321217772064 [label="stage4.2.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140321217772064 -> 140321213905168
	140321213905168 [label=AccumulateGrad]
	140321213905984 -> 140321223061520
	140321223610944 -> 140321242824656
	140321215930496 [label="stage4.2.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140321215930496 -> 140321223610944
	140321223610944 [label=AccumulateGrad]
	140321242824512 -> 140321255674048
	140321215930576 [label="stage4.2.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140321215930576 -> 140321242824512
	140321242824512 [label=AccumulateGrad]
	140321242819184 -> 140321255674048
	140321215930656 [label="stage4.2.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140321215930656 -> 140321242819184
	140321242819184 [label=AccumulateGrad]
	140321255308976 -> 140321223224688
	140321255308976 [label=UpsampleBilinear2DBackward0]
	140321223610848 -> 140321255308976
	140321223610848 [label=NativeBatchNormBackward0]
	140321223062672 -> 140321223610848
	140321223062672 [label=ConvolutionBackward0]
	140321213899984 -> 140321223062672
	140321213899984 [label=ReluBackward0]
	140321213901664 -> 140321213899984
	140321213901664 [label=AddBackward0]
	140321219586912 -> 140321213901664
	140321219586912 [label=NativeBatchNormBackward0]
	140321492645968 -> 140321219586912
	140321492645968 [label=ConvolutionBackward0]
	140321216163376 -> 140321492645968
	140321216163376 [label=ReluBackward0]
	140321216159584 -> 140321216163376
	140321216159584 [label=NativeBatchNormBackward0]
	140321216153968 -> 140321216159584
	140321216153968 [label=ConvolutionBackward0]
	140321219590656 -> 140321216153968
	140321219590656 [label=ReluBackward0]
	140321216154448 -> 140321219590656
	140321216154448 [label=AddBackward0]
	140321216154592 -> 140321216154448
	140321216154592 [label=NativeBatchNormBackward0]
	140321216156416 -> 140321216154592
	140321216156416 [label=ConvolutionBackward0]
	140321216156944 -> 140321216156416
	140321216156944 [label=ReluBackward0]
	140321216157280 -> 140321216156944
	140321216157280 [label=NativeBatchNormBackward0]
	140321216157520 -> 140321216157280
	140321216157520 [label=ConvolutionBackward0]
	140321216155792 -> 140321216157520
	140321216155792 [label=ReluBackward0]
	140321216157952 -> 140321216155792
	140321216157952 [label=AddBackward0]
	140321216158192 -> 140321216157952
	140321216158192 [label=NativeBatchNormBackward0]
	140321216158288 -> 140321216158192
	140321216158288 [label=ConvolutionBackward0]
	140321216158768 -> 140321216158288
	140321216158768 [label=ReluBackward0]
	140321216159008 -> 140321216158768
	140321216159008 [label=NativeBatchNormBackward0]
	140321216159152 -> 140321216159008
	140321216159152 [label=ConvolutionBackward0]
	140321216158048 -> 140321216159152
	140321216158048 [label=ReluBackward0]
	140321216159680 -> 140321216158048
	140321216159680 [label=AddBackward0]
	140321216159824 -> 140321216159680
	140321216159824 [label=NativeBatchNormBackward0]
	140321216160112 -> 140321216159824
	140321216160112 [label=ConvolutionBackward0]
	140321216160304 -> 140321216160112
	140321216160304 [label=ReluBackward0]
	140321216160640 -> 140321216160304
	140321216160640 [label=NativeBatchNormBackward0]
	140321216160880 -> 140321216160640
	140321216160880 [label=ConvolutionBackward0]
	140321216159632 -> 140321216160880
	140321216159632 [label=ReluBackward0]
	140321216161312 -> 140321216159632
	140321216161312 [label=AddBackward0]
	140321216161552 -> 140321216161312
	140321216161552 [label=AddBackward0]
	140321216161648 -> 140321216161552
	140321216161648 [label=AddBackward0]
	140321216161792 -> 140321216161648
	140321216161792 [label=NativeBatchNormBackward0]
	140321216162224 -> 140321216161792
	140321216162224 [label=ConvolutionBackward0]
	140321216162512 -> 140321216162224
	140321216162512 [label=ReluBackward0]
	140321216162800 -> 140321216162512
	140321216162800 [label=NativeBatchNormBackward0]
	140321216162848 -> 140321216162800
	140321216162848 [label=ConvolutionBackward0]
	140321213900128 -> 140321216162848
	140321216163136 -> 140321216162848
	140321217527504 [label="stage4.1.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217527504 -> 140321216163136
	140321216163136 [label=AccumulateGrad]
	140321216162896 -> 140321216162800
	140321217527584 [label="stage4.1.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140321217527584 -> 140321216162896
	140321216162896 [label=AccumulateGrad]
	140321216162464 -> 140321216162800
	140321217527664 [label="stage4.1.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140321217527664 -> 140321216162464
	140321216162464 [label=AccumulateGrad]
	140321216162320 -> 140321216162224
	140321217757504 [label="stage4.1.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140321217757504 -> 140321216162320
	140321216162320 [label=AccumulateGrad]
	140321216162128 -> 140321216161792
	140321217757584 [label="stage4.1.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140321217757584 -> 140321216162128
	140321216162128 [label=AccumulateGrad]
	140321216161984 -> 140321216161792
	140321217757664 [label="stage4.1.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140321217757664 -> 140321216161984
	140321216161984 [label=AccumulateGrad]
	140321216161840 -> 140321216161648
	140321216161840 [label=NativeBatchNormBackward0]
	140321216162992 -> 140321216161840
	140321216162992 [label=ConvolutionBackward0]
	140321213898064 -> 140321216162992
	140321216163184 -> 140321216162992
	140321217758144 [label="stage4.1.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140321217758144 -> 140321216163184
	140321216163184 [label=AccumulateGrad]
	140321216162656 -> 140321216161840
	140321217758224 [label="stage4.1.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140321217758224 -> 140321216162656
	140321216162656 [label=AccumulateGrad]
	140321216162176 -> 140321216161840
	140321217758304 [label="stage4.1.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140321217758304 -> 140321216162176
	140321216162176 [label=AccumulateGrad]
	140321213893360 -> 140321216161552
	140321216161456 -> 140321216161312
	140321216161456 [label=UpsampleBilinear2DBackward0]
	140321216162368 -> 140321216161456
	140321216162368 [label=NativeBatchNormBackward0]
	140321216163568 -> 140321216162368
	140321216163568 [label=ConvolutionBackward0]
	140321216693920 -> 140321216163568
	140321216163712 -> 140321216163568
	140321217758704 [label="stage4.1.fuse_layers.2.3.0.weight
 (72, 144, 1, 1)" fillcolor=lightblue]
	140321217758704 -> 140321216163712
	140321216163712 [label=AccumulateGrad]
	140321216163040 -> 140321216162368
	140321217758784 [label="stage4.1.fuse_layers.2.3.1.weight
 (72)" fillcolor=lightblue]
	140321217758784 -> 140321216163040
	140321216163040 [label=AccumulateGrad]
	140321216161696 -> 140321216162368
	140321217758864 [label="stage4.1.fuse_layers.2.3.1.bias
 (72)" fillcolor=lightblue]
	140321217758864 -> 140321216161696
	140321216161696 [label=AccumulateGrad]
	140321216161168 -> 140321216160880
	140321217772384 [label="stage4.2.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321217772384 -> 140321216161168
	140321216161168 [label=AccumulateGrad]
	140321216160784 -> 140321216160640
	140321217772464 [label="stage4.2.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140321217772464 -> 140321216160784
	140321216160784 [label=AccumulateGrad]
	140321216160496 -> 140321216160640
	140321217772544 [label="stage4.2.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140321217772544 -> 140321216160496
	140321216160496 [label=AccumulateGrad]
	140321216160352 -> 140321216160112
	140321217773024 [label="stage4.2.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321217773024 -> 140321216160352
	140321216160352 [label=AccumulateGrad]
	140321216159968 -> 140321216159824
	140321217773104 [label="stage4.2.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140321217773104 -> 140321216159968
	140321216159968 [label=AccumulateGrad]
	140321216159776 -> 140321216159824
	140321217773184 [label="stage4.2.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140321217773184 -> 140321216159776
	140321216159776 [label=AccumulateGrad]
	140321216159632 -> 140321216159680
	140321216159536 -> 140321216159152
	140321215922336 [label="stage4.2.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321215922336 -> 140321216159536
	140321216159536 [label=AccumulateGrad]
	140321216158960 -> 140321216159008
	140321215922416 [label="stage4.2.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140321215922416 -> 140321216158960
	140321216158960 [label=AccumulateGrad]
	140321216158864 -> 140321216159008
	140321215922496 [label="stage4.2.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140321215922496 -> 140321216158864
	140321216158864 [label=AccumulateGrad]
	140321216158624 -> 140321216158288
	140321215922976 [label="stage4.2.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321215922976 -> 140321216158624
	140321216158624 [label=AccumulateGrad]
	140321216158336 -> 140321216158192
	140321215923056 [label="stage4.2.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140321215923056 -> 140321216158336
	140321216158336 [label=AccumulateGrad]
	140321216158144 -> 140321216158192
	140321215923136 [label="stage4.2.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140321215923136 -> 140321216158144
	140321216158144 [label=AccumulateGrad]
	140321216158048 -> 140321216157952
	140321216157808 -> 140321216157520
	140321215923536 [label="stage4.2.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321215923536 -> 140321216157808
	140321216157808 [label=AccumulateGrad]
	140321216157424 -> 140321216157280
	140321215923616 [label="stage4.2.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140321215923616 -> 140321216157424
	140321216157424 [label=AccumulateGrad]
	140321216157136 -> 140321216157280
	140321215923696 [label="stage4.2.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140321215923696 -> 140321216157136
	140321216157136 [label=AccumulateGrad]
	140321216156800 -> 140321216156416
	140321215924176 [label="stage4.2.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321215924176 -> 140321216156800
	140321216156800 [label=AccumulateGrad]
	140321216156272 -> 140321216154592
	140321215924256 [label="stage4.2.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140321215924256 -> 140321216156272
	140321216156272 [label=AccumulateGrad]
	140321216154400 -> 140321216154592
	140321215924336 [label="stage4.2.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140321215924336 -> 140321216154400
	140321216154400 [label=AccumulateGrad]
	140321216155792 -> 140321216154448
	140321216154832 -> 140321216153968
	140321215924736 [label="stage4.2.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321215924736 -> 140321216154832
	140321216154832 [label=AccumulateGrad]
	140321216155024 -> 140321216159584
	140321215924816 [label="stage4.2.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140321215924816 -> 140321216155024
	140321216155024 [label=AccumulateGrad]
	140321216159872 -> 140321216159584
	140321215924896 [label="stage4.2.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140321215924896 -> 140321216159872
	140321216159872 [label=AccumulateGrad]
	140321216164288 -> 140321492645968
	140321215925296 [label="stage4.2.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140321215925296 -> 140321216164288
	140321216164288 [label=AccumulateGrad]
	140321216162608 -> 140321219586912
	140321215925376 [label="stage4.2.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140321215925376 -> 140321216162608
	140321216162608 [label=AccumulateGrad]
	140321216164960 -> 140321219586912
	140321215925456 [label="stage4.2.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140321215925456 -> 140321216164960
	140321216164960 [label=AccumulateGrad]
	140321219590656 -> 140321213901664
	140321213903680 -> 140321223062672
	140321215931056 [label="stage4.2.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140321215931056 -> 140321213903680
	140321213903680 [label=AccumulateGrad]
	140321255309024 -> 140321223610848
	140321215931136 [label="stage4.2.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140321215931136 -> 140321255309024
	140321255309024 [label=AccumulateGrad]
	140321213905504 -> 140321223610848
	140321215931216 [label="stage4.2.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140321215931216 -> 140321213905504
	140321213905504 [label=AccumulateGrad]
	140321223224016 -> 140321223224256
	140321223224016 [label=UpsampleBilinear2DBackward0]
	140321223783856 -> 140321223224016
	140321223783856 [label=NativeBatchNormBackward0]
	140321213903488 -> 140321223783856
	140321213903488 [label=ConvolutionBackward0]
	140321216153824 -> 140321213903488
	140321216153824 [label=ReluBackward0]
	140321216156992 -> 140321216153824
	140321216156992 [label=AddBackward0]
	140321216155360 -> 140321216156992
	140321216155360 [label=NativeBatchNormBackward0]
	140321216156752 -> 140321216155360
	140321216156752 [label=ConvolutionBackward0]
	140321216157664 -> 140321216156752
	140321216157664 [label=ReluBackward0]
	140321216158432 -> 140321216157664
	140321216158432 [label=NativeBatchNormBackward0]
	140321216160208 -> 140321216158432
	140321216160208 [label=ConvolutionBackward0]
	140321216154160 -> 140321216160208
	140321216154160 [label=ReluBackward0]
	140321216160832 -> 140321216154160
	140321216160832 [label=AddBackward0]
	140321216160976 -> 140321216160832
	140321216160976 [label=NativeBatchNormBackward0]
	140321216163328 -> 140321216160976
	140321216163328 [label=ConvolutionBackward0]
	140321216163808 -> 140321216163328
	140321216163808 [label=ReluBackward0]
	140321216164240 -> 140321216163808
	140321216164240 [label=NativeBatchNormBackward0]
	140321216164384 -> 140321216164240
	140321216164384 [label=ConvolutionBackward0]
	140321216161504 -> 140321216164384
	140321216161504 [label=ReluBackward0]
	140321216164912 -> 140321216161504
	140321216164912 [label=AddBackward0]
	140321216165056 -> 140321216164912
	140321216165056 [label=NativeBatchNormBackward0]
	140321216165152 -> 140321216165056
	140321216165152 [label=ConvolutionBackward0]
	140321216165536 -> 140321216165152
	140321216165536 [label=ReluBackward0]
	140321216165824 -> 140321216165536
	140321216165824 [label=NativeBatchNormBackward0]
	140321216166016 -> 140321216165824
	140321216166016 [label=ConvolutionBackward0]
	140321216164864 -> 140321216166016
	140321216164864 [label=ReluBackward0]
	140321216166544 -> 140321216164864
	140321216166544 [label=AddBackward0]
	140321216166688 -> 140321216166544
	140321216166688 [label=NativeBatchNormBackward0]
	140321216166880 -> 140321216166688
	140321216166880 [label=ConvolutionBackward0]
	140321216167168 -> 140321216166880
	140321216167168 [label=ReluBackward0]
	140321216167600 -> 140321216167168
	140321216167600 [label=NativeBatchNormBackward0]
	140321216167744 -> 140321216167600
	140321216167744 [label=ConvolutionBackward0]
	140321216166496 -> 140321216167744
	140321216166496 [label=ReluBackward0]
	140321216560912 -> 140321216166496
	140321216560912 [label=AddBackward0]
	140321216560624 -> 140321216560912
	140321216560624 [label=AddBackward0]
	140321216560288 -> 140321216560624
	140321216560288 [label=AddBackward0]
	140321216560096 -> 140321216560288
	140321216560096 [label=NativeBatchNormBackward0]
	140321216559616 -> 140321216560096
	140321216559616 [label=ConvolutionBackward0]
	140321216559280 -> 140321216559616
	140321216559280 [label=ReluBackward0]
	140321216558800 -> 140321216559280
	140321216558800 [label=NativeBatchNormBackward0]
	140321216558752 -> 140321216558800
	140321216558752 [label=ConvolutionBackward0]
	140321216558128 -> 140321216558752
	140321216558128 [label=ReluBackward0]
	140321216557936 -> 140321216558128
	140321216557936 [label=NativeBatchNormBackward0]
	140321216557600 -> 140321216557936
	140321216557600 [label=ConvolutionBackward0]
	140321213900128 -> 140321216557600
	140321216557264 -> 140321216557600
	140321217759264 [label="stage4.1.fuse_layers.3.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217759264 -> 140321216557264
	140321216557264 [label=AccumulateGrad]
	140321216557792 -> 140321216557936
	140321217759344 [label="stage4.1.fuse_layers.3.0.0.1.weight
 (18)" fillcolor=lightblue]
	140321217759344 -> 140321216557792
	140321216557792 [label=AccumulateGrad]
	140321216558224 -> 140321216557936
	140321217759424 [label="stage4.1.fuse_layers.3.0.0.1.bias
 (18)" fillcolor=lightblue]
	140321217759424 -> 140321216558224
	140321216558224 [label=AccumulateGrad]
	140321216558272 -> 140321216558752
	140321217759744 [label="stage4.1.fuse_layers.3.0.1.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321217759744 -> 140321216558272
	140321216558272 [label=AccumulateGrad]
	140321216558896 -> 140321216558800
	140321217759824 [label="stage4.1.fuse_layers.3.0.1.1.weight
 (18)" fillcolor=lightblue]
	140321217759824 -> 140321216558896
	140321216558896 [label=AccumulateGrad]
	140321216559136 -> 140321216558800
	140321217759904 [label="stage4.1.fuse_layers.3.0.1.1.bias
 (18)" fillcolor=lightblue]
	140321217759904 -> 140321216559136
	140321216559136 [label=AccumulateGrad]
	140321216559424 -> 140321216559616
	140321217760384 [label="stage4.1.fuse_layers.3.0.2.0.weight
 (144, 18, 3, 3)" fillcolor=lightblue]
	140321217760384 -> 140321216559424
	140321216559424 [label=AccumulateGrad]
	140321216559808 -> 140321216560096
	140321217760464 [label="stage4.1.fuse_layers.3.0.2.1.weight
 (144)" fillcolor=lightblue]
	140321217760464 -> 140321216559808
	140321216559808 [label=AccumulateGrad]
	140321216559952 -> 140321216560096
	140321217760544 [label="stage4.1.fuse_layers.3.0.2.1.bias
 (144)" fillcolor=lightblue]
	140321217760544 -> 140321216559952
	140321216559952 [label=AccumulateGrad]
	140321216560240 -> 140321216560288
	140321216560240 [label=NativeBatchNormBackward0]
	140321216558080 -> 140321216560240
	140321216558080 [label=ConvolutionBackward0]
	140321216558464 -> 140321216558080
	140321216558464 [label=ReluBackward0]
	140321216557408 -> 140321216558464
	140321216557408 [label=NativeBatchNormBackward0]
	140321216556784 -> 140321216557408
	140321216556784 [label=ConvolutionBackward0]
	140321213898064 -> 140321216556784
	140321216556448 -> 140321216556784
	140321217760944 [label="stage4.1.fuse_layers.3.1.0.0.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321217760944 -> 140321216556448
	140321216556448 [label=AccumulateGrad]
	140321216557120 -> 140321216557408
	140321217761024 [label="stage4.1.fuse_layers.3.1.0.1.weight
 (36)" fillcolor=lightblue]
	140321217761024 -> 140321216557120
	140321216557120 [label=AccumulateGrad]
	140321216557456 -> 140321216557408
	140321217761104 [label="stage4.1.fuse_layers.3.1.0.1.bias
 (36)" fillcolor=lightblue]
	140321217761104 -> 140321216557456
	140321216557456 [label=AccumulateGrad]
	140321216557552 -> 140321216558080
	140321217761584 [label="stage4.1.fuse_layers.3.1.1.0.weight
 (144, 36, 3, 3)" fillcolor=lightblue]
	140321217761584 -> 140321216557552
	140321216557552 [label=AccumulateGrad]
	140321216558944 -> 140321216560240
	140321217761664 [label="stage4.1.fuse_layers.3.1.1.1.weight
 (144)" fillcolor=lightblue]
	140321217761664 -> 140321216558944
	140321216558944 [label=AccumulateGrad]
	140321216559472 -> 140321216560240
	140321217761744 [label="stage4.1.fuse_layers.3.1.1.1.bias
 (144)" fillcolor=lightblue]
	140321217761744 -> 140321216559472
	140321216559472 [label=AccumulateGrad]
	140321216560480 -> 140321216560624
	140321216560480 [label=NativeBatchNormBackward0]
	140321216556928 -> 140321216560480
	140321216556928 [label=ConvolutionBackward0]
	140321213893360 -> 140321216556928
	140321216556112 -> 140321216556928
	140321217762224 [label="stage4.1.fuse_layers.3.2.0.0.weight
 (144, 72, 3, 3)" fillcolor=lightblue]
	140321217762224 -> 140321216556112
	140321216556112 [label=AccumulateGrad]
	140321216559568 -> 140321216560480
	140321217762304 [label="stage4.1.fuse_layers.3.2.0.1.weight
 (144)" fillcolor=lightblue]
	140321217762304 -> 140321216559568
	140321216559568 [label=AccumulateGrad]
	140321216560192 -> 140321216560480
	140321217762384 [label="stage4.1.fuse_layers.3.2.0.1.bias
 (144)" fillcolor=lightblue]
	140321217762384 -> 140321216560192
	140321216560192 [label=AccumulateGrad]
	140321216693920 -> 140321216560912
	140321216167840 -> 140321216167744
	140321215925856 [label="stage4.2.branches.3.0.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321215925856 -> 140321216167840
	140321216167840 [label=AccumulateGrad]
	140321216167552 -> 140321216167600
	140321215925936 [label="stage4.2.branches.3.0.bn1.weight
 (144)" fillcolor=lightblue]
	140321215925936 -> 140321216167552
	140321216167552 [label=AccumulateGrad]
	140321216167360 -> 140321216167600
	140321215926016 [label="stage4.2.branches.3.0.bn1.bias
 (144)" fillcolor=lightblue]
	140321215926016 -> 140321216167360
	140321216167360 [label=AccumulateGrad]
	140321216167216 -> 140321216166880
	140321215926416 [label="stage4.2.branches.3.0.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321215926416 -> 140321216167216
	140321216167216 [label=AccumulateGrad]
	140321216166928 -> 140321216166688
	140321215926496 [label="stage4.2.branches.3.0.bn2.weight
 (144)" fillcolor=lightblue]
	140321215926496 -> 140321216166928
	140321216166928 [label=AccumulateGrad]
	140321216166832 -> 140321216166688
	140321215926576 [label="stage4.2.branches.3.0.bn2.bias
 (144)" fillcolor=lightblue]
	140321215926576 -> 140321216166832
	140321216166832 [label=AccumulateGrad]
	140321216166496 -> 140321216166544
	140321216166400 -> 140321216166016
	140321215927056 [label="stage4.2.branches.3.1.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321215927056 -> 140321216166400
	140321216166400 [label=AccumulateGrad]
	140321216165872 -> 140321216165824
	140321215927136 [label="stage4.2.branches.3.1.bn1.weight
 (144)" fillcolor=lightblue]
	140321215927136 -> 140321216165872
	140321216165872 [label=AccumulateGrad]
	140321216165728 -> 140321216165824
	140321215927216 [label="stage4.2.branches.3.1.bn1.bias
 (144)" fillcolor=lightblue]
	140321215927216 -> 140321216165728
	140321216165728 [label=AccumulateGrad]
	140321216165584 -> 140321216165152
	140321215927696 [label="stage4.2.branches.3.1.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321215927696 -> 140321216165584
	140321216165584 [label=AccumulateGrad]
	140321216165200 -> 140321216165056
	140321215927776 [label="stage4.2.branches.3.1.bn2.weight
 (144)" fillcolor=lightblue]
	140321215927776 -> 140321216165200
	140321216165200 [label=AccumulateGrad]
	140321216165008 -> 140321216165056
	140321215927856 [label="stage4.2.branches.3.1.bn2.bias
 (144)" fillcolor=lightblue]
	140321215927856 -> 140321216165008
	140321216165008 [label=AccumulateGrad]
	140321216164864 -> 140321216164912
	140321216164672 -> 140321216164384
	140321215928256 [label="stage4.2.branches.3.2.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321215928256 -> 140321216164672
	140321216164672 [label=AccumulateGrad]
	140321216164192 -> 140321216164240
	140321215928336 [label="stage4.2.branches.3.2.bn1.weight
 (144)" fillcolor=lightblue]
	140321215928336 -> 140321216164192
	140321216164192 [label=AccumulateGrad]
	140321216164000 -> 140321216164240
	140321215928416 [label="stage4.2.branches.3.2.bn1.bias
 (144)" fillcolor=lightblue]
	140321215928416 -> 140321216164000
	140321216164000 [label=AccumulateGrad]
	140321216163664 -> 140321216163328
	140321215928896 [label="stage4.2.branches.3.2.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321215928896 -> 140321216163664
	140321216163664 [label=AccumulateGrad]
	140321216163472 -> 140321216160976
	140321215928976 [label="stage4.2.branches.3.2.bn2.weight
 (144)" fillcolor=lightblue]
	140321215928976 -> 140321216163472
	140321216163472 [label=AccumulateGrad]
	140321216161024 -> 140321216160976
	140321215929056 [label="stage4.2.branches.3.2.bn2.bias
 (144)" fillcolor=lightblue]
	140321215929056 -> 140321216161024
	140321216161024 [label=AccumulateGrad]
	140321216161504 -> 140321216160832
	140321216161120 -> 140321216160208
	140321215929456 [label="stage4.2.branches.3.3.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321215929456 -> 140321216161120
	140321216161120 [label=AccumulateGrad]
	140321216159104 -> 140321216158432
	140321215929536 [label="stage4.2.branches.3.3.bn1.weight
 (144)" fillcolor=lightblue]
	140321215929536 -> 140321216159104
	140321216159104 [label=AccumulateGrad]
	140321216158816 -> 140321216158432
	140321215929616 [label="stage4.2.branches.3.3.bn1.bias
 (144)" fillcolor=lightblue]
	140321215929616 -> 140321216158816
	140321216158816 [label=AccumulateGrad]
	140321216157616 -> 140321216156752
	140321215930016 [label="stage4.2.branches.3.3.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140321215930016 -> 140321216157616
	140321216157616 [label=AccumulateGrad]
	140321216157760 -> 140321216155360
	140321215930096 [label="stage4.2.branches.3.3.bn2.weight
 (144)" fillcolor=lightblue]
	140321215930096 -> 140321216157760
	140321216157760 [label=AccumulateGrad]
	140321216157088 -> 140321216155360
	140321215930176 [label="stage4.2.branches.3.3.bn2.bias
 (144)" fillcolor=lightblue]
	140321215930176 -> 140321216157088
	140321216157088 [label=AccumulateGrad]
	140321216154160 -> 140321216156992
	140321216154544 -> 140321213903488
	140321215931696 [label="stage4.2.fuse_layers.0.3.0.weight
 (18, 144, 1, 1)" fillcolor=lightblue]
	140321215931696 -> 140321216154544
	140321216154544 [label=AccumulateGrad]
	140321213902624 -> 140321223783856
	140321215931776 [label="stage4.2.fuse_layers.0.3.1.weight
 (18)" fillcolor=lightblue]
	140321215931776 -> 140321213902624
	140321213902624 [label=AccumulateGrad]
	140321213904352 -> 140321223783856
	140321215931856 [label="stage4.2.fuse_layers.0.3.1.bias
 (18)" fillcolor=lightblue]
	140321215931856 -> 140321213904352
	140321213904352 [label=AccumulateGrad]
	140321474593408 -> 140321454072320
	140321474593408 [label=UpsampleBilinear2DBackward0]
	140321255309168 -> 140321474593408
	140321255309168 [label=ReluBackward0]
	140321213906176 -> 140321255309168
	140321213906176 [label=AddBackward0]
	140321216164576 -> 140321213906176
	140321216164576 [label=AddBackward0]
	140321216160160 -> 140321216164576
	140321216160160 [label=AddBackward0]
	140321216163856 -> 140321216160160
	140321216163856 [label=NativeBatchNormBackward0]
	140321216159296 -> 140321216163856
	140321216159296 [label=ConvolutionBackward0]
	140321259687168 -> 140321216159296
	140321216164336 -> 140321216159296
	140321215932256 [label="stage4.2.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140321215932256 -> 140321216164336
	140321216164336 [label=AccumulateGrad]
	140321216160448 -> 140321216163856
	140321215932336 [label="stage4.2.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140321215932336 -> 140321216160448
	140321216160448 [label=AccumulateGrad]
	140321216158480 -> 140321216163856
	140321215932416 [label="stage4.2.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140321215932416 -> 140321216158480
	140321216158480 [label=AccumulateGrad]
	140321223619824 -> 140321216160160
	140321216159488 -> 140321216164576
	140321216159488 [label=UpsampleBilinear2DBackward0]
	140321216164816 -> 140321216159488
	140321216164816 [label=NativeBatchNormBackward0]
	140321216163520 -> 140321216164816
	140321216163520 [label=ConvolutionBackward0]
	140321213899984 -> 140321216163520
	140321216166352 -> 140321216163520
	140321215932816 [label="stage4.2.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140321215932816 -> 140321216166352
	140321216166352 [label=AccumulateGrad]
	140321216164480 -> 140321216164816
	140321215932896 [label="stage4.2.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140321215932896 -> 140321216164480
	140321216164480 [label=AccumulateGrad]
	140321216159440 -> 140321216164816
	140321215932976 [label="stage4.2.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140321215932976 -> 140321216159440
	140321216159440 [label=AccumulateGrad]
	140321216157472 -> 140321213906176
	140321216157472 [label=UpsampleBilinear2DBackward0]
	140321216165344 -> 140321216157472
	140321216165344 [label=NativeBatchNormBackward0]
	140321216166160 -> 140321216165344
	140321216166160 [label=ConvolutionBackward0]
	140321216153824 -> 140321216166160
	140321216166208 -> 140321216166160
	140321215933376 [label="stage4.2.fuse_layers.1.3.0.weight
 (36, 144, 1, 1)" fillcolor=lightblue]
	140321215933376 -> 140321216166208
	140321216166208 [label=AccumulateGrad]
	140321216164528 -> 140321216165344
	140321215933456 [label="stage4.2.fuse_layers.1.3.1.weight
 (36)" fillcolor=lightblue]
	140321215933456 -> 140321216164528
	140321216164528 [label=AccumulateGrad]
	140321216160544 -> 140321216165344
	140321215933536 [label="stage4.2.fuse_layers.1.3.1.bias
 (36)" fillcolor=lightblue]
	140321215933536 -> 140321216160544
	140321216160544 [label=AccumulateGrad]
	140321223223968 -> 140321454072320
	140321223223968 [label=UpsampleBilinear2DBackward0]
	140321223225744 -> 140321223223968
	140321223225744 [label=ReluBackward0]
	140321216165680 -> 140321223225744
	140321216165680 [label=AddBackward0]
	140321216167504 -> 140321216165680
	140321216167504 [label=AddBackward0]
	140321216167888 -> 140321216167504
	140321216167888 [label=AddBackward0]
	140321216167696 -> 140321216167888
	140321216167696 [label=NativeBatchNormBackward0]
	140321216560768 -> 140321216167696
	140321216560768 [label=ConvolutionBackward0]
	140321216556880 -> 140321216560768
	140321216556880 [label=ReluBackward0]
	140321216556064 -> 140321216556880
	140321216556064 [label=NativeBatchNormBackward0]
	140321216555776 -> 140321216556064
	140321216555776 [label=ConvolutionBackward0]
	140321259687168 -> 140321216555776
	140321216555392 -> 140321216555776
	140321215934016 [label="stage4.2.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321215934016 -> 140321216555392
	140321216555392 [label=AccumulateGrad]
	140321216555920 -> 140321216556064
	140321215934096 [label="stage4.2.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140321215934096 -> 140321216555920
	140321216555920 [label=AccumulateGrad]
	140321216556592 -> 140321216556064
	140321215934176 [label="stage4.2.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140321215934176 -> 140321216556592
	140321216556592 [label=AccumulateGrad]
	140321216556256 -> 140321216560768
	140321215934656 [label="stage4.2.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140321215934656 -> 140321216556256
	140321216556256 [label=AccumulateGrad]
	140321216560960 -> 140321216167696
	140321215934736 [label="stage4.2.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140321215934736 -> 140321216560960
	140321216560960 [label=AccumulateGrad]
	140321216560816 -> 140321216167696
	140321215934816 [label="stage4.2.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140321215934816 -> 140321216560816
	140321216560816 [label=AccumulateGrad]
	140321216167024 -> 140321216167888
	140321216167024 [label=NativeBatchNormBackward0]
	140321216555440 -> 140321216167024
	140321216555440 [label=ConvolutionBackward0]
	140321223619824 -> 140321216555440
	140321216555536 -> 140321216555440
	140321215935056 [label="stage4.2.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140321215935056 -> 140321216555536
	140321216555536 [label=AccumulateGrad]
	140321216556208 -> 140321216167024
	140321215935136 [label="stage4.2.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140321215935136 -> 140321216556208
	140321216556208 [label=AccumulateGrad]
	140321216556736 -> 140321216167024
	140321215935216 [label="stage4.2.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140321215935216 -> 140321216556736
	140321216556736 [label=AccumulateGrad]
	140321213899984 -> 140321216167504
	140321216165488 -> 140321216165680
	140321216165488 [label=UpsampleBilinear2DBackward0]
	140321216167072 -> 140321216165488
	140321216167072 [label=NativeBatchNormBackward0]
	140321216554912 -> 140321216167072
	140321216554912 [label=ConvolutionBackward0]
	140321216153824 -> 140321216554912
	140321216554864 -> 140321216554912
	140321215935616 [label="stage4.2.fuse_layers.2.3.0.weight
 (72, 144, 1, 1)" fillcolor=lightblue]
	140321215935616 -> 140321216554864
	140321216554864 [label=AccumulateGrad]
	140321216555584 -> 140321216167072
	140321215935696 [label="stage4.2.fuse_layers.2.3.1.weight
 (72)" fillcolor=lightblue]
	140321215935696 -> 140321216555584
	140321216555584 [label=AccumulateGrad]
	140321216558608 -> 140321216167072
	140321215935776 [label="stage4.2.fuse_layers.2.3.1.bias
 (72)" fillcolor=lightblue]
	140321215935776 -> 140321216558608
	140321216558608 [label=AccumulateGrad]
	140321223225792 -> 140321454072320
	140321223225792 [label=UpsampleBilinear2DBackward0]
	140321223228576 -> 140321223225792
	140321223228576 [label=ReluBackward0]
	140321216166256 -> 140321223228576
	140321216166256 [label=AddBackward0]
	140321216554576 -> 140321216166256
	140321216554576 [label=AddBackward0]
	140321216554720 -> 140321216554576
	140321216554720 [label=AddBackward0]
	140321216554096 -> 140321216554720
	140321216554096 [label=NativeBatchNormBackward0]
	140321216553904 -> 140321216554096
	140321216553904 [label=ConvolutionBackward0]
	140321216553520 -> 140321216553904
	140321216553520 [label=ReluBackward0]
	140321216553088 -> 140321216553520
	140321216553088 [label=NativeBatchNormBackward0]
	140321216552800 -> 140321216553088
	140321216552800 [label=ConvolutionBackward0]
	140321216552416 -> 140321216552800
	140321216552416 [label=ReluBackward0]
	140321216552176 -> 140321216552416
	140321216552176 [label=NativeBatchNormBackward0]
	140321216551888 -> 140321216552176
	140321216551888 [label=ConvolutionBackward0]
	140321259687168 -> 140321216551888
	140321216551504 -> 140321216551888
	140321215936176 [label="stage4.2.fuse_layers.3.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321215936176 -> 140321216551504
	140321216551504 [label=AccumulateGrad]
	140321216552032 -> 140321216552176
	140321215936256 [label="stage4.2.fuse_layers.3.0.0.1.weight
 (18)" fillcolor=lightblue]
	140321215936256 -> 140321216552032
	140321216552032 [label=AccumulateGrad]
	140321216552224 -> 140321216552176
	140321215936336 [label="stage4.2.fuse_layers.3.0.0.1.bias
 (18)" fillcolor=lightblue]
	140321215936336 -> 140321216552224
	140321216552224 [label=AccumulateGrad]
	140321216552560 -> 140321216552800
	140321215936816 [label="stage4.2.fuse_layers.3.0.1.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140321215936816 -> 140321216552560
	140321216552560 [label=AccumulateGrad]
	140321216552896 -> 140321216553088
	140321215936896 [label="stage4.2.fuse_layers.3.0.1.1.weight
 (18)" fillcolor=lightblue]
	140321215936896 -> 140321216552896
	140321216552896 [label=AccumulateGrad]
	140321216553376 -> 140321216553088
	140321215936976 [label="stage4.2.fuse_layers.3.0.1.1.bias
 (18)" fillcolor=lightblue]
	140321215936976 -> 140321216553376
	140321216553376 [label=AccumulateGrad]
	140321216553424 -> 140321216553904
	140321215937456 [label="stage4.2.fuse_layers.3.0.2.0.weight
 (144, 18, 3, 3)" fillcolor=lightblue]
	140321215937456 -> 140321216553424
	140321216553424 [label=AccumulateGrad]
	140321216554048 -> 140321216554096
	140321215937536 [label="stage4.2.fuse_layers.3.0.2.1.weight
 (144)" fillcolor=lightblue]
	140321215937536 -> 140321216554048
	140321216554048 [label=AccumulateGrad]
	140321216554192 -> 140321216554096
	140321215937616 [label="stage4.2.fuse_layers.3.0.2.1.bias
 (144)" fillcolor=lightblue]
	140321215937616 -> 140321216554192
	140321216554192 [label=AccumulateGrad]
	140321216554240 -> 140321216554720
	140321216554240 [label=NativeBatchNormBackward0]
	140321216552080 -> 140321216554240
	140321216552080 [label=ConvolutionBackward0]
	140321216552704 -> 140321216552080
	140321216552704 [label=ReluBackward0]
	140321216551408 -> 140321216552704
	140321216551408 [label=NativeBatchNormBackward0]
	140321216551072 -> 140321216551408
	140321216551072 [label=ConvolutionBackward0]
	140321223619824 -> 140321216551072
	140321216550688 -> 140321216551072
	140321215938016 [label="stage4.2.fuse_layers.3.1.0.0.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140321215938016 -> 140321216550688
	140321216550688 [label=AccumulateGrad]
	140321216551360 -> 140321216551408
	140321215938096 [label="stage4.2.fuse_layers.3.1.0.1.weight
 (36)" fillcolor=lightblue]
	140321215938096 -> 140321216551360
	140321216551360 [label=AccumulateGrad]
	140321216551744 -> 140321216551408
	140321215938176 [label="stage4.2.fuse_layers.3.1.0.1.bias
 (36)" fillcolor=lightblue]
	140321215938176 -> 140321216551744
	140321216551744 [label=AccumulateGrad]
	140321216551552 -> 140321216552080
	140321215938496 [label="stage4.2.fuse_layers.3.1.1.0.weight
 (144, 36, 3, 3)" fillcolor=lightblue]
	140321215938496 -> 140321216551552
	140321216551552 [label=AccumulateGrad]
	140321216553232 -> 140321216554240
	140321216200784 [label="stage4.2.fuse_layers.3.1.1.1.weight
 (144)" fillcolor=lightblue]
	140321216200784 -> 140321216553232
	140321216553232 [label=AccumulateGrad]
	140321216553760 -> 140321216554240
	140321216200864 [label="stage4.2.fuse_layers.3.1.1.1.bias
 (144)" fillcolor=lightblue]
	140321216200864 -> 140321216553760
	140321216553760 [label=AccumulateGrad]
	140321216554768 -> 140321216554576
	140321216554768 [label=NativeBatchNormBackward0]
	140321216551216 -> 140321216554768
	140321216551216 [label=ConvolutionBackward0]
	140321213899984 -> 140321216551216
	140321216550400 -> 140321216551216
	140321216201184 [label="stage4.2.fuse_layers.3.2.0.0.weight
 (144, 72, 3, 3)" fillcolor=lightblue]
	140321216201184 -> 140321216550400
	140321216550400 [label=AccumulateGrad]
	140321216553568 -> 140321216554768
	140321216201264 [label="stage4.2.fuse_layers.3.2.0.1.weight
 (144)" fillcolor=lightblue]
	140321216201264 -> 140321216553568
	140321216553568 [label=AccumulateGrad]
	140321216554432 -> 140321216554768
	140321216201344 [label="stage4.2.fuse_layers.3.2.0.1.bias
 (144)" fillcolor=lightblue]
	140321216201344 -> 140321216554432
	140321216554432 [label=AccumulateGrad]
	140321216153824 -> 140321216166256
	140321248361152 -> 140321255077680
	140321216201744 [label="head.0.weight
 (270, 270, 1, 1)" fillcolor=lightblue]
	140321216201744 -> 140321248361152
	140321248361152 [label=AccumulateGrad]
	140321467944288 -> 140321255077680
	140321216201824 [label="head.0.bias
 (270)" fillcolor=lightblue]
	140321216201824 -> 140321467944288
	140321467944288 [label=AccumulateGrad]
	140321254963472 -> 140321474227712
	140321216201904 [label="head.1.weight
 (270)" fillcolor=lightblue]
	140321216201904 -> 140321254963472
	140321254963472 [label=AccumulateGrad]
	140321254963664 -> 140321474227712
	140321216201984 [label="head.1.bias
 (270)" fillcolor=lightblue]
	140321216201984 -> 140321254963664
	140321254963664 [label=AccumulateGrad]
	140321259550800 -> 140321440313600
	140321216202384 [label="head.3.weight
 (9, 270, 1, 1)" fillcolor=lightblue]
	140321216202384 -> 140321259550800
	140321259550800 [label=AccumulateGrad]
	140321467785536 -> 140321440313600
	140321216202464 [label="head.3.bias
 (9)" fillcolor=lightblue]
	140321216202464 -> 140321467785536
	140321467785536 [label=AccumulateGrad]
	140321440313600 -> 140321213736400
}
