digraph {
	graph [size="904.8,904.8"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140367129939872 [label="
 (1, 9, 64, 64)" fillcolor=darkolivegreen1]
	140367130017120 [label=ConvolutionBackward0]
	140367130017360 -> 140367130017120
	140367130017360 [label=ReluBackward0]
	140367433701152 -> 140367130017360
	140367433701152 [label=NativeBatchNormBackward0]
	140367130016880 -> 140367433701152
	140367130016880 [label=ConvolutionBackward0]
	140367130016496 -> 140367130016880
	140367130016496 [label=CatBackward0]
	140367130017072 -> 140367130016496
	140367130017072 [label=ReluBackward0]
	140367130016064 -> 140367130017072
	140367130016064 [label=AddBackward0]
	140367130015680 -> 140367130016064
	140367130015680 [label=AddBackward0]
	140367130016592 -> 140367130015680
	140367130016592 [label=AddBackward0]
	140367130015728 -> 140367130016592
	140367130015728 [label=ReluBackward0]
	140367130015584 -> 140367130015728
	140367130015584 [label=AddBackward0]
	140367130015488 -> 140367130015584
	140367130015488 [label=NativeBatchNormBackward0]
	140367130015296 -> 140367130015488
	140367130015296 [label=ConvolutionBackward0]
	140367130015104 -> 140367130015296
	140367130015104 [label=ReluBackward0]
	140367130014816 -> 140367130015104
	140367130014816 [label=NativeBatchNormBackward0]
	140367130014720 -> 140367130014816
	140367130014720 [label=ConvolutionBackward0]
	140367130015536 -> 140367130014720
	140367130015536 [label=ReluBackward0]
	140367130014432 -> 140367130015536
	140367130014432 [label=AddBackward0]
	140367130014336 -> 140367130014432
	140367130014336 [label=NativeBatchNormBackward0]
	140367130014192 -> 140367130014336
	140367130014192 [label=ConvolutionBackward0]
	140367130013616 -> 140367130014192
	140367130013616 [label=ReluBackward0]
	140367130013808 -> 140367130013616
	140367130013808 [label=NativeBatchNormBackward0]
	140367130013712 -> 140367130013808
	140367130013712 [label=ConvolutionBackward0]
	140367130014384 -> 140367130013712
	140367130014384 [label=ReluBackward0]
	140367130012944 -> 140367130014384
	140367130012944 [label=AddBackward0]
	140367130012608 -> 140367130012944
	140367130012608 [label=NativeBatchNormBackward0]
	140367130012512 -> 140367130012608
	140367130012512 [label=ConvolutionBackward0]
	140367130012224 -> 140367130012512
	140367130012224 [label=ReluBackward0]
	140367130011888 -> 140367130012224
	140367130011888 [label=NativeBatchNormBackward0]
	140367130011648 -> 140367130011888
	140367130011648 [label=ConvolutionBackward0]
	140367130012896 -> 140367130011648
	140367130012896 [label=ReluBackward0]
	140367130011216 -> 140367130012896
	140367130011216 [label=AddBackward0]
	140367130010784 -> 140367130011216
	140367130010784 [label=NativeBatchNormBackward0]
	140367130010544 -> 140367130010784
	140367130010544 [label=ConvolutionBackward0]
	140367130010160 -> 140367130010544
	140367130010160 [label=ReluBackward0]
	140367130010064 -> 140367130010160
	140367130010064 [label=NativeBatchNormBackward0]
	140367130009824 -> 140367130010064
	140367130009824 [label=ConvolutionBackward0]
	140367130011168 -> 140367130009824
	140367130011168 [label=ReluBackward0]
	140367130009200 -> 140367130011168
	140367130009200 [label=AddBackward0]
	140367130009008 -> 140367130009200
	140367130009008 [label=AddBackward0]
	140367130008624 -> 140367130009008
	140367130008624 [label=AddBackward0]
	140367130008288 -> 140367130008624
	140367130008288 [label=ReluBackward0]
	140367130008192 -> 140367130008288
	140367130008192 [label=AddBackward0]
	140367130008000 -> 140367130008192
	140367130008000 [label=NativeBatchNormBackward0]
	140367130007760 -> 140367130008000
	140367130007760 [label=ConvolutionBackward0]
	140367130006320 -> 140367130007760
	140367130006320 [label=ReluBackward0]
	140367130007088 -> 140367130006320
	140367130007088 [label=NativeBatchNormBackward0]
	140367130006992 -> 140367130007088
	140367130006992 [label=ConvolutionBackward0]
	140367130008048 -> 140367130006992
	140367130008048 [label=ReluBackward0]
	140367130006704 -> 140367130008048
	140367130006704 [label=AddBackward0]
	140367130006272 -> 140367130006704
	140367130006272 [label=NativeBatchNormBackward0]
	140367130006464 -> 140367130006272
	140367130006464 [label=ConvolutionBackward0]
	140367130006224 -> 140367130006464
	140367130006224 [label=ReluBackward0]
	140367130006080 -> 140367130006224
	140367130006080 [label=NativeBatchNormBackward0]
	140367130004928 -> 140367130006080
	140367130004928 [label=ConvolutionBackward0]
	140367130006656 -> 140367130004928
	140367130006656 [label=ReluBackward0]
	140367130005552 -> 140367130006656
	140367130005552 [label=AddBackward0]
	140367130005456 -> 140367130005552
	140367130005456 [label=NativeBatchNormBackward0]
	140367130005312 -> 140367130005456
	140367130005312 [label=ConvolutionBackward0]
	140367130005120 -> 140367130005312
	140367130005120 [label=ReluBackward0]
	140367130004976 -> 140367130005120
	140367130004976 [label=NativeBatchNormBackward0]
	140367130004832 -> 140367130004976
	140367130004832 [label=ConvolutionBackward0]
	140367130005216 -> 140367130004832
	140367130005216 [label=ReluBackward0]
	140367130004112 -> 140367130005216
	140367130004112 [label=AddBackward0]
	140367130004304 -> 140367130004112
	140367130004304 [label=NativeBatchNormBackward0]
	140367130004160 -> 140367130004304
	140367130004160 [label=ConvolutionBackward0]
	140367130003968 -> 140367130004160
	140367130003968 [label=ReluBackward0]
	140367130003488 -> 140367130003968
	140367130003488 [label=NativeBatchNormBackward0]
	140367130003728 -> 140367130003488
	140367130003728 [label=ConvolutionBackward0]
	140367130004352 -> 140367130003728
	140367130004352 [label=ReluBackward0]
	140367130003392 -> 140367130004352
	140367130003392 [label=AddBackward0]
	140367130003296 -> 140367130003392
	140367130003296 [label=AddBackward0]
	140367130002720 -> 140367130003296
	140367130002720 [label=AddBackward0]
	140367130002864 -> 140367130002720
	140367130002864 [label=ReluBackward0]
	140367130002432 -> 140367130002864
	140367130002432 [label=AddBackward0]
	140367130002624 -> 140367130002432
	140367130002624 [label=NativeBatchNormBackward0]
	140367130002480 -> 140367130002624
	140367130002480 [label=ConvolutionBackward0]
	140367130002288 -> 140367130002480
	140367130002288 [label=ReluBackward0]
	140367130001760 -> 140367130002288
	140367130001760 [label=NativeBatchNormBackward0]
	140367130002000 -> 140367130001760
	140367130002000 [label=ConvolutionBackward0]
	140367130002672 -> 140367130002000
	140367130002672 [label=ReluBackward0]
	140367130001904 -> 140367130002672
	140367130001904 [label=AddBackward0]
	140367131552128 -> 140367130001904
	140367131552128 [label=NativeBatchNormBackward0]
	140367131557504 -> 140367131552128
	140367131557504 [label=ConvolutionBackward0]
	140367131557120 -> 140367131557504
	140367131557120 [label=ReluBackward0]
	140367131556880 -> 140367131557120
	140367131556880 [label=NativeBatchNormBackward0]
	140367131556784 -> 140367131556880
	140367131556784 [label=ConvolutionBackward0]
	140367131557552 -> 140367131556784
	140367131557552 [label=ReluBackward0]
	140367131556112 -> 140367131557552
	140367131556112 [label=AddBackward0]
	140367131555872 -> 140367131556112
	140367131555872 [label=NativeBatchNormBackward0]
	140367131555728 -> 140367131555872
	140367131555728 [label=ConvolutionBackward0]
	140367131555200 -> 140367131555728
	140367131555200 [label=ReluBackward0]
	140367131555008 -> 140367131555200
	140367131555008 [label=NativeBatchNormBackward0]
	140367131554672 -> 140367131555008
	140367131554672 [label=ConvolutionBackward0]
	140367131556064 -> 140367131554672
	140367131556064 [label=ReluBackward0]
	140367131554288 -> 140367131556064
	140367131554288 [label=AddBackward0]
	140367131553856 -> 140367131554288
	140367131553856 [label=NativeBatchNormBackward0]
	140367131553760 -> 140367131553856
	140367131553760 [label=ConvolutionBackward0]
	140367131553328 -> 140367131553760
	140367131553328 [label=ReluBackward0]
	140367131553232 -> 140367131553328
	140367131553232 [label=NativeBatchNormBackward0]
	140367131552176 -> 140367131553232
	140367131552176 [label=ConvolutionBackward0]
	140367131554240 -> 140367131552176
	140367131554240 [label=ReluBackward0]
	140367131552320 -> 140367131554240
	140367131552320 [label=AddBackward0]
	140367131552224 -> 140367131552320
	140367131552224 [label=AddBackward0]
	140367131550880 -> 140367131552224
	140367131550880 [label=ReluBackward0]
	140367131551648 -> 140367131550880
	140367131551648 [label=AddBackward0]
	140367131551552 -> 140367131551648
	140367131551552 [label=NativeBatchNormBackward0]
	140367131551408 -> 140367131551552
	140367131551408 [label=ConvolutionBackward0]
	140367131551216 -> 140367131551408
	140367131551216 [label=ReluBackward0]
	140367131551072 -> 140367131551216
	140367131551072 [label=NativeBatchNormBackward0]
	140367131550976 -> 140367131551072
	140367131550976 [label=ConvolutionBackward0]
	140367131551600 -> 140367131550976
	140367131551600 [label=ReluBackward0]
	140367131550640 -> 140367131551600
	140367131550640 [label=AddBackward0]
	140367131549536 -> 140367131550640
	140367131549536 [label=NativeBatchNormBackward0]
	140367131550256 -> 140367131549536
	140367131550256 [label=ConvolutionBackward0]
	140367131549824 -> 140367131550256
	140367131549824 [label=ReluBackward0]
	140367131549920 -> 140367131549824
	140367131549920 [label=NativeBatchNormBackward0]
	140367131549488 -> 140367131549920
	140367131549488 [label=ConvolutionBackward0]
	140367131550592 -> 140367131549488
	140367131550592 [label=ReluBackward0]
	140367131549008 -> 140367131550592
	140367131549008 [label=AddBackward0]
	140367131549392 -> 140367131549008
	140367131549392 [label=NativeBatchNormBackward0]
	140367131549248 -> 140367131549392
	140367131549248 [label=ConvolutionBackward0]
	140367131548912 -> 140367131549248
	140367131548912 [label=ReluBackward0]
	140367131548768 -> 140367131548912
	140367131548768 [label=NativeBatchNormBackward0]
	140367131548672 -> 140367131548768
	140367131548672 [label=ConvolutionBackward0]
	140367131549440 -> 140367131548672
	140367131549440 [label=ReluBackward0]
	140367131548384 -> 140367131549440
	140367131548384 [label=AddBackward0]
	140367131548288 -> 140367131548384
	140367131548288 [label=NativeBatchNormBackward0]
	140367131547616 -> 140367131548288
	140367131547616 [label=ConvolutionBackward0]
	140367131547904 -> 140367131547616
	140367131547904 [label=ReluBackward0]
	140367131547328 -> 140367131547904
	140367131547328 [label=NativeBatchNormBackward0]
	140367131547520 -> 140367131547328
	140367131547520 [label=ConvolutionBackward0]
	140367131548336 -> 140367131547520
	140367131548336 [label=ReluBackward0]
	140367131547232 -> 140367131548336
	140367131547232 [label=AddBackward0]
	140367131547136 -> 140367131547232
	140367131547136 [label=AddBackward0]
	140367131546992 -> 140367131547136
	140367131546992 [label=ReluBackward0]
	140367131546848 -> 140367131546992
	140367131546848 [label=AddBackward0]
	140367131546368 -> 140367131546848
	140367131546368 [label=NativeBatchNormBackward0]
	140367131546560 -> 140367131546368
	140367131546560 [label=ConvolutionBackward0]
	140367131545744 -> 140367131546560
	140367131545744 [label=ReluBackward0]
	140367131545696 -> 140367131545744
	140367131545696 [label=NativeBatchNormBackward0]
	140367131542672 -> 140367131545696
	140367131542672 [label=ConvolutionBackward0]
	140367131546800 -> 140367131542672
	140367131546800 [label=ReluBackward0]
	140367131544160 -> 140367131546800
	140367131544160 [label=AddBackward0]
	140367131544544 -> 140367131544160
	140367131544544 [label=NativeBatchNormBackward0]
	140367131544256 -> 140367131544544
	140367131544256 [label=ConvolutionBackward0]
	140367131543776 -> 140367131544256
	140367131543776 [label=ReluBackward0]
	140367131543392 -> 140367131543776
	140367131543392 [label=NativeBatchNormBackward0]
	140367131543440 -> 140367131543392
	140367131543440 [label=ConvolutionBackward0]
	140367131544592 -> 140367131543440
	140367131544592 [label=ReluBackward0]
	140367131542816 -> 140367131544592
	140367131542816 [label=AddBackward0]
	140367131542336 -> 140367131542816
	140367131542336 [label=NativeBatchNormBackward0]
	140367131542240 -> 140367131542336
	140367131542240 [label=ConvolutionBackward0]
	140367131541760 -> 140367131542240
	140367131541760 [label=ReluBackward0]
	140367131541904 -> 140367131541760
	140367131541904 [label=NativeBatchNormBackward0]
	140367131541808 -> 140367131541904
	140367131541808 [label=ConvolutionBackward0]
	140367131542768 -> 140367131541808
	140367131542768 [label=ReluBackward0]
	140367388229296 -> 140367131542768
	140367388229296 [label=AddBackward0]
	140367131541664 -> 140367388229296
	140367131541664 [label=NativeBatchNormBackward0]
	140367132311504 -> 140367131541664
	140367132311504 [label=ConvolutionBackward0]
	140367132311264 -> 140367132311504
	140367132311264 [label=ReluBackward0]
	140367132310112 -> 140367132311264
	140367132310112 [label=NativeBatchNormBackward0]
	140367132310880 -> 140367132310112
	140367132310880 [label=ConvolutionBackward0]
	140367132308432 -> 140367132310880
	140367132308432 [label=ReluBackward0]
	140367132310592 -> 140367132308432
	140367132310592 [label=AddBackward0]
	140367132310496 -> 140367132310592
	140367132310496 [label=AddBackward0]
	140367132310064 -> 140367132310496
	140367132310064 [label=ReluBackward0]
	140367132310208 -> 140367132310064
	140367132310208 [label=AddBackward0]
	140367132309584 -> 140367132310208
	140367132309584 [label=NativeBatchNormBackward0]
	140367132309920 -> 140367132309584
	140367132309920 [label=ConvolutionBackward0]
	140367132309296 -> 140367132309920
	140367132309296 [label=ReluBackward0]
	140367132309440 -> 140367132309296
	140367132309440 [label=NativeBatchNormBackward0]
	140367132309344 -> 140367132309440
	140367132309344 [label=ConvolutionBackward0]
	140367132310160 -> 140367132309344
	140367132310160 [label=ReluBackward0]
	140367132309056 -> 140367132310160
	140367132309056 [label=AddBackward0]
	140367132308960 -> 140367132309056
	140367132308960 [label=NativeBatchNormBackward0]
	140367132308816 -> 140367132308960
	140367132308816 [label=ConvolutionBackward0]
	140367132308576 -> 140367132308816
	140367132308576 [label=ReluBackward0]
	140367132301376 -> 140367132308576
	140367132301376 [label=NativeBatchNormBackward0]
	140367132305696 -> 140367132301376
	140367132305696 [label=ConvolutionBackward0]
	140367132308672 -> 140367132305696
	140367132308672 [label=ReluBackward0]
	140367132306992 -> 140367132308672
	140367132306992 [label=AddBackward0]
	140367132307376 -> 140367132306992
	140367132307376 [label=NativeBatchNormBackward0]
	140367132307088 -> 140367132307376
	140367132307088 [label=ConvolutionBackward0]
	140367132306608 -> 140367132307088
	140367132306608 [label=ReluBackward0]
	140367132306416 -> 140367132306608
	140367132306416 [label=NativeBatchNormBackward0]
	140367132305984 -> 140367132306416
	140367132305984 [label=ConvolutionBackward0]
	140367132307424 -> 140367132305984
	140367132307424 [label=ReluBackward0]
	140367132301040 -> 140367132307424
	140367132301040 [label=AddBackward0]
	140367132305024 -> 140367132301040
	140367132305024 [label=NativeBatchNormBackward0]
	140367132305168 -> 140367132305024
	140367132305168 [label=ConvolutionBackward0]
	140367132304976 -> 140367132305168
	140367132304976 [label=ReluBackward0]
	140367132304832 -> 140367132304976
	140367132304832 [label=NativeBatchNormBackward0]
	140367132304400 -> 140367132304832
	140367132304400 [label=ConvolutionBackward0]
	140367132304448 -> 140367132304400
	140367132304448 [label=ReluBackward0]
	140367132303968 -> 140367132304448
	140367132303968 [label=AddBackward0]
	140367132304304 -> 140367132303968
	140367132304304 [label=AddBackward0]
	140367132304160 -> 140367132304304
	140367132304160 [label=ReluBackward0]
	140367132303920 -> 140367132304160
	140367132303920 [label=AddBackward0]
	140367132303824 -> 140367132303920
	140367132303824 [label=NativeBatchNormBackward0]
	140367132303392 -> 140367132303824
	140367132303392 [label=ConvolutionBackward0]
	140367132303632 -> 140367132303392
	140367132303632 [label=ReluBackward0]
	140367132303584 -> 140367132303632
	140367132303584 [label=NativeBatchNormBackward0]
	140367132303296 -> 140367132303584
	140367132303296 [label=ConvolutionBackward0]
	140367132303872 -> 140367132303296
	140367132303872 [label=ReluBackward0]
	140367132298880 -> 140367132303872
	140367132298880 [label=AddBackward0]
	140367132302480 -> 140367132298880
	140367132302480 [label=NativeBatchNormBackward0]
	140367132301952 -> 140367132302480
	140367132301952 [label=ConvolutionBackward0]
	140367132302336 -> 140367132301952
	140367132302336 [label=ReluBackward0]
	140367132302192 -> 140367132302336
	140367132302192 [label=NativeBatchNormBackward0]
	140367132302096 -> 140367132302192
	140367132302096 [label=ConvolutionBackward0]
	140367132302624 -> 140367132302096
	140367132302624 [label=ReluBackward0]
	140367132301472 -> 140367132302624
	140367132301472 [label=AddBackward0]
	140367132301280 -> 140367132301472
	140367132301280 [label=NativeBatchNormBackward0]
	140367132301088 -> 140367132301280
	140367132301088 [label=ConvolutionBackward0]
	140367132298208 -> 140367132301088
	140367132298208 [label=ReluBackward0]
	140367132300320 -> 140367132298208
	140367132300320 [label=NativeBatchNormBackward0]
	140367132299888 -> 140367132300320
	140367132299888 [label=ConvolutionBackward0]
	140367132302144 -> 140367132299888
	140367132302144 [label=ReluBackward0]
	140367132299552 -> 140367132302144
	140367132299552 [label=AddBackward0]
	140367132298976 -> 140367132299552
	140367132298976 [label=NativeBatchNormBackward0]
	140367132302960 -> 140367132298976
	140367132302960 [label=ConvolutionBackward0]
	140367132298112 -> 140367132302960
	140367132298112 [label=ReluBackward0]
	140367132297920 -> 140367132298112
	140367132297920 [label=NativeBatchNormBackward0]
	140367132297824 -> 140367132297920
	140367132297824 [label=ConvolutionBackward0]
	140367132299456 -> 140367132297824
	140367132299456 [label=ReluBackward0]
	140367132297392 -> 140367132299456
	140367132297392 [label=AddBackward0]
	140367132297008 -> 140367132297392
	140367132297008 [label=ReluBackward0]
	140367132296864 -> 140367132297008
	140367132296864 [label=AddBackward0]
	140367132297344 -> 140367132296864
	140367132297344 [label=NativeBatchNormBackward0]
	140367132297200 -> 140367132297344
	140367132297200 [label=ConvolutionBackward0]
	140367132296192 -> 140367132297200
	140367132296192 [label=ReluBackward0]
	140367132296336 -> 140367132296192
	140367132296336 [label=NativeBatchNormBackward0]
	140367132296720 -> 140367132296336
	140367132296720 [label=ConvolutionBackward0]
	140367132297296 -> 140367132296720
	140367132297296 [label=ReluBackward0]
	140367132296240 -> 140367132297296
	140367132296240 [label=AddBackward0]
	140367132295616 -> 140367132296240
	140367132295616 [label=NativeBatchNormBackward0]
	140367132295568 -> 140367132295616
	140367132295568 [label=ConvolutionBackward0]
	140367132295808 -> 140367132295568
	140367132295808 [label=ReluBackward0]
	140367132295664 -> 140367132295808
	140367132295664 [label=NativeBatchNormBackward0]
	140367132301184 -> 140367132295664
	140367132301184 [label=ConvolutionBackward0]
	140367132295760 -> 140367132301184
	140367132295760 [label=ReluBackward0]
	140367132301568 -> 140367132295760
	140367132301568 [label=AddBackward0]
	140367132303056 -> 140367132301568
	140367132303056 [label=NativeBatchNormBackward0]
	140367377975136 -> 140367132303056
	140367377975136 [label=ConvolutionBackward0]
	140367135655632 -> 140367377975136
	140367135655632 [label=ReluBackward0]
	140367387742592 -> 140367135655632
	140367387742592 [label=NativeBatchNormBackward0]
	140367387752384 -> 140367387742592
	140367387752384 [label=ConvolutionBackward0]
	140367132298784 -> 140367387752384
	140367132298784 [label=ReluBackward0]
	140367368391936 -> 140367132298784
	140367368391936 [label=AddBackward0]
	140367160987984 -> 140367368391936
	140367160987984 [label=NativeBatchNormBackward0]
	140367144429760 -> 140367160987984
	140367144429760 [label=ConvolutionBackward0]
	140367173839712 -> 140367144429760
	140367173839712 [label=ReluBackward0]
	140367173932448 -> 140367173839712
	140367173932448 [label=NativeBatchNormBackward0]
	140367377826432 -> 140367173932448
	140367377826432 [label=ConvolutionBackward0]
	140367368391744 -> 140367377826432
	140367368391744 [label=ReluBackward0]
	140367378063536 -> 140367368391744
	140367378063536 [label=NativeBatchNormBackward0]
	140367175074960 -> 140367378063536
	140367175074960 [label=ConvolutionBackward0]
	140367135393104 -> 140367175074960
	140367135393104 [label=ReluBackward0]
	140367152133648 -> 140367135393104
	140367152133648 [label=AddBackward0]
	140367152127456 -> 140367152133648
	140367152127456 [label=NativeBatchNormBackward0]
	140367152125728 -> 140367152127456
	140367152125728 [label=ConvolutionBackward0]
	140367144201440 -> 140367152125728
	140367144201440 [label=ReluBackward0]
	140367144202256 -> 140367144201440
	140367144202256 [label=NativeBatchNormBackward0]
	140367144202784 -> 140367144202256
	140367144202784 [label=ConvolutionBackward0]
	140367144202976 -> 140367144202784
	140367144202976 [label=ReluBackward0]
	140367144190640 -> 140367144202976
	140367144190640 [label=NativeBatchNormBackward0]
	140367387411264 -> 140367144190640
	140367387411264 [label=ConvolutionBackward0]
	140367152127600 -> 140367387411264
	140367152127600 [label=ReluBackward0]
	140367130648320 -> 140367152127600
	140367130648320 [label=AddBackward0]
	140367130647600 -> 140367130648320
	140367130647600 [label=NativeBatchNormBackward0]
	140367130647456 -> 140367130647600
	140367130647456 [label=ConvolutionBackward0]
	140367130646736 -> 140367130647456
	140367130646736 [label=ReluBackward0]
	140367130646928 -> 140367130646736
	140367130646928 [label=NativeBatchNormBackward0]
	140367130646832 -> 140367130646928
	140367130646832 [label=ConvolutionBackward0]
	140367130646400 -> 140367130646832
	140367130646400 [label=ReluBackward0]
	140367130646112 -> 140367130646400
	140367130646112 [label=NativeBatchNormBackward0]
	140367130646016 -> 140367130646112
	140367130646016 [label=ConvolutionBackward0]
	140367130648128 -> 140367130646016
	140367130648128 [label=ReluBackward0]
	140367130644096 -> 140367130648128
	140367130644096 [label=AddBackward0]
	140367130645200 -> 140367130644096
	140367130645200 [label=NativeBatchNormBackward0]
	140367130644960 -> 140367130645200
	140367130644960 [label=ConvolutionBackward0]
	140367130644576 -> 140367130644960
	140367130644576 [label=ReluBackward0]
	140367130644288 -> 140367130644576
	140367130644288 [label=NativeBatchNormBackward0]
	140367130644192 -> 140367130644288
	140367130644192 [label=ConvolutionBackward0]
	140367130643664 -> 140367130644192
	140367130643664 [label=ReluBackward0]
	140367130643424 -> 140367130643664
	140367130643424 [label=NativeBatchNormBackward0]
	140367130643088 -> 140367130643424
	140367130643088 [label=ConvolutionBackward0]
	140367130645248 -> 140367130643088
	140367130645248 [label=ReluBackward0]
	140367130642608 -> 140367130645248
	140367130642608 [label=AddBackward0]
	140367130642416 -> 140367130642608
	140367130642416 [label=NativeBatchNormBackward0]
	140367130642176 -> 140367130642416
	140367130642176 [label=ConvolutionBackward0]
	140367130641600 -> 140367130642176
	140367130641600 [label=ReluBackward0]
	140367130641456 -> 140367130641600
	140367130641456 [label=NativeBatchNormBackward0]
	140367130641072 -> 140367130641456
	140367130641072 [label=ConvolutionBackward0]
	140367130641168 -> 140367130641072
	140367130641168 [label=ReluBackward0]
	140367130641024 -> 140367130641168
	140367130641024 [label=NativeBatchNormBackward0]
	140367130640928 -> 140367130641024
	140367130640928 [label=ConvolutionBackward0]
	140367130640640 -> 140367130640928
	140367130640640 [label=ReluBackward0]
	140367130640496 -> 140367130640640
	140367130640496 [label=NativeBatchNormBackward0]
	140367130656624 -> 140367130640496
	140367130656624 [label=ConvolutionBackward0]
	140367130648992 -> 140367130656624
	140367130648992 [label=ReluBackward0]
	140367130656672 -> 140367130648992
	140367130656672 [label=NativeBatchNormBackward0]
	140367130656288 -> 140367130656672
	140367130656288 [label=ConvolutionBackward0]
	140367130656144 -> 140367130656288
	140367388488592 [label="conv1.weight
 (64, 3, 3, 3)" fillcolor=lightblue]
	140367388488592 -> 140367130656144
	140367130656144 [label=AccumulateGrad]
	140367130655568 -> 140367130656672
	140367128597504 [label="bn1.weight
 (64)" fillcolor=lightblue]
	140367128597504 -> 140367130655568
	140367130655568 [label=AccumulateGrad]
	140367130656000 -> 140367130656672
	140367128595824 [label="bn1.bias
 (64)" fillcolor=lightblue]
	140367128595824 -> 140367130656000
	140367130656000 [label=AccumulateGrad]
	140367130649088 -> 140367130656624
	140367126526816 [label="conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140367126526816 -> 140367130649088
	140367130649088 [label=AccumulateGrad]
	140367130648944 -> 140367130640496
	140367126526736 [label="bn2.weight
 (64)" fillcolor=lightblue]
	140367126526736 -> 140367130648944
	140367130648944 [label=AccumulateGrad]
	140367130640592 -> 140367130640496
	140367126526896 [label="bn2.bias
 (64)" fillcolor=lightblue]
	140367126526896 -> 140367130640592
	140367130640592 [label=AccumulateGrad]
	140367130640688 -> 140367130640928
	140367126525136 [label="layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	140367126525136 -> 140367130640688
	140367130640688 [label=AccumulateGrad]
	140367130640976 -> 140367130641024
	140367126524816 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	140367126524816 -> 140367130640976
	140367130640976 [label=AccumulateGrad]
	140367130641120 -> 140367130641024
	140367126525216 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	140367126525216 -> 140367130641120
	140367130641120 [label=AccumulateGrad]
	140367130641216 -> 140367130641072
	140367126523616 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140367126523616 -> 140367130641216
	140367130641216 [label=AccumulateGrad]
	140367130641408 -> 140367130641456
	140367126523456 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	140367126523456 -> 140367130641408
	140367130641408 [label=AccumulateGrad]
	140367130641552 -> 140367130641456
	140367126523696 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	140367126523696 -> 140367130641552
	140367130641552 [label=AccumulateGrad]
	140367130641360 -> 140367130642176
	140367126522256 [label="layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140367126522256 -> 140367130641360
	140367130641360 [label=AccumulateGrad]
	140367130642224 -> 140367130642416
	140367126522096 [label="layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	140367126522096 -> 140367130642224
	140367130642224 [label=AccumulateGrad]
	140367130642368 -> 140367130642416
	140367126522336 [label="layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	140367126522336 -> 140367130642368
	140367130642368 [label=AccumulateGrad]
	140367130642464 -> 140367130642608
	140367130642464 [label=NativeBatchNormBackward0]
	140367130640736 -> 140367130642464
	140367130640736 [label=ConvolutionBackward0]
	140367130640640 -> 140367130640736
	140367130641264 -> 140367130640736
	140367126520656 [label="layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140367126520656 -> 140367130641264
	140367130641264 [label=AccumulateGrad]
	140367130641504 -> 140367130642464
	140367126520096 [label="layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	140367126520096 -> 140367130641504
	140367130641504 [label=AccumulateGrad]
	140367130642128 -> 140367130642464
	140367126520736 [label="layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	140367126520736 -> 140367130642128
	140367130642128 [label=AccumulateGrad]
	140367130642080 -> 140367130643088
	140367126520976 [label="layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	140367126520976 -> 140367130642080
	140367130642080 [label=AccumulateGrad]
	140367130643232 -> 140367130643424
	140367126518896 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	140367126518896 -> 140367130643232
	140367130643232 [label=AccumulateGrad]
	140367130643520 -> 140367130643424
	140367126524976 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	140367126524976 -> 140367130643520
	140367130643520 [label=AccumulateGrad]
	140367130643712 -> 140367130644192
	140367126517856 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140367126517856 -> 140367130643712
	140367130643712 [label=AccumulateGrad]
	140367130644240 -> 140367130644288
	140367126517776 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	140367126517776 -> 140367130644240
	140367130644240 [label=AccumulateGrad]
	140367130644528 -> 140367130644288
	140367126517936 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	140367126517936 -> 140367130644528
	140367130644528 [label=AccumulateGrad]
	140367130644144 -> 140367130644960
	140367126516496 [label="layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140367126516496 -> 140367130644144
	140367130644144 [label=AccumulateGrad]
	140367130644864 -> 140367130645200
	140367126516416 [label="layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	140367126516416 -> 140367130644864
	140367130644864 [label=AccumulateGrad]
	140367130645008 -> 140367130645200
	140367126516656 [label="layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	140367126516656 -> 140367130645008
	140367130645008 [label=AccumulateGrad]
	140367130645248 -> 140367130644096
	140367130645680 -> 140367130646016
	140367126520896 [label="layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	140367126520896 -> 140367130645680
	140367130645680 [label=AccumulateGrad]
	140367130646064 -> 140367130646112
	140367126515056 [label="layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	140367126515056 -> 140367130646064
	140367130646064 [label=AccumulateGrad]
	140367130646352 -> 140367130646112
	140367126515136 [label="layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	140367126515136 -> 140367130646352
	140367130646352 [label=AccumulateGrad]
	140367130645632 -> 140367130646832
	140367126513616 [label="layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140367126513616 -> 140367130645632
	140367130645632 [label=AccumulateGrad]
	140367130646880 -> 140367130646928
	140367126513536 [label="layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	140367126513536 -> 140367130646880
	140367130646880 [label=AccumulateGrad]
	140367130647168 -> 140367130646928
	140367126513776 [label="layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	140367126513776 -> 140367130647168
	140367130647168 [label=AccumulateGrad]
	140367130647216 -> 140367130647456
	140367126512096 [label="layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140367126512096 -> 140367130647216
	140367130647216 [label=AccumulateGrad]
	140367130645584 -> 140367130647600
	140367126512016 [label="layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	140367126512016 -> 140367130645584
	140367130645584 [label=AccumulateGrad]
	140367130641648 -> 140367130647600
	140367126512256 [label="layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	140367126512256 -> 140367130641648
	140367130641648 [label=AccumulateGrad]
	140367130648128 -> 140367130648320
	140367413136016 -> 140367387411264
	140367126515296 [label="layer1.3.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	140367126515296 -> 140367413136016
	140367413136016 [label=AccumulateGrad]
	140367144200672 -> 140367144190640
	140367126523296 [label="layer1.3.bn1.weight
 (64)" fillcolor=lightblue]
	140367126523296 -> 140367144200672
	140367144200672 [label=AccumulateGrad]
	140367144200336 -> 140367144190640
	140367126523536 [label="layer1.3.bn1.bias
 (64)" fillcolor=lightblue]
	140367126523536 -> 140367144200336
	140367144200336 [label=AccumulateGrad]
	140367144198608 -> 140367144202784
	140367126519056 [label="layer1.3.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140367126519056 -> 140367144198608
	140367144198608 [label=AccumulateGrad]
	140367144198656 -> 140367144202256
	140367126518656 [label="layer1.3.bn2.weight
 (64)" fillcolor=lightblue]
	140367126518656 -> 140367144198656
	140367144198656 [label=AccumulateGrad]
	140367144200816 -> 140367144202256
	140367126519296 [label="layer1.3.bn2.bias
 (64)" fillcolor=lightblue]
	140367126519296 -> 140367144200816
	140367144200816 [label=AccumulateGrad]
	140367144201104 -> 140367152125728
	140367126513936 [label="layer1.3.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140367126513936 -> 140367144201104
	140367144201104 [label=AccumulateGrad]
	140367152134992 -> 140367152127456
	140367126513696 [label="layer1.3.bn3.weight
 (256)" fillcolor=lightblue]
	140367126513696 -> 140367152134992
	140367152134992 [label=AccumulateGrad]
	140367152131920 -> 140367152127456
	140367126514176 [label="layer1.3.bn3.bias
 (256)" fillcolor=lightblue]
	140367126514176 -> 140367152131920
	140367152131920 [label=AccumulateGrad]
	140367152127600 -> 140367152133648
	140367135400880 -> 140367175074960
	140367128542928 [label="transition1.0.0.weight
 (18, 256, 3, 3)" fillcolor=lightblue]
	140367128542928 -> 140367135400880
	140367135400880 [label=AccumulateGrad]
	140367135405776 -> 140367378063536
	140367128542768 [label="transition1.0.1.weight
 (18)" fillcolor=lightblue]
	140367128542768 -> 140367135405776
	140367135405776 [label=AccumulateGrad]
	140367135402176 -> 140367378063536
	140367128542848 [label="transition1.0.1.bias
 (18)" fillcolor=lightblue]
	140367128542848 -> 140367135402176
	140367135402176 [label=AccumulateGrad]
	140367161180016 -> 140367377826432
	140367128538768 [label="stage2.0.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128538768 -> 140367161180016
	140367161180016 [label=AccumulateGrad]
	140367377833968 -> 140367173932448
	140367128538448 [label="stage2.0.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140367128538448 -> 140367377833968
	140367377833968 [label=AccumulateGrad]
	140367377837568 -> 140367173932448
	140367128538928 [label="stage2.0.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140367128538928 -> 140367377837568
	140367377837568 [label=AccumulateGrad]
	140367152038144 -> 140367144429760
	140367128538528 [label="stage2.0.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128538528 -> 140367152038144
	140367152038144 [label=AccumulateGrad]
	140367144427888 -> 140367160987984
	140367128536928 [label="stage2.0.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140367128536928 -> 140367144427888
	140367144427888 [label=AccumulateGrad]
	140367131825808 -> 140367160987984
	140367128537008 [label="stage2.0.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140367128537008 -> 140367131825808
	140367131825808 [label=AccumulateGrad]
	140367368391744 -> 140367368391936
	140367368391840 -> 140367387752384
	140367128535488 [label="stage2.0.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128535488 -> 140367368391840
	140367368391840 [label=AccumulateGrad]
	140367387742496 -> 140367387742592
	140367128535408 [label="stage2.0.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140367128535408 -> 140367387742496
	140367387742496 [label=AccumulateGrad]
	140367135608304 -> 140367387742592
	140367128535568 [label="stage2.0.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140367128535568 -> 140367135608304
	140367135608304 [label=AccumulateGrad]
	140367135656304 -> 140367377975136
	140367128537088 [label="stage2.0.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128537088 -> 140367135656304
	140367135656304 [label=AccumulateGrad]
	140367377975568 -> 140367132303056
	140367128533888 [label="stage2.0.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140367128533888 -> 140367377975568
	140367377975568 [label=AccumulateGrad]
	140367377975040 -> 140367132303056
	140367128533968 [label="stage2.0.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140367128533968 -> 140367377975040
	140367377975040 [label=AccumulateGrad]
	140367132298784 -> 140367132301568
	140367132295280 -> 140367132301184
	140367128532448 [label="stage2.0.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128532448 -> 140367132295280
	140367132295280 [label=AccumulateGrad]
	140367132298736 -> 140367132295664
	140367128532368 [label="stage2.0.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140367128532368 -> 140367132298736
	140367132298736 [label=AccumulateGrad]
	140367132295376 -> 140367132295664
	140367128532528 [label="stage2.0.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140367128532528 -> 140367132295376
	140367132295376 [label=AccumulateGrad]
	140367132295328 -> 140367132295568
	140367128534048 [label="stage2.0.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128534048 -> 140367132295328
	140367132295328 [label=AccumulateGrad]
	140367132295712 -> 140367132295616
	140367128530848 [label="stage2.0.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140367128530848 -> 140367132295712
	140367132295712 [label=AccumulateGrad]
	140367132296048 -> 140367132295616
	140367128530928 [label="stage2.0.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140367128530928 -> 140367132296048
	140367132296048 [label=AccumulateGrad]
	140367132295760 -> 140367132296240
	140367132295952 -> 140367132296720
	140367128529408 [label="stage2.0.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128529408 -> 140367132295952
	140367132295952 [label=AccumulateGrad]
	140367132297104 -> 140367132296336
	140367128529328 [label="stage2.0.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140367128529328 -> 140367132297104
	140367132297104 [label=AccumulateGrad]
	140367132296960 -> 140367132296336
	140367128529488 [label="stage2.0.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140367128529488 -> 140367132296960
	140367132296960 [label=AccumulateGrad]
	140367132297056 -> 140367132297200
	140367128531008 [label="stage2.0.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128531008 -> 140367132297056
	140367132297056 [label=AccumulateGrad]
	140367132297152 -> 140367132297344
	140367128527808 [label="stage2.0.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140367128527808 -> 140367132297152
	140367132297152 [label=AccumulateGrad]
	140367132296912 -> 140367132297344
	140367128527888 [label="stage2.0.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140367128527888 -> 140367132296912
	140367132296912 [label=AccumulateGrad]
	140367132297296 -> 140367132296864
	140367132298064 -> 140367132297392
	140367132298064 [label=UpsampleBilinear2DBackward0]
	140367132296624 -> 140367132298064
	140367132296624 [label=NativeBatchNormBackward0]
	140367132296144 -> 140367132296624
	140367132296144 [label=ConvolutionBackward0]
	140367132296384 -> 140367132296144
	140367132296384 [label=ReluBackward0]
	140367132295856 -> 140367132296384
	140367132295856 [label=AddBackward0]
	140367132298592 -> 140367132295856
	140367132298592 [label=NativeBatchNormBackward0]
	140367377975616 -> 140367132298592
	140367377975616 [label=ConvolutionBackward0]
	140367358479328 -> 140367377975616
	140367358479328 [label=ReluBackward0]
	140367131827008 -> 140367358479328
	140367131827008 [label=NativeBatchNormBackward0]
	140367378064976 -> 140367131827008
	140367378064976 [label=ConvolutionBackward0]
	140367132295472 -> 140367378064976
	140367132295472 [label=ReluBackward0]
	140367175076064 -> 140367132295472
	140367175076064 [label=AddBackward0]
	140367152120736 -> 140367175076064
	140367152120736 [label=NativeBatchNormBackward0]
	140367144201296 -> 140367152120736
	140367144201296 [label=ConvolutionBackward0]
	140367413134144 -> 140367144201296
	140367413134144 [label=ReluBackward0]
	140367130648464 -> 140367413134144
	140367130648464 [label=NativeBatchNormBackward0]
	140367130646160 -> 140367130648464
	140367130646160 [label=ConvolutionBackward0]
	140367152134512 -> 140367130646160
	140367152134512 [label=ReluBackward0]
	140367130644912 -> 140367152134512
	140367130644912 [label=AddBackward0]
	140367130645776 -> 140367130644912
	140367130645776 [label=NativeBatchNormBackward0]
	140367130644624 -> 140367130645776
	140367130644624 [label=ConvolutionBackward0]
	140367130643184 -> 140367130644624
	140367130643184 [label=ReluBackward0]
	140367130643136 -> 140367130643184
	140367130643136 [label=NativeBatchNormBackward0]
	140367130656576 -> 140367130643136
	140367130656576 [label=ConvolutionBackward0]
	140367130645728 -> 140367130656576
	140367130645728 [label=ReluBackward0]
	140367130656096 -> 140367130645728
	140367130656096 [label=AddBackward0]
	140367130655472 -> 140367130656096
	140367130655472 [label=NativeBatchNormBackward0]
	140367130655904 -> 140367130655472
	140367130655904 [label=ConvolutionBackward0]
	140367130654944 -> 140367130655904
	140367130654944 [label=ReluBackward0]
	140367130654416 -> 140367130654944
	140367130654416 [label=NativeBatchNormBackward0]
	140367130655088 -> 140367130654416
	140367130655088 [label=ConvolutionBackward0]
	140367130656240 -> 140367130655088
	140367130656240 [label=ReluBackward0]
	140367130654656 -> 140367130656240
	140367130654656 [label=NativeBatchNormBackward0]
	140367130654272 -> 140367130654656
	140367130654272 [label=ConvolutionBackward0]
	140367135393104 -> 140367130654272
	140367130653312 -> 140367130654272
	140367128541248 [label="transition1.1.0.0.weight
 (36, 256, 3, 3)" fillcolor=lightblue]
	140367128541248 -> 140367130653312
	140367130653312 [label=AccumulateGrad]
	140367130653744 -> 140367130654656
	140367128541008 [label="transition1.1.0.1.weight
 (36)" fillcolor=lightblue]
	140367128541008 -> 140367130653744
	140367130653744 [label=AccumulateGrad]
	140367130654800 -> 140367130654656
	140367128541408 [label="transition1.1.0.1.bias
 (36)" fillcolor=lightblue]
	140367128541408 -> 140367130654800
	140367130654800 [label=AccumulateGrad]
	140367130653936 -> 140367130655088
	140367128541728 [label="stage2.0.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128541728 -> 140367130653936
	140367130653936 [label=AccumulateGrad]
	140367130654896 -> 140367130654416
	140367128541328 [label="stage2.0.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140367128541328 -> 140367130654896
	140367130654896 [label=AccumulateGrad]
	140367130655328 -> 140367130654416
	140367128542128 [label="stage2.0.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140367128542128 -> 140367130655328
	140367130655328 [label=AccumulateGrad]
	140367130655616 -> 140367130655904
	140367128527968 [label="stage2.0.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128527968 -> 140367130655616
	140367130655616 [label=AccumulateGrad]
	140367130655232 -> 140367130655472
	140367128537808 [label="stage2.0.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140367128537808 -> 140367130655232
	140367130655232 [label=AccumulateGrad]
	140367130655952 -> 140367130655472
	140367128538048 [label="stage2.0.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140367128538048 -> 140367130655952
	140367130655952 [label=AccumulateGrad]
	140367130656240 -> 140367130656096
	140367130656432 -> 140367130656576
	140367128534528 [label="stage2.0.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128534528 -> 140367130656432
	140367130656432 [label=AccumulateGrad]
	140367130641312 -> 140367130643136
	140367128534128 [label="stage2.0.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140367128534128 -> 140367130641312
	140367130641312 [label=AccumulateGrad]
	140367130640784 -> 140367130643136
	140367128534768 [label="stage2.0.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140367128534768 -> 140367130640784
	140367130640784 [label=AccumulateGrad]
	140367130643040 -> 140367130644624
	140367128538288 [label="stage2.0.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128538288 -> 140367130643040
	140367130643040 [label=AccumulateGrad]
	140367130643472 -> 140367130645776
	140367128530448 [label="stage2.0.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140367128530448 -> 140367130643472
	140367130643472 [label=AccumulateGrad]
	140367130644336 -> 140367130645776
	140367128530688 [label="stage2.0.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140367128530688 -> 140367130644336
	140367130644336 [label=AccumulateGrad]
	140367130645728 -> 140367130644912
	140367130646448 -> 140367130646160
	140367128527168 [label="stage2.0.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128527168 -> 140367130646448
	140367130646448 [label=AccumulateGrad]
	140367130647120 -> 140367130648464
	140367128526928 [label="stage2.0.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140367128526928 -> 140367130647120
	140367130647120 [label=AccumulateGrad]
	140367130647552 -> 140367130648464
	140367128527408 [label="stage2.0.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140367128527408 -> 140367130647552
	140367130647552 [label=AccumulateGrad]
	140367144192608 -> 140367144201296
	140367128476512 [label="stage2.0.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128476512 -> 140367144192608
	140367144192608 [label=AccumulateGrad]
	140367144201872 -> 140367152120736
	140367128476272 [label="stage2.0.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140367128476272 -> 140367144201872
	140367144201872 [label=AccumulateGrad]
	140367144205568 -> 140367152120736
	140367128476352 [label="stage2.0.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140367128476352 -> 140367144205568
	140367144205568 [label=AccumulateGrad]
	140367152134512 -> 140367175076064
	140367161176080 -> 140367378064976
	140367128474832 [label="stage2.0.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128474832 -> 140367161176080
	140367161176080 [label=AccumulateGrad]
	140367398163296 -> 140367131827008
	140367128474752 [label="stage2.0.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140367128474752 -> 140367398163296
	140367398163296 [label=AccumulateGrad]
	140367368392128 -> 140367131827008
	140367128474992 [label="stage2.0.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140367128474992 -> 140367368392128
	140367368392128 [label=AccumulateGrad]
	140367135616416 -> 140367377975616
	140367128473472 [label="stage2.0.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128473472 -> 140367135616416
	140367135616416 [label=AccumulateGrad]
	140367161346848 -> 140367132298592
	140367128473232 [label="stage2.0.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140367128473232 -> 140367161346848
	140367161346848 [label=AccumulateGrad]
	140367132303488 -> 140367132298592
	140367128473312 [label="stage2.0.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140367128473312 -> 140367132303488
	140367132303488 [label=AccumulateGrad]
	140367132295472 -> 140367132295856
	140367132295904 -> 140367132296144
	140367128471792 [label="stage2.0.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140367128471792 -> 140367132295904
	140367132295904 [label=AccumulateGrad]
	140367132296480 -> 140367132296624
	140367128471712 [label="stage2.0.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140367128471712 -> 140367132296480
	140367132296480 [label=AccumulateGrad]
	140367132297440 -> 140367132296624
	140367128471952 [label="stage2.0.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140367128471952 -> 140367132297440
	140367132297440 [label=AccumulateGrad]
	140367132297872 -> 140367132297824
	140367128467232 [label="stage3.0.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128467232 -> 140367132297872
	140367132297872 [label=AccumulateGrad]
	140367132298160 -> 140367132297920
	140367128466912 [label="stage3.0.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140367128466912 -> 140367132298160
	140367132298160 [label=AccumulateGrad]
	140367132297728 -> 140367132297920
	140367128467392 [label="stage3.0.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140367128467392 -> 140367132297728
	140367132297728 [label=AccumulateGrad]
	140367132298496 -> 140367132302960
	140367128467152 [label="stage3.0.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128467152 -> 140367132298496
	140367132298496 [label=AccumulateGrad]
	140367132298688 -> 140367132298976
	140367128465392 [label="stage3.0.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140367128465392 -> 140367132298688
	140367132298688 [label=AccumulateGrad]
	140367132297680 -> 140367132298976
	140367128465632 [label="stage3.0.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140367128465632 -> 140367132297680
	140367132297680 [label=AccumulateGrad]
	140367132299456 -> 140367132299552
	140367132300032 -> 140367132299888
	140367128464112 [label="stage3.0.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128464112 -> 140367132300032
	140367132300032 [label=AccumulateGrad]
	140367132300464 -> 140367132300320
	140367128463872 [label="stage3.0.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140367128463872 -> 140367132300464
	140367132300464 [label=AccumulateGrad]
	140367132299696 -> 140367132300320
	140367128464192 [label="stage3.0.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140367128464192 -> 140367132299696
	140367132299696 [label=AccumulateGrad]
	140367132300752 -> 140367132301088
	140367128465712 [label="stage3.0.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128465712 -> 140367132300752
	140367132300752 [label=AccumulateGrad]
	140367132301232 -> 140367132301280
	140367128462352 [label="stage3.0.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140367128462352 -> 140367132301232
	140367132301232 [label=AccumulateGrad]
	140367132301760 -> 140367132301280
	140367128462592 [label="stage3.0.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140367128462592 -> 140367132301760
	140367132301760 [label=AccumulateGrad]
	140367132302144 -> 140367132301472
	140367132302048 -> 140367132302096
	140367128476672 [label="stage3.0.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128476672 -> 140367132302048
	140367132302048 [label=AccumulateGrad]
	140367132301856 -> 140367132302192
	140367128476432 [label="stage3.0.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140367128476432 -> 140367132301856
	140367132301856 [label=AccumulateGrad]
	140367132302000 -> 140367132302192
	140367128476912 [label="stage3.0.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140367128476912 -> 140367132302000
	140367132302000 [label=AccumulateGrad]
	140367132302528 -> 140367132301952
	140367128462672 [label="stage3.0.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128462672 -> 140367132302528
	140367132302528 [label=AccumulateGrad]
	140367132301904 -> 140367132302480
	140367128472752 [label="stage3.0.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140367128472752 -> 140367132301904
	140367132301904 [label=AccumulateGrad]
	140367132301424 -> 140367132302480
	140367128473152 [label="stage3.0.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140367128473152 -> 140367132301424
	140367132301424 [label=AccumulateGrad]
	140367132302624 -> 140367132298880
	140367132303008 -> 140367132303296
	140367128469312 [label="stage3.0.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128469312 -> 140367132303008
	140367132303008 [label=AccumulateGrad]
	140367132303152 -> 140367132303584
	140367128469072 [label="stage3.0.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140367128469072 -> 140367132303152
	140367132303152 [label=AccumulateGrad]
	140367132302816 -> 140367132303584
	140367128469712 [label="stage3.0.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140367128469712 -> 140367132302816
	140367132302816 [label=AccumulateGrad]
	140367132303680 -> 140367132303392
	140367128473392 [label="stage3.0.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128473392 -> 140367132303680
	140367132303680 [label=AccumulateGrad]
	140367132303536 -> 140367132303824
	140367128465552 [label="stage3.0.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140367128465552 -> 140367132303536
	140367132303536 [label=AccumulateGrad]
	140367132303776 -> 140367132303824
	140367128465792 [label="stage3.0.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140367128465792 -> 140367132303776
	140367132303776 [label=AccumulateGrad]
	140367132303872 -> 140367132303920
	140367132304208 -> 140367132304304
	140367132304208 [label=UpsampleBilinear2DBackward0]
	140367132303344 -> 140367132304208
	140367132303344 [label=NativeBatchNormBackward0]
	140367132303104 -> 140367132303344
	140367132303104 [label=ConvolutionBackward0]
	140367132302720 -> 140367132303104
	140367132302720 [label=ReluBackward0]
	140367132301712 -> 140367132302720
	140367132301712 [label=AddBackward0]
	140367132302240 -> 140367132301712
	140367132302240 [label=NativeBatchNormBackward0]
	140367132301664 -> 140367132302240
	140367132301664 [label=ConvolutionBackward0]
	140367132299936 -> 140367132301664
	140367132299936 [label=ReluBackward0]
	140367132300176 -> 140367132299936
	140367132300176 [label=NativeBatchNormBackward0]
	140367132296528 -> 140367132300176
	140367132296528 [label=ConvolutionBackward0]
	140367132302288 -> 140367132296528
	140367132302288 [label=ReluBackward0]
	140367132296672 -> 140367132302288
	140367132296672 [label=AddBackward0]
	140367132295424 -> 140367132296672
	140367132295424 [label=NativeBatchNormBackward0]
	140367168504304 -> 140367132295424
	140367168504304 [label=ConvolutionBackward0]
	140367152135856 -> 140367168504304
	140367152135856 [label=ReluBackward0]
	140367144200912 -> 140367152135856
	140367144200912 [label=NativeBatchNormBackward0]
	140367130648368 -> 140367144200912
	140367130648368 [label=ConvolutionBackward0]
	140367132295520 -> 140367130648368
	140367132295520 [label=ReluBackward0]
	140367130655760 -> 140367132295520
	140367130655760 [label=AddBackward0]
	140367130640544 -> 140367130655760
	140367130640544 [label=NativeBatchNormBackward0]
	140367130640880 -> 140367130640544
	140367130640880 [label=ConvolutionBackward0]
	140367130654080 -> 140367130640880
	140367130654080 [label=ReluBackward0]
	140367130654224 -> 140367130654080
	140367130654224 [label=NativeBatchNormBackward0]
	140367130654128 -> 140367130654224
	140367130654128 [label=ConvolutionBackward0]
	140367130642656 -> 140367130654128
	140367130642656 [label=ReluBackward0]
	140367130653264 -> 140367130642656
	140367130653264 [label=AddBackward0]
	140367130652544 -> 140367130653264
	140367130652544 [label=NativeBatchNormBackward0]
	140367130652256 -> 140367130652544
	140367130652256 [label=ConvolutionBackward0]
	140367130652640 -> 140367130652256
	140367130652640 [label=ReluBackward0]
	140367130652208 -> 140367130652640
	140367130652208 [label=NativeBatchNormBackward0]
	140367130651392 -> 140367130652208
	140367130651392 [label=ConvolutionBackward0]
	140367130653456 -> 140367130651392
	140367130653456 [label=ReluBackward0]
	140367130650720 -> 140367130653456
	140367130650720 [label=AddBackward0]
	140367130651536 -> 140367130650720
	140367130651536 [label=NativeBatchNormBackward0]
	140367130651248 -> 140367130651536
	140367130651248 [label=ConvolutionBackward0]
	140367132297008 -> 140367130651248
	140367130650192 -> 140367130651248
	140367128469952 [label="stage2.0.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140367128469952 -> 140367130650192
	140367130650192 [label=AccumulateGrad]
	140367130651056 -> 140367130651536
	140367128469552 [label="stage2.0.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140367128469552 -> 140367130651056
	140367130651056 [label=AccumulateGrad]
	140367130652064 -> 140367130651536
	140367128470192 [label="stage2.0.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140367128470192 -> 140367130652064
	140367130652064 [label=AccumulateGrad]
	140367132296384 -> 140367130650720
	140367130651872 -> 140367130651392
	140367128462112 [label="stage3.0.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128462112 -> 140367130651872
	140367130651872 [label=AccumulateGrad]
	140367130652400 -> 140367130652208
	140367128461712 [label="stage3.0.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140367128461712 -> 140367130652400
	140367130652400 [label=AccumulateGrad]
	140367130652592 -> 140367130652208
	140367128462512 [label="stage3.0.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140367128462512 -> 140367130652592
	140367130652592 [label=AccumulateGrad]
	140367130651920 -> 140367130652256
	140367128378288 [label="stage3.0.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128378288 -> 140367130651920
	140367130651920 [label=AccumulateGrad]
	140367130653168 -> 140367130652544
	140367128378048 [label="stage3.0.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140367128378048 -> 140367130653168
	140367130653168 [label=AccumulateGrad]
	140367130653072 -> 140367130652544
	140367128378128 [label="stage3.0.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140367128378128 -> 140367130653072
	140367130653072 [label=AccumulateGrad]
	140367130653456 -> 140367130653264
	140367130653552 -> 140367130654128
	140367128376608 [label="stage3.0.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128376608 -> 140367130653552
	140367130653552 [label=AccumulateGrad]
	140367130653984 -> 140367130654224
	140367128376528 [label="stage3.0.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140367128376528 -> 140367130653984
	140367130653984 [label=AccumulateGrad]
	140367130653408 -> 140367130654224
	140367128376768 [label="stage3.0.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140367128376768 -> 140367130653408
	140367130653408 [label=AccumulateGrad]
	140367130655424 -> 140367130640880
	140367128375248 [label="stage3.0.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128375248 -> 140367130655424
	140367130655424 [label=AccumulateGrad]
	140367130640832 -> 140367130640544
	140367128375008 [label="stage3.0.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140367128375008 -> 140367130640832
	140367130640832 [label=AccumulateGrad]
	140367130654608 -> 140367130640544
	140367128375088 [label="stage3.0.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140367128375088 -> 140367130654608
	140367130654608 [label=AccumulateGrad]
	140367130642656 -> 140367130655760
	140367130646784 -> 140367130648368
	140367128373568 [label="stage3.0.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128373568 -> 140367130646784
	140367130646784 [label=AccumulateGrad]
	140367130645824 -> 140367144200912
	140367128373488 [label="stage3.0.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140367128373488 -> 140367130645824
	140367130645824 [label=AccumulateGrad]
	140367130648416 -> 140367144200912
	140367128373728 [label="stage3.0.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140367128373728 -> 140367130648416
	140367130648416 [label=AccumulateGrad]
	140367172835536 -> 140367168504304
	140367128372208 [label="stage3.0.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128372208 -> 140367172835536
	140367172835536 [label=AccumulateGrad]
	140367387752240 -> 140367132295424
	140367128371968 [label="stage3.0.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140367128371968 -> 140367387752240
	140367387752240 [label=AccumulateGrad]
	140367132295232 -> 140367132295424
	140367128372048 [label="stage3.0.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140367128372048 -> 140367132295232
	140367132295232 [label=AccumulateGrad]
	140367132295520 -> 140367132296672
	140367132297776 -> 140367132296528
	140367128370528 [label="stage3.0.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128370528 -> 140367132297776
	140367132297776 [label=AccumulateGrad]
	140367132298352 -> 140367132300176
	140367128370448 [label="stage3.0.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140367128370448 -> 140367132298352
	140367132298352 [label=AccumulateGrad]
	140367132299216 -> 140367132300176
	140367128370688 [label="stage3.0.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140367128370688 -> 140367132299216
	140367132299216 [label=AccumulateGrad]
	140367132301520 -> 140367132301664
	140367128369168 [label="stage3.0.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128369168 -> 140367132301520
	140367132301520 [label=AccumulateGrad]
	140367132301808 -> 140367132302240
	140367128368928 [label="stage3.0.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140367128368928 -> 140367132301808
	140367132301808 [label=AccumulateGrad]
	140367132301328 -> 140367132302240
	140367128369008 [label="stage3.0.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140367128369008 -> 140367132301328
	140367132301328 [label=AccumulateGrad]
	140367132302288 -> 140367132301712
	140367132301616 -> 140367132303104
	140367128312912 [label="stage3.0.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140367128312912 -> 140367132301616
	140367132301616 [label=AccumulateGrad]
	140367132303248 -> 140367132303344
	140367128312752 [label="stage3.0.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140367128312752 -> 140367132303248
	140367132303248 [label=AccumulateGrad]
	140367132303728 -> 140367132303344
	140367128313152 [label="stage3.0.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140367128313152 -> 140367132303728
	140367132303728 [label=AccumulateGrad]
	140367132304352 -> 140367132303968
	140367132304352 [label=UpsampleBilinear2DBackward0]
	140367132302768 -> 140367132304352
	140367132302768 [label=NativeBatchNormBackward0]
	140367132300416 -> 140367132302768
	140367132300416 [label=ConvolutionBackward0]
	140367132297584 -> 140367132300416
	140367132297584 [label=ReluBackward0]
	140367132296768 -> 140367132297584
	140367132296768 [label=AddBackward0]
	140367135392000 -> 140367132296768
	140367135392000 [label=NativeBatchNormBackward0]
	140367144203120 -> 140367135392000
	140367144203120 [label=ConvolutionBackward0]
	140367130643760 -> 140367144203120
	140367130643760 [label=ReluBackward0]
	140367130654560 -> 140367130643760
	140367130654560 [label=NativeBatchNormBackward0]
	140367130652736 -> 140367130654560
	140367130652736 [label=ConvolutionBackward0]
	140367132297248 -> 140367130652736
	140367132297248 [label=ReluBackward0]
	140367130652112 -> 140367132297248
	140367130652112 [label=AddBackward0]
	140367130651296 -> 140367130652112
	140367130651296 [label=NativeBatchNormBackward0]
	140367130650864 -> 140367130651296
	140367130650864 [label=ConvolutionBackward0]
	140367130650576 -> 140367130650864
	140367130650576 [label=ReluBackward0]
	140367130650384 -> 140367130650576
	140367130650384 [label=NativeBatchNormBackward0]
	140367130649568 -> 140367130650384
	140367130649568 [label=ConvolutionBackward0]
	140367130651440 -> 140367130649568
	140367130651440 [label=ReluBackward0]
	140367130649040 -> 140367130651440
	140367130649040 [label=AddBackward0]
	140367130649712 -> 140367130649040
	140367130649712 [label=NativeBatchNormBackward0]
	140367130649376 -> 140367130649712
	140367130649376 [label=ConvolutionBackward0]
	140367130649760 -> 140367130649376
	140367130649760 [label=ReluBackward0]
	140367130650000 -> 140367130649760
	140367130650000 [label=NativeBatchNormBackward0]
	140367130649472 -> 140367130650000
	140367130649472 [label=ConvolutionBackward0]
	140367130649520 -> 140367130649472
	140367130649520 [label=ReluBackward0]
	140367130650144 -> 140367130649520
	140367130650144 [label=AddBackward0]
	140367130650336 -> 140367130650144
	140367130650336 [label=NativeBatchNormBackward0]
	140367130650672 -> 140367130650336
	140367130650672 [label=ConvolutionBackward0]
	140367130651824 -> 140367130650672
	140367130651824 [label=ReluBackward0]
	140367130652496 -> 140367130651824
	140367130652496 [label=NativeBatchNormBackward0]
	140367130651776 -> 140367130652496
	140367130651776 [label=ConvolutionBackward0]
	140367130651152 -> 140367130651776
	140367130651152 [label=ReluBackward0]
	140367130652448 -> 140367130651152
	140367130652448 [label=NativeBatchNormBackward0]
	140367130652832 -> 140367130652448
	140367130652832 [label=ConvolutionBackward0]
	140367130653456 -> 140367130652832
	140367130653120 -> 140367130652832
	140367128539728 [label="transition2.2.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140367128539728 -> 140367130653120
	140367130653120 [label=AccumulateGrad]
	140367130653648 -> 140367130652448
	140367128539248 [label="transition2.2.0.1.weight
 (72)" fillcolor=lightblue]
	140367128539248 -> 140367130653648
	140367130653648 [label=AccumulateGrad]
	140367130652160 -> 140367130652448
	140367128541168 [label="transition2.2.0.1.bias
 (72)" fillcolor=lightblue]
	140367128541168 -> 140367130652160
	140367130652160 [label=AccumulateGrad]
	140367130653216 -> 140367130651776
	140367128367488 [label="stage3.0.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128367488 -> 140367130653216
	140367130653216 [label=AccumulateGrad]
	140367130651680 -> 140367130652496
	140367128367408 [label="stage3.0.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140367128367408 -> 140367130651680
	140367130651680 [label=AccumulateGrad]
	140367130651488 -> 140367130652496
	140367128367648 [label="stage3.0.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140367128367648 -> 140367130651488
	140367130651488 [label=AccumulateGrad]
	140367130651104 -> 140367130650672
	140367128366128 [label="stage3.0.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128366128 -> 140367130651104
	140367130651104 [label=AccumulateGrad]
	140367130650816 -> 140367130650336
	140367128365888 [label="stage3.0.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140367128365888 -> 140367130650816
	140367130650816 [label=AccumulateGrad]
	140367130652304 -> 140367130650336
	140367128365968 [label="stage3.0.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140367128365968 -> 140367130652304
	140367130652304 [label=AccumulateGrad]
	140367130651152 -> 140367130650144
	140367130650480 -> 140367130649472
	140367128364448 [label="stage3.0.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128364448 -> 140367130650480
	140367130650480 [label=AccumulateGrad]
	140367130649616 -> 140367130650000
	140367128364368 [label="stage3.0.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140367128364368 -> 140367130649616
	140367130649616 [label=AccumulateGrad]
	140367130649232 -> 140367130650000
	140367128364608 [label="stage3.0.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140367128364608 -> 140367130649232
	140367130649232 [label=AccumulateGrad]
	140367130649184 -> 140367130649376
	140367128363088 [label="stage3.0.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128363088 -> 140367130649184
	140367130649184 [label=AccumulateGrad]
	140367130649424 -> 140367130649712
	140367128379008 [label="stage3.0.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140367128379008 -> 140367130649424
	140367130649424 [label=AccumulateGrad]
	140367130650960 -> 140367130649712
	140367128379248 [label="stage3.0.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140367128379248 -> 140367130650960
	140367130650960 [label=AccumulateGrad]
	140367130649520 -> 140367130649040
	140367130649952 -> 140367130649568
	140367128375968 [label="stage3.0.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128375968 -> 140367130649952
	140367130649952 [label=AccumulateGrad]
	140367130650528 -> 140367130650384
	140367128375568 [label="stage3.0.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140367128375568 -> 140367130650528
	140367130650528 [label=AccumulateGrad]
	140367130650768 -> 140367130650384
	140367128376208 [label="stage3.0.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140367128376208 -> 140367130650768
	140367130650768 [label=AccumulateGrad]
	140367130650096 -> 140367130650864
	140367128372528 [label="stage3.0.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128372528 -> 140367130650096
	140367130650096 [label=AccumulateGrad]
	140367130650624 -> 140367130651296
	140367128371888 [label="stage3.0.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140367128371888 -> 140367130650624
	140367130650624 [label=AccumulateGrad]
	140367130651584 -> 140367130651296
	140367128372128 [label="stage3.0.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140367128372128 -> 140367130651584
	140367130651584 [label=AccumulateGrad]
	140367130651440 -> 140367130652112
	140367130651968 -> 140367130652736
	140367128368608 [label="stage3.0.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128368608 -> 140367130651968
	140367130651968 [label=AccumulateGrad]
	140367130653888 -> 140367130654560
	140367128368368 [label="stage3.0.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140367128368368 -> 140367130653888
	140367130653888 [label=AccumulateGrad]
	140367130654752 -> 140367130654560
	140367128368848 [label="stage3.0.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140367128368848 -> 140367130654752
	140367130654752 [label=AccumulateGrad]
	140367130645296 -> 140367144203120
	140367128365328 [label="stage3.0.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128365328 -> 140367130645296
	140367130645296 [label=AccumulateGrad]
	140367368391984 -> 140367135392000
	140367128364528 [label="stage3.0.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140367128364528 -> 140367368391984
	140367368391984 [label=AccumulateGrad]
	140367130642704 -> 140367135392000
	140367128364928 [label="stage3.0.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140367128364928 -> 140367130642704
	140367130642704 [label=AccumulateGrad]
	140367132297248 -> 140367132296768
	140367132299840 -> 140367132300416
	140367128311392 [label="stage3.0.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140367128311392 -> 140367132299840
	140367132299840 [label=AccumulateGrad]
	140367132302384 -> 140367132302768
	140367128311232 [label="stage3.0.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140367128311232 -> 140367132302384
	140367132302384 [label=AccumulateGrad]
	140367132304256 -> 140367132302768
	140367128311632 [label="stage3.0.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140367128311632 -> 140367132304256
	140367132304256 [label=AccumulateGrad]
	140367132304544 -> 140367132304400
	140367128307232 [label="stage3.1.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128307232 -> 140367132304544
	140367132304544 [label=AccumulateGrad]
	140367132304784 -> 140367132304832
	140367128302592 [label="stage3.1.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140367128302592 -> 140367132304784
	140367132304784 [label=AccumulateGrad]
	140367132304928 -> 140367132304832
	140367128306992 [label="stage3.1.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140367128306992 -> 140367132304928
	140367132304928 [label=AccumulateGrad]
	140367132304736 -> 140367132305168
	140367128301792 [label="stage3.1.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128301792 -> 140367132304736
	140367132304736 [label=AccumulateGrad]
	140367132305216 -> 140367132305024
	140367128301392 [label="stage3.1.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140367128301392 -> 140367132305216
	140367132305216 [label=AccumulateGrad]
	140367132305264 -> 140367132305024
	140367128301552 [label="stage3.1.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140367128301552 -> 140367132305264
	140367132305264 [label=AccumulateGrad]
	140367132304448 -> 140367132301040
	140367132305792 -> 140367132305984
	140367128300192 [label="stage3.1.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128300192 -> 140367132305792
	140367132305792 [label=AccumulateGrad]
	140367132306368 -> 140367132306416
	140367128300032 [label="stage3.1.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140367128300032 -> 140367132306368
	140367132306368 [label=AccumulateGrad]
	140367132306560 -> 140367132306416
	140367128300432 [label="stage3.1.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140367128300432 -> 140367132306560
	140367132306560 [label=AccumulateGrad]
	140367132306272 -> 140367132307088
	140367128298912 [label="stage3.1.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128298912 -> 140367132306272
	140367132306272 [label=AccumulateGrad]
	140367132307136 -> 140367132307376
	140367128298512 [label="stage3.1.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140367128298512 -> 140367132307136
	140367132307136 [label=AccumulateGrad]
	140367132307184 -> 140367132307376
	140367128298672 [label="stage3.1.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140367128298672 -> 140367132307184
	140367132307184 [label=AccumulateGrad]
	140367132307424 -> 140367132306992
	140367132307760 -> 140367132305696
	140367128313792 [label="stage3.1.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128313792 -> 140367132307760
	140367132307760 [label=AccumulateGrad]
	140367132307856 -> 140367132301376
	140367128313552 [label="stage3.1.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140367128313552 -> 140367132307856
	140367132307856 [label=AccumulateGrad]
	140367132308528 -> 140367132301376
	140367128297552 [label="stage3.1.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140367128297552 -> 140367132308528
	140367132308528 [label=AccumulateGrad]
	140367132308624 -> 140367132308816
	140367128310512 [label="stage3.1.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128310512 -> 140367132308624
	140367132308624 [label=AccumulateGrad]
	140367132308864 -> 140367132308960
	140367128310032 [label="stage3.1.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140367128310032 -> 140367132308864
	140367132308864 [label=AccumulateGrad]
	140367132308912 -> 140367132308960
	140367128310272 [label="stage3.1.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140367128310272 -> 140367132308912
	140367132308912 [label=AccumulateGrad]
	140367132308672 -> 140367132309056
	140367132309152 -> 140367132309344
	140367128305792 [label="stage3.1.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128305792 -> 140367132309152
	140367132309152 [label=AccumulateGrad]
	140367132309392 -> 140367132309440
	140367128305392 [label="stage3.1.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140367128305392 -> 140367132309392
	140367132309392 [label=AccumulateGrad]
	140367132309536 -> 140367132309440
	140367128306032 [label="stage3.1.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140367128306032 -> 140367132309536
	140367132309536 [label=AccumulateGrad]
	140367132308720 -> 140367132309920
	140367128300592 [label="stage3.1.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128300592 -> 140367132308720
	140367132308720 [label=AccumulateGrad]
	140367132309968 -> 140367132309584
	140367128299952 [label="stage3.1.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140367128299952 -> 140367132309968
	140367132309968 [label=AccumulateGrad]
	140367132310016 -> 140367132309584
	140367128300352 [label="stage3.1.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140367128300352 -> 140367132310016
	140367132310016 [label=AccumulateGrad]
	140367132310160 -> 140367132310208
	140367132310400 -> 140367132310496
	140367132310400 [label=UpsampleBilinear2DBackward0]
	140367132309872 -> 140367132310400
	140367132309872 [label=NativeBatchNormBackward0]
	140367132309104 -> 140367132309872
	140367132309104 [label=ConvolutionBackward0]
	140367132309200 -> 140367132309104
	140367132309200 [label=ReluBackward0]
	140367132307472 -> 140367132309200
	140367132307472 [label=AddBackward0]
	140367132306944 -> 140367132307472
	140367132306944 [label=NativeBatchNormBackward0]
	140367132307712 -> 140367132306944
	140367132307712 [label=ConvolutionBackward0]
	140367132305744 -> 140367132307712
	140367132305744 [label=ReluBackward0]
	140367132305888 -> 140367132305744
	140367132305888 [label=NativeBatchNormBackward0]
	140367132304496 -> 140367132305888
	140367132304496 [label=ConvolutionBackward0]
	140367132308384 -> 140367132304496
	140367132308384 [label=ReluBackward0]
	140367132303440 -> 140367132308384
	140367132303440 [label=AddBackward0]
	140367132299504 -> 140367132303440
	140367132299504 [label=NativeBatchNormBackward0]
	140367132302912 -> 140367132299504
	140367132302912 [label=ConvolutionBackward0]
	140367130651200 -> 140367132302912
	140367130651200 [label=ReluBackward0]
	140367130649856 -> 140367130651200
	140367130649856 [label=NativeBatchNormBackward0]
	140367130650912 -> 140367130649856
	140367130650912 [label=ConvolutionBackward0]
	140367132298928 -> 140367130650912
	140367132298928 [label=ReluBackward0]
	140367130650288 -> 140367132298928
	140367130650288 [label=AddBackward0]
	140367130650432 -> 140367130650288
	140367130650432 [label=NativeBatchNormBackward0]
	140367130649808 -> 140367130650432
	140367130649808 [label=ConvolutionBackward0]
	140367130652976 -> 140367130649808
	140367130652976 [label=ReluBackward0]
	140367130652688 -> 140367130652976
	140367130652688 [label=NativeBatchNormBackward0]
	140367130653024 -> 140367130652688
	140367130653024 [label=ConvolutionBackward0]
	140367130648512 -> 140367130653024
	140367130648512 [label=ReluBackward0]
	140367130654032 -> 140367130648512
	140367130654032 [label=AddBackward0]
	140367130655040 -> 140367130654032
	140367130655040 [label=NativeBatchNormBackward0]
	140367130655520 -> 140367130655040
	140367130655520 [label=ConvolutionBackward0]
	140367130655136 -> 140367130655520
	140367130655136 [label=ReluBackward0]
	140367130655376 -> 140367130655136
	140367130655376 [label=NativeBatchNormBackward0]
	140367130656384 -> 140367130655376
	140367130656384 [label=ConvolutionBackward0]
	140367130653840 -> 140367130656384
	140367130653840 [label=ReluBackward0]
	140367130656480 -> 140367130653840
	140367130656480 [label=AddBackward0]
	140367130656720 -> 140367130656480
	140367130656720 [label=AddBackward0]
	140367130648800 -> 140367130656720
	140367130648800 [label=NativeBatchNormBackward0]
	140367151632144 -> 140367130648800
	140367151632144 [label=ConvolutionBackward0]
	140367132304160 -> 140367151632144
	140367151635648 -> 140367151632144
	140367128309552 [label="stage3.0.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140367128309552 -> 140367151635648
	140367151635648 [label=AccumulateGrad]
	140367151634304 -> 140367130648800
	140367128309392 [label="stage3.0.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140367128309392 -> 140367151634304
	140367151634304 [label=AccumulateGrad]
	140367151628736 -> 140367130648800
	140367128309712 [label="stage3.0.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140367128309712 -> 140367151628736
	140367151628736 [label=AccumulateGrad]
	140367132302720 -> 140367130656720
	140367130656336 -> 140367130656480
	140367130656336 [label=UpsampleBilinear2DBackward0]
	140367151635312 -> 140367130656336
	140367151635312 [label=NativeBatchNormBackward0]
	140367130656528 -> 140367151635312
	140367130656528 [label=ConvolutionBackward0]
	140367132297584 -> 140367130656528
	140367144649056 -> 140367130656528
	140367128310112 [label="stage3.0.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140367128310112 -> 140367144649056
	140367144649056 [label=AccumulateGrad]
	140367144649680 -> 140367151635312
	140367128308032 [label="stage3.0.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140367128308032 -> 140367144649680
	140367144649680 [label=AccumulateGrad]
	140367144659472 -> 140367151635312
	140367128309872 [label="stage3.0.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140367128309872 -> 140367144659472
	140367144659472 [label=AccumulateGrad]
	140367130656048 -> 140367130656384
	140367128264000 [label="stage3.1.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128264000 -> 140367130656048
	140367130656048 [label=AccumulateGrad]
	140367130655184 -> 140367130655376
	140367128263920 [label="stage3.1.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140367128263920 -> 140367130655184
	140367130655184 [label=AccumulateGrad]
	140367130654992 -> 140367130655376
	140367128264080 [label="stage3.1.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140367128264080 -> 140367130654992
	140367130654992 [label=AccumulateGrad]
	140367130655712 -> 140367130655520
	140367128262720 [label="stage3.1.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128262720 -> 140367130655712
	140367130655712 [label=AccumulateGrad]
	140367130654320 -> 140367130655040
	140367128262560 [label="stage3.1.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140367128262560 -> 140367130654320
	140367130654320 [label=AccumulateGrad]
	140367130654464 -> 140367130655040
	140367128262640 [label="stage3.1.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140367128262640 -> 140367130654464
	140367130654464 [label=AccumulateGrad]
	140367130653840 -> 140367130654032
	140367130653792 -> 140367130653024
	140367128261280 [label="stage3.1.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128261280 -> 140367130653792
	140367130653792 [label=AccumulateGrad]
	140367130653504 -> 140367130652688
	140367128261200 [label="stage3.1.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140367128261200 -> 140367130653504
	140367130653504 [label=AccumulateGrad]
	140367130653696 -> 140367130652688
	140367128261360 [label="stage3.1.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140367128261360 -> 140367130653696
	140367130653696 [label=AccumulateGrad]
	140367130651008 -> 140367130649808
	140367128259840 [label="stage3.1.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128259840 -> 140367130651008
	140367130651008 [label=AccumulateGrad]
	140367130649664 -> 140367130650432
	140367128259680 [label="stage3.1.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140367128259680 -> 140367130649664
	140367130649664 [label=AccumulateGrad]
	140367130651632 -> 140367130650432
	140367128259760 [label="stage3.1.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140367128259760 -> 140367130651632
	140367130651632 [label=AccumulateGrad]
	140367130648512 -> 140367130650288
	140367130650240 -> 140367130650912
	140367128258240 [label="stage3.1.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128258240 -> 140367130650240
	140367130650240 [label=AccumulateGrad]
	140367130649904 -> 140367130649856
	140367128258160 [label="stage3.1.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140367128258160 -> 140367130649904
	140367130649904 [label=AccumulateGrad]
	140367130651728 -> 140367130649856
	140367128258320 [label="stage3.1.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140367128258320 -> 140367130651728
	140367130651728 [label=AccumulateGrad]
	140367130653600 -> 140367132302912
	140367128256960 [label="stage3.1.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128256960 -> 140367130653600
	140367130653600 [label=AccumulateGrad]
	140367130652880 -> 140367132299504
	140367128256800 [label="stage3.1.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140367128256800 -> 140367130652880
	140367130652880 [label=AccumulateGrad]
	140367130647504 -> 140367132299504
	140367128256880 [label="stage3.1.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140367128256880 -> 140367130647504
	140367130647504 [label=AccumulateGrad]
	140367132298928 -> 140367132303440
	140367132304592 -> 140367132304496
	140367128255360 [label="stage3.1.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128255360 -> 140367132304592
	140367132304592 [label=AccumulateGrad]
	140367132304880 -> 140367132305888
	140367128255280 [label="stage3.1.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140367128255280 -> 140367132304880
	140367132304880 [label=AccumulateGrad]
	140367132305120 -> 140367132305888
	140367128255440 [label="stage3.1.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140367128255440 -> 140367132305120
	140367132305120 [label=AccumulateGrad]
	140367132306656 -> 140367132307712
	140367128254000 [label="stage3.1.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128254000 -> 140367132306656
	140367132306656 [label=AccumulateGrad]
	140367132307808 -> 140367132306944
	140367128253760 [label="stage3.1.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140367128253760 -> 140367132307808
	140367132307808 [label=AccumulateGrad]
	140367132307040 -> 140367132306944
	140367128253840 [label="stage3.1.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140367128253840 -> 140367132307040
	140367132307040 [label=AccumulateGrad]
	140367132308384 -> 140367132307472
	140367132308768 -> 140367132309104
	140367128180800 [label="stage3.1.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140367128180800 -> 140367132308768
	140367132308768 [label=AccumulateGrad]
	140367132309488 -> 140367132309872
	140367128180720 [label="stage3.1.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140367128180720 -> 140367132309488
	140367132309488 [label=AccumulateGrad]
	140367132310256 -> 140367132309872
	140367128180960 [label="stage3.1.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140367128180960 -> 140367132310256
	140367132310256 [label=AccumulateGrad]
	140367132310544 -> 140367132310592
	140367132310544 [label=UpsampleBilinear2DBackward0]
	140367132309824 -> 140367132310544
	140367132309824 [label=NativeBatchNormBackward0]
	140367132306320 -> 140367132309824
	140367132306320 [label=ConvolutionBackward0]
	140367132304640 -> 140367132306320
	140367132304640 [label=ReluBackward0]
	140367132304688 -> 140367132304640
	140367132304688 [label=AddBackward0]
	140367132303200 -> 140367132304688
	140367132303200 [label=NativeBatchNormBackward0]
	140367130655280 -> 140367132303200
	140367130655280 [label=ConvolutionBackward0]
	140367130649328 -> 140367130655280
	140367130649328 [label=ReluBackward0]
	140367130652352 -> 140367130649328
	140367130652352 [label=NativeBatchNormBackward0]
	140367130654704 -> 140367130652352
	140367130654704 [label=ConvolutionBackward0]
	140367132305312 -> 140367130654704
	140367132305312 [label=ReluBackward0]
	140367130655808 -> 140367132305312
	140367130655808 [label=AddBackward0]
	140367130648752 -> 140367130655808
	140367130648752 [label=NativeBatchNormBackward0]
	140367151641600 -> 140367130648752
	140367151641600 [label=ConvolutionBackward0]
	140367357832512 -> 140367151641600
	140367357832512 [label=ReluBackward0]
	140367151768112 -> 140367357832512
	140367151768112 [label=NativeBatchNormBackward0]
	140367129269712 -> 140367151768112
	140367129269712 [label=ConvolutionBackward0]
	140367130655664 -> 140367129269712
	140367130655664 [label=ReluBackward0]
	140367129269904 -> 140367130655664
	140367129269904 [label=AddBackward0]
	140367129269088 -> 140367129269904
	140367129269088 [label=NativeBatchNormBackward0]
	140367129268656 -> 140367129269088
	140367129268656 [label=ConvolutionBackward0]
	140367129269040 -> 140367129268656
	140367129269040 [label=ReluBackward0]
	140367129268848 -> 140367129269040
	140367129268848 [label=NativeBatchNormBackward0]
	140367129268032 -> 140367129268848
	140367129268032 [label=ConvolutionBackward0]
	140367129269856 -> 140367129268032
	140367129269856 [label=ReluBackward0]
	140367129267504 -> 140367129269856
	140367129267504 [label=AddBackward0]
	140367129268176 -> 140367129267504
	140367129268176 [label=NativeBatchNormBackward0]
	140367129267840 -> 140367129268176
	140367129267840 [label=ConvolutionBackward0]
	140367129266640 -> 140367129267840
	140367129266640 [label=ReluBackward0]
	140367129266304 -> 140367129266640
	140367129266304 [label=NativeBatchNormBackward0]
	140367129267216 -> 140367129266304
	140367129267216 [label=ConvolutionBackward0]
	140367129267984 -> 140367129267216
	140367129267984 [label=ReluBackward0]
	140367129266688 -> 140367129267984
	140367129266688 [label=AddBackward0]
	140367129266400 -> 140367129266688
	140367129266400 [label=AddBackward0]
	140367129265488 -> 140367129266400
	140367129265488 [label=NativeBatchNormBackward0]
	140367129265152 -> 140367129265488
	140367129265152 [label=ConvolutionBackward0]
	140367129265632 -> 140367129265152
	140367129265632 [label=ReluBackward0]
	140367129265344 -> 140367129265632
	140367129265344 [label=NativeBatchNormBackward0]
	140367129265104 -> 140367129265344
	140367129265104 [label=ConvolutionBackward0]
	140367132304160 -> 140367129265104
	140367129264816 -> 140367129265104
	140367128306672 [label="stage3.0.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128306672 -> 140367129264816
	140367129264816 [label=AccumulateGrad]
	140367129265296 -> 140367129265344
	140367128306512 [label="stage3.0.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140367128306512 -> 140367129265296
	140367129265296 [label=AccumulateGrad]
	140367129265728 -> 140367129265344
	140367128306832 [label="stage3.0.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140367128306832 -> 140367129265728
	140367129265728 [label=AccumulateGrad]
	140367129265056 -> 140367129265152
	140367128306592 [label="stage3.0.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140367128306592 -> 140367129265056
	140367129265056 [label=AccumulateGrad]
	140367129266160 -> 140367129265488
	140367128305152 [label="stage3.0.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140367128305152 -> 140367129266160
	140367129266160 [label=AccumulateGrad]
	140367129265968 -> 140367129265488
	140367128305232 [label="stage3.0.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140367128305232 -> 140367129265968
	140367129265968 [label=AccumulateGrad]
	140367129266352 -> 140367129266400
	140367129266352 [label=NativeBatchNormBackward0]
	140367129265200 -> 140367129266352
	140367129265200 [label=ConvolutionBackward0]
	140367132302720 -> 140367129265200
	140367129264528 -> 140367129265200
	140367128303872 [label="stage3.0.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140367128303872 -> 140367129264528
	140367129264528 [label=AccumulateGrad]
	140367129264624 -> 140367129266352
	140367128303792 [label="stage3.0.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140367128303792 -> 140367129264624
	140367129264624 [label=AccumulateGrad]
	140367129265872 -> 140367129266352
	140367128303952 [label="stage3.0.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140367128303952 -> 140367129265872
	140367129265872 [label=AccumulateGrad]
	140367132297584 -> 140367129266688
	140367129266016 -> 140367129267216
	140367128252320 [label="stage3.1.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128252320 -> 140367129266016
	140367129266016 [label=AccumulateGrad]
	140367129267024 -> 140367129266304
	140367128252240 [label="stage3.1.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140367128252240 -> 140367129267024
	140367129267024 [label=AccumulateGrad]
	140367129267360 -> 140367129266304
	140367128252400 [label="stage3.1.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140367128252400 -> 140367129267360
	140367129267360 [label=AccumulateGrad]
	140367129267744 -> 140367129267840
	140367128250880 [label="stage3.1.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128250880 -> 140367129267744
	140367129267744 [label=AccumulateGrad]
	140367129267888 -> 140367129268176
	140367128250720 [label="stage3.1.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140367128250720 -> 140367129267888
	140367129267888 [label=AccumulateGrad]
	140367129267168 -> 140367129268176
	140367128250800 [label="stage3.1.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140367128250800 -> 140367129267168
	140367129267168 [label=AccumulateGrad]
	140367129267984 -> 140367129267504
	140367129268416 -> 140367129268032
	140367128249280 [label="stage3.1.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128249280 -> 140367129268416
	140367129268416 [label=AccumulateGrad]
	140367129268992 -> 140367129268848
	140367128249200 [label="stage3.1.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140367128249200 -> 140367129268992
	140367129268992 [label=AccumulateGrad]
	140367129269232 -> 140367129268848
	140367128249360 [label="stage3.1.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140367128249360 -> 140367129269232
	140367129269232 [label=AccumulateGrad]
	140367129268320 -> 140367129268656
	140367128263280 [label="stage3.1.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128263280 -> 140367129268320
	140367129268320 [label=AccumulateGrad]
	140367129269760 -> 140367129269088
	140367128262160 [label="stage3.1.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140367128262160 -> 140367129269760
	140367129269760 [label=AccumulateGrad]
	140367129269664 -> 140367129269088
	140367128262880 [label="stage3.1.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140367128262880 -> 140367129269664
	140367129269664 [label=AccumulateGrad]
	140367129269856 -> 140367129269904
	140367129270192 -> 140367129269712
	140367128258880 [label="stage3.1.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128258880 -> 140367129270192
	140367129270192 [label=AccumulateGrad]
	140367129270048 -> 140367151768112
	140367128258480 [label="stage3.1.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140367128258480 -> 140367129270048
	140367129270048 [label=AccumulateGrad]
	140367129270336 -> 140367151768112
	140367128259120 [label="stage3.1.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140367128259120 -> 140367129270336
	140367129270336 [label=AccumulateGrad]
	140367144649488 -> 140367151641600
	140367128254960 [label="stage3.1.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128254960 -> 140367144649488
	140367144649488 [label=AccumulateGrad]
	140367144649632 -> 140367130648752
	140367128254480 [label="stage3.1.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140367128254480 -> 140367144649632
	140367144649632 [label=AccumulateGrad]
	140367144659616 -> 140367130648752
	140367128254720 [label="stage3.1.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140367128254720 -> 140367144659616
	140367144659616 [label=AccumulateGrad]
	140367130655664 -> 140367130655808
	140367130655856 -> 140367130654704
	140367128251040 [label="stage3.1.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128251040 -> 140367130655856
	140367130655856 [label=AccumulateGrad]
	140367130654176 -> 140367130652352
	140367128250640 [label="stage3.1.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140367128250640 -> 140367130654176
	140367130654176 [label=AccumulateGrad]
	140367130652016 -> 140367130652352
	140367128251440 [label="stage3.1.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140367128251440 -> 140367130652016
	140367130652016 [label=AccumulateGrad]
	140367130649136 -> 140367130655280
	140367128182480 [label="stage3.1.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128182480 -> 140367130649136
	140367130649136 [label=AccumulateGrad]
	140367130649280 -> 140367132303200
	140367128182240 [label="stage3.1.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140367128182240 -> 140367130649280
	140367130649280 [label=AccumulateGrad]
	140367130652784 -> 140367132303200
	140367128182320 [label="stage3.1.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140367128182320 -> 140367130652784
	140367130652784 [label=AccumulateGrad]
	140367132305312 -> 140367132304688
	140367132305840 -> 140367132306320
	140367144516128 [label="stage3.1.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140367144516128 -> 140367132305840
	140367132305840 [label=AccumulateGrad]
	140367132308480 -> 140367132309824
	140367128179280 [label="stage3.1.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140367128179280 -> 140367132308480
	140367132308480 [label=AccumulateGrad]
	140367132310448 -> 140367132309824
	140367128179440 [label="stage3.1.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140367128179440 -> 140367132310448
	140367132310448 [label=AccumulateGrad]
	140367132310688 -> 140367132310880
	140367128175040 [label="stage3.2.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128175040 -> 140367132310688
	140367132310688 [label=AccumulateGrad]
	140367132310640 -> 140367132310112
	140367128170080 [label="stage3.2.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140367128170080 -> 140367132310640
	140367132310640 [label=AccumulateGrad]
	140367132311216 -> 140367132310112
	140367128174880 [label="stage3.2.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140367128174880 -> 140367132311216
	140367132311216 [label=AccumulateGrad]
	140367132311312 -> 140367132311504
	140367128168960 [label="stage3.2.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128168960 -> 140367132311312
	140367132311312 [label=AccumulateGrad]
	140367132311408 -> 140367131541664
	140367128168640 [label="stage3.2.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140367128168640 -> 140367132311408
	140367132311408 [label=AccumulateGrad]
	140367132311456 -> 140367131541664
	140367128168800 [label="stage3.2.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140367128168800 -> 140367132311456
	140367132311456 [label=AccumulateGrad]
	140367132308432 -> 140367388229296
	140367131541568 -> 140367131541808
	140367128167280 [label="stage3.2.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128167280 -> 140367131541568
	140367131541568 [label=AccumulateGrad]
	140367131541856 -> 140367131541904
	140367128167120 [label="stage3.2.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140367128167120 -> 140367131541856
	140367131541856 [label=AccumulateGrad]
	140367131542000 -> 140367131541904
	140367128167440 [label="stage3.2.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140367128167440 -> 140367131542000
	140367131542000 [label=AccumulateGrad]
	140367131542096 -> 140367131542240
	140367128181520 [label="stage3.2.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128181520 -> 140367131542096
	140367131542096 [label=AccumulateGrad]
	140367131542288 -> 140367131542336
	140367128180880 [label="stage3.2.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140367128180880 -> 140367131542288
	140367131542288 [label=AccumulateGrad]
	140367131542048 -> 140367131542336
	140367128181280 [label="stage3.2.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140367128181280 -> 140367131542048
	140367131542048 [label=AccumulateGrad]
	140367131542768 -> 140367131542816
	140367131543008 -> 140367131543440
	140367128177440 [label="stage3.2.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128177440 -> 140367131543008
	140367131543008 [label=AccumulateGrad]
	140367131543488 -> 140367131543392
	140367128177200 [label="stage3.2.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140367128177200 -> 140367131543488
	140367131543488 [label=AccumulateGrad]
	140367131543728 -> 140367131543392
	140367128177840 [label="stage3.2.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140367128177840 -> 140367131543728
	140367131543728 [label=AccumulateGrad]
	140367131543344 -> 140367131544256
	140367128174160 [label="stage3.2.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128174160 -> 140367131543344
	140367131543344 [label=AccumulateGrad]
	140367131544304 -> 140367131544544
	140367128173680 [label="stage3.2.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140367128173680 -> 140367131544304
	140367131544304 [label=AccumulateGrad]
	140367131544352 -> 140367131544544
	140367128173920 [label="stage3.2.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140367128173920 -> 140367131544352
	140367131544352 [label=AccumulateGrad]
	140367131544592 -> 140367131544160
	140367131544880 -> 140367131542672
	140367128170240 [label="stage3.2.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128170240 -> 140367131544880
	140367131544880 [label=AccumulateGrad]
	140367131544976 -> 140367131545696
	140367128169840 [label="stage3.2.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140367128169840 -> 140367131544976
	140367131544976 [label=AccumulateGrad]
	140367131545840 -> 140367131545696
	140367128170640 [label="stage3.2.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140367128170640 -> 140367131545840
	140367131545840 [label=AccumulateGrad]
	140367131545456 -> 140367131546560
	140367128166800 [label="stage3.2.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128166800 -> 140367131545456
	140367131545456 [label=AccumulateGrad]
	140367131546608 -> 140367131546368
	140367128166560 [label="stage3.2.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140367128166560 -> 140367131546608
	140367131546608 [label=AccumulateGrad]
	140367131546656 -> 140367131546368
	140367128149952 [label="stage3.2.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140367128149952 -> 140367131546656
	140367131546656 [label=AccumulateGrad]
	140367131546800 -> 140367131546848
	140367131546704 -> 140367131547136
	140367131546704 [label=UpsampleBilinear2DBackward0]
	140367131546512 -> 140367131546704
	140367131546512 [label=NativeBatchNormBackward0]
	140367131544640 -> 140367131546512
	140367131544640 [label=ConvolutionBackward0]
	140367131544928 -> 140367131544640
	140367131544928 [label=ReluBackward0]
	140367131542864 -> 140367131544928
	140367131542864 [label=AddBackward0]
	140367131543104 -> 140367131542864
	140367131543104 [label=NativeBatchNormBackward0]
	140367131542720 -> 140367131543104
	140367131542720 [label=ConvolutionBackward0]
	140367131541712 -> 140367131542720
	140367131541712 [label=ReluBackward0]
	140367161496320 -> 140367131541712
	140367161496320 [label=NativeBatchNormBackward0]
	140367132310352 -> 140367161496320
	140367132310352 [label=ConvolutionBackward0]
	140367131543824 -> 140367132310352
	140367131543824 [label=ReluBackward0]
	140367132309008 -> 140367131543824
	140367132309008 [label=AddBackward0]
	140367132305072 -> 140367132309008
	140367132305072 [label=NativeBatchNormBackward0]
	140367130654848 -> 140367132305072
	140367130654848 [label=ConvolutionBackward0]
	140367130653360 -> 140367130654848
	140367130653360 [label=ReluBackward0]
	140367144657696 -> 140367130653360
	140367144657696 [label=NativeBatchNormBackward0]
	140367151763936 -> 140367144657696
	140367151763936 [label=ConvolutionBackward0]
	140367132309248 -> 140367151763936
	140367132309248 [label=ReluBackward0]
	140367129268368 -> 140367132309248
	140367129268368 [label=AddBackward0]
	140367129268512 -> 140367129268368
	140367129268512 [label=NativeBatchNormBackward0]
	140367129268704 -> 140367129268512
	140367129268704 [label=ConvolutionBackward0]
	140367129266544 -> 140367129268704
	140367129266544 [label=ReluBackward0]
	140367129265680 -> 140367129266544
	140367129265680 [label=NativeBatchNormBackward0]
	140367129265008 -> 140367129265680
	140367129265008 [label=ConvolutionBackward0]
	140367129269328 -> 140367129265008
	140367129269328 [label=ReluBackward0]
	140367129264384 -> 140367129269328
	140367129264384 [label=AddBackward0]
	140367129264864 -> 140367129264384
	140367129264864 [label=NativeBatchNormBackward0]
	140367129265536 -> 140367129264864
	140367129265536 [label=ConvolutionBackward0]
	140367129264912 -> 140367129265536
	140367129264912 [label=ReluBackward0]
	140367129265392 -> 140367129264912
	140367129265392 [label=NativeBatchNormBackward0]
	140367129266448 -> 140367129265392
	140367129266448 [label=ConvolutionBackward0]
	140367129264336 -> 140367129266448
	140367129264336 [label=ReluBackward0]
	140367129266928 -> 140367129264336
	140367129266928 [label=AddBackward0]
	140367129266112 -> 140367129266928
	140367129266112 [label=AddBackward0]
	140367129266592 -> 140367129266112
	140367129266592 [label=NativeBatchNormBackward0]
	140367129266784 -> 140367129266592
	140367129266784 [label=ConvolutionBackward0]
	140367132310064 -> 140367129266784
	140367129267552 -> 140367129266784
	140367128177680 [label="stage3.1.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140367128177680 -> 140367129267552
	140367129267552 [label=AccumulateGrad]
	140367129267456 -> 140367129266592
	140367128177520 [label="stage3.1.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140367128177520 -> 140367129267456
	140367129267456 [label=AccumulateGrad]
	140367129267264 -> 140367129266592
	140367128177760 [label="stage3.1.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140367128177760 -> 140367129267264
	140367129267264 [label=AccumulateGrad]
	140367132309200 -> 140367129266112
	140367129266256 -> 140367129266928
	140367129266256 [label=UpsampleBilinear2DBackward0]
	140367129267120 -> 140367129266256
	140367129267120 [label=NativeBatchNormBackward0]
	140367129268224 -> 140367129267120
	140367129268224 [label=ConvolutionBackward0]
	140367132304640 -> 140367129268224
	140367129269136 -> 140367129268224
	140367128178080 [label="stage3.1.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140367128178080 -> 140367129269136
	140367129269136 [label=AccumulateGrad]
	140367129268464 -> 140367129267120
	140367128176160 [label="stage3.1.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140367128176160 -> 140367129268464
	140367129268464 [label=AccumulateGrad]
	140367129266736 -> 140367129267120
	140367128177920 [label="stage3.1.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140367128177920 -> 140367129266736
	140367129266736 [label=AccumulateGrad]
	140367129266064 -> 140367129266448
	140367128148512 [label="stage3.2.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128148512 -> 140367129266064
	140367129266064 [label=AccumulateGrad]
	140367129265248 -> 140367129265392
	140367128148432 [label="stage3.2.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140367128148432 -> 140367129265248
	140367129265248 [label=AccumulateGrad]
	140367129264768 -> 140367129265392
	140367128148672 [label="stage3.2.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140367128148672 -> 140367129264768
	140367129264768 [label=AccumulateGrad]
	140367129265776 -> 140367129265536
	140367128147152 [label="stage3.2.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128147152 -> 140367129265776
	140367129265776 [label=AccumulateGrad]
	140367129264240 -> 140367129264864
	140367128146912 [label="stage3.2.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140367128146912 -> 140367129264240
	140367129264240 [label=AccumulateGrad]
	140367129264288 -> 140367129264864
	140367128146992 [label="stage3.2.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140367128146992 -> 140367129264288
	140367129264288 [label=AccumulateGrad]
	140367129264336 -> 140367129264384
	140367129264672 -> 140367129265008
	140367128145472 [label="stage3.2.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128145472 -> 140367129264672
	140367129264672 [label=AccumulateGrad]
	140367129265824 -> 140367129265680
	140367128145392 [label="stage3.2.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140367128145392 -> 140367129265824
	140367129265824 [label=AccumulateGrad]
	140367129266832 -> 140367129265680
	140367128145632 [label="stage3.2.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140367128145632 -> 140367129266832
	140367129266832 [label=AccumulateGrad]
	140367129267648 -> 140367129268704
	140367128144112 [label="stage3.2.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128144112 -> 140367129267648
	140367129267648 [label=AccumulateGrad]
	140367129267696 -> 140367129268512
	140367128143872 [label="stage3.2.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140367128143872 -> 140367129267696
	140367129267696 [label=AccumulateGrad]
	140367129267072 -> 140367129268512
	140367128143952 [label="stage3.2.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140367128143952 -> 140367129267072
	140367129267072 [label=AccumulateGrad]
	140367129269328 -> 140367129268368
	140367129269472 -> 140367151763936
	140367128142432 [label="stage3.2.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128142432 -> 140367129269472
	140367129269472 [label=AccumulateGrad]
	140367151769984 -> 140367144657696
	140367128142352 [label="stage3.2.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140367128142352 -> 140367151769984
	140367151769984 [label=AccumulateGrad]
	140367129269184 -> 140367144657696
	140367128142592 [label="stage3.2.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140367128142592 -> 140367129269184
	140367129269184 [label=AccumulateGrad]
	140367130654368 -> 140367130654848
	140367128141072 [label="stage3.2.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128141072 -> 140367130654368
	140367130654368 [label=AccumulateGrad]
	140367130652928 -> 140367132305072
	140367128140832 [label="stage3.2.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140367128140832 -> 140367130652928
	140367130652928 [label=AccumulateGrad]
	140367130650048 -> 140367132305072
	140367128140912 [label="stage3.2.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140367128140912 -> 140367130650048
	140367130650048 [label=AccumulateGrad]
	140367132309248 -> 140367132309008
	140367132310736 -> 140367132310352
	140367128139392 [label="stage3.2.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128139392 -> 140367132310736
	140367132310736 [label=AccumulateGrad]
	140367132311168 -> 140367161496320
	140367128139312 [label="stage3.2.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140367128139312 -> 140367132311168
	140367132311168 [label=AccumulateGrad]
	140367132310928 -> 140367161496320
	140367128139552 [label="stage3.2.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140367128139552 -> 140367132310928
	140367132310928 [label=AccumulateGrad]
	140367131542144 -> 140367131542720
	140367128138032 [label="stage3.2.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128138032 -> 140367131542144
	140367131542144 [label=AccumulateGrad]
	140367131543056 -> 140367131543104
	140367128137792 [label="stage3.2.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140367128137792 -> 140367131543056
	140367131543056 [label=AccumulateGrad]
	140367131542192 -> 140367131543104
	140367128137872 [label="stage3.2.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140367128137872 -> 140367131542192
	140367131542192 [label=AccumulateGrad]
	140367131543824 -> 140367131542864
	140367131544208 -> 140367131544640
	140367128065232 [label="stage3.2.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140367128065232 -> 140367131544208
	140367131544208 [label=AccumulateGrad]
	140367131545792 -> 140367131546512
	140367128065152 [label="stage3.2.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140367128065152 -> 140367131545792
	140367131545792 [label=AccumulateGrad]
	140367131546896 -> 140367131546512
	140367128065312 [label="stage3.2.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140367128065312 -> 140367131546896
	140367131546896 [label=AccumulateGrad]
	140367131547184 -> 140367131547232
	140367131547184 [label=UpsampleBilinear2DBackward0]
	140367131546464 -> 140367131547184
	140367131546464 [label=NativeBatchNormBackward0]
	140367131541952 -> 140367131546464
	140367131541952 [label=ConvolutionBackward0]
	140367131541616 -> 140367131541952
	140367131541616 [label=ReluBackward0]
	140367132310832 -> 140367131541616
	140367132310832 [label=AddBackward0]
	140367132310304 -> 140367132310832
	140367132310304 [label=NativeBatchNormBackward0]
	140367130656192 -> 140367132310304
	140367130656192 [label=ConvolutionBackward0]
	140367129269376 -> 140367130656192
	140367129269376 [label=ReluBackward0]
	140367129266496 -> 140367129269376
	140367129266496 [label=NativeBatchNormBackward0]
	140367129264720 -> 140367129266496
	140367129264720 [label=ConvolutionBackward0]
	140367132310784 -> 140367129264720
	140367132310784 [label=ReluBackward0]
	140367129265584 -> 140367132310784
	140367129265584 [label=AddBackward0]
	140367129266880 -> 140367129265584
	140367129266880 [label=NativeBatchNormBackward0]
	140367129267792 -> 140367129266880
	140367129267792 [label=ConvolutionBackward0]
	140367129268272 -> 140367129267792
	140367129268272 [label=ReluBackward0]
	140367129268752 -> 140367129268272
	140367129268752 [label=NativeBatchNormBackward0]
	140367129269808 -> 140367129268752
	140367129269808 [label=ConvolutionBackward0]
	140367129267936 -> 140367129269808
	140367129267936 [label=ReluBackward0]
	140367129270480 -> 140367129267936
	140367129270480 [label=AddBackward0]
	140367129269520 -> 140367129270480
	140367129269520 [label=NativeBatchNormBackward0]
	140367129269952 -> 140367129269520
	140367129269952 [label=ConvolutionBackward0]
	140367129271824 -> 140367129269952
	140367129271824 [label=ReluBackward0]
	140367129271584 -> 140367129271824
	140367129271584 [label=NativeBatchNormBackward0]
	140367129270816 -> 140367129271584
	140367129270816 [label=ConvolutionBackward0]
	140367129269616 -> 140367129270816
	140367129269616 [label=ReluBackward0]
	140367129271488 -> 140367129269616
	140367129271488 [label=AddBackward0]
	140367129272112 -> 140367129271488
	140367129272112 [label=NativeBatchNormBackward0]
	140367129272160 -> 140367129272112
	140367129272160 [label=ConvolutionBackward0]
	140367129273504 -> 140367129272160
	140367129273504 [label=ReluBackward0]
	140367129273840 -> 140367129273504
	140367129273840 [label=NativeBatchNormBackward0]
	140367129273168 -> 140367129273840
	140367129273168 [label=ConvolutionBackward0]
	140367129272784 -> 140367129273168
	140367129272784 [label=ReluBackward0]
	140367129274128 -> 140367129272784
	140367129274128 [label=AddBackward0]
	140367129274992 -> 140367129274128
	140367129274992 [label=AddBackward0]
	140367129274176 -> 140367129274992
	140367129274176 [label=NativeBatchNormBackward0]
	140367129274656 -> 140367129274176
	140367129274656 [label=ConvolutionBackward0]
	140367129275184 -> 140367129274656
	140367129275184 [label=ReluBackward0]
	140367129275472 -> 140367129275184
	140367129275472 [label=NativeBatchNormBackward0]
	140367129275856 -> 140367129275472
	140367129275856 [label=ConvolutionBackward0]
	140367132310064 -> 140367129275856
	140367129276144 -> 140367129275856
	140367128174640 [label="stage3.1.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128174640 -> 140367129276144
	140367129276144 [label=AccumulateGrad]
	140367129276672 -> 140367129275472
	140367128174480 [label="stage3.1.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140367128174480 -> 140367129276672
	140367129276672 [label=AccumulateGrad]
	140367129276192 -> 140367129275472
	140367128174720 [label="stage3.1.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140367128174720 -> 140367129276192
	140367129276192 [label=AccumulateGrad]
	140367129276000 -> 140367129274656
	140367128174560 [label="stage3.1.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140367128174560 -> 140367129276000
	140367129276000 [label=AccumulateGrad]
	140367129274800 -> 140367129274176
	140367128172960 [label="stage3.1.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140367128172960 -> 140367129274800
	140367129274800 [label=AccumulateGrad]
	140367129275328 -> 140367129274176
	140367128173040 [label="stage3.1.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140367128173040 -> 140367129275328
	140367129275328 [label=AccumulateGrad]
	140367129274320 -> 140367129274992
	140367129274320 [label=NativeBatchNormBackward0]
	140367129276864 -> 140367129274320
	140367129276864 [label=ConvolutionBackward0]
	140367132309200 -> 140367129276864
	140367129276288 -> 140367129276864
	140367128171520 [label="stage3.1.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140367128171520 -> 140367129276288
	140367129276288 [label=AccumulateGrad]
	140367129275616 -> 140367129274320
	140367128171440 [label="stage3.1.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140367128171440 -> 140367129275616
	140367129275616 [label=AccumulateGrad]
	140367129275520 -> 140367129274320
	140367128171600 [label="stage3.1.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140367128171600 -> 140367129275520
	140367129275520 [label=AccumulateGrad]
	140367132304640 -> 140367129274128
	140367129273648 -> 140367129273168
	140367128136352 [label="stage3.2.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128136352 -> 140367129273648
	140367129273648 [label=AccumulateGrad]
	140367129273312 -> 140367129273840
	140367128136272 [label="stage3.2.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140367128136272 -> 140367129273312
	140367129273312 [label=AccumulateGrad]
	140367129272832 -> 140367129273840
	140367128136512 [label="stage3.2.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140367128136512 -> 140367129272832
	140367129272832 [label=AccumulateGrad]
	140367129272496 -> 140367129272160
	140367128134992 [label="stage3.2.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128134992 -> 140367129272496
	140367129272496 [label=AccumulateGrad]
	140367129272976 -> 140367129272112
	140367128134752 [label="stage3.2.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140367128134752 -> 140367129272976
	140367129272976 [label=AccumulateGrad]
	140367129271968 -> 140367129272112
	140367128134832 [label="stage3.2.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140367128134832 -> 140367129271968
	140367129271968 [label=AccumulateGrad]
	140367129272784 -> 140367129271488
	140367129272304 -> 140367129270816
	140367128149232 [label="stage3.2.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128149232 -> 140367129272304
	140367129272304 [label=AccumulateGrad]
	140367129270960 -> 140367129271584
	140367128148832 [label="stage3.2.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140367128148832 -> 140367129270960
	140367129270960 [label=AccumulateGrad]
	140367129270768 -> 140367129271584
	140367128149632 [label="stage3.2.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140367128149632 -> 140367129270768
	140367129270768 [label=AccumulateGrad]
	140367129270144 -> 140367129269952
	140367128145792 [label="stage3.2.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128145792 -> 140367129270144
	140367129270144 [label=AccumulateGrad]
	140367129270096 -> 140367129269520
	140367128145312 [label="stage3.2.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140367128145312 -> 140367129270096
	140367129270096 [label=AccumulateGrad]
	140367129270912 -> 140367129269520
	140367128145552 [label="stage3.2.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140367128145552 -> 140367129270912
	140367129270912 [label=AccumulateGrad]
	140367129269616 -> 140367129270480
	140367129269424 -> 140367129269808
	140367128142032 [label="stage3.2.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128142032 -> 140367129269424
	140367129269424 [label=AccumulateGrad]
	140367129268608 -> 140367129268752
	140367128141632 [label="stage3.2.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140367128141632 -> 140367129268608
	140367129268608 [label=AccumulateGrad]
	140367129268128 -> 140367129268752
	140367128142272 [label="stage3.2.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140367128142272 -> 140367129268128
	140367129268128 [label=AccumulateGrad]
	140367129268080 -> 140367129267792
	140367128138592 [label="stage3.2.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128138592 -> 140367129268080
	140367129268080 [label=AccumulateGrad]
	140367129267408 -> 140367129266880
	140367128137952 [label="stage3.2.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140367128137952 -> 140367129267408
	140367129267408 [label=AccumulateGrad]
	140367129265440 -> 140367129266880
	140367128138192 [label="stage3.2.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140367128138192 -> 140367129265440
	140367129265440 [label=AccumulateGrad]
	140367129267936 -> 140367129265584
	140367129265920 -> 140367129264720
	140367128134672 [label="stage3.2.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128134672 -> 140367129265920
	140367129265920 [label=AccumulateGrad]
	140367129264480 -> 140367129266496
	140367128134432 [label="stage3.2.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140367128134432 -> 140367129264480
	140367129264480 [label=AccumulateGrad]
	140367129266976 -> 140367129266496
	140367128134912 [label="stage3.2.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140367128134912 -> 140367129266976
	140367129266976 [label=AccumulateGrad]
	140367129270000 -> 140367130656192
	140367128066832 [label="stage3.2.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128066832 -> 140367129270000
	140367129270000 [label=AccumulateGrad]
	140367130651344 -> 140367132310304
	140367128066672 [label="stage3.2.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140367128066672 -> 140367130651344
	140367130651344 [label=AccumulateGrad]
	140367129268560 -> 140367132310304
	140367128066752 [label="stage3.2.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140367128066752 -> 140367129268560
	140367129268560 [label=AccumulateGrad]
	140367132310784 -> 140367132310832
	140367131544832 -> 140367131541952
	140367128063712 [label="stage3.2.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140367128063712 -> 140367131544832
	140367131544832 [label=AccumulateGrad]
	140367131543536 -> 140367131546464
	140367128063632 [label="stage3.2.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140367128063632 -> 140367131543536
	140367131543536 [label=AccumulateGrad]
	140367131547088 -> 140367131546464
	140367128063792 [label="stage3.2.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140367128063792 -> 140367131547088
	140367131547088 [label=AccumulateGrad]
	140367131547040 -> 140367131547520
	140367128059232 [label="stage3.3.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128059232 -> 140367131547040
	140367131547040 [label=AccumulateGrad]
	140367131547568 -> 140367131547328
	140367128054592 [label="stage3.3.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140367128054592 -> 140367131547568
	140367131547568 [label=AccumulateGrad]
	140367131547856 -> 140367131547328
	140367128059152 [label="stage3.3.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140367128059152 -> 140367131547856
	140367131547856 [label=AccumulateGrad]
	140367131547952 -> 140367131547616
	140367128053472 [label="stage3.3.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128053472 -> 140367131547952
	140367131547952 [label=AccumulateGrad]
	140367131548192 -> 140367131548288
	140367128053312 [label="stage3.3.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140367128053312 -> 140367131548192
	140367131548192 [label=AccumulateGrad]
	140367131548240 -> 140367131548288
	140367128053392 [label="stage3.3.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140367128053392 -> 140367131548240
	140367131548240 [label=AccumulateGrad]
	140367131548336 -> 140367131548384
	140367131548480 -> 140367131548672
	140367128052032 [label="stage3.3.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128052032 -> 140367131548480
	140367131548480 [label=AccumulateGrad]
	140367131548432 -> 140367131548768
	140367128051952 [label="stage3.3.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140367128051952 -> 140367131548432
	140367131548432 [label=AccumulateGrad]
	140367131548864 -> 140367131548768
	140367128052112 [label="stage3.3.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140367128052112 -> 140367131548864
	140367131548864 [label=AccumulateGrad]
	140367131548960 -> 140367131549248
	140367128066032 [label="stage3.3.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128066032 -> 140367131548960
	140367131548960 [label=AccumulateGrad]
	140367131549296 -> 140367131549392
	140367128065392 [label="stage3.3.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140367128065392 -> 140367131549296
	140367131549296 [label=AccumulateGrad]
	140367131549344 -> 140367131549392
	140367128065792 [label="stage3.3.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140367128065792 -> 140367131549344
	140367131549344 [label=AccumulateGrad]
	140367131549440 -> 140367131549008
	140367131549632 -> 140367131549488
	140367128061952 [label="stage3.3.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128061952 -> 140367131549632
	140367131549632 [label=AccumulateGrad]
	140367131549872 -> 140367131549920
	140367128061712 [label="stage3.3.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140367128061712 -> 140367131549872
	140367131549872 [label=AccumulateGrad]
	140367131550016 -> 140367131549920
	140367128062352 [label="stage3.3.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140367128062352 -> 140367131550016
	140367131550016 [label=AccumulateGrad]
	140367131550112 -> 140367131550256
	140367128058672 [label="stage3.3.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128058672 -> 140367131550112
	140367131550112 [label=AccumulateGrad]
	140367131550304 -> 140367131549536
	140367128058192 [label="stage3.3.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140367128058192 -> 140367131550304
	140367131550304 [label=AccumulateGrad]
	140367131550064 -> 140367131549536
	140367128058432 [label="stage3.3.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140367128058432 -> 140367131550064
	140367131550064 [label=AccumulateGrad]
	140367131550592 -> 140367131550640
	140367131550736 -> 140367131550976
	140367128053952 [label="stage3.3.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128053952 -> 140367131550736
	140367131550736 [label=AccumulateGrad]
	140367131551024 -> 140367131551072
	140367128053552 [label="stage3.3.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140367128053552 -> 140367131551024
	140367131551024 [label=AccumulateGrad]
	140367131550832 -> 140367131551072
	140367128054192 [label="stage3.3.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140367128054192 -> 140367131550832
	140367131550832 [label=AccumulateGrad]
	140367131551264 -> 140367131551408
	140367128001696 [label="stage3.3.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128001696 -> 140367131551264
	140367131551264 [label=AccumulateGrad]
	140367131551168 -> 140367131551552
	140367128001456 [label="stage3.3.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140367128001456 -> 140367131551168
	140367131551168 [label=AccumulateGrad]
	140367131551504 -> 140367131551552
	140367128001536 [label="stage3.3.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140367128001536 -> 140367131551504
	140367131551504 [label=AccumulateGrad]
	140367131551600 -> 140367131551648
	140367131546416 -> 140367131552224
	140367131546416 [label=UpsampleBilinear2DBackward0]
	140367131551360 -> 140367131546416
	140367131551360 [label=NativeBatchNormBackward0]
	140367131550688 -> 140367131551360
	140367131550688 [label=ConvolutionBackward0]
	140367131550784 -> 140367131550688
	140367131550784 [label=ReluBackward0]
	140367131549584 -> 140367131550784
	140367131549584 [label=AddBackward0]
	140367131549776 -> 140367131549584
	140367131549776 [label=NativeBatchNormBackward0]
	140367131549728 -> 140367131549776
	140367131549728 [label=ConvolutionBackward0]
	140367131548624 -> 140367131549728
	140367131548624 [label=ReluBackward0]
	140367131548576 -> 140367131548624
	140367131548576 [label=NativeBatchNormBackward0]
	140367131547280 -> 140367131548576
	140367131547280 [label=ConvolutionBackward0]
	140367131550160 -> 140367131547280
	140367131550160 [label=ReluBackward0]
	140367131544112 -> 140367131550160
	140367131544112 [label=AddBackward0]
	140367132308336 -> 140367131544112
	140367132308336 [label=NativeBatchNormBackward0]
	140367130654512 -> 140367132308336
	140367130654512 [label=ConvolutionBackward0]
	140367129268896 -> 140367130654512
	140367129268896 [label=ReluBackward0]
	140367129269568 -> 140367129268896
	140367129269568 [label=NativeBatchNormBackward0]
	140367129267600 -> 140367129269568
	140367129267600 [label=ConvolutionBackward0]
	140367132311360 -> 140367129267600
	140367132311360 [label=ReluBackward0]
	140367129271632 -> 140367132311360
	140367129271632 [label=AddBackward0]
	140367129272256 -> 140367129271632
	140367129272256 [label=NativeBatchNormBackward0]
	140367129271440 -> 140367129272256
	140367129271440 [label=ConvolutionBackward0]
	140367129274944 -> 140367129271440
	140367129274944 [label=ReluBackward0]
	140367129273984 -> 140367129274944
	140367129273984 [label=NativeBatchNormBackward0]
	140367129275664 -> 140367129273984
	140367129275664 [label=ConvolutionBackward0]
	140367129270288 -> 140367129275664
	140367129270288 [label=ReluBackward0]
	140367129276816 -> 140367129270288
	140367129276816 [label=AddBackward0]
	140367129277200 -> 140367129276816
	140367129277200 [label=NativeBatchNormBackward0]
	140367129277632 -> 140367129277200
	140367129277632 [label=ConvolutionBackward0]
	140367129277680 -> 140367129277632
	140367129277680 [label=ReluBackward0]
	140367129278160 -> 140367129277680
	140367129278160 [label=NativeBatchNormBackward0]
	140367129278544 -> 140367129278160
	140367129278544 [label=ConvolutionBackward0]
	140367129278016 -> 140367129278544
	140367129278016 [label=ReluBackward0]
	140367129279216 -> 140367129278016
	140367129279216 [label=AddBackward0]
	140367129280224 -> 140367129279216
	140367129280224 [label=AddBackward0]
	140367129279888 -> 140367129280224
	140367129279888 [label=NativeBatchNormBackward0]
	140367129280320 -> 140367129279888
	140367129280320 [label=ConvolutionBackward0]
	140367131546992 -> 140367129280320
	140367129280368 -> 140367129280320
	140367128062032 [label="stage3.2.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140367128062032 -> 140367129280368
	140367129280368 [label=AccumulateGrad]
	140367129279696 -> 140367129279888
	140367128061792 [label="stage3.2.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140367128061792 -> 140367129279696
	140367129279696 [label=AccumulateGrad]
	140367129279648 -> 140367129279888
	140367128062112 [label="stage3.2.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140367128062112 -> 140367129279648
	140367129279648 [label=AccumulateGrad]
	140367131544928 -> 140367129280224
	140367129279024 -> 140367129279216
	140367129279024 [label=UpsampleBilinear2DBackward0]
	140367129270384 -> 140367129279024
	140367129270384 [label=NativeBatchNormBackward0]
	140367129279504 -> 140367129270384
	140367129279504 [label=ConvolutionBackward0]
	140367131541616 -> 140367129279504
	140367128549488 -> 140367129279504
	140367128062272 [label="stage3.2.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140367128062272 -> 140367128549488
	140367128549488 [label=AccumulateGrad]
	140367128545456 -> 140367129270384
	140367128060512 [label="stage3.2.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140367128060512 -> 140367128545456
	140367128545456 [label=AccumulateGrad]
	140367128553904 -> 140367129270384
	140367128062192 [label="stage3.2.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140367128062192 -> 140367128553904
	140367128553904 [label=AccumulateGrad]
	140367129278832 -> 140367129278544
	140367128000176 [label="stage3.3.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367128000176 -> 140367129278832
	140367129278832 [label=AccumulateGrad]
	140367129279360 -> 140367129278160
	140367128000096 [label="stage3.3.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140367128000096 -> 140367129279360
	140367129279360 [label=AccumulateGrad]
	140367129278688 -> 140367129278160
	140367128000336 [label="stage3.3.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140367128000336 -> 140367129278688
	140367129278688 [label=AccumulateGrad]
	140367129277872 -> 140367129277632
	140367127998976 [label="stage3.3.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127998976 -> 140367129277872
	140367129277872 [label=AccumulateGrad]
	140367129278208 -> 140367129277200
	140367127998736 [label="stage3.3.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140367127998736 -> 140367129278208
	140367129278208 [label=AccumulateGrad]
	140367129277008 -> 140367129277200
	140367127998816 [label="stage3.3.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140367127998816 -> 140367129277008
	140367129277008 [label=AccumulateGrad]
	140367129278016 -> 140367129276816
	140367129277536 -> 140367129275664
	140367127997296 [label="stage3.3.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127997296 -> 140367129277536
	140367129277536 [label=AccumulateGrad]
	140367129274848 -> 140367129273984
	140367127997216 [label="stage3.3.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140367127997216 -> 140367129274848
	140367129274848 [label=AccumulateGrad]
	140367129273600 -> 140367129273984
	140367127997456 [label="stage3.3.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140367127997456 -> 140367129273600
	140367129273600 [label=AccumulateGrad]
	140367129272640 -> 140367129271440
	140367127996096 [label="stage3.3.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127996096 -> 140367129272640
	140367129272640 [label=AccumulateGrad]
	140367129271296 -> 140367129272256
	140367127995856 [label="stage3.3.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140367127995856 -> 140367129271296
	140367129271296 [label=AccumulateGrad]
	140367129273456 -> 140367129272256
	140367127995936 [label="stage3.3.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140367127995936 -> 140367129273456
	140367129273456 [label=AccumulateGrad]
	140367129270288 -> 140367129271632
	140367129268800 -> 140367129267600
	140367127994576 [label="stage3.3.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127994576 -> 140367129268800
	140367129268800 [label=AccumulateGrad]
	140367129269280 -> 140367129269568
	140367127994496 [label="stage3.3.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140367127994496 -> 140367129269280
	140367129269280 [label=AccumulateGrad]
	140367129266208 -> 140367129269568
	140367127994736 [label="stage3.3.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140367127994736 -> 140367129266208
	140367129266208 [label=AccumulateGrad]
	140367129264960 -> 140367130654512
	140367127993376 [label="stage3.3.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127993376 -> 140367129264960
	140367129264960 [label=AccumulateGrad]
	140367129264432 -> 140367132308336
	140367127993136 [label="stage3.3.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140367127993136 -> 140367129264432
	140367129264432 [label=AccumulateGrad]
	140367129270432 -> 140367132308336
	140367127993216 [label="stage3.3.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140367127993216 -> 140367129270432
	140367129270432 [label=AccumulateGrad]
	140367132311360 -> 140367131544112
	140367131547376 -> 140367131547280
	140367127991696 [label="stage3.3.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127991696 -> 140367131547376
	140367131547376 [label=AccumulateGrad]
	140367131546752 -> 140367131548576
	140367127991616 [label="stage3.3.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140367127991616 -> 140367131546752
	140367131546752 [label=AccumulateGrad]
	140367131548048 -> 140367131548576
	140367127991856 [label="stage3.3.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140367127991856 -> 140367131548048
	140367131548048 [label=AccumulateGrad]
	140367131548720 -> 140367131549728
	140367127990336 [label="stage3.3.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127990336 -> 140367131548720
	140367131548720 [label=AccumulateGrad]
	140367131549680 -> 140367131549776
	140367127990096 [label="stage3.3.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140367127990096 -> 140367131549680
	140367131549680 [label=AccumulateGrad]
	140367131548144 -> 140367131549776
	140367127990176 [label="stage3.3.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140367127990176 -> 140367131548144
	140367131548144 [label=AccumulateGrad]
	140367131550160 -> 140367131549584
	140367131550208 -> 140367131550688
	140367127916896 [label="stage3.3.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140367127916896 -> 140367131550208
	140367131550208 [label=AccumulateGrad]
	140367131551120 -> 140367131551360
	140367127916736 [label="stage3.3.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140367127916736 -> 140367131551120
	140367131551120 [label=AccumulateGrad]
	140367131551696 -> 140367131551360
	140367127916976 [label="stage3.3.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140367127916976 -> 140367131551696
	140367131551696 [label=AccumulateGrad]
	140367131552272 -> 140367131552320
	140367131552272 [label=UpsampleBilinear2DBackward0]
	140367131551312 -> 140367131552272
	140367131551312 [label=NativeBatchNormBackward0]
	140367131548816 -> 140367131551312
	140367131548816 [label=ConvolutionBackward0]
	140367131547424 -> 140367131548816
	140367131547424 [label=ReluBackward0]
	140367131547472 -> 140367131547424
	140367131547472 [label=AddBackward0]
	140367131546944 -> 140367131547472
	140367131546944 [label=NativeBatchNormBackward0]
	140367129267312 -> 140367131546944
	140367129267312 [label=ConvolutionBackward0]
	140367129271152 -> 140367129267312
	140367129271152 [label=ReluBackward0]
	140367129274512 -> 140367129271152
	140367129274512 [label=NativeBatchNormBackward0]
	140367129277488 -> 140367129274512
	140367129277488 [label=ConvolutionBackward0]
	140367131548096 -> 140367129277488
	140367131548096 [label=ReluBackward0]
	140367129278352 -> 140367131548096
	140367129278352 [label=AddBackward0]
	140367129278976 -> 140367129278352
	140367129278976 [label=NativeBatchNormBackward0]
	140367128555728 -> 140367129278976
	140367128555728 [label=ConvolutionBackward0]
	140367405361584 -> 140367128555728
	140367405361584 [label=ReluBackward0]
	140367405361776 -> 140367405361584
	140367405361776 [label=NativeBatchNormBackward0]
	140367405362256 -> 140367405361776
	140367405362256 [label=ConvolutionBackward0]
	140367129280176 -> 140367405362256
	140367129280176 [label=ReluBackward0]
	140370527010576 -> 140367129280176
	140370527010576 [label=AddBackward0]
	140367161663856 -> 140370527010576
	140367161663856 [label=NativeBatchNormBackward0]
	140367167670784 -> 140367161663856
	140367167670784 [label=ConvolutionBackward0]
	140367132246512 -> 140367167670784
	140367132246512 [label=ReluBackward0]
	140367132260192 -> 140367132246512
	140367132260192 [label=NativeBatchNormBackward0]
	140367132262112 -> 140367132260192
	140367132262112 [label=ConvolutionBackward0]
	140367135281488 -> 140367132262112
	140367135281488 [label=ReluBackward0]
	140367132260960 -> 140367135281488
	140367132260960 [label=AddBackward0]
	140367132261296 -> 140367132260960
	140367132261296 [label=NativeBatchNormBackward0]
	140367132260576 -> 140367132261296
	140367132260576 [label=ConvolutionBackward0]
	140367132260096 -> 140367132260576
	140367132260096 [label=ReluBackward0]
	140367132260144 -> 140367132260096
	140367132260144 [label=NativeBatchNormBackward0]
	140367132259904 -> 140367132260144
	140367132259904 [label=ConvolutionBackward0]
	140367132261200 -> 140367132259904
	140367132261200 [label=ReluBackward0]
	140367132259328 -> 140367132261200
	140367132259328 [label=AddBackward0]
	140367132259616 -> 140367132259328
	140367132259616 [label=AddBackward0]
	140367132259424 -> 140367132259616
	140367132259424 [label=NativeBatchNormBackward0]
	140367132255872 -> 140367132259424
	140367132255872 [label=ConvolutionBackward0]
	140367132259040 -> 140367132255872
	140367132259040 [label=ReluBackward0]
	140367132258512 -> 140367132259040
	140367132258512 [label=NativeBatchNormBackward0]
	140367132258800 -> 140367132258512
	140367132258800 [label=ConvolutionBackward0]
	140367131546992 -> 140367132258800
	140367132258656 -> 140367132258800
	140367128058992 [label="stage3.2.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367128058992 -> 140367132258656
	140367132258656 [label=AccumulateGrad]
	140367132257600 -> 140367132258512
	140367128058752 [label="stage3.2.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140367128058752 -> 140367132257600
	140367132257600 [label=AccumulateGrad]
	140367132258272 -> 140367132258512
	140367128059072 [label="stage3.2.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140367128059072 -> 140367132258272
	140367132258272 [label=AccumulateGrad]
	140367132258944 -> 140367132255872
	140367128058832 [label="stage3.2.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140367128058832 -> 140367132258944
	140367132258944 [label=AccumulateGrad]
	140367132259280 -> 140367132259424
	140367128057232 [label="stage3.2.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140367128057232 -> 140367132259280
	140367132259280 [label=AccumulateGrad]
	140367132259184 -> 140367132259424
	140367128057312 [label="stage3.2.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140367128057312 -> 140367132259184
	140367132259184 [label=AccumulateGrad]
	140367132259088 -> 140367132259616
	140367132259088 [label=NativeBatchNormBackward0]
	140367132258608 -> 140367132259088
	140367132258608 [label=ConvolutionBackward0]
	140367131544928 -> 140367132258608
	140367132258560 -> 140367132258608
	140367128055872 [label="stage3.2.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140367128055872 -> 140367132258560
	140367132258560 [label=AccumulateGrad]
	140367132258896 -> 140367132259088
	140367128055792 [label="stage3.2.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140367128055792 -> 140367132258896
	140367132258896 [label=AccumulateGrad]
	140367132258848 -> 140367132259088
	140367128055952 [label="stage3.2.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140367128055952 -> 140367132258848
	140367132258848 [label=AccumulateGrad]
	140367131541616 -> 140367132259328
	140367132262352 -> 140367132259904
	140367127988816 [label="stage3.3.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127988816 -> 140367132262352
	140367132262352 [label=AccumulateGrad]
	140367132260336 -> 140367132260144
	140367127988736 [label="stage3.3.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140367127988736 -> 140367132260336
	140367132260336 [label=AccumulateGrad]
	140367132260240 -> 140367132260144
	140367127988976 [label="stage3.3.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140367127988976 -> 140367132260240
	140367132260240 [label=AccumulateGrad]
	140367132260672 -> 140367132260576
	140367127987456 [label="stage3.3.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127987456 -> 140367132260672
	140367132260672 [label=AccumulateGrad]
	140367132260720 -> 140367132261296
	140367127987216 [label="stage3.3.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140367127987216 -> 140367132260720
	140367132260720 [label=AccumulateGrad]
	140367132246608 -> 140367132261296
	140367127987296 [label="stage3.3.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140367127987296 -> 140367132246608
	140367132246608 [label=AccumulateGrad]
	140367132261200 -> 140367132260960
	140367132261824 -> 140367132262112
	140367128001616 [label="stage3.3.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367128001616 -> 140367132261824
	140367132261824 [label=AccumulateGrad]
	140367132261968 -> 140367132260192
	140367128000896 [label="stage3.3.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140367128000896 -> 140367132261968
	140367132261968 [label=AccumulateGrad]
	140367132255056 -> 140367132260192
	140367128002016 [label="stage3.3.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140367128002016 -> 140367132255056
	140367132255056 [label=AccumulateGrad]
	140367132246800 -> 140367167670784
	140367127997376 [label="stage3.3.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127997376 -> 140367132246800
	140367132246800 [label=AccumulateGrad]
	140367132255152 -> 140367161663856
	140367127996416 [label="stage3.3.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140367127996416 -> 140367132255152
	140367132255152 [label=AccumulateGrad]
	140367132255440 -> 140367161663856
	140367127996656 [label="stage3.3.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140367127996656 -> 140367132255440
	140367132255440 [label=AccumulateGrad]
	140367135281488 -> 140370527010576
	140367135293200 -> 140367405362256
	140367127992176 [label="stage3.3.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127992176 -> 140367135293200
	140367135293200 [label=AccumulateGrad]
	140367405357936 -> 140367405361776
	140367127991776 [label="stage3.3.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140367127991776 -> 140367405357936
	140367405357936 [label=AccumulateGrad]
	140367135282448 -> 140367405361776
	140367127992416 [label="stage3.3.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140367127992416 -> 140367135282448
	140367135282448 [label=AccumulateGrad]
	140367405361968 -> 140367128555728
	140367127988256 [label="stage3.3.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127988256 -> 140367405361968
	140367405361968 [label=AccumulateGrad]
	140367129279552 -> 140367129278976
	140367127987776 [label="stage3.3.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140367127987776 -> 140367129279552
	140367129279552 [label=AccumulateGrad]
	140367405361680 -> 140367129278976
	140367127988016 [label="stage3.3.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140367127988016 -> 140367405361680
	140367405361680 [label=AccumulateGrad]
	140367129280176 -> 140367129278352
	140367129280032 -> 140367129277488
	140367127919936 [label="stage3.3.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127919936 -> 140367129280032
	140367129280032 [label=AccumulateGrad]
	140367129276336 -> 140367129274512
	140367127919776 [label="stage3.3.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140367127919776 -> 140367129276336
	140367129276336 [label=AccumulateGrad]
	140367129274272 -> 140367129274512
	140367127920016 [label="stage3.3.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140367127920016 -> 140367129274272
	140367129274272 [label=AccumulateGrad]
	140367129270240 -> 140367129267312
	140367127918496 [label="stage3.3.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127918496 -> 140367129270240
	140367129270240 [label=AccumulateGrad]
	140367129270624 -> 140367131546944
	140367127918256 [label="stage3.3.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140367127918256 -> 140367129270624
	140367129270624 [label=AccumulateGrad]
	140367129264192 -> 140367131546944
	140367127918416 [label="stage3.3.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140367127918416 -> 140367129264192
	140367129264192 [label=AccumulateGrad]
	140367131548096 -> 140367131547472
	140367131548528 -> 140367131548816
	140367127915376 [label="stage3.3.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140367127915376 -> 140367131548528
	140367131548528 [label=AccumulateGrad]
	140367131549968 -> 140367131551312
	140367127915216 [label="stage3.3.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140367127915216 -> 140367131549968
	140367131549968 [label=AccumulateGrad]
	140367131551744 -> 140367131551312
	140367127915456 [label="stage3.3.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140367127915456 -> 140367131551744
	140367131551744 [label=AccumulateGrad]
	140367131552512 -> 140367131552176
	140367127904816 [label="stage4.0.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127904816 -> 140367131552512
	140367131552512 [label=AccumulateGrad]
	140367131552800 -> 140367131553232
	140367127904576 [label="stage4.0.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140367127904576 -> 140367131552800
	140367131552800 [label=AccumulateGrad]
	140367131553184 -> 140367131553232
	140367127904896 [label="stage4.0.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140367127904896 -> 140367131553184
	140367131553184 [label=AccumulateGrad]
	140367131553520 -> 140367131553760
	140367127904736 [label="stage4.0.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127904736 -> 140367131553520
	140367131553520 [label=AccumulateGrad]
	140367131553808 -> 140367131553856
	140367127917616 [label="stage4.0.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140367127917616 -> 140367131553808
	140367131553808 [label=AccumulateGrad]
	140367131553136 -> 140367131553856
	140367127917856 [label="stage4.0.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140367127917856 -> 140367131553136
	140367131553136 [label=AccumulateGrad]
	140367131554240 -> 140367131554288
	140367131554384 -> 140367131554672
	140367127914176 [label="stage4.0.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127914176 -> 140367131554384
	140367131554384 [label=AccumulateGrad]
	140367131554960 -> 140367131555008
	140367127913776 [label="stage4.0.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140367127913776 -> 140367131554960
	140367131554960 [label=AccumulateGrad]
	140367131555056 -> 140367131555008
	140367127914576 [label="stage4.0.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140367127914576 -> 140367131555056
	140367131555056 [label=AccumulateGrad]
	140367131555248 -> 140367131555728
	140367127918096 [label="stage4.0.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127918096 -> 140367131555248
	140367131555248 [label=AccumulateGrad]
	140367131555776 -> 140367131555872
	140367127910256 [label="stage4.0.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140367127910256 -> 140367131555776
	140367131555776 [label=AccumulateGrad]
	140367131555824 -> 140367131555872
	140367127910496 [label="stage4.0.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140367127910496 -> 140367131555824
	140367131555824 [label=AccumulateGrad]
	140367131556064 -> 140367131556112
	140367131556208 -> 140367131556784
	140367127906976 [label="stage4.0.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127906976 -> 140367131556208
	140367131556208 [label=AccumulateGrad]
	140367131556832 -> 140367131556880
	140367127906576 [label="stage4.0.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140367127906576 -> 140367131556832
	140367131556832 [label=AccumulateGrad]
	140367131557072 -> 140367131556880
	140367127907216 [label="stage4.0.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140367127907216 -> 140367131557072
	140367131557072 [label=AccumulateGrad]
	140367131556736 -> 140367131557504
	140367127871184 [label="stage4.0.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127871184 -> 140367131556736
	140367131556736 [label=AccumulateGrad]
	140367131557408 -> 140367131552128
	140367127870784 [label="stage4.0.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140367127870784 -> 140367131557408
	140367131557408 [label=AccumulateGrad]
	140367131555632 -> 140367131552128
	140367127870944 [label="stage4.0.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140367127870944 -> 140367131555632
	140367131555632 [label=AccumulateGrad]
	140367131557552 -> 140367130001904
	140367168605152 -> 140367130002000
	140367127869424 [label="stage4.0.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127869424 -> 140367168605152
	140367168605152 [label=AccumulateGrad]
	140367130002048 -> 140367130001760
	140367127869264 [label="stage4.0.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140367127869264 -> 140367130002048
	140367130002048 [label=AccumulateGrad]
	140367130002240 -> 140367130001760
	140367127869664 [label="stage4.0.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140367127869664 -> 140367130002240
	140367130002240 [label=AccumulateGrad]
	140367130002336 -> 140367130002480
	140367127868144 [label="stage4.0.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127868144 -> 140367130002336
	140367130002336 [label=AccumulateGrad]
	140367130002528 -> 140367130002624
	140367127867744 [label="stage4.0.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140367127867744 -> 140367130002528
	140367130002528 [label=AccumulateGrad]
	140367130002576 -> 140367130002624
	140367127867904 [label="stage4.0.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140367127867904 -> 140367130002576
	140367130002576 [label=AccumulateGrad]
	140367130002672 -> 140367130002432
	140367130002912 -> 140367130002720
	140367130002912 [label=UpsampleBilinear2DBackward0]
	140367130002096 -> 140367130002912
	140367130002096 [label=NativeBatchNormBackward0]
	140367130001856 -> 140367130002096
	140367130001856 [label=ConvolutionBackward0]
	140367130001952 -> 140367130001856
	140367130001952 [label=ReluBackward0]
	140367131556160 -> 140367130001952
	140367131556160 [label=AddBackward0]
	140367131555680 -> 140367131556160
	140367131555680 [label=NativeBatchNormBackward0]
	140367131556448 -> 140367131555680
	140367131556448 [label=ConvolutionBackward0]
	140367131554192 -> 140367131556448
	140367131554192 [label=ReluBackward0]
	140367131554624 -> 140367131554192
	140367131554624 [label=NativeBatchNormBackward0]
	140367131552464 -> 140367131554624
	140367131552464 [label=ConvolutionBackward0]
	140367131557168 -> 140367131552464
	140367131557168 [label=ReluBackward0]
	140367131550928 -> 140367131557168
	140367131550928 [label=AddBackward0]
	140367131548000 -> 140367131550928
	140367131548000 [label=NativeBatchNormBackward0]
	140367129276960 -> 140367131548000
	140367129276960 [label=ConvolutionBackward0]
	140367129276528 -> 140367129276960
	140367129276528 [label=ReluBackward0]
	140367129278304 -> 140367129276528
	140367129278304 [label=NativeBatchNormBackward0]
	140367167671264 -> 140367129278304
	140367167671264 [label=ConvolutionBackward0]
	140367131550352 -> 140367167671264
	140367131550352 [label=ReluBackward0]
	140367132261680 -> 140367131550352
	140367132261680 [label=AddBackward0]
	140367132261536 -> 140367132261680
	140367132261536 [label=NativeBatchNormBackward0]
	140367132260768 -> 140367132261536
	140367132260768 [label=ConvolutionBackward0]
	140367132259568 -> 140367132260768
	140367132259568 [label=ReluBackward0]
	140367132259472 -> 140367132259568
	140367132259472 [label=NativeBatchNormBackward0]
	140367132258416 -> 140367132259472
	140367132258416 [label=ConvolutionBackward0]
	140367132246656 -> 140367132258416
	140367132246656 [label=ReluBackward0]
	140367132258128 -> 140367132246656
	140367132258128 [label=AddBackward0]
	140367132258032 -> 140367132258128
	140367132258032 [label=NativeBatchNormBackward0]
	140367132258080 -> 140367132258032
	140367132258080 [label=ConvolutionBackward0]
	140367132257504 -> 140367132258080
	140367132257504 [label=ReluBackward0]
	140367132257264 -> 140367132257504
	140367132257264 [label=NativeBatchNormBackward0]
	140367132257216 -> 140367132257264
	140367132257216 [label=ConvolutionBackward0]
	140367132257840 -> 140367132257216
	140367132257840 [label=ReluBackward0]
	140367132259136 -> 140367132257840
	140367132259136 [label=AddBackward0]
	140367132256352 -> 140367132259136
	140367132256352 [label=AddBackward0]
	140367132256208 -> 140367132256352
	140367132256208 [label=NativeBatchNormBackward0]
	140367132256544 -> 140367132256208
	140367132256544 [label=ConvolutionBackward0]
	140367131550880 -> 140367132256544
	140367132255296 -> 140367132256544
	140367127913616 [label="stage3.3.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140367127913616 -> 140367132255296
	140367132255296 [label=AccumulateGrad]
	140367132256064 -> 140367132256208
	140367127913376 [label="stage3.3.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140367127913376 -> 140367132256064
	140367132256064 [label=AccumulateGrad]
	140367132256592 -> 140367132256208
	140367127913696 [label="stage3.3.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140367127913696 -> 140367132256592
	140367132256592 [label=AccumulateGrad]
	140367131550784 -> 140367132256352
	140367132256880 -> 140367132259136
	140367132256880 [label=UpsampleBilinear2DBackward0]
	140367132256304 -> 140367132256880
	140367132256304 [label=NativeBatchNormBackward0]
	140367132256400 -> 140367132256304
	140367132256400 [label=ConvolutionBackward0]
	140367131547424 -> 140367132256400
	140367132256112 -> 140367132256400
	140367127913936 [label="stage3.3.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140367127913936 -> 140367132256112
	140367132256112 [label=AccumulateGrad]
	140367132256256 -> 140367132256304
	140367127912096 [label="stage3.3.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140367127912096 -> 140367132256256
	140367132256256 [label=AccumulateGrad]
	140367132256736 -> 140367132256304
	140367127913856 [label="stage3.3.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140367127913856 -> 140367132256736
	140367132256736 [label=AccumulateGrad]
	140367132257120 -> 140367132257216
	140367127866384 [label="stage4.0.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127866384 -> 140367132257120
	140367132257120 [label=AccumulateGrad]
	140367132256688 -> 140367132257264
	140367127866224 [label="stage4.0.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140367127866224 -> 140367132256688
	140367132256688 [label=AccumulateGrad]
	140367132257648 -> 140367132257264
	140367127866624 [label="stage4.0.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140367127866624 -> 140367132257648
	140367132257648 [label=AccumulateGrad]
	140367132257360 -> 140367132258080
	140367127865104 [label="stage4.0.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127865104 -> 140367132257360
	140367132257360 [label=AccumulateGrad]
	140367132257408 -> 140367132258032
	140367127864704 [label="stage4.0.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140367127864704 -> 140367132257408
	140367132257408 [label=AccumulateGrad]
	140367132257552 -> 140367132258032
	140367127864864 [label="stage4.0.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140367127864864 -> 140367132257552
	140367132257552 [label=AccumulateGrad]
	140367132257840 -> 140367132258128
	140367132257936 -> 140367132258416
	140367127863344 [label="stage4.0.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127863344 -> 140367132257936
	140367132257936 [label=AccumulateGrad]
	140367132257888 -> 140367132259472
	140367127863184 [label="stage4.0.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140367127863184 -> 140367132257888
	140367132257888 [label=AccumulateGrad]
	140367132255632 -> 140367132259472
	140367127863584 [label="stage4.0.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140367127863584 -> 140367132255632
	140367132255632 [label=AccumulateGrad]
	140367132260624 -> 140367132260768
	140367127862064 [label="stage4.0.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127862064 -> 140367132260624
	140367132260624 [label=AccumulateGrad]
	140367132261392 -> 140367132261536
	140367127861664 [label="stage4.0.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140367127861664 -> 140367132261392
	140367132261392 [label=AccumulateGrad]
	140367132261008 -> 140367132261536
	140367127861824 [label="stage4.0.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140367127861824 -> 140367132261008
	140367132261008 [label=AccumulateGrad]
	140367132246656 -> 140367132261680
	140367135281392 -> 140367167671264
	140367127860304 [label="stage4.0.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127860304 -> 140367135281392
	140367135281392 [label=AccumulateGrad]
	140367405357600 -> 140367129278304
	140367127860144 [label="stage4.0.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140367127860144 -> 140367405357600
	140367405357600 [label=AccumulateGrad]
	140367405362064 -> 140367129278304
	140367127860544 [label="stage4.0.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140367127860544 -> 140367405362064
	140367405362064 [label=AccumulateGrad]
	140367129277344 -> 140367129276960
	140367127858944 [label="stage4.0.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127858944 -> 140367129277344
	140367129277344 [label=AccumulateGrad]
	140367129264576 -> 140367131548000
	140367127858624 [label="stage4.0.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140367127858624 -> 140367129264576
	140367129264576 [label=AccumulateGrad]
	140367129268944 -> 140367131548000
	140367127858784 [label="stage4.0.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140367127858784 -> 140367129268944
	140367129268944 [label=AccumulateGrad]
	140367131550352 -> 140367131550928
	140367131552560 -> 140367131552464
	140367127857264 [label="stage4.0.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127857264 -> 140367131552560
	140367131552560 [label=AccumulateGrad]
	140367131553280 -> 140367131554624
	140367127857104 [label="stage4.0.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140367127857104 -> 140367131553280
	140367131553280 [label=AccumulateGrad]
	140367131553616 -> 140367131554624
	140367127857504 [label="stage4.0.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140367127857504 -> 140367131553616
	140367131553616 [label=AccumulateGrad]
	140367131554144 -> 140367131556448
	140367127855984 [label="stage4.0.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127855984 -> 140367131554144
	140367131554144 [label=AccumulateGrad]
	140367131556400 -> 140367131555680
	140367127855584 [label="stage4.0.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140367127855584 -> 140367131556400
	140367131556400 [label=AccumulateGrad]
	140367131555296 -> 140367131555680
	140367127855744 [label="stage4.0.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140367127855744 -> 140367131555296
	140367131555296 [label=AccumulateGrad]
	140367131557168 -> 140367131556160
	140367131557456 -> 140367130001856
	140367127751696 [label="stage4.0.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140367127751696 -> 140367131557456
	140367131557456 [label=AccumulateGrad]
	140367130002192 -> 140367130002096
	140367127751456 [label="stage4.0.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140367127751456 -> 140367130002192
	140367130002192 [label=AccumulateGrad]
	140367130002768 -> 140367130002096
	140367127751936 [label="stage4.0.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140367127751936 -> 140367130002768
	140367130002768 [label=AccumulateGrad]
	140367130002144 -> 140367130003296
	140367130002144 [label=UpsampleBilinear2DBackward0]
	140367130002384 -> 140367130002144
	140367130002384 [label=NativeBatchNormBackward0]
	140367130002960 -> 140367130002384
	140367130002960 [label=ConvolutionBackward0]
	140367131552704 -> 140367130002960
	140367131552704 [label=ReluBackward0]
	140367131552752 -> 140367131552704
	140367131552752 [label=AddBackward0]
	140367405356784 -> 140367131552752
	140367405356784 [label=NativeBatchNormBackward0]
	140367129272928 -> 140367405356784
	140367129272928 [label=ConvolutionBackward0]
	140367132246704 -> 140367129272928
	140367132246704 [label=ReluBackward0]
	140367132259760 -> 140367132246704
	140367132259760 [label=NativeBatchNormBackward0]
	140367132257792 -> 140367132259760
	140367132257792 [label=ConvolutionBackward0]
	140367131551456 -> 140367132257792
	140367131551456 [label=ReluBackward0]
	140367132257312 -> 140367131551456
	140367132257312 [label=AddBackward0]
	140367132256448 -> 140367132257312
	140367132256448 [label=NativeBatchNormBackward0]
	140367132255824 -> 140367132256448
	140367132255824 [label=ConvolutionBackward0]
	140367132255776 -> 140367132255824
	140367132255776 [label=ReluBackward0]
	140367132254720 -> 140367132255776
	140367132254720 [label=NativeBatchNormBackward0]
	140367132254048 -> 140367132254720
	140367132254048 [label=ConvolutionBackward0]
	140367132256160 -> 140367132254048
	140367132256160 [label=ReluBackward0]
	140367132253328 -> 140367132256160
	140367132253328 [label=AddBackward0]
	140367132254288 -> 140367132253328
	140367132254288 [label=NativeBatchNormBackward0]
	140367132253904 -> 140367132254288
	140367132253904 [label=ConvolutionBackward0]
	140367132252944 -> 140367132253904
	140367132252944 [label=ReluBackward0]
	140367132252704 -> 140367132252944
	140367132252704 [label=NativeBatchNormBackward0]
	140367132253280 -> 140367132252704
	140367132253280 [label=ConvolutionBackward0]
	140367132253808 -> 140367132253280
	140367132253808 [label=ReluBackward0]
	140367132246944 -> 140367132253808
	140367132246944 [label=AddBackward0]
	140367132247232 -> 140367132246944
	140367132247232 [label=NativeBatchNormBackward0]
	140367132249536 -> 140367132247232
	140367132249536 [label=ConvolutionBackward0]
	140367132252656 -> 140367132249536
	140367132252656 [label=ReluBackward0]
	140367132256928 -> 140367132252656
	140367132256928 [label=NativeBatchNormBackward0]
	140367132259808 -> 140367132256928
	140367132259808 [label=ConvolutionBackward0]
	140367132247088 -> 140367132259808
	140367132247088 [label=ReluBackward0]
	140367132250736 -> 140367132247088
	140367132250736 [label=AddBackward0]
	140367132250496 -> 140367132250736
	140367132250496 [label=AddBackward0]
	140367132250880 -> 140367132250496
	140367132250880 [label=NativeBatchNormBackward0]
	140367132251216 -> 140367132250880
	140367132251216 [label=ConvolutionBackward0]
	140367132251552 -> 140367132251216
	140367132251552 [label=ReluBackward0]
	140367132251744 -> 140367132251552
	140367132251744 [label=NativeBatchNormBackward0]
	140367132252080 -> 140367132251744
	140367132252080 [label=ConvolutionBackward0]
	140367131550880 -> 140367132252080
	140367132252176 -> 140367132252080
	140367127910576 [label="stage3.3.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127910576 -> 140367132252176
	140367132252176 [label=AccumulateGrad]
	140367132251504 -> 140367132251744
	140367127910336 [label="stage3.3.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140367127910336 -> 140367132251504
	140367132251504 [label=AccumulateGrad]
	140367132251360 -> 140367132251744
	140367127910656 [label="stage3.3.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140367127910656 -> 140367132251360
	140367132251360 [label=AccumulateGrad]
	140367132251168 -> 140367132251216
	140367127910416 [label="stage3.3.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140367127910416 -> 140367132251168
	140367132251168 [label=AccumulateGrad]
	140367132250784 -> 140367132250880
	140367127908816 [label="stage3.3.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140367127908816 -> 140367132250784
	140367132250784 [label=AccumulateGrad]
	140367132250640 -> 140367132250880
	140367127908896 [label="stage3.3.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140367127908896 -> 140367132250640
	140367132250640 [label=AccumulateGrad]
	140367132251408 -> 140367132250496
	140367132251408 [label=NativeBatchNormBackward0]
	140367132251312 -> 140367132251408
	140367132251312 [label=ConvolutionBackward0]
	140367131550784 -> 140367132251312
	140367132250352 -> 140367132251312
	140367127907376 [label="stage3.3.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140367127907376 -> 140367132250352
	140367132250352 [label=AccumulateGrad]
	140367132251600 -> 140367132251408
	140367127907296 [label="stage3.3.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140367127907296 -> 140367132251600
	140367132251600 [label=AccumulateGrad]
	140367132250976 -> 140367132251408
	140367127907536 [label="stage3.3.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140367127907536 -> 140367132250976
	140367132250976 [label=AccumulateGrad]
	140367131547424 -> 140367132250736
	140367132248960 -> 140367132259808
	140367127869584 [label="stage4.0.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127869584 -> 140367132248960
	140367132248960 [label=AccumulateGrad]
	140367132259232 -> 140367132256928
	140367127869184 [label="stage4.0.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140367127869184 -> 140367132259232
	140367132259232 [label=AccumulateGrad]
	140367132249248 -> 140367132256928
	140367127869824 [label="stage4.0.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140367127869824 -> 140367132249248
	140367132249248 [label=AccumulateGrad]
	140367132252416 -> 140367132249536
	140367127866144 [label="stage4.0.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127866144 -> 140367132252416
	140367132252416 [label=AccumulateGrad]
	140367132255728 -> 140367132247232
	140367127865504 [label="stage4.0.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140367127865504 -> 140367132255728
	140367132255728 [label=AccumulateGrad]
	140367132249392 -> 140367132247232
	140367127865744 [label="stage4.0.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140367127865744 -> 140367132249392
	140367132249392 [label=AccumulateGrad]
	140367132247088 -> 140367132246944
	140367132249632 -> 140367132253280
	140367127862224 [label="stage4.0.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127862224 -> 140367132249632
	140367132249632 [label=AccumulateGrad]
	140367132253040 -> 140367132252704
	140367127861984 [label="stage4.0.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140367127861984 -> 140367132253040
	140367132253040 [label=AccumulateGrad]
	140367132251936 -> 140367132252704
	140367127862464 [label="stage4.0.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140367127862464 -> 140367132251936
	140367132251936 [label=AccumulateGrad]
	140367132253616 -> 140367132253904
	140367127859024 [label="stage4.0.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127859024 -> 140367132253616
	140367132253616 [label=AccumulateGrad]
	140367132253952 -> 140367132254288
	140367127858144 [label="stage4.0.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140367127858144 -> 140367132253952
	140367132253952 [label=AccumulateGrad]
	140367132253856 -> 140367132254288
	140367127858544 [label="stage4.0.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140367127858544 -> 140367132253856
	140367132253856 [label=AccumulateGrad]
	140367132253808 -> 140367132253328
	140367132254768 -> 140367132254048
	140367127756576 [label="stage4.0.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127756576 -> 140367132254768
	140367132254768 [label=AccumulateGrad]
	140367132254816 -> 140367132254720
	140367127756416 [label="stage4.0.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140367127756416 -> 140367132254816
	140367132254816 [label=AccumulateGrad]
	140367132255344 -> 140367132254720
	140367127756656 [label="stage4.0.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140367127756656 -> 140367132255344
	140367132255344 [label=AccumulateGrad]
	140367132255680 -> 140367132255824
	140367127755136 [label="stage4.0.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127755136 -> 140367132255680
	140367132255680 [label=AccumulateGrad]
	140367132255104 -> 140367132256448
	140367127754896 [label="stage4.0.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140367127754896 -> 140367132255104
	140367132255104 [label=AccumulateGrad]
	140367132256832 -> 140367132256448
	140367127755056 [label="stage4.0.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140367127755056 -> 140367132256832
	140367132256832 [label=AccumulateGrad]
	140367132256160 -> 140367132257312
	140367132255920 -> 140367132257792
	140367127753536 [label="stage4.0.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127753536 -> 140367132255920
	140367132255920 [label=AccumulateGrad]
	140367132258224 -> 140367132259760
	140367127753376 [label="stage4.0.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140367127753376 -> 140367132258224
	140367132258224 [label=AccumulateGrad]
	140367132258752 -> 140367132259760
	140367127753616 [label="stage4.0.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140367127753616 -> 140367132258752
	140367132258752 [label=AccumulateGrad]
	140367132260384 -> 140367129272928
	140367127752096 [label="stage4.0.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127752096 -> 140367132260384
	140367132260384 [label=AccumulateGrad]
	140367129278880 -> 140367405356784
	140367127751856 [label="stage4.0.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140367127751856 -> 140367129278880
	140367129278880 [label=AccumulateGrad]
	140367135287824 -> 140367405356784
	140367127752016 [label="stage4.0.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140367127752016 -> 140367135287824
	140367135287824 [label=AccumulateGrad]
	140367131551456 -> 140367131552752
	140367131554576 -> 140367130002960
	140367127748016 [label="stage4.0.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140367127748016 -> 140367131554576
	140367131554576 [label=AccumulateGrad]
	140367131554912 -> 140367130002384
	140367127747616 [label="stage4.0.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140367127747616 -> 140367131554912
	140367131554912 [label=AccumulateGrad]
	140367131556928 -> 140367130002384
	140367127748416 [label="stage4.0.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140367127748416 -> 140367131556928
	140367131556928 [label=AccumulateGrad]
	140367130003344 -> 140367130003392
	140367130003344 [label=UpsampleBilinear2DBackward0]
	140367130002816 -> 140367130003344
	140367130002816 [label=NativeBatchNormBackward0]
	140367131554336 -> 140367130002816
	140367131554336 [label=ConvolutionBackward0]
	140367352517328 -> 140367131554336
	140367352517328 [label=ReluBackward0]
	140367132255248 -> 140367352517328
	140367132255248 [label=AddBackward0]
	140367132257984 -> 140367132255248
	140367132257984 [label=NativeBatchNormBackward0]
	140367132255968 -> 140367132257984
	140367132255968 [label=ConvolutionBackward0]
	140367132254672 -> 140367132255968
	140367132254672 [label=ReluBackward0]
	140367132253472 -> 140367132254672
	140367132253472 [label=NativeBatchNormBackward0]
	140367132250688 -> 140367132253472
	140367132250688 [label=ConvolutionBackward0]
	140367132257072 -> 140367132250688
	140367132257072 [label=ReluBackward0]
	140367132247280 -> 140367132257072
	140367132247280 [label=AddBackward0]
	140367132250544 -> 140367132247280
	140367132250544 [label=NativeBatchNormBackward0]
	140367132252224 -> 140367132250544
	140367132252224 [label=ConvolutionBackward0]
	140367132249872 -> 140367132252224
	140367132249872 [label=ReluBackward0]
	140367132250304 -> 140367132249872
	140367132250304 [label=NativeBatchNormBackward0]
	140367132252560 -> 140367132250304
	140367132252560 [label=ConvolutionBackward0]
	140367132251456 -> 140367132252560
	140367132251456 [label=ReluBackward0]
	140367132249344 -> 140367132251456
	140367132249344 [label=AddBackward0]
	140367132250160 -> 140367132249344
	140367132250160 [label=NativeBatchNormBackward0]
	140367132252320 -> 140367132250160
	140367132252320 [label=ConvolutionBackward0]
	140367132247520 -> 140367132252320
	140367132247520 [label=ReluBackward0]
	140367132247808 -> 140367132247520
	140367132247808 [label=NativeBatchNormBackward0]
	140367132248336 -> 140367132247808
	140367132248336 [label=ConvolutionBackward0]
	140367132249584 -> 140367132248336
	140367132249584 [label=ReluBackward0]
	140367132247472 -> 140367132249584
	140367132247472 [label=AddBackward0]
	140367132247424 -> 140367132247472
	140367132247424 [label=NativeBatchNormBackward0]
	140367132251696 -> 140367132247424
	140367132251696 [label=ConvolutionBackward0]
	140367132251648 -> 140367132251696
	140367132251648 [label=ReluBackward0]
	140367132246128 -> 140367132251648
	140367132246128 [label=NativeBatchNormBackward0]
	140367132248144 -> 140367132246128
	140367132248144 [label=ConvolutionBackward0]
	140367132247040 -> 140367132248144
	140367132247040 [label=ReluBackward0]
	140367132248768 -> 140367132247040
	140367132248768 [label=NativeBatchNormBackward0]
	140367132249200 -> 140367132248768
	140367132249200 [label=ConvolutionBackward0]
	140367132247088 -> 140367132249200
	140367132249824 -> 140367132249200
	140367128467952 [label="transition3.3.0.0.weight
 (144, 72, 3, 3)" fillcolor=lightblue]
	140367128467952 -> 140367132249824
	140367132249824 [label=AccumulateGrad]
	140367132248096 -> 140367132248768
	140367128467712 [label="transition3.3.0.1.weight
 (144)" fillcolor=lightblue]
	140367128467712 -> 140367132248096
	140367132248096 [label=AccumulateGrad]
	140367132249728 -> 140367132248768
	140367128467872 [label="transition3.3.0.1.bias
 (144)" fillcolor=lightblue]
	140367128467872 -> 140367132249728
	140367132249728 [label=AccumulateGrad]
	140367132248480 -> 140367132248144
	140367127750496 [label="stage4.0.branches.3.0.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367127750496 -> 140367132248480
	140367132248480 [label=AccumulateGrad]
	140367132247904 -> 140367132246128
	140367127750336 [label="stage4.0.branches.3.0.bn1.weight
 (144)" fillcolor=lightblue]
	140367127750336 -> 140367132247904
	140367132247904 [label=AccumulateGrad]
	140367132248432 -> 140367132246128
	140367127750576 [label="stage4.0.branches.3.0.bn1.bias
 (144)" fillcolor=lightblue]
	140367127750576 -> 140367132248432
	140367132248432 [label=AccumulateGrad]
	140367132251888 -> 140367132251696
	140367127749056 [label="stage4.0.branches.3.0.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367127749056 -> 140367132251888
	140367132251888 [label=AccumulateGrad]
	140367132247568 -> 140367132247424
	140367127748816 [label="stage4.0.branches.3.0.bn2.weight
 (144)" fillcolor=lightblue]
	140367127748816 -> 140367132247568
	140367132247568 [label=AccumulateGrad]
	140367132247184 -> 140367132247424
	140367127748976 [label="stage4.0.branches.3.0.bn2.bias
 (144)" fillcolor=lightblue]
	140367127748976 -> 140367132247184
	140367132247184 [label=AccumulateGrad]
	140367132247040 -> 140367132247472
	140367132250832 -> 140367132248336
	140367127747456 [label="stage4.0.branches.3.1.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367127747456 -> 140367132250832
	140367132250832 [label=AccumulateGrad]
	140367132247664 -> 140367132247808
	140367127747296 [label="stage4.0.branches.3.1.bn1.weight
 (144)" fillcolor=lightblue]
	140367127747296 -> 140367132247664
	140367132247664 [label=AccumulateGrad]
	140367132248240 -> 140367132247808
	140367127747536 [label="stage4.0.branches.3.1.bn1.bias
 (144)" fillcolor=lightblue]
	140367127747536 -> 140367132248240
	140367132248240 [label=AccumulateGrad]
	140367132248528 -> 140367132252320
	140367127746016 [label="stage4.0.branches.3.1.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367127746016 -> 140367132248528
	140367132248528 [label=AccumulateGrad]
	140367132249968 -> 140367132250160
	140367127745776 [label="stage4.0.branches.3.1.bn2.weight
 (144)" fillcolor=lightblue]
	140367127745776 -> 140367132249968
	140367132249968 [label=AccumulateGrad]
	140367132248384 -> 140367132250160
	140367127745936 [label="stage4.0.branches.3.1.bn2.bias
 (144)" fillcolor=lightblue]
	140367127745936 -> 140367132248384
	140367132248384 [label=AccumulateGrad]
	140367132249584 -> 140367132249344
	140367132247856 -> 140367132252560
	140367127744416 [label="stage4.0.branches.3.2.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367127744416 -> 140367132247856
	140367132247856 [label=AccumulateGrad]
	140367132249008 -> 140367132250304
	140367127744256 [label="stage4.0.branches.3.2.bn1.weight
 (144)" fillcolor=lightblue]
	140367127744256 -> 140367132249008
	140367132249008 [label=AccumulateGrad]
	140367132247760 -> 140367132250304
	140367127744496 [label="stage4.0.branches.3.2.bn1.bias
 (144)" fillcolor=lightblue]
	140367127744496 -> 140367132247760
	140367132247760 [label=AccumulateGrad]
	140367132250256 -> 140367132252224
	140367127742976 [label="stage4.0.branches.3.2.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367127742976 -> 140367132250256
	140367132250256 [label=AccumulateGrad]
	140367132251120 -> 140367132250544
	140367127742736 [label="stage4.0.branches.3.2.bn2.weight
 (144)" fillcolor=lightblue]
	140367127742736 -> 140367132251120
	140367132251120 [label=AccumulateGrad]
	140367132249488 -> 140367132250544
	140367127742896 [label="stage4.0.branches.3.2.bn2.bias
 (144)" fillcolor=lightblue]
	140367127742896 -> 140367132249488
	140367132249488 [label=AccumulateGrad]
	140367132251456 -> 140367132247280
	140367132248816 -> 140367132250688
	140367127741376 [label="stage4.0.branches.3.3.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367127741376 -> 140367132248816
	140367132248816 [label=AccumulateGrad]
	140367132252896 -> 140367132253472
	140367127741216 [label="stage4.0.branches.3.3.bn1.weight
 (144)" fillcolor=lightblue]
	140367127741216 -> 140367132252896
	140367132252896 [label=AccumulateGrad]
	140367132253712 -> 140367132253472
	140367127741456 [label="stage4.0.branches.3.3.bn1.bias
 (144)" fillcolor=lightblue]
	140367127741456 -> 140367132253712
	140367132253712 [label=AccumulateGrad]
	140367132254960 -> 140367132255968
	140367127755616 [label="stage4.0.branches.3.3.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367127755616 -> 140367132254960
	140367132254960 [label=AccumulateGrad]
	140367132254144 -> 140367132257984
	140367127754976 [label="stage4.0.branches.3.3.bn2.weight
 (144)" fillcolor=lightblue]
	140367127754976 -> 140367132254144
	140367132254144 [label=AccumulateGrad]
	140367132255584 -> 140367132257984
	140367127755216 [label="stage4.0.branches.3.3.bn2.bias
 (144)" fillcolor=lightblue]
	140367127755216 -> 140367132255584
	140367132255584 [label=AccumulateGrad]
	140367132257072 -> 140367132255248
	140367132257024 -> 140367131554336
	140367127744336 [label="stage4.0.fuse_layers.0.3.0.weight
 (18, 144, 1, 1)" fillcolor=lightblue]
	140367127744336 -> 140367132257024
	140367132257024 [label=AccumulateGrad]
	140367131553568 -> 140367130002816
	140367127744096 [label="stage4.0.fuse_layers.0.3.1.weight
 (18)" fillcolor=lightblue]
	140367127744096 -> 140367131553568
	140367131553568 [label=AccumulateGrad]
	140367131545888 -> 140367130002816
	140367127744576 [label="stage4.0.fuse_layers.0.3.1.bias
 (18)" fillcolor=lightblue]
	140367127744576 -> 140367131545888
	140367131545888 [label=AccumulateGrad]
	140367130003008 -> 140367130003728
	140367127681280 [label="stage4.1.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127681280 -> 140367130003008
	140367130003008 [label=AccumulateGrad]
	140367130003776 -> 140367130003488
	140367127682960 [label="stage4.1.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140367127682960 -> 140367130003776
	140367130003776 [label=AccumulateGrad]
	140367130003920 -> 140367130003488
	140367127681440 [label="stage4.1.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140367127681440 -> 140367130003920
	140367130003920 [label=AccumulateGrad]
	140367130004016 -> 140367130004160
	140367127679680 [label="stage4.1.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127679680 -> 140367130004016
	140367130004016 [label=AccumulateGrad]
	140367130004208 -> 140367130004304
	140367127679040 [label="stage4.1.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140367127679040 -> 140367130004208
	140367130004208 [label=AccumulateGrad]
	140367130004256 -> 140367130004304
	140367127679280 [label="stage4.1.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140367127679280 -> 140367130004256
	140367130004256 [label=AccumulateGrad]
	140367130004352 -> 140367130004112
	140367130004640 -> 140367130004832
	140367127675760 [label="stage4.1.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127675760 -> 140367130004640
	140367130004640 [label=AccumulateGrad]
	140367130004400 -> 140367130004976
	140367127675520 [label="stage4.1.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140367127675520 -> 140367130004400
	140367130004400 [label=AccumulateGrad]
	140367130005072 -> 140367130004976
	140367127676000 [label="stage4.1.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140367127676000 -> 140367130005072
	140367130005072 [label=AccumulateGrad]
	140367130005168 -> 140367130005312
	140367127641008 [label="stage4.1.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127641008 -> 140367130005168
	140367130005168 [label=AccumulateGrad]
	140367130005360 -> 140367130005456
	140367127640688 [label="stage4.1.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140367127640688 -> 140367130005360
	140367130005360 [label=AccumulateGrad]
	140367130005408 -> 140367130005456
	140367127640848 [label="stage4.1.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140367127640848 -> 140367130005408
	140367130005408 [label=AccumulateGrad]
	140367130005216 -> 140367130005552
	140367130005648 -> 140367130004928
	140367127639328 [label="stage4.1.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127639328 -> 140367130005648
	140367130005648 [label=AccumulateGrad]
	140367130006032 -> 140367130006080
	140367127639168 [label="stage4.1.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140367127639168 -> 140367130006032
	140367130006032 [label=AccumulateGrad]
	140367130006176 -> 140367130006080
	140367127639488 [label="stage4.1.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140367127639488 -> 140367130006176
	140367130006176 [label=AccumulateGrad]
	140367130005792 -> 140367130006464
	140367127637968 [label="stage4.1.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127637968 -> 140367130005792
	140367130005792 [label=AccumulateGrad]
	140367130006512 -> 140367130006272
	140367127637648 [label="stage4.1.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140367127637648 -> 140367130006512
	140367130006512 [label=AccumulateGrad]
	140367130006560 -> 140367130006272
	140367127637808 [label="stage4.1.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140367127637808 -> 140367130006560
	140367130006560 [label=AccumulateGrad]
	140367130006656 -> 140367130006704
	140367130006800 -> 140367130006992
	140367127636288 [label="stage4.1.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127636288 -> 140367130006800
	140367130006800 [label=AccumulateGrad]
	140367130007040 -> 140367130007088
	140367127636128 [label="stage4.1.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140367127636128 -> 140367130007040
	140367130007040 [label=AccumulateGrad]
	140367130006896 -> 140367130007088
	140367127636448 [label="stage4.1.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140367127636448 -> 140367130006896
	140367130006896 [label=AccumulateGrad]
	140367130001808 -> 140367130007760
	140367127634928 [label="stage4.1.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127634928 -> 140367130001808
	140367130001808 [label=AccumulateGrad]
	140367130007808 -> 140367130008000
	140367127634608 [label="stage4.1.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140367127634608 -> 140367130007808
	140367130007808 [label=AccumulateGrad]
	140367130007952 -> 140367130008000
	140367127634768 [label="stage4.1.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140367127634768 -> 140367130007952
	140367130007952 [label=AccumulateGrad]
	140367130008048 -> 140367130008192
	140367130008672 -> 140367130008624
	140367130008672 [label=UpsampleBilinear2DBackward0]
	140367130007712 -> 140367130008672
	140367130007712 [label=NativeBatchNormBackward0]
	140367130006752 -> 140367130007712
	140367130006752 [label=ConvolutionBackward0]
	140367130006848 -> 140367130006752
	140367130006848 [label=ReluBackward0]
	140367130005600 -> 140367130006848
	140367130005600 [label=AddBackward0]
	140367130005504 -> 140367130005600
	140367130005504 [label=NativeBatchNormBackward0]
	140367130005744 -> 140367130005504
	140367130005744 [label=ConvolutionBackward0]
	140367130004784 -> 140367130005744
	140367130004784 [label=ReluBackward0]
	140367130004736 -> 140367130004784
	140367130004736 [label=NativeBatchNormBackward0]
	140367130003440 -> 140367130004736
	140367130003440 [label=ConvolutionBackward0]
	140367130006368 -> 140367130003440
	140367130006368 [label=ReluBackward0]
	140367131546320 -> 140367130006368
	140367131546320 [label=AddBackward0]
	140367130003680 -> 140367131546320
	140367130003680 [label=NativeBatchNormBackward0]
	140367132252848 -> 140367130003680
	140367132252848 [label=ConvolutionBackward0]
	140367132250400 -> 140367132252848
	140367132250400 [label=ReluBackward0]
	140367132246992 -> 140367132250400
	140367132246992 [label=NativeBatchNormBackward0]
	140367132252368 -> 140367132246992
	140367132252368 [label=ConvolutionBackward0]
	140367132254912 -> 140367132252368
	140367132254912 [label=ReluBackward0]
	140367132247952 -> 140367132254912
	140367132247952 [label=AddBackward0]
	140367132251264 -> 140367132247952
	140367132251264 [label=NativeBatchNormBackward0]
	140367132249056 -> 140367132251264
	140367132249056 [label=ConvolutionBackward0]
	140367132247616 -> 140367132249056
	140367132247616 [label=ReluBackward0]
	140367132248576 -> 140367132247616
	140367132248576 [label=NativeBatchNormBackward0]
	140367132252272 -> 140367132248576
	140367132252272 [label=ConvolutionBackward0]
	140367132247328 -> 140367132252272
	140367132247328 [label=ReluBackward0]
	140367132250016 -> 140367132247328
	140367132250016 [label=AddBackward0]
	140367132252752 -> 140367132250016
	140367132252752 [label=NativeBatchNormBackward0]
	140367132246416 -> 140367132252752
	140367132246416 [label=ConvolutionBackward0]
	140367387035440 -> 140367132246416
	140367387035440 [label=ReluBackward0]
	140367151174448 -> 140367387035440
	140367151174448 [label=NativeBatchNormBackward0]
	140367387119376 -> 140367151174448
	140367387119376 [label=ConvolutionBackward0]
	140367132248000 -> 140367387119376
	140367132248000 [label=ReluBackward0]
	140367135101072 -> 140367132248000
	140367135101072 [label=AddBackward0]
	140367135101408 -> 140367135101072
	140367135101408 [label=AddBackward0]
	140367135097376 -> 140367135101408
	140367135097376 [label=AddBackward0]
	140367135096944 -> 140367135097376
	140367135096944 [label=NativeBatchNormBackward0]
	140367168218944 -> 140367135096944
	140367168218944 [label=ConvolutionBackward0]
	140367130002864 -> 140367168218944
	140367367308432 -> 140367168218944
	140367127691040 [label="stage4.0.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140367127691040 -> 140367367308432
	140367367308432 [label=AccumulateGrad]
	140367168220768 -> 140367135096944
	140367127690880 [label="stage4.0.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140367127690880 -> 140367168220768
	140367168220768 [label=AccumulateGrad]
	140367168220960 -> 140367135096944
	140367127691120 [label="stage4.0.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140367127691120 -> 140367168220960
	140367168220960 [label=AccumulateGrad]
	140367130001952 -> 140367135097376
	140367135110288 -> 140367135101408
	140367135110288 [label=UpsampleBilinear2DBackward0]
	140367367308528 -> 140367135110288
	140367367308528 [label=NativeBatchNormBackward0]
	140367168219376 -> 140367367308528
	140367168219376 [label=ConvolutionBackward0]
	140367131552704 -> 140367168219376
	140367151323536 -> 140367168219376
	140367127741056 [label="stage4.0.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140367127741056 -> 140367151323536
	140367151323536 [label=AccumulateGrad]
	140367168209776 -> 140367367308528
	140367127740816 [label="stage4.0.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140367127740816 -> 140367168209776
	140367168209776 [label=AccumulateGrad]
	140367151324304 -> 140367367308528
	140367127689520 [label="stage4.0.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140367127689520 -> 140367151324304
	140367151324304 [label=AccumulateGrad]
	140367135106208 -> 140367135101072
	140367135106208 [label=UpsampleBilinear2DBackward0]
	140367168219136 -> 140367135106208
	140367168219136 [label=NativeBatchNormBackward0]
	140367151320608 -> 140367168219136
	140367151320608 [label=ConvolutionBackward0]
	140367352517328 -> 140367151320608
	140367132162656 -> 140367151320608
	140367127688240 [label="stage4.0.fuse_layers.1.3.0.weight
 (36, 144, 1, 1)" fillcolor=lightblue]
	140367127688240 -> 140367132162656
	140367132162656 [label=AccumulateGrad]
	140367151324064 -> 140367168219136
	140367127688080 [label="stage4.0.fuse_layers.1.3.1.weight
 (36)" fillcolor=lightblue]
	140367127688080 -> 140367151324064
	140367151324064 [label=AccumulateGrad]
	140367151327856 -> 140367168219136
	140367127688400 [label="stage4.0.fuse_layers.1.3.1.bias
 (36)" fillcolor=lightblue]
	140367127688400 -> 140367151327856
	140367151327856 [label=AccumulateGrad]
	140367135106256 -> 140367387119376
	140367135575008 [label="stage4.1.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367135575008 -> 140367135106256
	140367135106256 [label=AccumulateGrad]
	140367387121104 -> 140367151174448
	140367127633248 [label="stage4.1.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140367127633248 -> 140367387121104
	140367387121104 [label=AccumulateGrad]
	140367387120768 -> 140367151174448
	140367127633408 [label="stage4.1.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140367127633408 -> 140367387120768
	140367387120768 [label=AccumulateGrad]
	140367387040000 -> 140367132246416
	140367127632128 [label="stage4.1.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127632128 -> 140367387040000
	140367387040000 [label=AccumulateGrad]
	140367132250208 -> 140367132252752
	140367127631728 [label="stage4.1.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140367127631728 -> 140367132250208
	140367132250208 [label=AccumulateGrad]
	140367132251072 -> 140367132252752
	140367127631888 [label="stage4.1.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140367127631888 -> 140367132251072
	140367132251072 [label=AccumulateGrad]
	140367132248000 -> 140367132250016
	140367132250928 -> 140367132252272
	140367127630368 [label="stage4.1.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127630368 -> 140367132250928
	140367132250928 [label=AccumulateGrad]
	140367132247136 -> 140367132248576
	140367127630208 [label="stage4.1.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140367127630208 -> 140367132247136
	140367132247136 [label=AccumulateGrad]
	140367132249296 -> 140367132248576
	140367127630608 [label="stage4.1.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140367127630608 -> 140367132249296
	140367132249296 [label=AccumulateGrad]
	140367132248192 -> 140367132249056
	140367127629088 [label="stage4.1.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127629088 -> 140367132248192
	140367132248192 [label=AccumulateGrad]
	140367132246752 -> 140367132251264
	140367127628688 [label="stage4.1.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140367127628688 -> 140367132246752
	140367132246752 [label=AccumulateGrad]
	140367132252032 -> 140367132251264
	140367127628848 [label="stage4.1.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140367127628848 -> 140367132252032
	140367132252032 [label=AccumulateGrad]
	140367132247328 -> 140367132247952
	140367132250448 -> 140367132252368
	140367127627328 [label="stage4.1.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127627328 -> 140367132250448
	140367132250448 [label=AccumulateGrad]
	140367132250592 -> 140367132246992
	140367127627168 [label="stage4.1.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140367127627168 -> 140367132250592
	140367132250592 [label=AccumulateGrad]
	140367132256016 -> 140367132246992
	140367127627568 [label="stage4.1.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140367127627568 -> 140367132256016
	140367132256016 [label=AccumulateGrad]
	140367132253136 -> 140367132252848
	140367127626048 [label="stage4.1.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127626048 -> 140367132253136
	140367132253136 [label=AccumulateGrad]
	140367132261056 -> 140367130003680
	140367127641888 [label="stage4.1.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140367127641888 -> 140367132261056
	140367132261056 [label=AccumulateGrad]
	140367132257744 -> 140367130003680
	140367127625808 [label="stage4.1.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140367127625808 -> 140367132257744
	140367132257744 [label=AccumulateGrad]
	140367132254912 -> 140367131546320
	140367130003584 -> 140367130003440
	140367127638608 [label="stage4.1.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127638608 -> 140367130003584
	140367130003584 [label=AccumulateGrad]
	140367130003872 -> 140367130004736
	140367127638368 [label="stage4.1.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140367127638368 -> 140367130003872
	140367130003872 [label=AccumulateGrad]
	140367130003824 -> 140367130004736
	140367127638848 [label="stage4.1.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140367127638848 -> 140367130003824
	140367130003824 [label=AccumulateGrad]
	140367130004880 -> 140367130005744
	140367127635328 [label="stage4.1.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127635328 -> 140367130004880
	140367130004880 [label=AccumulateGrad]
	140367130005696 -> 140367130005504
	140367127634688 [label="stage4.1.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140367127634688 -> 140367130005696
	140367130005696 [label=AccumulateGrad]
	140367130005264 -> 140367130005504
	140367127635088 [label="stage4.1.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140367127635088 -> 140367130005264
	140367130005264 [label=AccumulateGrad]
	140367130006368 -> 140367130005600
	140367130006416 -> 140367130006752
	140367127563072 [label="stage4.1.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140367127563072 -> 140367130006416
	140367130006416 [label=AccumulateGrad]
	140367130007136 -> 140367130007712
	140367127562672 [label="stage4.1.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140367127562672 -> 140367130007136
	140367130007136 [label=AccumulateGrad]
	140367130008240 -> 140367130007712
	140367127563312 [label="stage4.1.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140367127563312 -> 140367130008240
	140367130008240 [label=AccumulateGrad]
	140367130008768 -> 140367130009008
	140367130008768 [label=UpsampleBilinear2DBackward0]
	140367130007184 -> 140367130008768
	140367130007184 [label=NativeBatchNormBackward0]
	140367130005024 -> 140367130007184
	140367130005024 [label=ConvolutionBackward0]
	140367130003248 -> 140367130005024
	140367130003248 [label=ReluBackward0]
	140367130003632 -> 140367130003248
	140367130003632 [label=AddBackward0]
	140367130003536 -> 140367130003632
	140367130003536 [label=NativeBatchNormBackward0]
	140367132253760 -> 140367130003536
	140367132253760 [label=ConvolutionBackward0]
	140367132248288 -> 140367132253760
	140367132248288 [label=ReluBackward0]
	140367132249680 -> 140367132248288
	140367132249680 [label=NativeBatchNormBackward0]
	140367132250112 -> 140367132249680
	140367132250112 [label=ConvolutionBackward0]
	140367132257456 -> 140367132250112
	140367132257456 [label=ReluBackward0]
	140367387035680 -> 140367132257456
	140367387035680 [label=AddBackward0]
	140367135108944 -> 140367387035680
	140367135108944 [label=NativeBatchNormBackward0]
	140367151324160 -> 140367135108944
	140367151324160 [label=ConvolutionBackward0]
	140367132162800 -> 140367151324160
	140367132162800 [label=ReluBackward0]
	140367151453264 -> 140367132162800
	140367151453264 [label=NativeBatchNormBackward0]
	140367151453792 -> 140367151453264
	140367151453792 [label=ConvolutionBackward0]
	140367135097232 -> 140367151453792
	140367135097232 [label=ReluBackward0]
	140367388461952 -> 140367135097232
	140367388461952 [label=AddBackward0]
	140370526803504 -> 140367388461952
	140370526803504 [label=NativeBatchNormBackward0]
	140367172729776 -> 140370526803504
	140367172729776 [label=ConvolutionBackward0]
	140367354385344 -> 140367172729776
	140367354385344 [label=ReluBackward0]
	140367167935856 -> 140367354385344
	140367167935856 [label=NativeBatchNormBackward0]
	140367129411840 -> 140367167935856
	140367129411840 [label=ConvolutionBackward0]
	140367364505072 -> 140367129411840
	140367364505072 [label=ReluBackward0]
	140367129412368 -> 140367364505072
	140367129412368 [label=AddBackward0]
	140367129412800 -> 140367129412368
	140367129412800 [label=NativeBatchNormBackward0]
	140367129413040 -> 140367129412800
	140367129413040 [label=ConvolutionBackward0]
	140367129413328 -> 140367129413040
	140367129413328 [label=ReluBackward0]
	140367129413520 -> 140367129413328
	140367129413520 [label=NativeBatchNormBackward0]
	140367129414144 -> 140367129413520
	140367129414144 [label=ConvolutionBackward0]
	140367129413376 -> 140367129414144
	140367129413376 [label=ReluBackward0]
	140367129414816 -> 140367129413376
	140367129414816 [label=AddBackward0]
	140367129415872 -> 140367129414816
	140367129415872 [label=AddBackward0]
	140367129416064 -> 140367129415872
	140367129416064 [label=AddBackward0]
	140367129415344 -> 140367129416064
	140367129415344 [label=NativeBatchNormBackward0]
	140367129415536 -> 140367129415344
	140367129415536 [label=ConvolutionBackward0]
	140367129417216 -> 140367129415536
	140367129417216 [label=ReluBackward0]
	140367129417888 -> 140367129417216
	140367129417888 [label=NativeBatchNormBackward0]
	140367129416688 -> 140367129417888
	140367129416688 [label=ConvolutionBackward0]
	140367130002864 -> 140367129416688
	140367129418080 -> 140367129416688
	140367127686640 [label="stage4.0.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127686640 -> 140367129418080
	140367129418080 [label=AccumulateGrad]
	140367129416832 -> 140367129417888
	140367127686480 [label="stage4.0.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140367127686480 -> 140367129416832
	140367129416832 [label=AccumulateGrad]
	140367129416400 -> 140367129417888
	140367127686720 [label="stage4.0.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140367127686720 -> 140367129416400
	140367129416400 [label=AccumulateGrad]
	140367129416016 -> 140367129415536
	140367127686560 [label="stage4.0.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140367127686560 -> 140367129416016
	140367129416016 [label=AccumulateGrad]
	140367129415728 -> 140367129415344
	140367127685120 [label="stage4.0.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140367127685120 -> 140367129415728
	140367129415728 [label=AccumulateGrad]
	140367129416544 -> 140367129415344
	140367127685200 [label="stage4.0.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140367127685200 -> 140367129416544
	140367129416544 [label=AccumulateGrad]
	140367129415488 -> 140367129416064
	140367129415488 [label=NativeBatchNormBackward0]
	140367129417072 -> 140367129415488
	140367129417072 [label=ConvolutionBackward0]
	140367130001952 -> 140367129417072
	140367129416880 -> 140367129417072
	140367127683840 [label="stage4.0.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140367127683840 -> 140367129416880
	140367129416880 [label=AccumulateGrad]
	140367129416208 -> 140367129415488
	140367127683760 [label="stage4.0.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140367127683760 -> 140367129416208
	140367129416208 [label=AccumulateGrad]
	140367129416736 -> 140367129415488
	140367127683920 [label="stage4.0.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140367127683920 -> 140367129416736
	140367129416736 [label=AccumulateGrad]
	140367131552704 -> 140367129415872
	140367129414672 -> 140367129414816
	140367129414672 [label=UpsampleBilinear2DBackward0]
	140367129416160 -> 140367129414672
	140367129416160 [label=NativeBatchNormBackward0]
	140367129418560 -> 140367129416160
	140367129418560 [label=ConvolutionBackward0]
	140367352517328 -> 140367129418560
	140367129417552 -> 140367129418560
	140367127687040 [label="stage4.0.fuse_layers.2.3.0.weight
 (72, 144, 1, 1)" fillcolor=lightblue]
	140367127687040 -> 140367129417552
	140367129417552 [label=AccumulateGrad]
	140367129417408 -> 140367129416160
	140367127682400 [label="stage4.0.fuse_layers.2.3.1.weight
 (72)" fillcolor=lightblue]
	140367127682400 -> 140367129417408
	140367129417408 [label=AccumulateGrad]
	140367129414864 -> 140367129416160
	140367127686880 [label="stage4.0.fuse_layers.2.3.1.bias
 (72)" fillcolor=lightblue]
	140367127686880 -> 140367129414864
	140367129414864 [label=AccumulateGrad]
	140367129414192 -> 140367129414144
	140367127631248 [label="stage4.1.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127631248 -> 140367129414192
	140367129414192 [label=AccumulateGrad]
	140367129415200 -> 140367129413520
	140367127631008 [label="stage4.1.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140367127631008 -> 140367129415200
	140367129415200 [label=AccumulateGrad]
	140367129414528 -> 140367129413520
	140367127631648 [label="stage4.1.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140367127631648 -> 140367129414528
	140367129414528 [label=AccumulateGrad]
	140367129413472 -> 140367129413040
	140367127627968 [label="stage4.1.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127627968 -> 140367129413472
	140367129413472 [label=AccumulateGrad]
	140367129413856 -> 140367129412800
	140367127627488 [label="stage4.1.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140367127627488 -> 140367129413856
	140367129413856 [label=AccumulateGrad]
	140367129412656 -> 140367129412800
	140367127627728 [label="stage4.1.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140367127627728 -> 140367129412656
	140367129412656 [label=AccumulateGrad]
	140367129413376 -> 140367129412368
	140367129412128 -> 140367129411840
	140367127575872 [label="stage4.1.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127575872 -> 140367129412128
	140367129412128 [label=AccumulateGrad]
	140367129412512 -> 140367167935856
	140367127575792 [label="stage4.1.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140367127575792 -> 140367129412512
	140367129412512 [label=AccumulateGrad]
	140367129411984 -> 140367167935856
	140367127576032 [label="stage4.1.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140367127576032 -> 140367129411984
	140367129411984 [label=AccumulateGrad]
	140367354394224 -> 140367172729776
	140367127574512 [label="stage4.1.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127574512 -> 140367354394224
	140367354394224 [label=AccumulateGrad]
	140367172722576 -> 140370526803504
	140367127574272 [label="stage4.1.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140367127574272 -> 140367172722576
	140367172722576 [label=AccumulateGrad]
	140367172718208 -> 140370526803504
	140367127574352 [label="stage4.1.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140367127574352 -> 140367172718208
	140367172718208 [label=AccumulateGrad]
	140367364505072 -> 140367388461952
	140367439236832 -> 140367151453792
	140367127572832 [label="stage4.1.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127572832 -> 140367439236832
	140367439236832 [label=AccumulateGrad]
	140367151452976 -> 140367151453264
	140367127572752 [label="stage4.1.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140367127572752 -> 140367151452976
	140367151452976 [label=AccumulateGrad]
	140367151449520 -> 140367151453264
	140367127572992 [label="stage4.1.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140367127572992 -> 140367151449520
	140367151449520 [label=AccumulateGrad]
	140367132163568 -> 140367151324160
	140367127571472 [label="stage4.1.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127571472 -> 140367132163568
	140367132163568 [label=AccumulateGrad]
	140367135106448 -> 140367135108944
	140367127571232 [label="stage4.1.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140367127571232 -> 140367135106448
	140367135106448 [label=AccumulateGrad]
	140367132161888 -> 140367135108944
	140367127571312 [label="stage4.1.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140367127571312 -> 140367132161888
	140367132161888 [label=AccumulateGrad]
	140367135097232 -> 140367387035680
	140367151172432 -> 140367132250112
	140367127569792 [label="stage4.1.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127569792 -> 140367151172432
	140367151172432 [label=AccumulateGrad]
	140367132249440 -> 140367132249680
	140367127569712 [label="stage4.1.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140367127569712 -> 140367132249440
	140367132249440 [label=AccumulateGrad]
	140367132248048 -> 140367132249680
	140367127569952 [label="stage4.1.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140367127569952 -> 140367132248048
	140367132248048 [label=AccumulateGrad]
	140367132250064 -> 140367132253760
	140367127568432 [label="stage4.1.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367127568432 -> 140367132250064
	140367132250064 [label=AccumulateGrad]
	140367132248624 -> 140367130003536
	140367127568192 [label="stage4.1.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140367127568192 -> 140367132248624
	140367132248624 [label=AccumulateGrad]
	140367132252992 -> 140367130003536
	140367127568272 [label="stage4.1.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140367127568272 -> 140367132252992
	140367132252992 [label=AccumulateGrad]
	140367132257456 -> 140367130003632
	140367130004688 -> 140367130005024
	140367129575040 [label="stage4.1.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140367129575040 -> 140367130004688
	140367130004688 [label=AccumulateGrad]
	140367130006128 -> 140367130007184
	140367129574880 [label="stage4.1.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140367129574880 -> 140367130006128
	140367130006128 [label=AccumulateGrad]
	140367130008720 -> 140367130007184
	140367129575280 [label="stage4.1.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140367129575280 -> 140367130008720
	140367130008720 [label=AccumulateGrad]
	140367130009056 -> 140367130009200
	140367130009056 [label=UpsampleBilinear2DBackward0]
	140367130006944 -> 140367130009056
	140367130006944 [label=NativeBatchNormBackward0]
	140367130004064 -> 140367130006944
	140367130004064 [label=ConvolutionBackward0]
	140367132249920 -> 140367130004064
	140367132249920 [label=ReluBackward0]
	140367387040336 -> 140367132249920
	140367387040336 [label=AddBackward0]
	140367132162128 -> 140367387040336
	140367132162128 [label=NativeBatchNormBackward0]
	140367151452064 -> 140367132162128
	140367151452064 [label=ConvolutionBackward0]
	140367364504880 -> 140367151452064
	140367364504880 [label=ReluBackward0]
	140367167936000 -> 140367364504880
	140367167936000 [label=NativeBatchNormBackward0]
	140367129412848 -> 140367167936000
	140367129412848 [label=ConvolutionBackward0]
	140367135111056 -> 140367129412848
	140367135111056 [label=ReluBackward0]
	140367129414000 -> 140367135111056
	140367129414000 [label=AddBackward0]
	140367129414384 -> 140367129414000
	140367129414384 [label=NativeBatchNormBackward0]
	140367129417504 -> 140367129414384
	140367129417504 [label=ConvolutionBackward0]
	140367129418032 -> 140367129417504
	140367129418032 [label=ReluBackward0]
	140367129418224 -> 140367129418032
	140367129418224 [label=NativeBatchNormBackward0]
	140367129418848 -> 140367129418224
	140367129418848 [label=ConvolutionBackward0]
	140367129415056 -> 140367129418848
	140367129415056 [label=ReluBackward0]
	140367129419376 -> 140367129415056
	140367129419376 [label=AddBackward0]
	140367129419568 -> 140367129419376
	140367129419568 [label=NativeBatchNormBackward0]
	140367129420048 -> 140367129419568
	140367129420048 [label=ConvolutionBackward0]
	140367129420096 -> 140367129420048
	140367129420096 [label=ReluBackward0]
	140367129420576 -> 140367129420096
	140367129420576 [label=NativeBatchNormBackward0]
	140367129420912 -> 140367129420576
	140367129420912 [label=ConvolutionBackward0]
	140367129420192 -> 140367129420912
	140367129420192 [label=ReluBackward0]
	140367129421584 -> 140367129420192
	140367129421584 [label=AddBackward0]
	140367129422880 -> 140367129421584
	140367129422880 [label=NativeBatchNormBackward0]
	140367129423120 -> 140367129422880
	140367129423120 [label=ConvolutionBackward0]
	140367129422736 -> 140367129423120
	140367129422736 [label=ReluBackward0]
	140367129422928 -> 140367129422736
	140367129422928 [label=NativeBatchNormBackward0]
	140367129423792 -> 140367129422928
	140367129423792 [label=ConvolutionBackward0]
	140367129421440 -> 140367129423792
	140367129421440 [label=ReluBackward0]
	140367129424752 -> 140367129421440
	140367129424752 [label=AddBackward0]
	140367129423936 -> 140367129424752
	140367129423936 [label=AddBackward0]
	140367129424128 -> 140367129423936
	140367129424128 [label=AddBackward0]
	140367129424464 -> 140367129424128
	140367129424464 [label=NativeBatchNormBackward0]
	140367129424896 -> 140367129424464
	140367129424896 [label=ConvolutionBackward0]
	140367129426768 -> 140367129424896
	140367129426768 [label=ReluBackward0]
	140367129426288 -> 140367129426768
	140367129426288 [label=NativeBatchNormBackward0]
	140367129425808 -> 140367129426288
	140367129425808 [label=ConvolutionBackward0]
	140367129427488 -> 140367129425808
	140367129427488 [label=ReluBackward0]
	140367129427296 -> 140367129427488
	140367129427296 [label=NativeBatchNormBackward0]
	140367129426912 -> 140367129427296
	140367129426912 [label=ConvolutionBackward0]
	140367130002864 -> 140367129426912
	140367129427824 -> 140367129426912
	140367127681040 [label="stage4.0.fuse_layers.3.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127681040 -> 140367129427824
	140367129427824 [label=AccumulateGrad]
	140367129426816 -> 140367129427296
	140367127680880 [label="stage4.0.fuse_layers.3.0.0.1.weight
 (18)" fillcolor=lightblue]
	140367127680880 -> 140367129426816
	140367129426816 [label=AccumulateGrad]
	140367129426624 -> 140367129427296
	140367127681120 [label="stage4.0.fuse_layers.3.0.0.1.bias
 (18)" fillcolor=lightblue]
	140367127681120 -> 140367129426624
	140367129426624 [label=AccumulateGrad]
	140367129426240 -> 140367129425808
	140367127680960 [label="stage4.0.fuse_layers.3.0.1.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367127680960 -> 140367129426240
	140367129426240 [label=AccumulateGrad]
	140367129425952 -> 140367129426288
	140367127679360 [label="stage4.0.fuse_layers.3.0.1.1.weight
 (18)" fillcolor=lightblue]
	140367127679360 -> 140367129425952
	140367129425952 [label=AccumulateGrad]
	140367129425472 -> 140367129426288
	140367127679440 [label="stage4.0.fuse_layers.3.0.1.1.bias
 (18)" fillcolor=lightblue]
	140367127679440 -> 140367129425472
	140367129425472 [label=AccumulateGrad]
	140367129425136 -> 140367129424896
	140367127679520 [label="stage4.0.fuse_layers.3.0.2.0.weight
 (144, 18, 3, 3)" fillcolor=lightblue]
	140367127679520 -> 140367129425136
	140367129425136 [label=AccumulateGrad]
	140367129424800 -> 140367129424464
	140367127677840 [label="stage4.0.fuse_layers.3.0.2.1.weight
 (144)" fillcolor=lightblue]
	140367127677840 -> 140367129424800
	140367129424800 [label=AccumulateGrad]
	140367129425616 -> 140367129424464
	140367127677920 [label="stage4.0.fuse_layers.3.0.2.1.bias
 (144)" fillcolor=lightblue]
	140367127677920 -> 140367129425616
	140367129425616 [label=AccumulateGrad]
	140367129424608 -> 140367129424128
	140367129424608 [label=NativeBatchNormBackward0]
	140367129426480 -> 140367129424608
	140367129426480 [label=ConvolutionBackward0]
	140367129426144 -> 140367129426480
	140367129426144 [label=ReluBackward0]
	140367129427440 -> 140367129426144
	140367129427440 [label=NativeBatchNormBackward0]
	140367129427152 -> 140367129427440
	140367129427152 [label=ConvolutionBackward0]
	140367130001952 -> 140367129427152
	140367151950256 -> 140367129427152
	140367127676400 [label="stage4.0.fuse_layers.3.1.0.0.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367127676400 -> 140367151950256
	140367151950256 [label=AccumulateGrad]
	140367151940704 -> 140367129427440
	140367127676320 [label="stage4.0.fuse_layers.3.1.0.1.weight
 (36)" fillcolor=lightblue]
	140367127676320 -> 140367151940704
	140367151940704 [label=AccumulateGrad]
	140367151950832 -> 140367129427440
	140367127676480 [label="stage4.0.fuse_layers.3.1.0.1.bias
 (36)" fillcolor=lightblue]
	140367127676480 -> 140367151950832
	140367151950832 [label=AccumulateGrad]
	140367129427584 -> 140367129426480
	140367127678080 [label="stage4.0.fuse_layers.3.1.1.0.weight
 (144, 36, 3, 3)" fillcolor=lightblue]
	140367127678080 -> 140367129427584
	140367129427584 [label=AccumulateGrad]
	140367129425568 -> 140367129424608
	140367127690800 [label="stage4.0.fuse_layers.3.1.1.1.weight
 (144)" fillcolor=lightblue]
	140367127690800 -> 140367129425568
	140367129425568 [label=AccumulateGrad]
	140367129426096 -> 140367129424608
	140367127691200 [label="stage4.0.fuse_layers.3.1.1.1.bias
 (144)" fillcolor=lightblue]
	140367127691200 -> 140367129426096
	140367129426096 [label=AccumulateGrad]
	140367129424944 -> 140367129423936
	140367129424944 [label=NativeBatchNormBackward0]
	140367129426960 -> 140367129424944
	140367129426960 [label=ConvolutionBackward0]
	140367131552704 -> 140367129426960
	140367151940464 -> 140367129426960
	140367127687200 [label="stage4.0.fuse_layers.3.2.0.0.weight
 (144, 72, 3, 3)" fillcolor=lightblue]
	140367127687200 -> 140367151940464
	140367151940464 [label=AccumulateGrad]
	140367129425280 -> 140367129424944
	140367127686800 [label="stage4.0.fuse_layers.3.2.0.1.weight
 (144)" fillcolor=lightblue]
	140367127686800 -> 140367129425280
	140367129425280 [label=AccumulateGrad]
	140367129425424 -> 140367129424944
	140367127687440 [label="stage4.0.fuse_layers.3.2.0.1.bias
 (144)" fillcolor=lightblue]
	140367127687440 -> 140367129425424
	140367129425424 [label=AccumulateGrad]
	140367352517328 -> 140367129424752
	140367129423600 -> 140367129423792
	140367127566752 [label="stage4.1.branches.3.0.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367127566752 -> 140367129423600
	140367129423600 [label=AccumulateGrad]
	140367129422784 -> 140367129422928
	140367127566672 [label="stage4.1.branches.3.0.bn1.weight
 (144)" fillcolor=lightblue]
	140367127566672 -> 140367129422784
	140367129422784 [label=AccumulateGrad]
	140367129422592 -> 140367129422928
	140367127566912 [label="stage4.1.branches.3.0.bn1.bias
 (144)" fillcolor=lightblue]
	140367127566912 -> 140367129422592
	140367129422592 [label=AccumulateGrad]
	140367129423552 -> 140367129423120
	140367127565392 [label="stage4.1.branches.3.0.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367127565392 -> 140367129423552
	140367129423552 [label=AccumulateGrad]
	140367129421920 -> 140367129422880
	140367127565152 [label="stage4.1.branches.3.0.bn2.weight
 (144)" fillcolor=lightblue]
	140367127565152 -> 140367129421920
	140367129421920 [label=AccumulateGrad]
	140367129422064 -> 140367129422880
	140367127565232 [label="stage4.1.branches.3.0.bn2.bias
 (144)" fillcolor=lightblue]
	140367127565232 -> 140367129422064
	140367129422064 [label=AccumulateGrad]
	140367129421440 -> 140367129421584
	140367129421248 -> 140367129420912
	140367127563712 [label="stage4.1.branches.3.1.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367127563712 -> 140367129421248
	140367129421248 [label=AccumulateGrad]
	140367129421776 -> 140367129420576
	140367127563632 [label="stage4.1.branches.3.1.bn1.weight
 (144)" fillcolor=lightblue]
	140367127563632 -> 140367129421776
	140367129421776 [label=AccumulateGrad]
	140367129421536 -> 140367129420576
	140367127563872 [label="stage4.1.branches.3.1.bn1.bias
 (144)" fillcolor=lightblue]
	140367127563872 -> 140367129421536
	140367129421536 [label=AccumulateGrad]
	140367129420240 -> 140367129420048
	140367127562352 [label="stage4.1.branches.3.1.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367127562352 -> 140367129420240
	140367129420240 [label=AccumulateGrad]
	140367129420432 -> 140367129419568
	140367127562112 [label="stage4.1.branches.3.1.bn2.weight
 (144)" fillcolor=lightblue]
	140367127562112 -> 140367129420432
	140367129420432 [label=AccumulateGrad]
	140367129419424 -> 140367129419568
	140367127562192 [label="stage4.1.branches.3.1.bn2.bias
 (144)" fillcolor=lightblue]
	140367127562192 -> 140367129419424
	140367129419424 [label=AccumulateGrad]
	140367129420192 -> 140367129419376
	140367129418896 -> 140367129418848
	140367127560672 [label="stage4.1.branches.3.2.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367127560672 -> 140367129418896
	140367129418896 [label=AccumulateGrad]
	140367129419520 -> 140367129418224
	140367127560592 [label="stage4.1.branches.3.2.bn1.weight
 (144)" fillcolor=lightblue]
	140367127560592 -> 140367129419520
	140367129419520 [label=AccumulateGrad]
	140367129419232 -> 140367129418224
	140367127560832 [label="stage4.1.branches.3.2.bn1.bias
 (144)" fillcolor=lightblue]
	140367127560832 -> 140367129419232
	140367129419232 [label=AccumulateGrad]
	140367129418752 -> 140367129417504
	140367127574192 [label="stage4.1.branches.3.2.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367127574192 -> 140367129418752
	140367129418752 [label=AccumulateGrad]
	140367129417360 -> 140367129414384
	140367127573712 [label="stage4.1.branches.3.2.bn2.weight
 (144)" fillcolor=lightblue]
	140367127573712 -> 140367129417360
	140367129417360 [label=AccumulateGrad]
	140367129414720 -> 140367129414384
	140367127573952 [label="stage4.1.branches.3.2.bn2.bias
 (144)" fillcolor=lightblue]
	140367127573952 -> 140367129414720
	140367129414720 [label=AccumulateGrad]
	140367129415056 -> 140367129414000
	140367129415392 -> 140367129412848
	140367127570272 [label="stage4.1.branches.3.3.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367127570272 -> 140367129415392
	140367129415392 [label=AccumulateGrad]
	140367129411696 -> 140367167936000
	140367127569872 [label="stage4.1.branches.3.3.bn1.weight
 (144)" fillcolor=lightblue]
	140367127569872 -> 140367129411696
	140367129411696 [label=AccumulateGrad]
	140367129412176 -> 140367167936000
	140367127570672 [label="stage4.1.branches.3.3.bn1.bias
 (144)" fillcolor=lightblue]
	140367127570672 -> 140367129412176
	140367129412176 [label=AccumulateGrad]
	140367432313696 -> 140367151452064
	140367127566832 [label="stage4.1.branches.3.3.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367127566832 -> 140367432313696
	140367432313696 [label=AccumulateGrad]
	140367151450576 -> 140367132162128
	140367127566352 [label="stage4.1.branches.3.3.bn2.weight
 (144)" fillcolor=lightblue]
	140367127566352 -> 140367151450576
	140367151450576 [label=AccumulateGrad]
	140367151455952 -> 140367132162128
	140367127566592 [label="stage4.1.branches.3.3.bn2.bias
 (144)" fillcolor=lightblue]
	140367127566592 -> 140367151455952
	140367151455952 [label=AccumulateGrad]
	140367135111056 -> 140367387040336
	140367132248864 -> 140367130004064
	140367129573680 [label="stage4.1.fuse_layers.0.3.0.weight
 (18, 144, 1, 1)" fillcolor=lightblue]
	140367129573680 -> 140367132248864
	140367132248864 [label=AccumulateGrad]
	140367130006608 -> 140367130006944
	140367129573520 [label="stage4.1.fuse_layers.0.3.1.weight
 (18)" fillcolor=lightblue]
	140367129573520 -> 140367130006608
	140367130006608 [label=AccumulateGrad]
	140367130008960 -> 140367130006944
	140367129573920 [label="stage4.1.fuse_layers.0.3.1.bias
 (18)" fillcolor=lightblue]
	140367129573920 -> 140367130008960
	140367130008960 [label=AccumulateGrad]
	140367130008576 -> 140367130009824
	140367129562000 [label="stage4.2.branches.0.0.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367129562000 -> 140367130008576
	140367130008576 [label=AccumulateGrad]
	140367130009872 -> 140367130010064
	140367129565440 [label="stage4.2.branches.0.0.bn1.weight
 (18)" fillcolor=lightblue]
	140367129565440 -> 140367130009872
	140367130009872 [label=AccumulateGrad]
	140367130009680 -> 140367130010064
	140367129562240 [label="stage4.2.branches.0.0.bn1.bias
 (18)" fillcolor=lightblue]
	140367129562240 -> 140367130009680
	140367130009680 [label=AccumulateGrad]
	140367130010448 -> 140367130010544
	140367129508464 [label="stage4.2.branches.0.0.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367129508464 -> 140367130010448
	140367130010448 [label=AccumulateGrad]
	140367130010736 -> 140367130010784
	140367129508064 [label="stage4.2.branches.0.0.bn2.weight
 (18)" fillcolor=lightblue]
	140367129508064 -> 140367130010736
	140367130010736 [label=AccumulateGrad]
	140367130009632 -> 140367130010784
	140367129508224 [label="stage4.2.branches.0.0.bn2.bias
 (18)" fillcolor=lightblue]
	140367129508224 -> 140367130009632
	140367130009632 [label=AccumulateGrad]
	140367130011168 -> 140367130011216
	140367130011312 -> 140367130011648
	140367129506704 [label="stage4.2.branches.0.1.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367129506704 -> 140367130011312
	140367130011312 [label=AccumulateGrad]
	140367130011840 -> 140367130011888
	140367129506544 [label="stage4.2.branches.0.1.bn1.weight
 (18)" fillcolor=lightblue]
	140367129506544 -> 140367130011840
	140367130011840 [label=AccumulateGrad]
	140367130011936 -> 140367130011888
	140367129506944 [label="stage4.2.branches.0.1.bn1.bias
 (18)" fillcolor=lightblue]
	140367129506944 -> 140367130011936
	140367130011936 [label=AccumulateGrad]
	140367130012272 -> 140367130012512
	140367129505424 [label="stage4.2.branches.0.1.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367129505424 -> 140367130012272
	140367130012272 [label=AccumulateGrad]
	140367130012560 -> 140367130012608
	140367129505024 [label="stage4.2.branches.0.1.bn2.weight
 (18)" fillcolor=lightblue]
	140367129505024 -> 140367130012560
	140367130012560 [label=AccumulateGrad]
	140367130012176 -> 140367130012608
	140367129505184 [label="stage4.2.branches.0.1.bn2.bias
 (18)" fillcolor=lightblue]
	140367129505184 -> 140367130012176
	140367130012176 [label=AccumulateGrad]
	140367130012896 -> 140367130012944
	140367130011072 -> 140367130013712
	140367129503664 [label="stage4.2.branches.0.2.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367129503664 -> 140367130011072
	140367130011072 [label=AccumulateGrad]
	140367130013760 -> 140367130013808
	140367129503504 [label="stage4.2.branches.0.2.bn1.weight
 (18)" fillcolor=lightblue]
	140367129503504 -> 140367130013760
	140367130013760 [label=AccumulateGrad]
	140367130013904 -> 140367130013808
	140367129503904 [label="stage4.2.branches.0.2.bn1.bias
 (18)" fillcolor=lightblue]
	140367129503904 -> 140367130013904
	140367130013904 [label=AccumulateGrad]
	140367130014048 -> 140367130014192
	140367129502384 [label="stage4.2.branches.0.2.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367129502384 -> 140367130014048
	140367130014048 [label=AccumulateGrad]
	140367130014240 -> 140367130014336
	140367129501984 [label="stage4.2.branches.0.2.bn2.weight
 (18)" fillcolor=lightblue]
	140367129501984 -> 140367130014240
	140367130014240 [label=AccumulateGrad]
	140367130013952 -> 140367130014336
	140367129502144 [label="stage4.2.branches.0.2.bn2.bias
 (18)" fillcolor=lightblue]
	140367129502144 -> 140367130013952
	140367130013952 [label=AccumulateGrad]
	140367130014384 -> 140367130014432
	140367130014528 -> 140367130014720
	140367129500624 [label="stage4.2.branches.0.3.conv1.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367129500624 -> 140367130014528
	140367130014528 [label=AccumulateGrad]
	140367130014768 -> 140367130014816
	140367129500464 [label="stage4.2.branches.0.3.bn1.weight
 (18)" fillcolor=lightblue]
	140367129500464 -> 140367130014768
	140367130014768 [label=AccumulateGrad]
	140367130014000 -> 140367130014816
	140367129500864 [label="stage4.2.branches.0.3.bn1.bias
 (18)" fillcolor=lightblue]
	140367129500864 -> 140367130014000
	140367130014000 [label=AccumulateGrad]
	140367130015152 -> 140367130015296
	140367129499344 [label="stage4.2.branches.0.3.conv2.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367129499344 -> 140367130015152
	140367130015152 [label=AccumulateGrad]
	140367130014864 -> 140367130015488
	140367129498944 [label="stage4.2.branches.0.3.bn2.weight
 (18)" fillcolor=lightblue]
	140367129498944 -> 140367130014864
	140367130014864 [label=AccumulateGrad]
	140367130015440 -> 140367130015488
	140367129499104 [label="stage4.2.branches.0.3.bn2.bias
 (18)" fillcolor=lightblue]
	140367129499104 -> 140367130015440
	140367130015440 [label=AccumulateGrad]
	140367130015536 -> 140367130015584
	140367130015776 -> 140367130016592
	140367130015776 [label=UpsampleBilinear2DBackward0]
	140367130015248 -> 140367130015776
	140367130015248 [label=NativeBatchNormBackward0]
	140367130014480 -> 140367130015248
	140367130014480 [label=ConvolutionBackward0]
	140367130014288 -> 140367130014480
	140367130014288 [label=ReluBackward0]
	140367130012848 -> 140367130014288
	140367130012848 [label=AddBackward0]
	140367130001712 -> 140367130012848
	140367130001712 [label=NativeBatchNormBackward0]
	140367130012992 -> 140367130001712
	140367130012992 [label=ConvolutionBackward0]
	140367130011600 -> 140367130012992
	140367130011600 [label=ReluBackward0]
	140367130011552 -> 140367130011600
	140367130011552 [label=NativeBatchNormBackward0]
	140367130009248 -> 140367130011552
	140367130009248 [label=ConvolutionBackward0]
	140367130014096 -> 140367130009248
	140367130014096 [label=ReluBackward0]
	140367130009728 -> 140367130014096
	140367130009728 [label=AddBackward0]
	140367132251024 -> 140367130009728
	140367132251024 [label=NativeBatchNormBackward0]
	140367354393552 -> 140367132251024
	140367354393552 [label=ConvolutionBackward0]
	140367129418176 -> 140367354393552
	140367129418176 [label=ReluBackward0]
	140367129418416 -> 140367129418176
	140367129418416 [label=NativeBatchNormBackward0]
	140367129417744 -> 140367129418416
	140367129417744 [label=ConvolutionBackward0]
	140367132247712 -> 140367129417744
	140367132247712 [label=ReluBackward0]
	140367129422448 -> 140367132247712
	140367129422448 [label=AddBackward0]
	140367129420768 -> 140367129422448
	140367129420768 [label=NativeBatchNormBackward0]
	140367129422208 -> 140367129420768
	140367129422208 [label=ConvolutionBackward0]
	140367129423408 -> 140367129422208
	140367129423408 [label=ReluBackward0]
	140367129424080 -> 140367129423408
	140367129424080 [label=NativeBatchNormBackward0]
	140367129427632 -> 140367129424080
	140367129427632 [label=ConvolutionBackward0]
	140367129421104 -> 140367129427632
	140367129421104 [label=ReluBackward0]
	140367151941184 -> 140367129421104
	140367151941184 [label=AddBackward0]
	140367129558512 -> 140367151941184
	140367129558512 [label=NativeBatchNormBackward0]
	140367129554480 -> 140367129558512
	140367129554480 [label=ConvolutionBackward0]
	140367129542912 -> 140367129554480
	140367129542912 [label=ReluBackward0]
	140367129542864 -> 140367129542912
	140367129542864 [label=NativeBatchNormBackward0]
	140367129546416 -> 140367129542864
	140367129546416 [label=ConvolutionBackward0]
	140367129556304 -> 140367129546416
	140367129556304 [label=ReluBackward0]
	140367129544736 -> 140367129556304
	140367129544736 [label=AddBackward0]
	140367129556976 -> 140367129544736
	140367129556976 [label=AddBackward0]
	140367129550640 -> 140367129556976
	140367129550640 [label=AddBackward0]
	140367174287904 -> 140367129550640
	140367174287904 [label=NativeBatchNormBackward0]
	140367128236080 -> 140367174287904
	140367128236080 [label=ConvolutionBackward0]
	140367130008288 -> 140367128236080
	140367172412912 -> 140367128236080
	140367129572000 [label="stage4.1.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140367129572000 -> 140367172412912
	140367172412912 [label=AccumulateGrad]
	140367129555488 -> 140367174287904
	140367129571840 [label="stage4.1.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140367129571840 -> 140367129555488
	140367129555488 [label=AccumulateGrad]
	140367172412576 -> 140367174287904
	140367129572160 [label="stage4.1.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140367129572160 -> 140367172412576
	140367172412576 [label=AccumulateGrad]
	140367130006848 -> 140367129550640
	140367129543248 -> 140367129556976
	140367129543248 [label=UpsampleBilinear2DBackward0]
	140367172412432 -> 140367129543248
	140367172412432 [label=NativeBatchNormBackward0]
	140367129543584 -> 140367172412432
	140367129543584 [label=ConvolutionBackward0]
	140367130003248 -> 140367129543584
	140367127931840 -> 140367129543584
	140367129572560 [label="stage4.1.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140367129572560 -> 140367127931840
	140367127931840 [label=AccumulateGrad]
	140367128409136 -> 140367172412432
	140367129570640 [label="stage4.1.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140367129570640 -> 140367128409136
	140367128409136 [label=AccumulateGrad]
	140367128411680 -> 140367172412432
	140367129572320 [label="stage4.1.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140367129572320 -> 140367128411680
	140367128411680 [label=AccumulateGrad]
	140367129543392 -> 140367129544736
	140367129543392 [label=UpsampleBilinear2DBackward0]
	140367172412624 -> 140367129543392
	140367172412624 [label=NativeBatchNormBackward0]
	140367128407120 -> 140367172412624
	140367128407120 [label=ConvolutionBackward0]
	140367132249920 -> 140367128407120
	140367127613776 -> 140367128407120
	140367129569440 [label="stage4.1.fuse_layers.1.3.0.weight
 (36, 144, 1, 1)" fillcolor=lightblue]
	140367129569440 -> 140367127613776
	140367127613776 [label=AccumulateGrad]
	140367128410672 -> 140367172412624
	140367129569280 [label="stage4.1.fuse_layers.1.3.1.weight
 (36)" fillcolor=lightblue]
	140367129569280 -> 140367128410672
	140367128410672 [label=AccumulateGrad]
	140367128409088 -> 140367172412624
	140367129569680 [label="stage4.1.fuse_layers.1.3.1.bias
 (36)" fillcolor=lightblue]
	140367129569680 -> 140367128409088
	140367128409088 [label=AccumulateGrad]
	140367129543680 -> 140367129546416
	140367129497584 [label="stage4.2.branches.1.0.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367129497584 -> 140367129543680
	140367129543680 [label=AccumulateGrad]
	140367129546896 -> 140367129542864
	140367129497424 [label="stage4.2.branches.1.0.bn1.weight
 (36)" fillcolor=lightblue]
	140367129497424 -> 140367129546896
	140367129546896 [label=AccumulateGrad]
	140367129545696 -> 140367129542864
	140367129497824 [label="stage4.2.branches.1.0.bn1.bias
 (36)" fillcolor=lightblue]
	140367129497824 -> 140367129545696
	140367129545696 [label=AccumulateGrad]
	140367129542720 -> 140367129554480
	140367129496304 [label="stage4.2.branches.1.0.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367129496304 -> 140367129542720
	140367129542720 [label=AccumulateGrad]
	140367129555104 -> 140367129558512
	140367129495904 [label="stage4.2.branches.1.0.bn2.weight
 (36)" fillcolor=lightblue]
	140367129495904 -> 140367129555104
	140367129555104 [label=AccumulateGrad]
	140367129555152 -> 140367129558512
	140367129496064 [label="stage4.2.branches.1.0.bn2.bias
 (36)" fillcolor=lightblue]
	140367129496064 -> 140367129555152
	140367129555152 [label=AccumulateGrad]
	140367129556304 -> 140367151941184
	140367151950592 -> 140367129427632
	140367129494544 [label="stage4.2.branches.1.1.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367129494544 -> 140367151950592
	140367151950592 [label=AccumulateGrad]
	140367129423264 -> 140367129424080
	140367129494384 [label="stage4.2.branches.1.1.bn1.weight
 (36)" fillcolor=lightblue]
	140367129494384 -> 140367129423264
	140367129423264 [label=AccumulateGrad]
	140367151940608 -> 140367129424080
	140367129494784 [label="stage4.2.branches.1.1.bn1.bias
 (36)" fillcolor=lightblue]
	140367129494784 -> 140367151940608
	140367151940608 [label=AccumulateGrad]
	140367129422112 -> 140367129422208
	140367129508864 [label="stage4.2.branches.1.1.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367129508864 -> 140367129422112
	140367129422112 [label=AccumulateGrad]
	140367129421392 -> 140367129420768
	140367129508384 [label="stage4.2.branches.1.1.bn2.weight
 (36)" fillcolor=lightblue]
	140367129508384 -> 140367129421392
	140367129421392 [label=AccumulateGrad]
	140367129422256 -> 140367129420768
	140367129508624 [label="stage4.2.branches.1.1.bn2.bias
 (36)" fillcolor=lightblue]
	140367129508624 -> 140367129422256
	140367129422256 [label=AccumulateGrad]
	140367129421104 -> 140367129422448
	140367129419760 -> 140367129417744
	140367129504944 [label="stage4.2.branches.1.2.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367129504944 -> 140367129419760
	140367129419760 [label=AccumulateGrad]
	140367129420864 -> 140367129418416
	140367129504544 [label="stage4.2.branches.1.2.bn1.weight
 (36)" fillcolor=lightblue]
	140367129504544 -> 140367129420864
	140367129420864 [label=AccumulateGrad]
	140367129413712 -> 140367129418416
	140367129505344 [label="stage4.2.branches.1.2.bn1.bias
 (36)" fillcolor=lightblue]
	140367129505344 -> 140367129413712
	140367129413712 [label=AccumulateGrad]
	140367129412032 -> 140367354393552
	140367129501504 [label="stage4.2.branches.1.2.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367129501504 -> 140367129412032
	140367129412032 [label=AccumulateGrad]
	140367135097280 -> 140367132251024
	140367129501024 [label="stage4.2.branches.1.2.bn2.weight
 (36)" fillcolor=lightblue]
	140367129501024 -> 140367135097280
	140367135097280 [label=AccumulateGrad]
	140367151454416 -> 140367132251024
	140367129501264 [label="stage4.2.branches.1.2.bn2.bias
 (36)" fillcolor=lightblue]
	140367129501264 -> 140367151454416
	140367151454416 [label=AccumulateGrad]
	140367132247712 -> 140367130009728
	140367130009296 -> 140367130009248
	140367129497744 [label="stage4.2.branches.1.3.conv1.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367129497744 -> 140367130009296
	140367130009296 [label=AccumulateGrad]
	140367130010112 -> 140367130011552
	140367129497344 [label="stage4.2.branches.1.3.bn1.weight
 (36)" fillcolor=lightblue]
	140367129497344 -> 140367130010112
	140367130010112 [label=AccumulateGrad]
	140367130010400 -> 140367130011552
	140367129497984 [label="stage4.2.branches.1.3.bn1.bias
 (36)" fillcolor=lightblue]
	140367129497984 -> 140367130010400
	140367130010400 [label=AccumulateGrad]
	140367130012320 -> 140367130012992
	140367129494704 [label="stage4.2.branches.1.3.conv2.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367129494704 -> 140367130012320
	140367130012320 [label=AccumulateGrad]
	140367130007616 -> 140367130001712
	140367129493904 [label="stage4.2.branches.1.3.bn2.weight
 (36)" fillcolor=lightblue]
	140367129493904 -> 140367130007616
	140367130007616 [label=AccumulateGrad]
	140367130012368 -> 140367130001712
	140367129494304 [label="stage4.2.branches.1.3.bn2.bias
 (36)" fillcolor=lightblue]
	140367129494304 -> 140367130012368
	140367130012368 [label=AccumulateGrad]
	140367130014096 -> 140367130012848
	140367130014144 -> 140367130014480
	140367129376432 [label="stage4.2.fuse_layers.0.1.0.weight
 (18, 36, 1, 1)" fillcolor=lightblue]
	140367129376432 -> 140367130014144
	140367130014144 [label=AccumulateGrad]
	140367130014576 -> 140367130015248
	140367129376352 [label="stage4.2.fuse_layers.0.1.1.weight
 (18)" fillcolor=lightblue]
	140367129376352 -> 140367130014576
	140367130014576 [label=AccumulateGrad]
	140367130015632 -> 140367130015248
	140367129376512 [label="stage4.2.fuse_layers.0.1.1.bias
 (18)" fillcolor=lightblue]
	140367129376512 -> 140367130015632
	140367130015632 [label=AccumulateGrad]
	140367130015872 -> 140367130015680
	140367130015872 [label=UpsampleBilinear2DBackward0]
	140367130015200 -> 140367130015872
	140367130015200 [label=NativeBatchNormBackward0]
	140367130011120 -> 140367130015200
	140367130011120 [label=ConvolutionBackward0]
	140367130009776 -> 140367130011120
	140367130009776 [label=ReluBackward0]
	140367130007664 -> 140367130009776
	140367130007664 [label=AddBackward0]
	140367132248912 -> 140367130007664
	140367132248912 [label=NativeBatchNormBackward0]
	140367129414048 -> 140367132248912
	140367129414048 [label=ConvolutionBackward0]
	140367129419904 -> 140367129414048
	140367129419904 [label=ReluBackward0]
	140367129424272 -> 140367129419904
	140367129424272 [label=NativeBatchNormBackward0]
	140367151940896 -> 140367129424272
	140367151940896 [label=ConvolutionBackward0]
	140367130011264 -> 140367151940896
	140367130011264 [label=ReluBackward0]
	140367129543056 -> 140367130011264
	140367129543056 [label=AddBackward0]
	140367129544352 -> 140367129543056
	140367129544352 [label=NativeBatchNormBackward0]
	140367364901904 -> 140367129544352
	140367364901904 [label=ConvolutionBackward0]
	140367127612576 -> 140367364901904
	140367127612576 [label=ReluBackward0]
	140367144540848 -> 140367127612576
	140367144540848 [label=NativeBatchNormBackward0]
	140367168280928 -> 140367144540848
	140367168280928 [label=ConvolutionBackward0]
	140367129543728 -> 140367168280928
	140367129543728 [label=ReluBackward0]
	140367126608912 -> 140367129543728
	140367126608912 [label=AddBackward0]
	140367126608672 -> 140367126608912
	140367126608672 [label=NativeBatchNormBackward0]
	140367126608528 -> 140367126608672
	140367126608528 [label=ConvolutionBackward0]
	140367126608096 -> 140367126608528
	140367126608096 [label=ReluBackward0]
	140367126607952 -> 140367126608096
	140367126607952 [label=NativeBatchNormBackward0]
	140367126608192 -> 140367126607952
	140367126608192 [label=ConvolutionBackward0]
	140367126608480 -> 140367126608192
	140367126608480 [label=ReluBackward0]
	140367126607904 -> 140367126608480
	140367126607904 [label=AddBackward0]
	140367126607712 -> 140367126607904
	140367126607712 [label=NativeBatchNormBackward0]
	140367126607568 -> 140367126607712
	140367126607568 [label=ConvolutionBackward0]
	140367126607472 -> 140367126607568
	140367126607472 [label=ReluBackward0]
	140367126607328 -> 140367126607472
	140367126607328 [label=NativeBatchNormBackward0]
	140367126607136 -> 140367126607328
	140367126607136 [label=ConvolutionBackward0]
	140367126607088 -> 140367126607136
	140367126607088 [label=ReluBackward0]
	140367126606944 -> 140367126607088
	140367126606944 [label=AddBackward0]
	140367126606752 -> 140367126606944
	140367126606752 [label=AddBackward0]
	140367126606608 -> 140367126606752
	140367126606608 [label=AddBackward0]
	140367126606128 -> 140367126606608
	140367126606128 [label=NativeBatchNormBackward0]
	140367126605984 -> 140367126606128
	140367126605984 [label=ConvolutionBackward0]
	140367126606176 -> 140367126605984
	140367126606176 [label=ReluBackward0]
	140367126606032 -> 140367126606176
	140367126606032 [label=NativeBatchNormBackward0]
	140367126593600 -> 140367126606032
	140367126593600 [label=ConvolutionBackward0]
	140367130008288 -> 140367126593600
	140367126605744 -> 140367126593600
	140367129567760 [label="stage4.1.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367129567760 -> 140367126605744
	140367126605744 [label=AccumulateGrad]
	140367126606080 -> 140367126606032
	140367129567600 [label="stage4.1.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140367129567600 -> 140367126606080
	140367126606080 [label=AccumulateGrad]
	140367126606224 -> 140367126606032
	140367129567920 [label="stage4.1.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140367129567920 -> 140367126606224
	140367126606224 [label=AccumulateGrad]
	140367126605840 -> 140367126605984
	140367129567680 [label="stage4.1.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140367129567680 -> 140367126605840
	140367126605840 [label=AccumulateGrad]
	140367126606512 -> 140367126606128
	140367129566080 [label="stage4.1.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140367129566080 -> 140367126606512
	140367126606512 [label=AccumulateGrad]
	140367126606464 -> 140367126606128
	140367129566160 [label="stage4.1.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140367129566160 -> 140367126606464
	140367126606464 [label=AccumulateGrad]
	140367126606656 -> 140367126606608
	140367126606656 [label=NativeBatchNormBackward0]
	140367126605936 -> 140367126606656
	140367126605936 [label=ConvolutionBackward0]
	140367130006848 -> 140367126605936
	140367126594080 -> 140367126605936
	140367129564640 [label="stage4.1.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140367129564640 -> 140367126594080
	140367126594080 [label=AccumulateGrad]
	140367126605696 -> 140367126606656
	140367129564560 [label="stage4.1.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140367129564560 -> 140367126605696
	140367126605696 [label=AccumulateGrad]
	140367126606320 -> 140367126606656
	140367129564720 [label="stage4.1.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140367129564720 -> 140367126606320
	140367126606320 [label=AccumulateGrad]
	140367130003248 -> 140367126606752
	140367126606416 -> 140367126606944
	140367126606416 [label=UpsampleBilinear2DBackward0]
	140367126606368 -> 140367126606416
	140367126606368 [label=NativeBatchNormBackward0]
	140367126593696 -> 140367126606368
	140367126593696 [label=ConvolutionBackward0]
	140367132249920 -> 140367126593696
	140367126595040 -> 140367126593696
	140367129568320 [label="stage4.1.fuse_layers.2.3.0.weight
 (72, 144, 1, 1)" fillcolor=lightblue]
	140367129568320 -> 140367126595040
	140367126595040 [label=AccumulateGrad]
	140367126605888 -> 140367126606368
	140367129563200 [label="stage4.1.fuse_layers.2.3.1.weight
 (72)" fillcolor=lightblue]
	140367129563200 -> 140367126605888
	140367126605888 [label=AccumulateGrad]
	140367126606272 -> 140367126606368
	140367129568080 [label="stage4.1.fuse_layers.2.3.1.bias
 (72)" fillcolor=lightblue]
	140367129568080 -> 140367126606272
	140367126606272 [label=AccumulateGrad]
	140367126606560 -> 140367126607136
	140367129443088 [label="stage4.2.branches.2.0.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367129443088 -> 140367126606560
	140367126606560 [label=AccumulateGrad]
	140367126606848 -> 140367126607328
	140367129443008 [label="stage4.2.branches.2.0.bn1.weight
 (72)" fillcolor=lightblue]
	140367129443008 -> 140367126606848
	140367126606848 [label=AccumulateGrad]
	140367126606992 -> 140367126607328
	140367129443248 [label="stage4.2.branches.2.0.bn1.bias
 (72)" fillcolor=lightblue]
	140367129443248 -> 140367126606992
	140367126606992 [label=AccumulateGrad]
	140367126607424 -> 140367126607568
	140367129441728 [label="stage4.2.branches.2.0.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367129441728 -> 140367126607424
	140367126607424 [label=AccumulateGrad]
	140367126607376 -> 140367126607712
	140367129441488 [label="stage4.2.branches.2.0.bn2.weight
 (72)" fillcolor=lightblue]
	140367129441488 -> 140367126607376
	140367126607376 [label=AccumulateGrad]
	140367126607760 -> 140367126607712
	140367129441568 [label="stage4.2.branches.2.0.bn2.bias
 (72)" fillcolor=lightblue]
	140367129441568 -> 140367126607760
	140367126607760 [label=AccumulateGrad]
	140367126607088 -> 140367126607904
	140367126607520 -> 140367126608192
	140367129440048 [label="stage4.2.branches.2.1.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367129440048 -> 140367126607520
	140367126607520 [label=AccumulateGrad]
	140367126608144 -> 140367126607952
	140367129439968 [label="stage4.2.branches.2.1.bn1.weight
 (72)" fillcolor=lightblue]
	140367129439968 -> 140367126608144
	140367126608144 [label=AccumulateGrad]
	140367126608288 -> 140367126607952
	140367129440208 [label="stage4.2.branches.2.1.bn1.bias
 (72)" fillcolor=lightblue]
	140367129440208 -> 140367126608288
	140367126608288 [label=AccumulateGrad]
	140367126608432 -> 140367126608528
	140367129438688 [label="stage4.2.branches.2.1.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367129438688 -> 140367126608432
	140367126608432 [label=AccumulateGrad]
	140367126608384 -> 140367126608672
	140367129438448 [label="stage4.2.branches.2.1.bn2.weight
 (72)" fillcolor=lightblue]
	140367129438448 -> 140367126608384
	140367126608384 [label=AccumulateGrad]
	140367126608720 -> 140367126608672
	140367129438528 [label="stage4.2.branches.2.1.bn2.bias
 (72)" fillcolor=lightblue]
	140367129438528 -> 140367126608720
	140367126608720 [label=AccumulateGrad]
	140367126608480 -> 140367126608912
	140367126607664 -> 140367168280928
	140367129437008 [label="stage4.2.branches.2.2.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367129437008 -> 140367126607664
	140367126607664 [label=AccumulateGrad]
	140367168283664 -> 140367144540848
	140367129436928 [label="stage4.2.branches.2.2.bn1.weight
 (72)" fillcolor=lightblue]
	140367129436928 -> 140367168283664
	140367168283664 [label=AccumulateGrad]
	140367126605408 -> 140367144540848
	140367129437168 [label="stage4.2.branches.2.2.bn1.bias
 (72)" fillcolor=lightblue]
	140367129437168 -> 140367126605408
	140367126605408 [label=AccumulateGrad]
	140367144540704 -> 140367364901904
	140367129435648 [label="stage4.2.branches.2.2.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367129435648 -> 140367144540704
	140367144540704 [label=AccumulateGrad]
	140367129547952 -> 140367129544352
	140367129435408 [label="stage4.2.branches.2.2.bn2.weight
 (72)" fillcolor=lightblue]
	140367129435408 -> 140367129547952
	140367129547952 [label=AccumulateGrad]
	140367127610080 -> 140367129544352
	140367129435488 [label="stage4.2.branches.2.2.bn2.bias
 (72)" fillcolor=lightblue]
	140367129435488 -> 140367127610080
	140367127610080 [label=AccumulateGrad]
	140367129543728 -> 140367129543056
	140367129544592 -> 140367151940896
	140367129433968 [label="stage4.2.branches.2.3.conv1.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367129433968 -> 140367129544592
	140367129544592 [label=AccumulateGrad]
	140367151950352 -> 140367129424272
	140367129433888 [label="stage4.2.branches.2.3.bn1.weight
 (72)" fillcolor=lightblue]
	140367129433888 -> 140367151950352
	140367151950352 [label=AccumulateGrad]
	140367151940992 -> 140367129424272
	140367129434128 [label="stage4.2.branches.2.3.bn1.bias
 (72)" fillcolor=lightblue]
	140367129434128 -> 140367151940992
	140367151940992 [label=AccumulateGrad]
	140367129419088 -> 140367129414048
	140367129432608 [label="stage4.2.branches.2.3.conv2.weight
 (72, 72, 3, 3)" fillcolor=lightblue]
	140367129432608 -> 140367129419088
	140367129419088 [label=AccumulateGrad]
	140367129420720 -> 140367132248912
	140367129432368 [label="stage4.2.branches.2.3.bn2.weight
 (72)" fillcolor=lightblue]
	140367129432368 -> 140367129420720
	140367129420720 [label=AccumulateGrad]
	140367129412704 -> 140367132248912
	140367129432448 [label="stage4.2.branches.2.3.bn2.bias
 (72)" fillcolor=lightblue]
	140367129432448 -> 140367129412704
	140367129412704 [label=AccumulateGrad]
	140367130011264 -> 140367130007664
	140367130011504 -> 140367130011120
	140367129374912 [label="stage4.2.fuse_layers.0.2.0.weight
 (18, 72, 1, 1)" fillcolor=lightblue]
	140367129374912 -> 140367130011504
	140367130011504 [label=AccumulateGrad]
	140367130013856 -> 140367130015200
	140367129374832 [label="stage4.2.fuse_layers.0.2.1.weight
 (18)" fillcolor=lightblue]
	140367129374832 -> 140367130013856
	140367130013856 [label=AccumulateGrad]
	140367130015824 -> 140367130015200
	140367129374992 [label="stage4.2.fuse_layers.0.2.1.bias
 (18)" fillcolor=lightblue]
	140367129374992 -> 140367130015824
	140367130015824 [label=AccumulateGrad]
	140367130016160 -> 140367130016064
	140367130016160 [label=UpsampleBilinear2DBackward0]
	140367130014672 -> 140367130016160
	140367130014672 [label=NativeBatchNormBackward0]
	140367130010496 -> 140367130014672
	140367130010496 [label=ConvolutionBackward0]
	140367129423456 -> 140367130010496
	140367129423456 [label=ReluBackward0]
	140367129556496 -> 140367129423456
	140367129556496 [label=AddBackward0]
	140367127614064 -> 140367129556496
	140367127614064 [label=NativeBatchNormBackward0]
	140367168288560 -> 140367127614064
	140367168288560 [label=ConvolutionBackward0]
	140367126609008 -> 140367168288560
	140367126609008 [label=ReluBackward0]
	140367126608240 -> 140367126609008
	140367126608240 [label=NativeBatchNormBackward0]
	140367126607616 -> 140367126608240
	140367126607616 [label=ConvolutionBackward0]
	140367129543008 -> 140367126607616
	140367129543008 [label=ReluBackward0]
	140367126607184 -> 140367129543008
	140367126607184 [label=AddBackward0]
	140367126607040 -> 140367126607184
	140367126607040 [label=NativeBatchNormBackward0]
	140367126605792 -> 140367126607040
	140367126605792 [label=ConvolutionBackward0]
	140367126605120 -> 140367126605792
	140367126605120 [label=ReluBackward0]
	140367126595280 -> 140367126605120
	140367126595280 [label=NativeBatchNormBackward0]
	140367126594416 -> 140367126595280
	140367126594416 [label=ConvolutionBackward0]
	140367126606800 -> 140367126594416
	140367126606800 [label=ReluBackward0]
	140367126594944 -> 140367126606800
	140367126594944 [label=AddBackward0]
	140367126595568 -> 140367126594944
	140367126595568 [label=NativeBatchNormBackward0]
	140367126595616 -> 140367126595568
	140367126595616 [label=ConvolutionBackward0]
	140367126596384 -> 140367126595616
	140367126596384 [label=ReluBackward0]
	140367126596288 -> 140367126596384
	140367126596288 [label=NativeBatchNormBackward0]
	140367126596912 -> 140367126596288
	140367126596912 [label=ConvolutionBackward0]
	140367126596096 -> 140367126596912
	140367126596096 [label=ReluBackward0]
	140367126597584 -> 140367126596096
	140367126597584 [label=AddBackward0]
	140367126598640 -> 140367126597584
	140367126598640 [label=NativeBatchNormBackward0]
	140367126599072 -> 140367126598640
	140367126599072 [label=ConvolutionBackward0]
	140367126598448 -> 140367126599072
	140367126598448 [label=ReluBackward0]
	140367126598928 -> 140367126598448
	140367126598928 [label=NativeBatchNormBackward0]
	140367126599744 -> 140367126598928
	140367126599744 [label=ConvolutionBackward0]
	140367126597440 -> 140367126599744
	140367126597440 [label=ReluBackward0]
	140367126600656 -> 140367126597440
	140367126600656 [label=AddBackward0]
	140367126599648 -> 140367126600656
	140367126599648 [label=AddBackward0]
	140367126600272 -> 140367126599648
	140367126600272 [label=AddBackward0]
	140367126600464 -> 140367126600272
	140367126600464 [label=NativeBatchNormBackward0]
	140367126600944 -> 140367126600464
	140367126600944 [label=ConvolutionBackward0]
	140367126600992 -> 140367126600944
	140367126600992 [label=ReluBackward0]
	140367126604256 -> 140367126600992
	140367126604256 [label=NativeBatchNormBackward0]
	140367126601760 -> 140367126604256
	140367126601760 [label=ConvolutionBackward0]
	140367126602960 -> 140367126601760
	140367126602960 [label=ReluBackward0]
	140367126603392 -> 140367126602960
	140367126603392 [label=NativeBatchNormBackward0]
	140367126602624 -> 140367126603392
	140367126602624 [label=ConvolutionBackward0]
	140367130008288 -> 140367126602624
	140367126604064 -> 140367126602624
	140367129561680 [label="stage4.1.fuse_layers.3.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367129561680 -> 140367126604064
	140367126604064 [label=AccumulateGrad]
	140367126602768 -> 140367126603392
	140367129561520 [label="stage4.1.fuse_layers.3.0.0.1.weight
 (18)" fillcolor=lightblue]
	140367129561520 -> 140367126602768
	140367126602768 [label=AccumulateGrad]
	140367126602576 -> 140367126603392
	140367129561840 [label="stage4.1.fuse_layers.3.0.0.1.bias
 (18)" fillcolor=lightblue]
	140367129561840 -> 140367126602576
	140367126602576 [label=AccumulateGrad]
	140367126601952 -> 140367126601760
	140367129561600 [label="stage4.1.fuse_layers.3.0.1.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367129561600 -> 140367126601952
	140367126601952 [label=AccumulateGrad]
	140367126601904 -> 140367126604256
	140367129560000 [label="stage4.1.fuse_layers.3.0.1.1.weight
 (18)" fillcolor=lightblue]
	140367129560000 -> 140367126601904
	140367126601904 [label=AccumulateGrad]
	140367126602288 -> 140367126604256
	140367129560080 [label="stage4.1.fuse_layers.3.0.1.1.bias
 (18)" fillcolor=lightblue]
	140367129560080 -> 140367126602288
	140367126602288 [label=AccumulateGrad]
	140367126601136 -> 140367126600944
	140367129560160 [label="stage4.1.fuse_layers.3.0.2.0.weight
 (144, 18, 3, 3)" fillcolor=lightblue]
	140367129560160 -> 140367126601136
	140367126601136 [label=AccumulateGrad]
	140367126601616 -> 140367126600464
	140367129573440 [label="stage4.1.fuse_layers.3.0.2.1.weight
 (144)" fillcolor=lightblue]
	140367129573440 -> 140367126601616
	140367126601616 [label=AccumulateGrad]
	140367126600320 -> 140367126600464
	140367129573840 [label="stage4.1.fuse_layers.3.0.2.1.bias
 (144)" fillcolor=lightblue]
	140367129573840 -> 140367126600320
	140367126600320 [label=AccumulateGrad]
	140367126601328 -> 140367126600272
	140367126601328 [label=NativeBatchNormBackward0]
	140367126602432 -> 140367126601328
	140367126602432 [label=ConvolutionBackward0]
	140367126602144 -> 140367126602432
	140367126602144 [label=ReluBackward0]
	140367126603104 -> 140367126602144
	140367126603104 [label=NativeBatchNormBackward0]
	140367126604592 -> 140367126603104
	140367126604592 [label=ConvolutionBackward0]
	140367130006848 -> 140367126604592
	140367126604352 -> 140367126604592
	140367129569200 [label="stage4.1.fuse_layers.3.1.0.0.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367129569200 -> 140367126604352
	140367126604352 [label=AccumulateGrad]
	140367126603440 -> 140367126603104
	140367129568480 [label="stage4.1.fuse_layers.3.1.0.1.weight
 (36)" fillcolor=lightblue]
	140367129568480 -> 140367126603440
	140367126603440 [label=AccumulateGrad]
	140367126603584 -> 140367126603104
	140367129569600 [label="stage4.1.fuse_layers.3.1.0.1.bias
 (36)" fillcolor=lightblue]
	140367129569600 -> 140367126603584
	140367126603584 [label=AccumulateGrad]
	140367126603248 -> 140367126602432
	140367129574080 [label="stage4.1.fuse_layers.3.1.1.0.weight
 (144, 36, 3, 3)" fillcolor=lightblue]
	140367129574080 -> 140367126603248
	140367126603248 [label=AccumulateGrad]
	140367126601472 -> 140367126601328
	140367129564800 [label="stage4.1.fuse_layers.3.1.1.1.weight
 (144)" fillcolor=lightblue]
	140367129564800 -> 140367126601472
	140367126601472 [label=AccumulateGrad]
	140367126600800 -> 140367126601328
	140367129565200 [label="stage4.1.fuse_layers.3.1.1.1.bias
 (144)" fillcolor=lightblue]
	140367129565200 -> 140367126600800
	140367126600800 [label=AccumulateGrad]
	140367126601088 -> 140367126599648
	140367126601088 [label=NativeBatchNormBackward0]
	140367126603536 -> 140367126601088
	140367126603536 [label=ConvolutionBackward0]
	140367130003248 -> 140367126603536
	140367126604688 -> 140367126603536
	140367129561360 [label="stage4.1.fuse_layers.3.2.0.0.weight
 (144, 72, 3, 3)" fillcolor=lightblue]
	140367129561360 -> 140367126604688
	140367126604688 [label=AccumulateGrad]
	140367126601808 -> 140367126601088
	140367129561120 [label="stage4.1.fuse_layers.3.2.0.1.weight
 (144)" fillcolor=lightblue]
	140367129561120 -> 140367126601808
	140367126601808 [label=AccumulateGrad]
	140367126600128 -> 140367126601088
	140367129561760 [label="stage4.1.fuse_layers.3.2.0.1.bias
 (144)" fillcolor=lightblue]
	140367129561760 -> 140367126600128
	140367126600128 [label=AccumulateGrad]
	140367132249920 -> 140367126600656
	140367126599600 -> 140367126599744
	140367129430928 [label="stage4.2.branches.3.0.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367129430928 -> 140367126599600
	140367126599600 [label=AccumulateGrad]
	140367126598784 -> 140367126598928
	140367129430848 [label="stage4.2.branches.3.0.bn1.weight
 (144)" fillcolor=lightblue]
	140367129430848 -> 140367126598784
	140367126598784 [label=AccumulateGrad]
	140367126598304 -> 140367126598928
	140367129431088 [label="stage4.2.branches.3.0.bn1.bias
 (144)" fillcolor=lightblue]
	140367129431088 -> 140367126598304
	140367126598304 [label=AccumulateGrad]
	140367126599312 -> 140367126599072
	140367129429568 [label="stage4.2.branches.3.0.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367129429568 -> 140367126599312
	140367126599312 [label=AccumulateGrad]
	140367126597632 -> 140367126598640
	140367129429408 [label="stage4.2.branches.3.0.bn2.weight
 (144)" fillcolor=lightblue]
	140367129429408 -> 140367126597632
	140367126597632 [label=AccumulateGrad]
	140367126597776 -> 140367126598640
	140367129429488 [label="stage4.2.branches.3.0.bn2.bias
 (144)" fillcolor=lightblue]
	140367129429488 -> 140367126597776
	140367126597776 [label=AccumulateGrad]
	140367126597440 -> 140367126597584
	140367126596960 -> 140367126596912
	140367129428128 [label="stage4.2.branches.3.1.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367129428128 -> 140367126596960
	140367126596960 [label=AccumulateGrad]
	140367126597728 -> 140367126596288
	140367129428048 [label="stage4.2.branches.3.1.bn1.weight
 (144)" fillcolor=lightblue]
	140367129428048 -> 140367126597728
	140367126597728 [label=AccumulateGrad]
	140367126596240 -> 140367126596288
	140367129428208 [label="stage4.2.branches.3.1.bn1.bias
 (144)" fillcolor=lightblue]
	140367129428208 -> 140367126596240
	140367126596240 [label=AccumulateGrad]
	140367126597296 -> 140367126595616
	140367129441408 [label="stage4.2.branches.3.1.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367129441408 -> 140367126597296
	140367126597296 [label=AccumulateGrad]
	140367126596432 -> 140367126595568
	140367129440928 [label="stage4.2.branches.3.1.bn2.weight
 (144)" fillcolor=lightblue]
	140367129440928 -> 140367126596432
	140367126596432 [label=AccumulateGrad]
	140367126595424 -> 140367126595568
	140367129441168 [label="stage4.2.branches.3.1.bn2.bias
 (144)" fillcolor=lightblue]
	140367129441168 -> 140367126595424
	140367126595424 [label=AccumulateGrad]
	140367126596096 -> 140367126594944
	140367126595760 -> 140367126594416
	140367129437488 [label="stage4.2.branches.3.2.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367129437488 -> 140367126595760
	140367126595760 [label=AccumulateGrad]
	140367126594608 -> 140367126595280
	140367129437088 [label="stage4.2.branches.3.2.bn1.weight
 (144)" fillcolor=lightblue]
	140367129437088 -> 140367126594608
	140367126594608 [label=AccumulateGrad]
	140367126594368 -> 140367126595280
	140367129437888 [label="stage4.2.branches.3.2.bn1.bias
 (144)" fillcolor=lightblue]
	140367129437888 -> 140367126594368
	140367126594368 [label=AccumulateGrad]
	140367126593936 -> 140367126605792
	140367129434048 [label="stage4.2.branches.3.2.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367129434048 -> 140367126593936
	140367126593936 [label=AccumulateGrad]
	140367126594272 -> 140367126607040
	140367129433568 [label="stage4.2.branches.3.2.bn2.weight
 (144)" fillcolor=lightblue]
	140367129433568 -> 140367126594272
	140367126594272 [label=AccumulateGrad]
	140367126606704 -> 140367126607040
	140367129433808 [label="stage4.2.branches.3.2.bn2.bias
 (144)" fillcolor=lightblue]
	140367129433808 -> 140367126606704
	140367126606704 [label=AccumulateGrad]
	140367126606800 -> 140367126607184
	140367126606896 -> 140367126607616
	140367129430288 [label="stage4.2.branches.3.3.conv1.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367129430288 -> 140367126606896
	140367126606896 [label=AccumulateGrad]
	140367126607808 -> 140367126608240
	140367129429888 [label="stage4.2.branches.3.3.bn1.weight
 (144)" fillcolor=lightblue]
	140367129429888 -> 140367126607808
	140367126607808 [label=AccumulateGrad]
	140367126608336 -> 140367126608240
	140367129430528 [label="stage4.2.branches.3.3.bn1.bias
 (144)" fillcolor=lightblue]
	140367129430528 -> 140367126608336
	140367126608336 [label=AccumulateGrad]
	140367126609056 -> 140367168288560
	140367129377872 [label="stage4.2.branches.3.3.conv2.weight
 (144, 144, 3, 3)" fillcolor=lightblue]
	140367129377872 -> 140367126609056
	140367126609056 [label=AccumulateGrad]
	140367144540224 -> 140367127614064
	140367129377712 [label="stage4.2.branches.3.3.bn2.weight
 (144)" fillcolor=lightblue]
	140367129377712 -> 140367144540224
	140367144540224 [label=AccumulateGrad]
	140367126608864 -> 140367127614064
	140367129377792 [label="stage4.2.branches.3.3.bn2.bias
 (144)" fillcolor=lightblue]
	140367129377792 -> 140367126608864
	140367126608864 [label=AccumulateGrad]
	140367129543008 -> 140367129556496
	140367129424224 -> 140367130010496
	140367129373552 [label="stage4.2.fuse_layers.0.3.0.weight
 (18, 144, 1, 1)" fillcolor=lightblue]
	140367129373552 -> 140367129424224
	140367129424224 [label=AccumulateGrad]
	140367130014624 -> 140367130014672
	140367129373472 [label="stage4.2.fuse_layers.0.3.1.weight
 (18)" fillcolor=lightblue]
	140367129373472 -> 140367130014624
	140367130014624 [label=AccumulateGrad]
	140367130016928 -> 140367130014672
	140367129373632 [label="stage4.2.fuse_layers.0.3.1.bias
 (18)" fillcolor=lightblue]
	140367129373632 -> 140367130016928
	140367130016928 [label=AccumulateGrad]
	140367130016832 -> 140367130016496
	140367130016832 [label=UpsampleBilinear2DBackward0]
	140367130015344 -> 140367130016832
	140367130015344 [label=ReluBackward0]
	140367129413184 -> 140367130015344
	140367129413184 [label=AddBackward0]
	140367129553664 -> 140367129413184
	140367129553664 [label=AddBackward0]
	140367126607232 -> 140367129553664
	140367126607232 [label=AddBackward0]
	140367126593744 -> 140367126607232
	140367126593744 [label=NativeBatchNormBackward0]
	140367126608000 -> 140367126593744
	140367126608000 [label=ConvolutionBackward0]
	140367130015728 -> 140367126608000
	140367126595712 -> 140367126608000
	140367129371792 [label="stage4.2.fuse_layers.1.0.0.0.weight
 (36, 18, 3, 3)" fillcolor=lightblue]
	140367129371792 -> 140367126595712
	140367126595712 [label=AccumulateGrad]
	140367126607280 -> 140367126593744
	140367129371632 [label="stage4.2.fuse_layers.1.0.0.1.weight
 (36)" fillcolor=lightblue]
	140367129371632 -> 140367126607280
	140367126607280 [label=AccumulateGrad]
	140367126608576 -> 140367126593744
	140367129371952 [label="stage4.2.fuse_layers.1.0.0.1.bias
 (36)" fillcolor=lightblue]
	140367129371952 -> 140367126608576
	140367126608576 [label=AccumulateGrad]
	140367130014288 -> 140367126607232
	140367126607856 -> 140367129553664
	140367126607856 [label=UpsampleBilinear2DBackward0]
	140367126595088 -> 140367126607856
	140367126595088 [label=NativeBatchNormBackward0]
	140367126605024 -> 140367126595088
	140367126605024 [label=ConvolutionBackward0]
	140367130009776 -> 140367126605024
	140367126598400 -> 140367126605024
	140367129372112 [label="stage4.2.fuse_layers.1.2.0.weight
 (36, 72, 1, 1)" fillcolor=lightblue]
	140367129372112 -> 140367126598400
	140367126598400 [label=AccumulateGrad]
	140367126594752 -> 140367126595088
	140367129370352 [label="stage4.2.fuse_layers.1.2.1.weight
 (36)" fillcolor=lightblue]
	140367129370352 -> 140367126594752
	140367126594752 [label=AccumulateGrad]
	140367126608048 -> 140367126595088
	140367129372032 [label="stage4.2.fuse_layers.1.2.1.bias
 (36)" fillcolor=lightblue]
	140367129372032 -> 140367126608048
	140367126608048 [label=AccumulateGrad]
	140367129557648 -> 140367129413184
	140367129557648 [label=UpsampleBilinear2DBackward0]
	140367126596624 -> 140367129557648
	140367126596624 [label=NativeBatchNormBackward0]
	140367126596768 -> 140367126596624
	140367126596768 [label=ConvolutionBackward0]
	140367129423456 -> 140367126596768
	140367126597104 -> 140367126596768
	140367129368992 [label="stage4.2.fuse_layers.1.3.0.weight
 (36, 144, 1, 1)" fillcolor=lightblue]
	140367129368992 -> 140367126597104
	140367126597104 [label=AccumulateGrad]
	140367126594896 -> 140367126596624
	140367129368912 [label="stage4.2.fuse_layers.1.3.1.weight
 (36)" fillcolor=lightblue]
	140367129368912 -> 140367126594896
	140367126594896 [label=AccumulateGrad]
	140367126605648 -> 140367126596624
	140367129369072 [label="stage4.2.fuse_layers.1.3.1.bias
 (36)" fillcolor=lightblue]
	140367129369072 -> 140367126605648
	140367126605648 [label=AccumulateGrad]
	140367130016016 -> 140367130016496
	140367130016016 [label=UpsampleBilinear2DBackward0]
	140367130015392 -> 140367130016016
	140367130015392 [label=ReluBackward0]
	140367129418704 -> 140367130015392
	140367129418704 [label=AddBackward0]
	140367126599984 -> 140367129418704
	140367126599984 [label=AddBackward0]
	140367126599456 -> 140367126599984
	140367126599456 [label=AddBackward0]
	140367126599120 -> 140367126599456
	140367126599120 [label=NativeBatchNormBackward0]
	140367126599792 -> 140367126599120
	140367126599792 [label=ConvolutionBackward0]
	140367126603920 -> 140367126599792
	140367126603920 [label=ReluBackward0]
	140367126604400 -> 140367126603920
	140367126604400 [label=NativeBatchNormBackward0]
	140367126604640 -> 140367126604400
	140367126604640 [label=ConvolutionBackward0]
	140367130015728 -> 140367126604640
	140367126604880 -> 140367126604640
	140367129367312 [label="stage4.2.fuse_layers.2.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367129367312 -> 140367126604880
	140367126604880 [label=AccumulateGrad]
	140367126604832 -> 140367126604400
	140367129367072 [label="stage4.2.fuse_layers.2.0.0.1.weight
 (18)" fillcolor=lightblue]
	140367129367072 -> 140367126604832
	140367126604832 [label=AccumulateGrad]
	140367126604496 -> 140367126604400
	140367129367392 [label="stage4.2.fuse_layers.2.0.0.1.bias
 (18)" fillcolor=lightblue]
	140367129367392 -> 140367126604496
	140367126604496 [label=AccumulateGrad]
	140367126604208 -> 140367126599792
	140367129367152 [label="stage4.2.fuse_layers.2.0.1.0.weight
 (72, 18, 3, 3)" fillcolor=lightblue]
	140367129367152 -> 140367126604208
	140367126604208 [label=AccumulateGrad]
	140367126600416 -> 140367126599120
	140367129365552 [label="stage4.2.fuse_layers.2.0.1.1.weight
 (72)" fillcolor=lightblue]
	140367129365552 -> 140367126600416
	140367126600416 [label=AccumulateGrad]
	140367126598976 -> 140367126599120
	140367129365632 [label="stage4.2.fuse_layers.2.0.1.1.bias
 (72)" fillcolor=lightblue]
	140367129365632 -> 140367126598976
	140367126598976 [label=AccumulateGrad]
	140367126598112 -> 140367126599456
	140367126598112 [label=NativeBatchNormBackward0]
	140367126604736 -> 140367126598112
	140367126604736 [label=ConvolutionBackward0]
	140367130014288 -> 140367126604736
	140367126604928 -> 140367126604736
	140367129364112 [label="stage4.2.fuse_layers.2.1.0.0.weight
 (72, 36, 3, 3)" fillcolor=lightblue]
	140367129364112 -> 140367126604928
	140367126604928 [label=AccumulateGrad]
	140367126604544 -> 140367126598112
	140367129364032 [label="stage4.2.fuse_layers.2.1.0.1.weight
 (72)" fillcolor=lightblue]
	140367129364032 -> 140367126604544
	140367126604544 [label=AccumulateGrad]
	140367126603776 -> 140367126598112
	140367129364272 [label="stage4.2.fuse_layers.2.1.0.1.bias
 (72)" fillcolor=lightblue]
	140367129364272 -> 140367126603776
	140367126603776 [label=AccumulateGrad]
	140367130009776 -> 140367126599984
	140367126595952 -> 140367129418704
	140367126595952 [label=UpsampleBilinear2DBackward0]
	140367126602720 -> 140367126595952
	140367126602720 [label=NativeBatchNormBackward0]
	140367126608624 -> 140367126602720
	140367126608624 [label=ConvolutionBackward0]
	140367129423456 -> 140367126608624
	140367126608960 -> 140367126608624
	140367129367552 [label="stage4.2.fuse_layers.2.3.0.weight
 (72, 144, 1, 1)" fillcolor=lightblue]
	140367129367552 -> 140367126608960
	140367126608960 [label=AccumulateGrad]
	140367126604784 -> 140367126602720
	140367129362752 [label="stage4.2.fuse_layers.2.3.1.weight
 (72)" fillcolor=lightblue]
	140367129362752 -> 140367126604784
	140367126604784 [label=AccumulateGrad]
	140367126597968 -> 140367126602720
	140367129367472 [label="stage4.2.fuse_layers.2.3.1.bias
 (72)" fillcolor=lightblue]
	140367129367472 -> 140367126597968
	140367126597968 [label=AccumulateGrad]
	140367130016112 -> 140367130016496
	140367130016112 [label=UpsampleBilinear2DBackward0]
	140367130015920 -> 140367130016112
	140367130015920 [label=ReluBackward0]
	140367126608768 -> 140367130015920
	140367126608768 [label=AddBackward0]
	140367126609152 -> 140367126608768
	140367126609152 [label=AddBackward0]
	140367126609104 -> 140367126609152
	140367126609104 [label=AddBackward0]
	140367126609296 -> 140367126609104
	140367126609296 [label=NativeBatchNormBackward0]
	140367126609440 -> 140367126609296
	140367126609440 [label=ConvolutionBackward0]
	140367126609632 -> 140367126609440
	140367126609632 [label=ReluBackward0]
	140367126609776 -> 140367126609632
	140367126609776 [label=NativeBatchNormBackward0]
	140367126609872 -> 140367126609776
	140367126609872 [label=ConvolutionBackward0]
	140367127347408 -> 140367126609872
	140367127347408 [label=ReluBackward0]
	140367127347552 -> 140367127347408
	140367127347552 [label=NativeBatchNormBackward0]
	140367127347648 -> 140367127347552
	140367127347648 [label=ConvolutionBackward0]
	140367130015728 -> 140367127347648
	140367127347840 -> 140367127347648
	140367129375472 [label="stage4.2.fuse_layers.3.0.0.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367129375472 -> 140367127347840
	140367127347840 [label=AccumulateGrad]
	140367127347600 -> 140367127347552
	140367129374352 [label="stage4.2.fuse_layers.3.0.0.1.weight
 (18)" fillcolor=lightblue]
	140367129374352 -> 140367127347600
	140367127347600 [label=AccumulateGrad]
	140367127347456 -> 140367127347552
	140367129375712 [label="stage4.2.fuse_layers.3.0.0.1.bias
 (18)" fillcolor=lightblue]
	140367129375712 -> 140367127347456
	140367127347456 [label=AccumulateGrad]
	140367127347360 -> 140367126609872
	140367129375072 [label="stage4.2.fuse_layers.3.0.1.0.weight
 (18, 18, 3, 3)" fillcolor=lightblue]
	140367129375072 -> 140367127347360
	140367127347360 [label=AccumulateGrad]
	140367126609824 -> 140367126609776
	140367129370672 [label="stage4.2.fuse_layers.3.0.1.1.weight
 (18)" fillcolor=lightblue]
	140367129370672 -> 140367126609824
	140367126609824 [label=AccumulateGrad]
	140367126609680 -> 140367126609776
	140367129371072 [label="stage4.2.fuse_layers.3.0.1.1.bias
 (18)" fillcolor=lightblue]
	140367129371072 -> 140367126609680
	140367126609680 [label=AccumulateGrad]
	140367126609584 -> 140367126609440
	140367129371312 [label="stage4.2.fuse_layers.3.0.2.0.weight
 (144, 18, 3, 3)" fillcolor=lightblue]
	140367129371312 -> 140367126609584
	140367126609584 [label=AccumulateGrad]
	140367126609392 -> 140367126609296
	140367129366992 [label="stage4.2.fuse_layers.3.0.2.1.weight
 (144)" fillcolor=lightblue]
	140367129366992 -> 140367126609392
	140367126609392 [label=AccumulateGrad]
	140367126609344 -> 140367126609296
	140367129367232 [label="stage4.2.fuse_layers.3.0.2.1.bias
 (144)" fillcolor=lightblue]
	140367129367232 -> 140367126609344
	140367126609344 [label=AccumulateGrad]
	140367126609248 -> 140367126609104
	140367126609248 [label=NativeBatchNormBackward0]
	140367126609728 -> 140367126609248
	140367126609728 [label=ConvolutionBackward0]
	140367127347312 -> 140367126609728
	140367127347312 [label=ReluBackward0]
	140367127347792 -> 140367127347312
	140367127347792 [label=NativeBatchNormBackward0]
	140367127347984 -> 140367127347792
	140367127347984 [label=ConvolutionBackward0]
	140367130014288 -> 140367127347984
	140367127348176 -> 140367127347984
	140367129363712 [label="stage4.2.fuse_layers.3.1.0.0.weight
 (36, 36, 3, 3)" fillcolor=lightblue]
	140367129363712 -> 140367127348176
	140367127348176 [label=AccumulateGrad]
	140367127347888 -> 140367127347792
	140367129363472 [label="stage4.2.fuse_layers.3.1.0.1.weight
 (36)" fillcolor=lightblue]
	140367129363472 -> 140367127347888
	140367127347888 [label=AccumulateGrad]
	140367127347696 -> 140367127347792
	140367129363952 [label="stage4.2.fuse_layers.3.1.0.1.bias
 (36)" fillcolor=lightblue]
	140367129363952 -> 140367127347696
	140367127347696 [label=AccumulateGrad]
	140367127347744 -> 140367126609728
	140367129312176 [label="stage4.2.fuse_layers.3.1.1.0.weight
 (144, 36, 3, 3)" fillcolor=lightblue]
	140367129312176 -> 140367127347744
	140367127347744 [label=AccumulateGrad]
	140367126609536 -> 140367126609248
	140367129312016 [label="stage4.2.fuse_layers.3.1.1.1.weight
 (144)" fillcolor=lightblue]
	140367129312016 -> 140367126609536
	140367126609536 [label=AccumulateGrad]
	140367126609488 -> 140367126609248
	140367129312096 [label="stage4.2.fuse_layers.3.1.1.1.bias
 (144)" fillcolor=lightblue]
	140367129312096 -> 140367126609488
	140367126609488 [label=AccumulateGrad]
	140367126608816 -> 140367126609152
	140367126608816 [label=NativeBatchNormBackward0]
	140367126609200 -> 140367126608816
	140367126609200 [label=ConvolutionBackward0]
	140367130009776 -> 140367126609200
	140367127348272 -> 140367126609200
	140367129310576 [label="stage4.2.fuse_layers.3.2.0.0.weight
 (144, 72, 3, 3)" fillcolor=lightblue]
	140367129310576 -> 140367127348272
	140367127348272 [label=AccumulateGrad]
	140367127347936 -> 140367126608816
	140367129310496 [label="stage4.2.fuse_layers.3.2.0.1.weight
 (144)" fillcolor=lightblue]
	140367129310496 -> 140367127347936
	140367127347936 [label=AccumulateGrad]
	140367127347504 -> 140367126608816
	140367129310656 [label="stage4.2.fuse_layers.3.2.0.1.bias
 (144)" fillcolor=lightblue]
	140367129310656 -> 140367127347504
	140367127347504 [label=AccumulateGrad]
	140367129423456 -> 140367126608768
	140367130016544 -> 140367130016880
	140367126525296 [label="head.0.weight
 (270, 270, 1, 1)" fillcolor=lightblue]
	140367126525296 -> 140367130016544
	140367130016544 [label=AccumulateGrad]
	140367130016256 -> 140367130016880
	140367126525456 [label="head.0.bias
 (270)" fillcolor=lightblue]
	140367126525456 -> 140367130016256
	140367130016256 [label=AccumulateGrad]
	140367130016640 -> 140367433701152
	140367126524256 [label="head.1.weight
 (270)" fillcolor=lightblue]
	140367126524256 -> 140367130016640
	140367130016640 [label=AccumulateGrad]
	140367130016688 -> 140367433701152
	140367128541488 [label="head.1.bias
 (270)" fillcolor=lightblue]
	140367128541488 -> 140367130016688
	140367130016688 [label=AccumulateGrad]
	140367130017168 -> 140367130017120
	140367129376192 [label="head.3.weight
 (9, 270, 1, 1)" fillcolor=lightblue]
	140367129376192 -> 140367130017168
	140367130017168 [label=AccumulateGrad]
	140367130015968 -> 140367130017120
	140367129367632 [label="head.3.bias
 (9)" fillcolor=lightblue]
	140367129367632 -> 140367130015968
	140367130015968 [label=AccumulateGrad]
	140367130017120 -> 140367129939872
}
